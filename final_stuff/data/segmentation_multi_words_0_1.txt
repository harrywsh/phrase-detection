dual recurrent attention units for <phrase>visual question answering</phrase>
we propose an architecture for vqa which utilizes recurrent layers <phrase>to generate</phrase> visual and textual attention. the memory characteristic of <phrase>the proposed</phrase> recurrent attention units offers a rich joint embedding of visual and textual features and enables <phrase>the model</phrase> to reason <phrase>relations between</phrase> several <phrase>parts of</phrase> the image and question. our single <phrase>model outperforms</phrase> the first place winner on the vqa 1.0 dataset performs within margin to <phrase>the current state of</phrase> <phrase>the art</phrase> ensemble model. we also experiment with replacing attention mechanisms in other <phrase>state of</phrase> <phrase>the art</phrase> models with our implementation and show increased accuracy. in both cases our recurrent <phrase>attention mechanism</phrase> improves performance in tasks requiring sequential or relational reasoning on the vqa dataset.
sequential short <phrase>text classification</phrase> with recurrent and <phrase>convolutional neural networks</phrase>
recent approaches <phrase>based on</phrase> <phrase>artificial neural networks</phrase> anns have shown <phrase>promising results</phrase> for short <phrase>text classification</phrase>. however many short texts occur in sequences e.g. sentences in a document or utterances in a dialog and most existing ann based systems <phrase>do not</phrase> leverage the preceding short texts when classifying a subsequent one. in <phrase>this work</phrase> we present a <phrase>model based</phrase> on <phrase>recurrent neural networks</phrase> and <phrase>convolutional neural networks</phrase> that incorporates the preceding short texts. our <phrase>model achieves</phrase> <phrase>state of</phrase> <phrase>the art results</phrase> on <phrase>three different</phrase> datasets for dialog act prediction.
multiresolution <phrase>recurrent neural networks</phrase> an <phrase>application to</phrase> dialogue <phrase>response generation</phrase>
we introduce the multiresolution <phrase>recurrent neural network</phrase> which extends the <phrase>sequence to sequence</phrase> framework to model <phrase>natural language</phrase> generation as two parallel discrete <phrase>stochastic processes</phrase> a sequence of <phrase>high level</phrase> coarse tokens and a sequence of <phrase>natural language</phrase> tokens. there are many ways to estimate or learn the <phrase>high level</phrase> coarse tokens but we argue that <phrase>a simple</phrase> extraction procedure is sufficient <phrase>to capture</phrase> a wealth of <phrase>high level</phrase> discourse semantics. such procedure allows training the multiresolution <phrase>recurrent neural network</phrase> by maximizing the exact joint log likelihood over both sequences. <phrase>in contrast to</phrase> the standard log likelihood objective w.r.t. <phrase>natural language</phrase> tokens word perplexity optimizing the joint log likelihood biases <phrase>the model</phrase> towards modeling <phrase>high level</phrase> abstractions. we apply <phrase>the proposed</phrase> model to <phrase>the task of</phrase> dialogue <phrase>response generation</phrase> in two challenging domains the ubuntu technical support domain and twitter conversations. on ubuntu <phrase>the model</phrase> outperforms competing approaches by a substantial margin achieving <phrase>state of</phrase> <phrase>the art</phrase> results <phrase>according to</phrase> both automatic <phrase>evaluation metrics</phrase> and a human evaluation study. on twitter <phrase>the model</phrase> appears <phrase>to generate</phrase> more relevant and on topic responses <phrase>according to</phrase> automatic <phrase>evaluation metrics</phrase>. finally our <phrase>experiments demonstrate</phrase> that <phrase>the proposed</phrase> model is more adept at overcoming the sparsity of <phrase>natural language</phrase> and is better <phrase>able to</phrase> capture <phrase>long term</phrase> structure.
learning what to share between loosely related tasks
<phrase>multi task learning</phrase> is <phrase>motivated by</phrase> the observation that humans bring to bear what they know about related problems when solving new ones. similarly <phrase>deep neural networks</phrase> can profit from related tasks by sharing parameters with other networks. however humans <phrase>do not</phrase> consciously decide to transfer knowledge between tasks. in <phrase>natural language</phrase> processing nlp it is hard <phrase>to predict</phrase> if sharing will <phrase>lead to</phrase> improvements particularly if tasks are only loosely related. <phrase>to overcome</phrase> this we introduce sluice networks a general <phrase>framework for</phrase> <phrase>multi task learning</phrase> where trainable parameters control the <phrase>amount of</phrase> sharing. our framework generalizes previous proposals in enabling sharing of all combinations of subspaces layers and skip connections. we perform <phrase>experiments on</phrase> three task pairs and across seven different domains using data from ontonotes 5.0 and achieve up to 15 average error reductions over common approaches to <phrase>multi task learning</phrase>. we show that a label entropy is predictive of gains in sluice networks confirming findings for hard parameter sharing and b while sluice networks easily fit noise they are robust across domains <phrase>in practice</phrase>.
a <phrase>deep reinforcement learning</phrase> chatbot
we present milabot a <phrase>deep reinforcement learning</phrase> chatbot developed by the montreal institute for <phrase>learning algorithms</phrase> mila for the amazon alexa prize competition. milabot is <phrase>capable of</phrase> conversing with humans on popular small talk topics through both speech and text. the system <phrase>consists of</phrase> an ensemble of <phrase>natural language</phrase> generation and retrieval models including template based models bag of words models <phrase>sequence to sequence</phrase> <phrase>neural network</phrase> and <phrase>latent variable</phrase> <phrase>neural network</phrase> models. by applying <phrase>reinforcement learning</phrase> to crowdsourced data and <phrase>real world</phrase> user interactions the system has been trained <phrase>to select</phrase> an appropriate response from the models in its ensemble. the system has been evaluated through <phrase>a b testing</phrase> with <phrase>real world</phrase> users where it performed significantly <phrase>better than</phrase> many competing systems. <phrase>due to</phrase> its <phrase>machine learning</phrase> architecture the system is likely <phrase>to improve</phrase> with additional data.
generating sentences by editing prototypes
we propose <phrase>a new</phrase> <phrase>generative model</phrase> of sentences that first samples a prototype sentence from the training corpus and then edits it into <phrase>a new</phrase> sentence. <phrase>compared to</phrase> traditional models that generate <phrase>from scratch</phrase> either left to right or by first sampling a latent sentence vector our prototype then edit model improves perplexity on <phrase>language modeling</phrase> and generates higher quality outputs <phrase>according to</phrase> human evaluation. furthermore <phrase>the model</phrase> gives rise to a latent edit vector that captures interpretable semantics <phrase>such as</phrase> sentence similarity and <phrase>sentence level</phrase> analogies.
a <phrase>deep reinforcement learning</phrase> chatbot short version 
we present milabot a <phrase>deep reinforcement learning</phrase> chatbot developed by the montreal institute for <phrase>learning algorithms</phrase> mila for the amazon alexa prize competition. milabot is <phrase>capable of</phrase> conversing with humans on popular small talk topics through both speech and text. the system <phrase>consists of</phrase> an ensemble of <phrase>natural language</phrase> generation and retrieval models including <phrase>neural network</phrase> and template based models. by applying <phrase>reinforcement learning</phrase> to crowdsourced data and <phrase>real world</phrase> user interactions the system has been trained <phrase>to select</phrase> an appropriate response from the models in its ensemble. the system has been evaluated through <phrase>a b testing</phrase> with <phrase>real world</phrase> users where it performed significantly <phrase>better than</phrase> other systems. the results highlight the potential of coupling ensemble systems with <phrase>deep reinforcement learning</phrase> as a fruitful path for developing <phrase>real world</phrase> <phrase>open domain</phrase> conversational agents.
document image coding and clustering for script discrimination
the <phrase>paper introduces</phrase> <phrase>a new</phrase> <phrase>method for</phrase> discrimination of documents given in different scripts. the document is mapped into a uniformly coded text of numerical values. it is <phrase>derived from</phrase> the position of the letters in the text line <phrase>based on</phrase> their typographical characteristics. each code is considered as a gray level. accordingly the coded text determines a 1 d image on which texture analysis by run length statistics and local binary pattern is performed. it defines feature vectors representing the script content of the document. a modified clustering approach employed on document feature vector groups documents written in <phrase>the same</phrase> script. experimentation performed on two custom oriented databases of historical documents in old cyrillic angular and round glagolitic <phrase>as well as</phrase> antiqua and fraktur scripts demonstrates the superiority of <phrase>the proposed</phrase> method <phrase>with respect to</phrase> <phrase>well known</phrase> methods in the <phrase>state of</phrase> <phrase>the art</phrase>.
tutorial on answering <phrase>questions about</phrase> images with <phrase>deep learning</phrase>
together with the development of <phrase>more accurate</phrase> methods <phrase>in computer vision</phrase> and <phrase>natural language</phrase> understanding holistic architectures that answer on <phrase>questions about</phrase> the content of <phrase>real world</phrase> images have emerged. in this tutorial we build a neural <phrase>based approach</phrase> to answer <phrase>questions about</phrase> images. we base our tutorial on two datasets mostly on daquar and a bit on vqa. with small tweaks the models that we present here can achieve a competitive <phrase>performance on</phrase> both datasets in fact they are among <phrase>the best</phrase> methods that use a <phrase>combination of</phrase> lstm with a global full frame cnn representation of <phrase>an image</phrase>. we hope that after reading this tutorial the reader will be <phrase>able to</phrase> use <phrase>deep learning</phrase> frameworks <phrase>such as</phrase> keras and introduced kraino to build various architectures that will <phrase>lead to</phrase> a further <phrase>performance improvement</phrase> on this <phrase>challenging task</phrase>.
pix2code generating code from a <phrase>graphical user interface</phrase> screenshot
transforming a <phrase>graphical user interface</phrase> screenshot created by a designer into computer code is a typical task conducted by a developer <phrase>in order to</phrase> build customized software websites and mobile applications. in <phrase>this paper</phrase> we show that <phrase>deep learning</phrase> methods can be leveraged <phrase>to train</phrase> a model <phrase>end to end</phrase> to automatically generate code from <phrase>a single</phrase> input image with over 77 of accuracy for <phrase>three different</phrase> platforms i.e. ios android and web based technologies .
<phrase>a unified</phrase> <phrase>deep neural network</phrase> for speaker and language recognition
learned <phrase>feature representations</phrase> and sub phoneme posteriors from <phrase>deep neural networks</phrase> dnns have been used separately <phrase>to produce</phrase> significant performance gains for speaker and language <phrase>recognition tasks</phrase>. in <phrase>this work</phrase> we show how these gains are possible using <phrase>a single</phrase> dnn for both speaker and language recognition. the unified dnn approach is <phrase>shown to</phrase> yield substantial performance improvements on the the 2013 <phrase>domain adaptation</phrase> challenge <phrase>speaker recognition</phrase> task 55 <phrase>reduction in</phrase> eer for the out of domain condition and on the nist 2011 language recognition evaluation 48 <phrase>reduction in</phrase> eer for the 30s test condition .
efficient neural architecture search via parameter sharing
we propose efficient neural architecture search enas a fast and inexpensive approach for automatic model design. in enas a controller learns <phrase>to discover</phrase> <phrase>neural network</phrase> architectures by searching for an optimal subgraph within <phrase>a large</phrase> computational graph. the controller is trained with policy gradient <phrase>to select</phrase> a subgraph that maximizes the expected reward on the validation set. meanwhile <phrase>the model</phrase> corresponding to the selected subgraph is trained to minimize a canonical <phrase>cross entropy</phrase> loss. thanks to parameter sharing between child models enas is fast it delivers strong empirical performances using much fewer gpu hours than all existing automatic model design approaches and notably 1000x less expensive than standard neural architecture search. on the <phrase>penn treebank</phrase> dataset enas discovers <phrase>a novel</phrase> architecture that achieves a test perplexity of 55.8 establishing <phrase>a new</phrase> <phrase>state of</phrase> <phrase>the art</phrase> among all methods without post training processing. on the <phrase>cifar 10</phrase> dataset enas designs novel architectures that achieve a test error of 2.89 which is on par with nasnet zoph <phrase>et al</phrase>. 2018 whose test error is 2.65 .
building machines that learn and think like people
recent progress in <phrase>artificial intelligence</phrase> ai has renewed interest in building systems that learn and think like people. many advances have come from using <phrase>deep neural networks</phrase> <phrase>trained end to end</phrase> in <phrase>tasks such as</phrase> <phrase>object recognition</phrase> <phrase>video games</phrase> and <phrase>board games</phrase> achieving performance that equals or even beats humans in some respects. despite their biological inspiration and performance achievements these systems differ from <phrase>human intelligence</phrase> in crucial ways. we review progress in <phrase>cognitive science</phrase> suggesting that truly human like learning and <phrase>thinking machines</phrase> will have to reach beyond current engineering trends in both what they learn and how they learn it. specifically we argue that these machines should a build causal models of the world that support explanation and understanding <phrase>rather than</phrase> merely solving <phrase>pattern recognition</phrase> problems b ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned and c harness compositionality and learning <phrase>to learn</phrase> to rapidly acquire and generalize knowledge to new tasks and situations. we suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent <phrase>neural network</phrase> advances with more structured cognitive models.
towards <phrase>bayesian deep learning</phrase> a survey
while perception <phrase>tasks such as</phrase> visual <phrase>object recognition</phrase> and text understanding play <phrase>an important</phrase> <phrase>role in</phrase> <phrase>human intelligence</phrase> the subsequent tasks that involve inference reasoning and planning require an even <phrase>higher level</phrase> of intelligence. <phrase>the past</phrase> few years have seen major <phrase>advances in</phrase> many perception tasks using <phrase>deep learning</phrase> models. for <phrase>higher level</phrase> inference however probabilistic <phrase>graphical models</phrase> with their bayesian nature are still <phrase>more powerful</phrase> and flexible. to achieve integrated intelligence that involves both perception and inference it is naturally desirable to tightly integrate <phrase>deep learning</phrase> and bayesian models within a principled probabilistic framework which we call <phrase>bayesian deep learning</phrase>. in this unified framework the perception of text or images using <phrase>deep learning</phrase> can boost <phrase>the performance of</phrase> <phrase>higher level</phrase> inference and in return the feedback from the inference process is <phrase>able to</phrase> enhance the perception of text or images. this survey provides a general introduction to <phrase>bayesian deep learning</phrase> and reviews its recent applications on recommender systems topic models and control. in this survey we also discuss the relationship and differences between <phrase>bayesian deep learning</phrase> and other related topics like bayesian treatment of <phrase>neural networks</phrase>.
hierarchical <phrase>deep reinforcement learning</phrase> integrating temporal abstraction and intrinsic motivation
learning goal directed behavior in environments with sparse feedback is a major challenge for <phrase>reinforcement learning</phrase> algorithms. the primary difficulty arises <phrase>due to</phrase> insufficient exploration resulting in <phrase>an agent</phrase> being unable <phrase>to learn</phrase> robust value functions. intrinsically motivated agents can explore new behavior for its own sake <phrase>rather than</phrase> to directly solve problems. such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. we present hierarchical dqn h dqn a framework to integrate hierarchical value functions operating at different temporal scales with intrinsically motivated <phrase>deep reinforcement learning</phrase>. a top level <phrase>value function</phrase> learns a policy over intrinsic goals and a lower level function learns a policy over atomic actions to satisfy the given goals. h dqn allows for flexible goal specifications <phrase>such as</phrase> functions over entities and relations. this provides an efficient space for exploration in complicated environments. we demonstrate the strength of our approach on two problems with very sparse delayed feedback 1 a complex discrete stochastic decision process and 2 the classic atari game montezuma s revenge .
learning features by watching objects move
<phrase>this paper</phrase> presents <phrase>a novel</phrase> yet intuitive <phrase>approach to</phrase> unsupervised <phrase>feature learning</phrase>. <phrase>inspired by</phrase> the human visual system we explore whether low level motion based grouping cues can be used <phrase>to learn</phrase> <phrase>an effective</phrase> visual representation. specifically we use unsupervised motion based segmentation on videos <phrase>to obtain</phrase> segments which we use as pseudo ground truth <phrase>to train</phrase> a convolutional network to segment objects from <phrase>a single</phrase> frame. given the extensive evidence that motion plays a key <phrase>role in</phrase> the development of the human visual system we hope that this straightforward <phrase>approach to</phrase> <phrase>unsupervised learning</phrase> will be <phrase>more effective</phrase> than cleverly designed pretext tasks studied in the literature. indeed our <phrase>extensive experiments</phrase> show that this is the case. when used for <phrase>transfer learning</phrase> on <phrase>object detection</phrase> our representation <phrase>significantly outperforms</phrase> previous unsupervised approaches across multiple settings especially when <phrase>training data</phrase> for the target task is scarce.
domain adaptive <phrase>neural networks</phrase> for <phrase>object recognition</phrase>
we propose <phrase>a simple</phrase> <phrase>neural network</phrase> model to deal with the <phrase>domain adaptation</phrase> problem in <phrase>object recognition</phrase>. our model incorporates the maximum mean discrepancy mmd measure as a regularization in the <phrase>supervised learning</phrase> <phrase>to reduce</phrase> the distribution mismatch between the source and target domains in the <phrase>latent space</phrase>. from experiments we demonstrate that the mmd regularization is <phrase>an effective</phrase> tool to provide good <phrase>domain adaptation</phrase> models on both surf features and raw image pixels of a particular image <phrase>data set</phrase>. we <phrase>also show</phrase> that our <phrase>proposed model</phrase> preceded by the denoising auto encoder pretraining achieves <phrase>better performance</phrase> than recent benchmark models on <phrase>the same</phrase> <phrase>data sets</phrase>. <phrase>this work</phrase> represents the first study of mmd measure in <phrase>the context of</phrase> <phrase>neural networks</phrase>.
beyond temporal pooling recurrence and temporal convolutions for <phrase>gesture recognition</phrase> in video
recent studies have demonstrated the power of <phrase>recurrent neural networks</phrase> for <phrase>machine translation</phrase> image captioning and <phrase>speech recognition</phrase>. for <phrase>the task of</phrase> capturing temporal structure in video however there still remain numerous open research questions. current research suggests using <phrase>a simple</phrase> temporal feature pooling strategy to take into account the temporal aspect of video. we demonstrate that this method is not sufficient for <phrase>gesture recognition</phrase> where temporal information is more discriminative <phrase>compared to</phrase> general video <phrase>classification tasks</phrase>. we explore deep architectures for <phrase>gesture recognition</phrase> in video and propose <phrase>a new</phrase> <phrase>end to end</phrase> trainable <phrase>neural network</phrase> architecture incorporating temporal convolutions and bidirectional recurrence. our main contributions are twofold first we show that recurrence is crucial for <phrase>this task</phrase> second we show that adding temporal convolutions <phrase>leads to</phrase> <phrase>significant improvements</phrase>. we evaluate the different approaches on the montalbano <phrase>gesture recognition</phrase> dataset where we <phrase>achieve state of</phrase> <phrase>the art</phrase> results.
telugu ocr framework using <phrase>deep learning</phrase>
in <phrase>this paper</phrase> we address <phrase>the task of</phrase> <phrase>optical character recognition</phrase> ocr for the telugu script. we present <phrase>an end to end</phrase> framework that segments the text image classifies the characters and extracts lines using a <phrase>language model</phrase>. the segmentation is <phrase>based on</phrase> <phrase>mathematical morphology</phrase>. the classification module which is the most <phrase>challenging task</phrase> of the three is a <phrase>deep convolutional</phrase> <phrase>neural network</phrase>. the language is modelled as a third degree <phrase>markov chain</phrase> at the glyph level. telugu script is a complex alphasyllabary and the language is agglutinative making the problem hard. in <phrase>this paper</phrase> we apply the latest <phrase>advances in</phrase> <phrase>neural networks</phrase> to <phrase>achieve state of</phrase> <phrase>the art</phrase> <phrase>error rates</phrase>. we also review <phrase>convolutional neural networks</phrase> in great detail and expound the statistical justification behind the many tricks needed to make <phrase>deep learning</phrase> work.
adversarial <phrase>feature learning</phrase>
the ability of the <phrase>generative adversarial networks</phrase> gans framework <phrase>to learn</phrase> <phrase>generative models</phrase> mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically with compelling results showing that the <phrase>latent space</phrase> of such generators captures semantic variation in the data distribution. intuitively models trained <phrase>to predict</phrase> these semantic latent representations given data may serve as useful <phrase>feature representations</phrase> for auxiliary problems where semantics are relevant. however in their existing form gans have no means of learning the inverse mapping projecting data back into the <phrase>latent space</phrase>. we propose bidirectional <phrase>generative adversarial networks</phrase> bigans as a means of learning this inverse mapping and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks competitive with contemporary approaches to unsupervised and self supervised <phrase>feature learning</phrase>.
the mythos of model interpretability
supervised <phrase>machine learning</phrase> models boast remarkable predictive capabilities. but can you trust your model will it work in deployment what else can it tell you about the world we want models to be <phrase>not only</phrase> good but interpretable. and yet <phrase>the task of</phrase> interpretation appears underspecified. papers provide diverse and sometimes non overlapping motivations for interpretability and offer myriad notions of what attributes render models interpretable. despite this ambiguity many papers proclaim interpretability axiomatically absent further explanation. in <phrase>this paper</phrase> we <phrase>seek to</phrase> refine the discourse on interpretability. first we examine the motivations underlying interest in interpretability finding them to be diverse and occasionally discordant. then we address model properties and techniques thought to confer interpretability identifying transparency to humans and post hoc explanations as competing notions. throughout we discuss the feasibility and desirability of different notions and question the oft made assertions that linear models are interpretable and that <phrase>deep neural networks</phrase> are not.
neurogenesis inspired dictionary learning online model adaption in a changing world
in <phrase>this paper</phrase> we <phrase>focus on</phrase> online <phrase>representation learning</phrase> in non stationary environments which may require continuous adaptation of model architecture. we propose <phrase>a novel</phrase> online dictionary learning sparse coding framework which incorporates the addition and deletion of hidden units dictionary elements and is <phrase>inspired by</phrase> the adult neurogenesis phenomenon in the <phrase>dentate gyrus</phrase> of the hippocampus known to be <phrase>associated with</phrase> improved <phrase>cognitive function</phrase> and adaptation to new environments. in the online learning setting where new input instances arrive sequentially in batches the neuronal birth is implemented by adding new units with random initial weights random dictionary elements <phrase>the number of</phrase> new units is determined by the current performance representation error of the dictionary higher error causing an increase in the <phrase>birth rate</phrase>. neuronal death is implemented by imposing l1 l2 regularization group sparsity on the dictionary within the block coordinate descent optimization at each iteration of our online alternating minimization scheme which iterates between the code and dictionary updates. finally hidden unit connectivity adaptation is facilitated <phrase>by introducing</phrase> sparsity in dictionary elements. our empirical evaluation on several real life datasets images and language <phrase>as well as</phrase> on synthetic data demonstrates that <phrase>the proposed</phrase> approach can considerably outperform the <phrase>state of</phrase> art fixed size nonadaptive online sparse coding of mairal <phrase>et al</phrase>. 2009 in the presence of nonstationary data. moreover we identify certain <phrase>properties of</phrase> the data e.g. sparse inputs with nearly non overlapping supports and of <phrase>the model</phrase> e.g. dictionary sparsity <phrase>associated with</phrase> such improvements.
borrowing treasures from the wealthy deep <phrase>transfer learning</phrase> through selective joint fine tuning
<phrase>deep neural networks</phrase> require <phrase>a large</phrase> <phrase>amount of</phrase> labeled <phrase>training data</phrase> during <phrase>supervised learning</phrase>. however collecting and labeling so much data might be infeasible in many cases. in <phrase>this paper</phrase> we introduce a source target selective joint fine tuning scheme for improving <phrase>the performance of</phrase> <phrase>deep learning</phrase> tasks with insufficient <phrase>training data</phrase>. in this scheme a target learning task with insufficient <phrase>training data</phrase> is carried out simultaneously with another source learning task with abundant <phrase>training data</phrase>. however the source learning task <phrase>does not</phrase> use all existing <phrase>training data</phrase>. our core idea is to identify and use <phrase>a subset of</phrase> training images from <phrase>the original</phrase> source learning task whose low level characteristics are <phrase>similar to</phrase> those from the target learning task and jointly fine tune shared convolutional layers for both tasks. specifically we compute descriptors from linear or nonlinear filter bank responses on training images from both tasks and use such descriptors to search for a desired <phrase>subset of</phrase> <phrase>training samples</phrase> for the source learning task. <phrase>experiments demonstrate</phrase> that our selective joint fine tuning scheme <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> multiple visual <phrase>classification tasks</phrase> with insufficient <phrase>training data</phrase> for <phrase>deep learning</phrase>. such tasks include caltech 256 mit indoor 67 oxford flowers 102 and stanford dogs 120. in comparison to fine tuning without a source domain <phrase>the proposed</phrase> method can improve the <phrase>classification accuracy</phrase> by 2 10 using <phrase>a single</phrase> model.
aligned image word representations improve inductive transfer across vision language tasks
<phrase>an important</phrase> goal of <phrase>computer vision</phrase> is to build systems that learn visual representations over time that can be <phrase>applied to</phrase> many tasks. in <phrase>this paper</phrase> we investigate a vision language embedding as a core representation and show that it <phrase>leads to</phrase> better cross task transfer than standard <phrase>multi task learning</phrase>. <phrase>in particular</phrase> <phrase>the task of</phrase> visual recognition is aligned to <phrase>the task of</phrase> <phrase>visual question answering</phrase> by forcing each to use <phrase>the same</phrase> word region embeddings. we show this <phrase>leads to</phrase> greater inductive transfer from recognition to vqa than standard multitask learning. visual recognition also improves especially for categories that have relatively few recognition training labels but appear often in the vqa setting. thus our paper takes <phrase>a small</phrase> <phrase>step towards</phrase> creating more general vision systems by showing the benefit of interpretable flexible and trainable core representations.
universal <phrase>adversarial perturbations</phrase> against semantic <phrase>image segmentation</phrase>
while <phrase>deep learning</phrase> is remarkably successful on perceptual tasks it was also <phrase>shown to</phrase> be vulnerable to <phrase>adversarial perturbations</phrase> of <phrase>the input</phrase>. these perturbations denote noise added to <phrase>the input</phrase> that was generated specifically to fool the system while being quasi imperceptible for humans. more severely there even exist <phrase>universal perturbations</phrase> that are input agnostic but fool <phrase>the network</phrase> on the majority of inputs. while <phrase>recent work</phrase> has <phrase>focused on</phrase> <phrase>image classification</phrase> <phrase>this work</phrase> proposes attacks against semantic <phrase>image segmentation</phrase> we present an approach for generating universal <phrase>adversarial perturbations</phrase> that make <phrase>the network</phrase> yield a desired target segmentation as output. we show empirically that there exist barely perceptible universal noise patterns which result in nearly <phrase>the same</phrase> predicted segmentation for arbitrary inputs. furthermore we <phrase>also show</phrase> <phrase>the existence of</phrase> universal noise which removes a target class e.g. all pedestrians from the segmentation while leaving the segmentation mostly unchanged otherwise.
the loss surface of deep and wide <phrase>neural networks</phrase>
while the <phrase>optimization problem</phrase> behind <phrase>deep neural networks</phrase> is highly <phrase>non convex</phrase> it is frequently observed <phrase>in practice</phrase> that training <phrase>deep networks</phrase> seems possible without getting stuck in suboptimal points. it has been argued that this is the case as all <phrase>local minima</phrase> are <phrase>close to</phrase> being globally optimal. we show that this is almost true in fact almost all <phrase>local minima</phrase> are globally optimal for a fully connected network with squared loss and analytic <phrase>activation function</phrase> given that <phrase>the number of</phrase> hidden units of one layer of <phrase>the network</phrase> is larger than <phrase>the number of</phrase> training points and <phrase>the network</phrase> structure from this layer on is pyramidal.
semantically decomposing the latent spaces of <phrase>generative adversarial networks</phrase>
we propose <phrase>a new</phrase> algorithm for training <phrase>generative adversarial networks</phrase> that jointly learns latent codes for both identities e.g. individual humans and observations e.g. specific photographs . by fixing the identity portion of the latent codes we can generate diverse images of <phrase>the same</phrase> subject and by fixing the observation portion we can traverse the manifold of subjects while maintaining contingent aspects <phrase>such as</phrase> lighting and pose. our algorithm features a pairwise training scheme in which each sample from the generator <phrase>consists of</phrase> two images with a common identity code. corresponding samples from the real dataset consist of two distinct photographs of <phrase>the same</phrase> subject. <phrase>in order to</phrase> fool the discriminator the generator must produce pairs that are photorealistic distinct and appear to depict <phrase>the same</phrase> individual. we augment both the dcgan and began approaches with siamese discriminators to facilitate pairwise training. experiments with human judges and an off the shelf face verification system demonstrate our algorithm s <phrase>ability to</phrase> generate convincing identity matched photographs.
variants of rmsprop and adagrad with logarithmic regret bounds
adaptive gradient methods have become recently very popular <phrase>in particular</phrase> as they have been <phrase>shown to</phrase> be useful in the training of <phrase>deep neural networks</phrase>. in <phrase>this paper</phrase> we have analyzed rmsprop originally proposed for the training of <phrase>deep neural networks</phrase> in <phrase>the context of</phrase> online <phrase>convex optimization</phrase> and show sqrt t type regret bounds. moreover we propose two variants sc adagrad and sc rmsprop for which we show logarithmic regret bounds for strongly convex functions. finally we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or <phrase>stochastic gradient descent</phrase> in the optimization of strongly convex functions <phrase>as well as</phrase> in training of <phrase>deep neural networks</phrase>.
alice towards understanding adversarial learning for joint distribution matching
we investigate the non identifiability issues <phrase>associated with</phrase> bidirectional adversarial training for joint distribution matching. within a framework of conditional entropy we propose both adversarial and non adversarial approaches <phrase>to learn</phrase> desirable matched joint distributions for unsupervised and supervised tasks. we unify a broad <phrase>family of</phrase> adversarial models as joint distribution matching problems. our approach stabilizes learning of unsupervised bidirectional adversarial <phrase>learning methods</phrase>. further we introduce an extension for <phrase>semi supervised</phrase> <phrase>learning tasks</phrase>. theoretical results are validated in synthetic data and <phrase>real world</phrase> applications.
a systematic study of the class imbalance problem in <phrase>convolutional neural networks</phrase>
in <phrase>this study</phrase> we systematically investigate the impact of class imbalance on <phrase>classification performance</phrase> of <phrase>convolutional neural networks</phrase> cnns and compare frequently used methods <phrase>to address</phrase> the issue. class imbalance is a common problem that has been comprehensively studied in classical <phrase>machine learning</phrase> yet very limited systematic research is available in <phrase>the context of</phrase> <phrase>deep learning</phrase>. in our study we use three <phrase>benchmark datasets</phrase> of increasing complexity mnist <phrase>cifar 10</phrase> and imagenet to investigate the effects of imbalance on classification and perform an extensive comparison of several methods <phrase>to address</phrase> the issue oversampling undersampling two phase training and thresholding that compensates for prior class probabilities. our main evaluation metric is area under the <phrase>receiver operating characteristic</phrase> curve roc auc adjusted to <phrase>multi class</phrase> tasks since overall accuracy metric is <phrase>associated with</phrase> notable difficulties in <phrase>the context of</phrase> imbalanced data. <phrase>based on</phrase> results from our experiments we conclude that i <phrase>the effect of</phrase> class imbalance on <phrase>classification performance</phrase> is detrimental ii the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling iii oversampling should be <phrase>applied to</phrase> the level that totally eliminates the imbalance whereas undersampling can perform better when the imbalance is only removed to some extent iv as opposed to some classical <phrase>machine learning</phrase> models oversampling <phrase>does not</phrase> necessarily cause overfitting of cnns v thresholding should be <phrase>applied to</phrase> compensate for prior class probabilities when overall <phrase>number of</phrase> properly classified cases is of interest.
regularization for <phrase>deep learning</phrase> a taxonomy
regularization is one of the crucial ingredients of <phrase>deep learning</phrase> yet the term regularization has various definitions and regularization methods are often studied separately from each other. in our work we present a systematic unifying taxonomy to categorize <phrase>existing methods</phrase>. we distinguish methods that affect data <phrase>network architectures</phrase> error terms regularization terms and optimization procedures. we <phrase>do not</phrase> provide all details about the listed methods instead we present an overview of how the methods can be sorted into meaningful categories and sub categories. this helps revealing links and fundamental similarities between them. finally we include practical recommendations both for users and for developers of new regularization methods.
clustering with <phrase>deep learning</phrase> taxonomy and new methods
clustering is a fundamental <phrase>machine learning</phrase> method. the quality of its results is dependent on the data distribution. for this reason <phrase>deep neural networks</phrase> can be used for learning better representations of the data. in <phrase>this paper</phrase> we propose a systematic taxonomy for clustering with <phrase>deep learning</phrase> <phrase>in addition</phrase> to a review of methods from the field. <phrase>based on</phrase> our taxonomy creating new methods is more straightforward. we also propose <phrase>a new</phrase> approach which is built on the taxonomy and surpasses some of the limitations of some <phrase>previous work</phrase>. our experimental evaluation on image datasets shows that the method approaches <phrase>state of</phrase> <phrase>the art</phrase> clustering quality and performs better in some cases.
coarse to fine non rigid registration a chain of scale specific <phrase>neural networks</phrase> for multimodal image alignment with <phrase>application to</phrase> <phrase>remote sensing</phrase>
we tackle here <phrase>the problem of</phrase> multimodal image non rigid registration which is of prime importance in <phrase>remote sensing</phrase> and <phrase>medical imaging</phrase>. the difficulties encountered by classical registration approaches include feature design and slow optimization by <phrase>gradient descent</phrase>. by analyzing these methods we note the significance of the <phrase>notion of</phrase> scale. we design <phrase>easy to</phrase> train fully <phrase>convolutional neural networks</phrase> <phrase>able to</phrase> learn scale specific features. once chained appropriately they perform global registration in linear time getting rid of <phrase>gradient descent</phrase> schemes by predicting directly the deformation.we show their performance <phrase>in terms of</phrase> quality and speed through various tasks of <phrase>remote sensing</phrase> multimodal image alignment. <phrase>in particular</phrase> we are <phrase>able to</phrase> register correctly cadastral maps of buildings <phrase>as well as</phrase> road polylines onto rgb images and outperform current keypoint matching methods.
describing videos by exploiting temporal structure
recent progress in using <phrase>recurrent neural networks</phrase> rnns for image description has motivated the exploration of their application for video description. however while images are static working with videos requires modeling their dynamic temporal structure and then properly integrating that information into a <phrase>natural language</phrase> description. in this context we propose an approach that successfully takes into account both the local and global temporal structure of videos <phrase>to produce</phrase> descriptions. first our approach incorporates a spatial temporal 3 d <phrase>convolutional neural network</phrase> 3 d cnn representation of the short temporal dynamics. the 3 d cnn representation is <phrase>trained on</phrase> video action <phrase>recognition tasks</phrase> so as <phrase>to produce</phrase> a representation that is tuned to human motion and behavior. second we propose a temporal <phrase>attention mechanism</phrase> that allows to go beyond local temporal modeling and learns to automatically select the most relevant temporal segments given the text generating rnn. our approach exceeds <phrase>the current state of</phrase> art for both bleu and meteor metrics on the youtube2text dataset. we <phrase>also present</phrase> <phrase>results on</phrase> <phrase>a new</phrase> larger and more challenging dataset of paired video and <phrase>natural language</phrase> descriptions.
collaborative recurrent autoencoder recommend while learning to fill in the blanks
hybrid methods that utilize both content and rating information are commonly used in many recommender systems. however most of them use either handcrafted features or the bag of words representation as a surrogate for the content information but they are neither effective nor natural enough. <phrase>to address</phrase> <phrase>this problem</phrase> we develop a collaborative recurrent autoencoder crae which is a denoising recurrent autoencoder drae that models <phrase>the generation of</phrase> content sequences in the <phrase>collaborative filtering</phrase> cf setting. <phrase>the model</phrase> generalizes <phrase>recent advances in</phrase> recurrent <phrase>deep learning</phrase> from i.i.d. input to non i.i.d. cf based input and provides <phrase>a new</phrase> denoising scheme <phrase>along with</phrase> <phrase>a novel</phrase> learnable pooling scheme for the recurrent autoencoder. to do this we first develop a hierarchical bayesian model for the drae and then generalize it to the cf setting. the synergy between denoising and cf enables crae to make accurate recommendations while learning to fill in the blanks in sequences. <phrase>experiments on</phrase> <phrase>real world</phrase> datasets from different domains citeulike and netflix show that by jointly modeling the order aware generation of sequences for the content information and performing cf for the ratings crae is <phrase>able to</phrase> <phrase>significantly outperform</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> on both the recommendation task <phrase>based on</phrase> ratings and the sequence generation task <phrase>based on</phrase> content information.
sentiment classification using images and label embeddings
in this project we analysed how much semantic information images carry and how much value image data can add to <phrase>sentiment analysis</phrase> of the text <phrase>associated with</phrase> the images. to better understand the contribution from images we compared models which only made use of image data models which only made use of text data and models which combined both data types. we also analysed if <phrase>this approach</phrase> could help sentiment classifiers generalize to unknown sentiments.
natural parameter networks a class of probabilistic <phrase>neural networks</phrase>
<phrase>neural networks</phrase> nn have achieved <phrase>state of</phrase> <phrase>the art</phrase> performance in various applications. unfortunately in applications where <phrase>training data</phrase> is insufficient they are often prone to overfitting. one effective way to alleviate <phrase>this problem</phrase> is to exploit the bayesian approach <phrase>by using</phrase> bayesian <phrase>neural networks</phrase> bnn . another shortcoming of nn is <phrase>the lack of</phrase> flexibility to customize different distributions for the weights and neurons <phrase>according to</phrase> the data as is often done in probabilistic <phrase>graphical models</phrase>. <phrase>to address</phrase> these problems we propose a class of probabilistic <phrase>neural networks</phrase> dubbed natural parameter networks npn as <phrase>a novel</phrase> and lightweight bayesian treatment of nn. npn allows the usage of arbitrary <phrase>exponential family</phrase> distributions to model the weights and neurons. different from traditional nn and bnn npn takes distributions as input and goes through layers of transformation before producing distributions to match the target output distributions. as a bayesian treatment efficient backpropagation bp is performed <phrase>to learn</phrase> the natural parameters for the distributions over both the weights and neurons. the output distributions of <phrase>each layer</phrase> as byproducts may be <phrase>used as</phrase> second order representations for the associated <phrase>tasks such as</phrase> link prediction. <phrase>experiments on</phrase> <phrase>real world</phrase> datasets show that npn can <phrase>achieve state of</phrase> <phrase>the art</phrase> performance.
learning <phrase>to perform</phrase> physics experiments via <phrase>deep reinforcement learning</phrase>
when encountering novel objects humans are <phrase>able to</phrase> infer <phrase>a wide range of</phrase> physical properties <phrase>such as</phrase> mass friction and deformability by interacting with them in a goal driven way. this process of active interaction is in <phrase>the same</phrase> spirit as a scientist performing experiments <phrase>to discover</phrase> hidden facts. <phrase>recent advances in</phrase> <phrase>artificial intelligence</phrase> have yielded machines that can achieve superhuman performance in go atari <phrase>natural language</phrase> processing and complex control problems however it is not clear that these systems can rival the scientific intuition of even a young child. in <phrase>this work</phrase> we introduce a basic <phrase>set of</phrase> tasks that require agents to estimate properties <phrase>such as</phrase> mass and cohesion of objects in an interactive simulated environment where they can manipulate the objects and observe the consequences. we found that <phrase>state of</phrase> art <phrase>deep reinforcement learning</phrase> methods can learn <phrase>to perform</phrase> the experiments necessary <phrase>to discover</phrase> such hidden properties. by systematically manipulating the problem difficulty and the cost incurred by the agent for performing experiments we found that agents learn different strategies that balance the cost of gathering information against the cost of making mistakes in different situations.
a network based <phrase>end to end</phrase> trainable task oriented dialogue system
teaching machines to accomplish tasks by conversing naturally with humans is challenging. currently developing task oriented <phrase>dialogue systems</phrase> requires creating multiple components and typically this involves either <phrase>a large</phrase> <phrase>amount of</phrase> handcrafting or acquiring costly labelled datasets <phrase>to solve</phrase> a statistical learning problem for each component. in <phrase>this work</phrase> we introduce <phrase>a neural network</phrase> based text in text out <phrase>end to end</phrase> trainable <phrase>goal oriented</phrase> dialogue system <phrase>along with</phrase> <phrase>a new</phrase> way of collecting dialogue data <phrase>based on</phrase> <phrase>a novel</phrase> pipe lined wizard of oz framework. <phrase>this approach</phrase> allows us to develop <phrase>dialogue systems</phrase> easily and without making too many assumptions about the task at hand. the <phrase>results show</phrase> that <phrase>the model</phrase> can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.
a factorization machine <phrase>framework for</phrase> testing bigram embeddings in knowledgebase completion
embedding based <phrase>knowledge base</phrase> completion models have <phrase>so far</phrase> mostly combined distributed representations of individual entities or relations to compute truth scores of missing links. facts can however also be represented using pairwise embeddings i.e. embeddings for pairs of entities and relations. in <phrase>this paper</phrase> we explore such bigram embeddings with a flexible factorization machine model and several ablations from it. we investigate the relevance of various bigram types on the fb15k237 dataset and find relative improvements <phrase>compared to</phrase> a compositional model.
<phrase>neural networks</phrase> for joint <phrase>sentence classification</phrase> in medical paper abstracts
existing models <phrase>based on</phrase> <phrase>artificial neural networks</phrase> anns for <phrase>sentence classification</phrase> often <phrase>do not</phrase> incorporate the context in which sentences appear and classify sentences individually. however traditional <phrase>sentence classification</phrase> approaches have been <phrase>shown to</phrase> greatly benefit from jointly classifying subsequent sentences <phrase>such as</phrase> with conditional random fields. in <phrase>this work</phrase> we present an ann architecture that combines <phrase>the effectiveness of</phrase> typical ann models to classify sentences in isolation with the strength of <phrase>structured prediction</phrase>. our <phrase>model achieves</phrase> <phrase>state of</phrase> <phrase>the art results</phrase> on two different datasets for sequential <phrase>sentence classification</phrase> in medical abstracts.
<phrase>de identification</phrase> of patient notes with <phrase>recurrent neural networks</phrase>
objective patient notes in <phrase>electronic health records</phrase> ehrs may contain critical information for medical investigations. however the vast majority of medical investigators can only access de identified notes <phrase>in order to</phrase> protect the confidentiality of patients. in the <phrase>united states</phrase> the <phrase>health insurance</phrase> portability and accountability act hipaa defines 18 <phrase>types of</phrase> protected health information phi that <phrase>needs to</phrase> be removed to de identify patient notes. manual <phrase>de identification</phrase> is impractical given the size of ehr databases the limited <phrase>number of</phrase> researchers with access to the non de identified notes and the frequent mistakes of human annotators. a reliable automated <phrase>de identification</phrase> system would consequently be of high value. materials and methods we introduce the first <phrase>de identification</phrase> system <phrase>based on</phrase> <phrase>artificial neural networks</phrase> anns which requires no handcrafted features or rules unlike existing systems. we compare <phrase>the performance of</phrase> the system with <phrase>state of</phrase> <phrase>the art</phrase> systems on two datasets the i2b2 2014 <phrase>de identification</phrase> challenge dataset which is the largest <phrase>publicly available</phrase> <phrase>de identification</phrase> dataset and the mimic <phrase>de identification</phrase> dataset which we assembled and is twice as large as the i2b2 2014 dataset. results our ann <phrase>model outperforms</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> systems. it yields an f1 score of 97.85 on the i2b2 2014 dataset with a recall 97.38 and a precision of 97.32 and an f1 score of 99.23 on the mimic <phrase>de identification</phrase> dataset with a recall 99.25 and a precision of 99.06. conclusion our findings support <phrase>the use of</phrase> anns for <phrase>de identification</phrase> of patient notes as they show <phrase>better performance</phrase> than previously published systems while requiring no feature engineering.
reasoning with memory augmented <phrase>neural networks</phrase> for language comprehension
<phrase>hypothesis testing</phrase> is <phrase>an important</phrase> <phrase>cognitive process</phrase> that supports human reasoning. in <phrase>this paper</phrase> we introduce a computational <phrase>hypothesis testing</phrase> <phrase>approach based on</phrase> memory augmented <phrase>neural networks</phrase>. our approach involves a <phrase>hypothesis testing</phrase> loop that reconsiders and progressively refines a previously formed hypothesis <phrase>in order to</phrase> generate new hypotheses to test. we apply <phrase>the proposed approach</phrase> to language comprehension task <phrase>by using</phrase> neural semantic encoders nse . our nse models achieve the <phrase>state of</phrase> <phrase>the art</phrase> results showing an absolute improvement of 1.2 to 2.6 accuracy over previous results <phrase>obtained by</phrase> single and ensemble systems on standard machine comprehension benchmarks <phrase>such as</phrase> the children s book test cbt and who did what wdw news article datasets.
automatic rule extraction from <phrase>long short term memory</phrase> networks
although <phrase>deep learning</phrase> models have proven effective at solving problems in <phrase>natural language</phrase> processing the mechanism by which they come to their conclusions is often unclear. as a result <phrase>these models</phrase> are generally treated as black boxes yielding no insight of the underlying learned patterns. in <phrase>this paper</phrase> we consider <phrase>long short term memory</phrase> networks lstms and demonstrate <phrase>a new</phrase> approach for tracking the importance of a given input to the lstm for a given output. by identifying consistently important patterns of words we are <phrase>able to</phrase> distill <phrase>state of</phrase> <phrase>the art</phrase> lstms on <phrase>sentiment analysis</phrase> and <phrase>question answering</phrase> into <phrase>a set of</phrase> representative phrases. this representation is then quantitatively validated <phrase>by using</phrase> the extracted phrases to construct <phrase>a simple</phrase> rule based classifier which approximates the output of the lstm.
comparing rule based and <phrase>deep learning</phrase> models for patient phenotyping
objective we investigate whether <phrase>deep learning</phrase> techniques for <phrase>natural language</phrase> processing nlp can be used efficiently for patient phenotyping. patient phenotyping is a <phrase>classification task</phrase> for determining whether a patient has a medical condition and is a crucial part of secondary analysis of healthcare data. we assess <phrase>the performance of</phrase> <phrase>deep learning</phrase> algorithms and compare them with classical nlp approaches. materials and methods we compare <phrase>convolutional neural networks</phrase> cnns <phrase>n gram</phrase> models and approaches <phrase>based on</phrase> ctakes that extract pre defined medical concepts from clinical notes and use them <phrase>to predict</phrase> patient phenotypes. the performance is <phrase>tested on</phrase> 10 different phenotyping tasks using 1 610 discharge summaries <phrase>extracted from</phrase> the mimic iii database. results cnns outperform other phenotyping algorithms in all 10 tasks. the average f1 score of our model is 76 ppv of 83 and sensitivity of 71 with our model having an f1 score up to 37 points higher than alternative approaches. we additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction. conclusion we show that nlp methods <phrase>based on</phrase> <phrase>deep learning</phrase> improve <phrase>the performance of</phrase> patient phenotyping. our cnn based algorithm automatically learns the phrases <phrase>associated with</phrase> each patient phenotype. as such it reduces the annotation complexity for clinical domain experts who are normally required to develop <phrase>task specific</phrase> annotation rules and identify relevant phrases. our method performs well <phrase>in terms of</phrase> both performance and interpretability which indicates that <phrase>deep learning</phrase> is <phrase>an effective</phrase> <phrase>approach to</phrase> patient phenotyping <phrase>based on</phrase> clinicians notes.
mit at semeval 2017 task 10 relation extraction with <phrase>convolutional neural networks</phrase>
over 50 million scholarly articles have been published they constitute a unique repository of knowledge. <phrase>in particular</phrase> one may infer from them <phrase>relations between</phrase> scientific concepts <phrase>such as</phrase> synonyms and hyponyms. <phrase>artificial neural networks</phrase> have been recently explored for relation extraction. in <phrase>this work</phrase> we continue this line of work and present a system <phrase>based on</phrase> <phrase>a convolutional neural network</phrase> <phrase>to extract</phrase> relations. our model ranked first in the semeval 2017 task 10 scienceie for relation extraction in scientific articles subtask c .
<phrase>transfer learning</phrase> for <phrase>named entity recognition</phrase> with <phrase>neural networks</phrase>
recent approaches <phrase>based on</phrase> <phrase>artificial neural networks</phrase> anns have shown <phrase>promising results</phrase> for <phrase>named entity recognition</phrase> ner . <phrase>in order to</phrase> achieve high performances anns <phrase>need to</phrase> be <phrase>trained on</phrase> <phrase>a large</phrase> labeled dataset. however labels might be difficult <phrase>to obtain</phrase> for the dataset on which the user wants <phrase>to perform</phrase> ner label scarcity is particularly pronounced for patient note <phrase>de identification</phrase> which is an instance of ner. in <phrase>this work</phrase> we analyze to what extent <phrase>transfer learning</phrase> may address <phrase>this issue</phrase>. <phrase>in particular</phrase> we demonstrate that transferring an ann model <phrase>trained on</phrase> <phrase>a large</phrase> labeled dataset to another dataset with a limited <phrase>number of</phrase> labels improves upon the <phrase>state of</phrase> <phrase>the art results</phrase> on two different datasets for patient note <phrase>de identification</phrase>.
adversarial generation of <phrase>natural language</phrase>
<phrase>generative adversarial networks</phrase> gans have gathered a lot of attention from the <phrase>computer vision</phrase> community yielding impressive results for image generation. <phrase>advances in</phrase> the adversarial generation of <phrase>natural language</phrase> from noise however are not commensurate with the progress made in generating images and still lag far behind likelihood <phrase>based methods</phrase>. in <phrase>this paper</phrase> we take a <phrase>step towards</phrase> generating <phrase>natural language</phrase> with a gan objective alone. we introduce <phrase>a simple</phrase> baseline that addresses the discrete output space problem without relying on gradient estimators and show that it is <phrase>able to achieve</phrase> <phrase>state of</phrase> <phrase>the art results</phrase> on a chinese poem generation dataset. we present quantitative <phrase>results on</phrase> generating sentences from <phrase>context free</phrase> and probabilistic <phrase>context free</phrase> grammars and qualitative <phrase>language modeling</phrase> results. a conditional version is also described that can generate sequences <phrase>conditioned on</phrase> sentence characteristics.
explaining <phrase>recurrent neural network</phrase> predictions in <phrase>sentiment analysis</phrase>
recently a technique called <phrase>layer wise</phrase> relevance propagation lrp was <phrase>shown to</phrase> deliver insightful explanations in the form of input space relevances for understanding <phrase>feed forward</phrase> <phrase>neural network</phrase> classification decisions. in the present work we extend the usage of lrp to <phrase>recurrent neural networks</phrase>. we propose a specific propagation rule <phrase>applicable to</phrase> multiplicative connections as they arise in <phrase>recurrent network</phrase> architectures <phrase>such as</phrase> lstms and grus. we apply our technique to a word based bi directional lstm model on a five class sentiment prediction task and evaluate the resulting lrp relevances both qualitatively and quantitatively obtaining better results than a <phrase>gradient based</phrase> related method which was used in <phrase>previous work</phrase>.
text compression for <phrase>sentiment analysis</phrase> via <phrase>evolutionary algorithms</phrase>
can textual data be compressed intelligently without losing accuracy in evaluating sentiment in <phrase>this study</phrase> we propose <phrase>a novel</phrase> evolutionary compression algorithm parsec <phrase>parts of</phrase> speech for sentiment compression which makes use of <phrase>parts of</phrase> speech tags to compress text in a way that sacrifices minimal <phrase>classification accuracy</phrase> when used in conjunction with <phrase>sentiment analysis</phrase> algorithms. an analysis of parsec with eight commercial and non commercial <phrase>sentiment analysis</phrase> algorithms on twelve english sentiment <phrase>data sets</phrase> reveals that accurate compression is possible with 0 1.3 3.3 loss in sentiment <phrase>classification accuracy</phrase> for 20 50 75 <phrase>data compression</phrase> with parsec using lingpipe the most accurate of the sentiment algorithms. other <phrase>sentiment analysis</phrase> algorithms are more severely affected by compression. we conclude that significant compression of text data is possible for <phrase>sentiment analysis</phrase> depending on the accuracy demands of the specific application and the specific <phrase>sentiment analysis</phrase> algorithm used.
building competitive direct acoustics to word models for english conversational <phrase>speech recognition</phrase>
direct acoustics to word a2w models in the <phrase>end to end</phrase> paradigm have received increasing attention <phrase>compared to</phrase> conventional sub word based <phrase>automatic speech recognition</phrase> models using phones characters or context dependent <phrase>hidden markov model</phrase> states. this is because a2w models recognize words from speech without any decoder pronunciation lexicon or externally trained <phrase>language model</phrase> making training and decoding with such models simple. prior work has shown that a2w models require orders <phrase>of magnitude</phrase> more <phrase>training data</phrase> <phrase>in order to</phrase> perform comparably to conventional models. our work also showed this accuracy gap when using the english switchboard fisher <phrase>data set</phrase>. <phrase>this paper</phrase> describes a recipe <phrase>to train</phrase> an a2w model that closes this gap and is at par with <phrase>state of</phrase> <phrase>the art</phrase> sub word based models. we achieve a <phrase>word error rate</phrase> of 8.8 13.9 on the hub5 2000 switchboard callhome test sets without any decoder or <phrase>language model</phrase>. we find that model initialization <phrase>training data</phrase> order and regularization have the most impact on the a2w model performance. next we present a joint word character a2w model that learns to first spell the word and then recognize it. this model provides a rich output to the user <phrase>instead of</phrase> simple word hypotheses making it especially useful in the case of words unseen or rarely seen <phrase>during training</phrase>.
ask attend and answer exploring question guided spatial attention for <phrase>visual question answering</phrase>
we address <phrase>the problem of</phrase> <phrase>visual question answering</phrase> vqa which requires joint image and <phrase>language understanding</phrase> to answer a question about a given photograph. recent approaches have applied deep image captioning methods <phrase>based on</phrase> convolutional recurrent networks to <phrase>this problem</phrase> but have failed to model spatial inference. to remedy this we propose a model we call the <phrase>spatial memory</phrase> network and apply it to the vqa task. <phrase>memory networks</phrase> are <phrase>recurrent neural networks</phrase> with an explicit <phrase>attention mechanism</phrase> that selects certain <phrase>parts of</phrase> the information stored in memory. our <phrase>spatial memory</phrase> network stores neuron activations from different spatial regions of the image in its memory and uses the question to choose relevant regions for computing the answer a process of which constitutes <phrase>a single</phrase> hop in <phrase>the network</phrase>. we propose <phrase>a novel</phrase> spatial attention architecture that aligns words with image patches in the first hop and obtain improved results by adding a second attention hop which considers the whole question to choose visual <phrase>evidence based</phrase> on the results of the first hop. to better understand the inference process learned by <phrase>the network</phrase> we design synthetic questions that specifically require spatial inference and visualize the attention weights. we evaluate our model on two published <phrase>visual question answering</phrase> datasets daquar 1 and vqa 2 and obtain improved results <phrase>compared to</phrase> a strong deep baseline model ibowimg which concatenates image and question features <phrase>to predict</phrase> the answer 3 .
task driven visual saliency and <phrase>attention based</phrase> <phrase>visual question answering</phrase>
<phrase>visual question answering</phrase> vqa has witnessed great progress since may 2015 as a classic problem unifying visual and textual data into a system. many enlightening vqa works explore deep into the image and question encodings and fusing methods of which attention is the most effective and infusive mechanism. current <phrase>attention based</phrase> methods <phrase>focus on</phrase> adequate fusion of visual and textual features but lack the attention to where people focus to ask <phrase>questions about</phrase> the image. traditional <phrase>attention based</phrase> methods attach <phrase>a single</phrase> value to the feature at each spatial location which losses many useful information. to remedy these problems we propose a general method <phrase>to perform</phrase> saliency like pre selection on overlapped region features by the interrelation of bidirectional lstm bilstm and use <phrase>a novel</phrase> element wise multiplication based attention method <phrase>to capture</phrase> more competent correlation information between visual and textual features. we conduct <phrase>experiments on</phrase> the <phrase>large scale</phrase> coco vqa dataset and analyze <phrase>the effectiveness of</phrase> our model demonstrated by strong empirical results.
optimising <phrase>the input</phrase> window alignment in cd dnn based <phrase>phoneme recognition</phrase> for low latency processing
we present a systematic analysis on <phrase>the performance of</phrase> a phonetic recogniser when the window of <phrase>input features</phrase> is not symmetric <phrase>with respect to</phrase> the current frame. the recogniser is <phrase>based on</phrase> context dependent <phrase>deep neural networks</phrase> cd dnns and <phrase>hidden markov models</phrase> hmms . the objective is <phrase>to reduce</phrase> the latency of the system by reducing <phrase>the number of</phrase> future feature frames required to estimate the current output. our tests performed on the timit database show that the performance <phrase>does not</phrase> degrade when <phrase>the input</phrase> window is shifted up to 5 frames in <phrase>the past</phrase> <phrase>compared to</phrase> common practice no future frame . this corresponds to improving the latency by 50 ms in our settings. our tests <phrase>also show</phrase> that <phrase>the best</phrase> results are not obtained with the symmetric window commonly employed but with an asymmetric window with eight past and two future context frames although this observation should be confirmed on other <phrase>data sets</phrase>. the <phrase>reduction in</phrase> latency suggested by our results is critical for specific <phrase>applications such as</phrase> <phrase>real time</phrase> lip synchronisation for tele presence but may also be beneficial in general applications <phrase>to improve</phrase> the lag in human machine spoken interaction.
bridging lstm architecture and the neural dynamics during reading
recently the <phrase>long short term memory</phrase> <phrase>neural network</phrase> lstm has attracted wide interest <phrase>due to</phrase> its success in many tasks. lstm architecture <phrase>consists of</phrase> a memory cell and three gates which looks <phrase>similar to</phrase> the neuronal networks in the brain. however there still lacks the evidence of the cognitive plausibility of lstm architecture <phrase>as well as</phrase> its working mechanism. in <phrase>this paper</phrase> we study the cognitive plausibility of lstm by aligning its internal architecture with the brain activity observed via fmri when the subjects read a story. experiment <phrase>results show</phrase> that the artificial memory vector in lstm can accurately predict the observed sequential brain activities indicating the correlation between lstm architecture and the <phrase>cognitive process</phrase> of story reading.
feature weight tuning for <phrase>recursive neural</phrase> networks
<phrase>this paper</phrase> addresses how a <phrase>recursive neural</phrase> network model can automatically leave out useless information and emphasize important evidence in other words <phrase>to perform</phrase> weight tuning for <phrase>higher level</phrase> representation acquisition. we propose two models weighted <phrase>neural network</phrase> wnn and binary expectation <phrase>neural network</phrase> benn which automatically control how much one specific unit contributes to the <phrase>higher level</phrase> representation. <phrase>the proposed</phrase> model can be viewed as incorporating a <phrase>more powerful</phrase> compositional function for embedding acquisition in <phrase>recursive neural</phrase> networks. <phrase>experimental results</phrase> demonstrate the <phrase>significant improvement</phrase> over standard <phrase>neural models</phrase>.
<phrase>a new</phrase> data representation <phrase>based on</phrase> <phrase>training data</phrase> characteristics <phrase>to extract</phrase> drug <phrase>named entity</phrase> in medical text
one essential task in <phrase>information extraction</phrase> from the medical corpus is drug name recognition. <phrase>compared with</phrase> text sources come from other domains the medical text is special and has unique characteristics. <phrase>in addition</phrase> the medical <phrase>text mining</phrase> poses more challenges e.g. more unstructured text the fast growing of new terms addition <phrase>a wide range of</phrase> name variation for <phrase>the same</phrase> drug. the mining is even more challenging <phrase>due to</phrase> <phrase>the lack of</phrase> labeled dataset sources and external knowledge <phrase>as well as</phrase> multiple token representations for <phrase>a single</phrase> drug name that is more common in the real application setting. although many approaches have been proposed to overwhelm the task some problems remained with poor f score performance less than 0.75 . <phrase>this paper</phrase> presents <phrase>a new</phrase> treatment in data representation techniques <phrase>to overcome</phrase> some of those challenges. we propose three data representation techniques <phrase>based on</phrase> the characteristics of word distribution and word similarities as a result of <phrase>word embedding</phrase> training. the first technique is evaluated with the standard nn model i.e. mlp <phrase>multi layer</phrase> perceptrons . the second technique involves two <phrase>deep network</phrase> classifiers i.e. dbn deep belief networks and sae stacked denoising encoders . the third technique represents the sentence as a sequence that is evaluated with a recurrent nn model i.e. lstm <phrase>long short term memory</phrase> . in extracting the drug name entities the third technique gives <phrase>the best</phrase> f score performance <phrase>compared to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> with its average f score being 0.8645.
dopelearning a computational <phrase>approach to</phrase> rap lyrics generation
writing rap lyrics requires both creativity to construct a meaningful interesting story and lyrical skills <phrase>to produce</phrase> complex rhyme patterns which form the cornerstone of good flow. we present a rap lyrics generation method that captures both of these aspects. first we develop a prediction model to identify the next line of existing lyrics from <phrase>a set of</phrase> candidate next lines. this model is <phrase>based on</phrase> two <phrase>machine learning</phrase> techniques the ranksvm algorithm and <phrase>a deep neural network</phrase> model with <phrase>a novel</phrase> structure. <phrase>results show</phrase> that the prediction model can identify the true next line among 299 randomly selected lines with an accuracy of 17 i.e. over 50 times more likely than by random. second we employ the prediction model to combine lines from existing songs producing lyrics with rhyme and a meaning. an evaluation of the produced lyrics shows that <phrase>in terms of</phrase> quantitative rhyme density the method outperforms <phrase>the best</phrase> human rappers by 21 . the rap lyrics generator has been deployed as an online tool called deepbeat and <phrase>the performance of</phrase> the tool has been assessed by analyzing its usage logs. this analysis shows that machine learned rankings correlate with user preferences.
match srnn modeling the recursive matching structure with spatial rnn
semantic matching which aims to determine the matching degree between two texts is a fundamental problem for many nlp applications. recently <phrase>deep learning</phrase> approach has been <phrase>applied to</phrase> <phrase>this problem</phrase> and <phrase>significant improvements</phrase> have been achieved. in <phrase>this paper</phrase> we propose to view <phrase>the generation of</phrase> the global interaction between two texts as a recursive process i.e. the interaction of two texts at each position is a composition of the interactions between their prefixes <phrase>as well as</phrase> the <phrase>word level</phrase> interaction at the current position. <phrase>based on</phrase> this idea we propose <phrase>a novel</phrase> deep architecture namely match srnn to model the recursive matching structure. firstly a tensor is constructed <phrase>to capture</phrase> the <phrase>word level</phrase> interactions. then a spatial rnn is <phrase>applied to</phrase> integrate the local interactions recursively with importance determined by four <phrase>types of</phrase> gates. finally the matching score is calculated <phrase>based on</phrase> the global interaction. we show that after degenerated to the exact matching scenario match srnn can approximate the <phrase>dynamic programming</phrase> process of longest common subsequence. thus there exists a clear interpretation for match srnn. our <phrase>experiments on</phrase> two semantic matching tasks showed <phrase>the effectiveness of</phrase> match srnn and its ability of visualizing the learned matching structure.
piecewise <phrase>latent variables</phrase> for neural variational text processing
<phrase>advances in</phrase> neural <phrase>variational inference</phrase> have facilitated the learning of powerful directed <phrase>graphical models</phrase> with continuous <phrase>latent variables</phrase> <phrase>such as</phrase> variational autoencoders. the hope is that such models will learn <phrase>to represent</phrase> rich multi modal latent factors in <phrase>real world</phrase> data <phrase>such as</phrase> <phrase>natural language</phrase> text. however current models often assume simplistic priors on the <phrase>latent variables</phrase> <phrase>such as</phrase> the uni modal <phrase>gaussian distribution</phrase> which are incapable of representing complex latent factors efficiently. <phrase>to overcome</phrase> this restriction we propose the simple but highly flexible piecewise constant distribution. this distribution has the capacity <phrase>to represent</phrase> an exponential <phrase>number of</phrase> modes of a latent target distribution while remaining mathematically tractable. our <phrase>results demonstrate</phrase> that incorporating this new latent distribution into different models yields substantial improvements in <phrase>natural language</phrase> processing <phrase>tasks such as</phrase> document modeling and <phrase>natural language</phrase> generation for dialogue.
<phrase>recurrent neural networks</phrase> with external memory for <phrase>language understanding</phrase>
<phrase>recurrent neural networks</phrase> rnns have become increasingly popular for <phrase>the task of</phrase> <phrase>language understanding</phrase>. in <phrase>this task</phrase> a semantic tagger is deployed to associate a semantic label to each word in an <phrase>input sequence</phrase>. the success of rnn may be attributed to its <phrase>ability to</phrase> memorize <phrase>long term</phrase> dependence that relates the current time semantic label prediction to the observations many time instances away. however the memory capacity of simple rnns is limited because of the gradient vanishing and exploding problem. we propose to use an external memory <phrase>to improve</phrase> memorization capability of rnns. we conducted <phrase>experiments on</phrase> the atis dataset and observed that <phrase>the proposed</phrase> model was <phrase>able to</phrase> achieve the <phrase>state of</phrase> <phrase>the art</phrase> results. we compare our <phrase>proposed model</phrase> with alternative models and report analysis results that may provide insights for future research.
<phrase>a neural network</phrase> <phrase>approach to</phrase> context sensitive generation of conversational responses
we present <phrase>a novel</phrase> <phrase>response generation</phrase> system that can be <phrase>trained end to end</phrase> on large quantities of unstructured twitter conversations. <phrase>a neural network</phrase> architecture is used <phrase>to address</phrase> sparsity issues that arise when integrating contextual information into classic statistical models allowing the system to take into account previous dialog utterances. our dynamic context <phrase>generative models</phrase> show consistent gains over both context sensitive and non context sensitive <phrase>machine translation</phrase> and <phrase>information retrieval</phrase> baselines.
the ubuntu dialogue corpus <phrase>a large</phrase> dataset for research in unstructured multi turn <phrase>dialogue systems</phrase>
<phrase>this paper</phrase> introduces the ubuntu dialogue corpus a dataset containing almost 1 million multi turn dialogues with a total of over 7 million utterances and 100 million words. this provides a unique resource for research into building dialogue managers <phrase>based on</phrase> <phrase>neural language models</phrase> that can make use of large <phrase>amounts of</phrase> unlabeled data. the dataset has both the multi turn property of conversations in the dialog state tracking challenge datasets and the unstructured nature of interactions from microblog services <phrase>such as</phrase> twitter. we also describe two neural learning architectures <phrase>suitable for</phrase> analyzing this dataset and provide benchmark <phrase>performance on</phrase> <phrase>the task of</phrase> selecting <phrase>the best</phrase> next response.
building <phrase>end to end</phrase> <phrase>dialogue systems</phrase> using generative hierarchical <phrase>neural network</phrase> models
we investigate <phrase>the task of</phrase> building <phrase>open domain</phrase> conversational <phrase>dialogue systems</phrase> <phrase>based on</phrase> large dialogue corpora using <phrase>generative models</phrase>. <phrase>generative models</phrase> produce system responses that are autonomously generated word by word opening up the possibility for realistic flexible interactions. in support of this goal we extend the <phrase>recently proposed</phrase> hierarchical recurrent <phrase>encoder decoder</phrase> <phrase>neural network</phrase> to the dialogue domain and demonstrate that this model is competitive with <phrase>state of</phrase> <phrase>the art</phrase> <phrase>neural language models</phrase> and back off <phrase>n gram</phrase> models. we investigate the limitations of this and similar approaches and show how its performance can be improved by bootstrapping the learning from a larger <phrase>question answer</phrase> pair corpus and from pretrained <phrase>word embeddings</phrase>.
<phrase>end to end</phrase> <phrase>attention based</phrase> <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>
many of <phrase>the current state of</phrase> <phrase>the art</phrase> <phrase>large vocabulary</phrase> <phrase>continuous speech</phrase> <phrase>recognition systems</phrase> lvcsr are hybrids of <phrase>neural networks</phrase> and <phrase>hidden markov models</phrase> hmms . most of these systems contain separate components that deal with the acoustic modelling language modelling and sequence decoding. we investigate a more direct approach in which the hmm is replaced with <phrase>a recurrent neural network</phrase> rnn that performs sequence prediction directly at the <phrase>character level</phrase>. alignment between <phrase>the input</phrase> features and the desired character sequence is learned automatically by an <phrase>attention mechanism</phrase> built into the rnn. for each predicted character the <phrase>attention mechanism</phrase> scans <phrase>the input</phrase> sequence and chooses relevant frames. we propose two methods to speed up this operation limiting the scan to <phrase>a subset of</phrase> most promising frames and pooling over time the information contained in neighboring frames thereby reducing source sequence length. integrating an <phrase>n gram</phrase> <phrase>language model</phrase> into the decoding process yields recognition accuracies <phrase>similar to</phrase> other hmm free <phrase>rnn based</phrase> approaches.
towards <phrase>neural network</phrase> based reasoning
we propose neural reasoner a <phrase>framework for</phrase> <phrase>neural network</phrase> based reasoning over <phrase>natural language</phrase> sentences. given a question neural reasoner can infer over multiple supporting facts and find an answer to the question in specific forms. neural reasoner has 1 a specific interaction pooling mechanism allowing it to examine multiple facts and 2 a deep architecture allowing it to model the complicated logical relations in reasoning tasks. assuming no particular structure exists in the question and facts neural reasoner is <phrase>able to</phrase> accommodate different <phrase>types of</phrase> reasoning and different forms of language expressions. despite <phrase>the model</phrase> complexity neural reasoner can still be trained effectively in <phrase>an end to end</phrase> manner. our empirical studies show that neural reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks positional reasoning and path finding proposed in 8 . for example it improves the accuracy on path finding 10k from 33.4 6 to over 98 .
what to talk about and how selective generation using lstms with coarse to fine alignment
we propose <phrase>an end to end</phrase> domain independent neural encoder aligner decoder model for selective generation i.e. the joint task of content selection and surface realization. our model first encodes a full <phrase>set of</phrase> over determined database event records via an lstm based <phrase>recurrent neural network</phrase> then utilizes <phrase>a novel</phrase> coarse to fine aligner to identify the small <phrase>subset of</phrase> salient records to talk about and finally employs a decoder <phrase>to generate</phrase> free form descriptions of the aligned selected records. our <phrase>model achieves</phrase> <phrase>the best</phrase> selection and generation results reported <phrase>to date</phrase> with 59 relative improvement in generation on the benchmark weathergov dataset despite using no specialized features or linguistic resources. using an improved k nearest neighbor beam filter helps further. we also perform <phrase>a series of</phrase> ablations and visualizations to elucidate the contributions of our key model components. lastly we evaluate the generalizability of our model on the robocup dataset and get results that are competitive with or <phrase>better than</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> despite being severely data starved.
reasoning about entailment with neural attention
while most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features <phrase>derived from</phrase> complex <phrase>natural language</phrase> processing pipelines <phrase>in practice</phrase> their performance has been only slightly <phrase>better than</phrase> bag of word pair classifiers using only <phrase>lexical similarity</phrase>. the only attempt <phrase>so far</phrase> to build <phrase>an end to end</phrase> differentiable <phrase>neural network</phrase> for entailment failed to outperform such <phrase>a simple</phrase> similarity classifier. in <phrase>this paper</phrase> we propose a neural model that reads two sentences to determine entailment using <phrase>long short term memory</phrase> units. we extend this model with a word by word neural <phrase>attention mechanism</phrase> that encourages reasoning over entailments of pairs of words and phrases. furthermore we present a qualitative analysis of attention weights <phrase>produced by</phrase> this model demonstrating such reasoning capabilities. on <phrase>a large</phrase> entailment dataset this <phrase>model outperforms</phrase> the previous best neural model and a classifier with engineered features by a substantial margin. it is the first generic <phrase>end to end</phrase> differentiable system that <phrase>achieves state of</phrase> <phrase>the art</phrase> accuracy on a <phrase>textual entailment</phrase> dataset.
highway <phrase>long short term memory</phrase> rnns for distant <phrase>speech recognition</phrase>
in <phrase>this paper</phrase> we extend the deep <phrase>long short term memory</phrase> dlstm <phrase>recurrent neural networks</phrase> <phrase>by introducing</phrase> gated direct connections between memory cells in adjacent layers. these direct links called highway connections enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper lstms. we further introduce the latency controlled bidirectional lstms blstms which can exploit the whole history while keeping the latency under control. efficient algorithms are proposed <phrase>to train</phrase> these novel networks using both frame and sequence discriminative criteria. <phrase>experiments on</phrase> the ami distant <phrase>speech recognition</phrase> dsr task indicate that we can train deeper lstms and achieve better improvement from sequence training with highway lstms hlstms . our novel model obtains 43.9 47.7 wer on ami sdm dev and eval sets outperforming all previous works. it beats the strong dnn and dlstm baselines with 15.7 and 5.3 relative improvement respectively.
neural enquirer learning to query tables with <phrase>natural language</phrase>
we proposed neural enquirer as <phrase>a neural network</phrase> architecture to execute a <phrase>natural language</phrase> nl query on a <phrase>knowledge base</phrase> kb for answers. basically neural enquirer finds the distributed representation of a query and then executes it on <phrase>knowledge base</phrase> tables <phrase>to obtain</phrase> the answer as one of the values in the tables. unlike similar efforts in <phrase>end to end</phrase> training of semantic parsers neural enquirer is fully neuralized it <phrase>not only</phrase> gives distributional representation of the query and the <phrase>knowledge base</phrase> <phrase>but also</phrase> realizes the execution of compositional queries as <phrase>a series of</phrase> differentiable operations with intermediate results <phrase>consisting of</phrase> annotations of the tables at different levels saved on multiple layers of memory. neural enquirer can be trained with <phrase>gradient descent</phrase> with which <phrase>not only</phrase> <phrase>the parameters of</phrase> the controlling components and semantic parsing component <phrase>but also</phrase> the embeddings of the tables and query words can be learned <phrase>from scratch</phrase>. the training can be done in <phrase>an end to end</phrase> fashion but it can take stronger guidance e.g. the step by step supervision for complicated queries and benefit from it. neural enquirer is one <phrase>step towards</phrase> building <phrase>neural network</phrase> systems which <phrase>seek to</phrase> understand language by executing it on <phrase>real world</phrase>. our <phrase>experiments show</phrase> that neural enquirer can learn to execute fairly complicated nl queries on tables with rich structures.
sentence pair scoring towards unified <phrase>framework for</phrase> text comprehension
we review <phrase>the task of</phrase> sentence pair scoring popular in the literature in various forms viewed as answer sentence selection semantic text scoring next utterance ranking recognizing <phrase>textual entailment</phrase> paraphrasing or e.g. a component of <phrase>memory networks</phrase>. we argue that all such tasks are similar from <phrase>the model</phrase> perspective and propose new baselines by comparing <phrase>the performance of</phrase> common ir metrics and popular convolutional recurrent and <phrase>attention based</phrase> <phrase>neural models</phrase> across many sentence pair scoring tasks and datasets. we discuss <phrase>the problem of</phrase> evaluating randomized models propose a statistically grounded methodology and <phrase>attempt to</phrase> improve comparisons by releasing new datasets that are much harder than some of the currently used well explored benchmarks. we introduce <phrase>a unified</phrase> <phrase>open source</phrase> <phrase>software framework</phrase> with easily pluggable models and tasks which enables us to experiment with <phrase>multi task</phrase> reusability of trained sentence model. we set <phrase>a new</phrase> <phrase>state of</phrase> art in <phrase>performance on</phrase> the ubuntu dialogue dataset.
incorporating copying mechanism in <phrase>sequence to sequence</phrase> learning
we address <phrase>an important</phrase> problem in <phrase>sequence to sequence</phrase> seq2seq learning referred to as copying in which certain segments in <phrase>the input</phrase> sequence are selectively replicated in the output sequence. a similar phenomenon is observable in human language communication. for example humans <phrase>tend to</phrase> repeat entity names or even long phrases in conversation. the challenge with regard to copying in seq2seq is that new machinery is needed to decide when <phrase>to perform</phrase> the operation. in <phrase>this paper</phrase> we incorporate copying into <phrase>neural network</phrase> based seq2seq learning and propose <phrase>a new</phrase> model called copynet with <phrase>encoder decoder</phrase> structure. copynet can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub sequences in <phrase>the input</phrase> sequence and put them at proper places in the output sequence. our empirical study on both synthetic <phrase>data sets</phrase> and <phrase>real world</phrase> <phrase>data sets</phrase> demonstrates <phrase>the efficacy of</phrase> copynet. for example copynet can outperform regular <phrase>rnn based</phrase> model with remarkable margins on text summarization tasks.
generating factoid questions with <phrase>recurrent neural networks</phrase> the 30m factoid <phrase>question answer</phrase> corpus
over <phrase>the past</phrase> decade <phrase>large scale</phrase> <phrase>supervised learning</phrase> corpora have enabled <phrase>machine learning</phrase> researchers to make substantial advances. however to this date there are no <phrase>large scale</phrase> <phrase>question answer</phrase> corpora available. in <phrase>this paper</phrase> we present the 30m factoid <phrase>question answer</phrase> corpus an enormous <phrase>question answer</phrase> pair corpus <phrase>produced by</phrase> applying <phrase>a novel</phrase> <phrase>neural network</phrase> architecture on the <phrase>knowledge base</phrase> freebase to transduce facts into <phrase>natural language</phrase> questions. the produced <phrase>question answer</phrase> pairs are evaluated both by human evaluators and using automatic <phrase>evaluation metrics</phrase> including well established <phrase>machine translation</phrase> and sentence similarity metrics. across all evaluation criteria the question generation <phrase>model outperforms</phrase> the competing template based baseline. furthermore when presented to human evaluators the generated questions appear comparable in quality to real human generated questions.
how not to evaluate your dialogue system an empirical study of unsupervised <phrase>evaluation metrics</phrase> for dialogue <phrase>response generation</phrase>
we investigate <phrase>evaluation metrics</phrase> for dialogue <phrase>response generation</phrase> systems where supervised labels <phrase>such as</phrase> task completion are not available. recent works in <phrase>response generation</phrase> have adopted metrics from <phrase>machine translation</phrase> to compare a model s generated response to <phrase>a single</phrase> target response. we show that these metrics correlate very weakly with human judgements in the non technical twitter domain and not at all in the technical ubuntu domain. we provide quantitative and qualitative results highlighting specific weaknesses in existing metrics and provide recommendations for future development of better automatic <phrase>evaluation metrics</phrase> for <phrase>dialogue systems</phrase>.
a hierarchical <phrase>latent variable</phrase> <phrase>encoder decoder</phrase> model for generating dialogues
sequential data often possesses a hierarchical structure with complex dependencies between subsequences <phrase>such as</phrase> found between the utterances in a dialogue. in an effort to model this <phrase>kind of</phrase> generative process we propose <phrase>a neural network</phrase> based generative architecture with latent stochastic variables that span a variable <phrase>number of</phrase> time steps. we apply <phrase>the proposed</phrase> model to <phrase>the task of</phrase> dialogue <phrase>response generation</phrase> and compare it with recent <phrase>neural network</phrase> architectures. we evaluate <phrase>the model</phrase> performance through automatic <phrase>evaluation metrics</phrase> and by carrying out a human evaluation. the <phrase>experiments demonstrate</phrase> that our model improves upon <phrase>recently proposed</phrase> models and that the <phrase>latent variables</phrase> facilitate <phrase>the generation of</phrase> long outputs and maintain the context.
neural associative memory for dual <phrase>sequence modeling</phrase>
many important nlp problems can be posed as dual sequence or <phrase>sequence to sequence</phrase> modeling tasks. <phrase>recent advances in</phrase> building <phrase>end to end</phrase> <phrase>neural architectures</phrase> have been highly successful in solving such tasks. in <phrase>this work</phrase> we propose <phrase>a new</phrase> architecture for dual <phrase>sequence modeling</phrase> that is <phrase>based on</phrase> associative memory. we derive am rnns a recurrent associative memory am which augments generic <phrase>recurrent neural networks</phrase> rnn . this architecture is extended to the dual am rnn which operates on two ams at once. our models achieve very <phrase>competitive results</phrase> on <phrase>textual entailment</phrase>. a qualitative analysis demonstrates that <phrase>long range</phrase> dependencies between source and target sequence can be bridged effectively using dual am rnns. however an initial experiment on auto encoding reveals that these benefits are not exploited by the system when learning <phrase>to solve</phrase> <phrase>sequence to sequence</phrase> tasks which indicates that additional supervision or regularization is needed.
log linear rnns towards <phrase>recurrent neural networks</phrase> with flexible <phrase>prior knowledge</phrase>
we introduce ll rnns log linear rnns an extension of <phrase>recurrent neural networks</phrase> that replaces the softmax <phrase>output layer</phrase> by a log linear <phrase>output layer</phrase> of which the softmax is <phrase>a special</phrase> case. this conceptually simple move has two main advantages. first it allows the learner to combat <phrase>training data</phrase> sparsity by allowing it to model words or more generally output symbols as complex combinations of attributes <phrase>without requiring</phrase> that each combination is directly observed in <phrase>the training data</phrase> as the softmax does . second it permits the inclusion of flexible <phrase>prior knowledge</phrase> in the form of a priori specified modular features where the <phrase>neural network</phrase> component learns to dynamically control the weights of a log linear distribution exploiting these features. we conduct experiments in the domain of language modelling of french that exploit morphological <phrase>prior knowledge</phrase> and show <phrase>an important</phrase> <phrase>decrease in</phrase> perplexity relative to a baseline rnn. we provide other motivating iillustrations and finally argue that the log linear and the <phrase>neural network</phrase> components contribute complementary strengths to the ll rnn the ll aspect allows <phrase>the model</phrase> to incorporate rich <phrase>prior knowledge</phrase> while the nn aspect <phrase>according to</phrase> the <phrase>representation learning</phrase> paradigm allows <phrase>the model</phrase> <phrase>to discover</phrase> novel <phrase>combination of</phrase> characteristics.
embracing data abundance booktest dataset for <phrase>reading comprehension</phrase>
there is a practically unlimited <phrase>amount of</phrase> <phrase>natural language</phrase> data available. still <phrase>recent work</phrase> in text comprehension has <phrase>focused on</phrase> datasets which are small relative to current computing possibilities. this article is making a case for the community to move to larger data and as a step in that direction it is proposing the booktest <phrase>a new</phrase> dataset <phrase>similar to</phrase> the popular children s book test cbt however <phrase>more than</phrase> 60 times larger. we show that training on the new data improves the accuracy of our attention sum reader model on <phrase>the original</phrase> cbt test data by a much larger margin than many recent attempts <phrase>to improve</phrase> <phrase>the model</phrase> architecture. on one <phrase>version of</phrase> the dataset our ensemble even exceeds the human baseline provided by facebook. we then show in our own human study that there is still space for further improvement.
quasi <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> are a powerful tool for modeling sequential data but the dependence of each timestep s computation on the previous timestep s output limits parallelism and makes rnns unwieldy for very long sequences. we introduce quasi <phrase>recurrent neural networks</phrase> qrnns an <phrase>approach to</phrase> neural <phrase>sequence modeling</phrase> that alternates convolutional layers which apply in parallel across timesteps and a minimalist recurrent pooling function that applies in parallel across channels. despite lacking trainable recurrent layers stacked qrnns have better predictive accuracy than stacked lstms of <phrase>the same</phrase> hidden size. <phrase>due to</phrase> their increased parallelism they are up to 16 times faster at train and <phrase>test time</phrase>. <phrase>experiments on</phrase> <phrase>language modeling</phrase> sentiment classification and <phrase>character level</phrase> <phrase>neural machine translation</phrase> demonstrate these advantages and underline the viability of qrnns as a basic building block for <phrase>a variety of</phrase> sequence tasks.
input switched affine networks an rnn architecture designed for interpretability
there exist many problem domains where the interpretability of <phrase>neural network</phrase> models is essential for deployment. here we introduce a recurrent architecture <phrase>composed of</phrase> input switched affine transformations in other words an rnn without any explicit nonlinearities but with input dependent recurrent weights. this simple form allows the rnn to be analyzed via straightforward linear methods we can exactly characterize the linear contribution of each input to <phrase>the model</phrase> predictions we can use a change of basis to disentangle <phrase>input output</phrase> and computational hidden unit subspaces we can fully <phrase>reverse engineer</phrase> the architecture s solution to <phrase>a simple</phrase> task. despite this ease of interpretation <phrase>the input</phrase> switched affine network achieves reasonable <phrase>performance on</phrase> a text modeling tasks and allows greater computational efficiency than networks with standard nonlinearities.
frustratingly short attention spans in neural <phrase>language modeling</phrase>
<phrase>neural language models</phrase> predict the next token using a latent representation of the immediate token history. recently various methods for augmenting <phrase>neural language models</phrase> with an <phrase>attention mechanism</phrase> over a differentiable memory have been proposed. for predicting the next token <phrase>these models</phrase> query information from a memory of the recent history which can facilitate learning mid and <phrase>long range</phrase> dependencies. however conventional attention mechanisms used in memory augmented <phrase>neural language models</phrase> produce <phrase>a single</phrase> output vector per time step. this vector is used both for predicting the next token <phrase>as well as</phrase> for the key and value of a differentiable memory of a token history. in <phrase>this paper</phrase> we propose a neural <phrase>language model</phrase> with a key value <phrase>attention mechanism</phrase> that outputs separate representations for the key and value of a differentiable memory <phrase>as well as</phrase> for encoding the next word distribution. this <phrase>model outperforms</phrase> existing memory augmented <phrase>neural language models</phrase> on two corpora. yet we found that our method mainly utilizes a memory of the five most recent output representations. this led to the unexpected main finding that a much simpler <phrase>model based</phrase> only on the concatenation of recent output representations from previous time steps is on par with more sophisticated memory augmented <phrase>neural language models</phrase>.
a structured self attentive sentence embedding
<phrase>this paper</phrase> proposes <phrase>a new</phrase> model for extracting an interpretable sentence embedding <phrase>by introducing</phrase> self attention. <phrase>instead of</phrase> using a vector we use a 2 d matrix <phrase>to represent</phrase> the embedding with each row of the matrix attending on a different part of the sentence. we also propose a self <phrase>attention mechanism</phrase> and <phrase>a special</phrase> regularization term for <phrase>the model</phrase>. as a side effect the embedding comes with an easy way of visualizing what specific <phrase>parts of</phrase> the sentence are encoded into the embedding. we evaluate our model on 3 different tasks author profiling sentiment classification and <phrase>textual entailment</phrase>. <phrase>results show</phrase> that our model yields a significant performance gain <phrase>compared to</phrase> other sentence embedding methods in all of the 3 tasks.
<phrase>a recurrent neural</phrase> model with attention for the recognition of chinese implicit discourse relations
we introduce an <phrase>attention based</phrase> bi lstm for chinese implicit discourse relations and demonstrate that modeling argument pairs as a joint sequence can outperform <phrase>word order</phrase> agnostic approaches. our model benefits from a partial sampling scheme and is conceptually simple yet <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> the chinese discourse treebank. we also visualize its attention activity to illustrate <phrase>the model</phrase> s <phrase>ability to</phrase> selectively <phrase>focus on</phrase> the relevant <phrase>parts of</phrase> an <phrase>input sequence</phrase>.
event representations for automated story generation with <phrase>deep neural</phrase> nets
automated story generation is <phrase>the problem of</phrase> automatically selecting a sequence of events actions or words that can be told as a story. we <phrase>seek to</phrase> develop a system that can generate stories by learning everything it <phrase>needs to</phrase> know from textual story corpora. <phrase>to date</phrase> <phrase>recurrent neural networks</phrase> that learn <phrase>language models</phrase> at character word or sentence levels have had little success generating coherent stories. we explore the question of event representations that provide a mid level of abstraction between words and sentences <phrase>in order to</phrase> retain the semantic information of <phrase>the original</phrase> data while minimizing event sparsity. we present a technique for preprocessing textual story data into event sequences. we then present a technique for automated story generation whereby we decompose the problem into <phrase>the generation of</phrase> successive events event2event and <phrase>the generation of</phrase> <phrase>natural language</phrase> sentences from events event2sentence . we give empirical results comparing different event representations and their effects on event successor generation and the translation of events to <phrase>natural language</phrase>.
a joint model for <phrase>question answering</phrase> and question generation
we propose a generative machine comprehension model that learns jointly to ask and answer questions <phrase>based on</phrase> documents. <phrase>the proposed</phrase> model uses a <phrase>sequence to sequence</phrase> framework that encodes the document and generates a <phrase>question answer</phrase> given an answer question . <phrase>significant improvement</phrase> in model performance is observed empirically on the squad corpus confirming our hypothesis that <phrase>the model</phrase> benefits from jointly learning <phrase>to perform</phrase> both tasks. we believe the joint model s novelty offers <phrase>a new</phrase> perspective on machine comprehension beyond <phrase>architectural engineering</phrase> and serves as a first <phrase>step towards</phrase> autonomous information seeking.
learning intrinsic sparse structures within <phrase>long short term memory</phrase>
model compression is significant for the wide adoption of <phrase>recurrent neural networks</phrase> rnns in both user devices possessing limited resources and business clusters requiring quick responses to <phrase>large scale</phrase> service requests. <phrase>this work</phrase> aims <phrase>to learn</phrase> structurally sparse <phrase>long short term memory lstm</phrase> by reducing the sizes of basic structures within lstm units including input updates gates hidden states cell states and outputs. independently reducing the sizes of basic structures can result in inconsistent dimensions among them and consequently end up with invalid lstm units. <phrase>to overcome</phrase> the problem we propose intrinsic sparse structures iss in lstms. removing a component of iss will simultaneously decrease the sizes of all basic structures by one and thereby always maintain the dimension consistency. by learning iss within lstm units the obtained lstms remain regular while having much smaller basic structures. <phrase>based on</phrase> group lasso regularization our method achieves 10.59x speedup without losing any perplexity of a <phrase>language modeling</phrase> of <phrase>penn treebank</phrase> dataset. it is also successfully evaluated through a compact model with only 2.69m weights for machine <phrase>question answering</phrase> of squad dataset. our approach is successfully extended to non lstm rnns like recurrent highway networks rhns . our <phrase>source code</phrase> is <phrase>publicly available</phrase> at https github.com wenwei202 iss rnns
why pairdiff works a <phrase>mathematical analysis</phrase> of bilinear relational compositional operators for analogy detection
representing the semantic relations that exist between two given words or entities is <phrase>an important</phrase> first step in <phrase>a wide range of</phrase> nlp <phrase>applications such as</phrase> analogical reasoning <phrase>knowledge base</phrase> completion and relational <phrase>information retrieval</phrase>. <phrase>a simple</phrase> yet surprisingly accurate <phrase>method for</phrase> representing a relation between two words is to compute the vector offset pairdiff between their corresponding <phrase>word embeddings</phrase>. despite the empirical success it remains unclear as to whether pairdiff is <phrase>the best</phrase> operator for obtaining a relational representation from <phrase>word embeddings</phrase>. we conduct a theoretical analysis of generalised bilinear operators that can be used to measure the ell 2 relational distance between two word pairs. we show that if the <phrase>word embeddings</phrase> are standardised and uncorrelated such an operator will be independent of bilinear terms and can be simplified to a linear form where pairdiff is <phrase>a special</phrase> case. for numerous <phrase>word embedding</phrase> types we empirically verify the uncorrelation assumption demonstrating the general applicability of our theoretical result. moreover we experimentally discover pairdiff from the bilinear relation composition operator on several benchmark analogy datasets.
<phrase>object oriented</phrase> neural programming oonp for document understanding
we propose <phrase>object oriented</phrase> neural programming oonp a <phrase>framework for</phrase> semantically parsing documents in specific domains. basically oonp reads a document and parses it into a predesigned <phrase>object oriented</phrase> <phrase>data structure</phrase> referred to as ontology in <phrase>this paper</phrase> that reflects the <phrase>domain specific</phrase> semantics of the document. an oonp parser models semantic parsing as a decision process a neural net based reader sequentially goes through the document and during the process it builds and updates an intermediate ontology to summarize its partial understanding of the text it covers. oonp supports a rich <phrase>family of</phrase> operations both symbolic and differentiable for composing the ontology and a big <phrase>variety of</phrase> forms both symbolic and differentiable for representing the state and the document. an oonp parser can be trained with supervision of different forms and strength including <phrase>supervised learning</phrase> sl <phrase>reinforcement learning</phrase> rl and hybrid of the two. our <phrase>experiments on</phrase> both synthetic and <phrase>real world</phrase> document parsing tasks have shown that oonp can learn to handle fairly complicated ontology with <phrase>training data</phrase> of modest sizes.
a neural comprehensive ranker ncr for <phrase>open domain</phrase> <phrase>question answering</phrase>
<phrase>this paper</phrase> proposes <phrase>a novel</phrase> neural machine reading model for <phrase>open domain</phrase> <phrase>question answering</phrase> at scale. existing machine comprehension models typically assume that a short piece of relevant text containing answers is already identified and given to the models from which the models are designed <phrase>to extract</phrase> answers. this assumption however is not realistic for building <phrase>a large</phrase> scale <phrase>open domain</phrase> <phrase>question answering</phrase> system which requires both deep text understanding and identifying relevant text from corpus simultaneously. in <phrase>this paper</phrase> we introduce neural comprehensive ranker ncr that integrates both passage ranking and answer extraction in one single framework. a q a system <phrase>based on</phrase> this framework allows users to issue an <phrase>open domain</phrase> question without needing to provide a piece of text that must contain the answer. <phrase>experiments show</phrase> that the unified ncr model is <phrase>able to</phrase> outperform the states of <phrase>the art</phrase> in both retrieval of relevant text and answer extraction.
improving <phrase>speech recognition</phrase> by revising <phrase>gated recurrent</phrase> units
<phrase>speech recognition</phrase> is largely taking <phrase>advantage of</phrase> <phrase>deep learning</phrase> showing that substantial benefits can be <phrase>obtained by</phrase> modern <phrase>recurrent neural networks</phrase> rnns . the most popular rnns are <phrase>long short term memory</phrase> lstms which typically reach <phrase>state of</phrase> <phrase>the art</phrase> performance in many tasks thanks to their <phrase>ability to</phrase> learn <phrase>long term</phrase> dependencies and robustness to vanishing gradients. nevertheless lstms have a rather complex design with three multiplicative gates that might impair their efficient implementation. an <phrase>attempt to</phrase> simplify lstms has recently led to <phrase>gated recurrent</phrase> units grus which are <phrase>based on</phrase> just two multiplicative gates. <phrase>this paper</phrase> builds on these efforts by further revising grus and proposing a simplified architecture potentially more <phrase>suitable for</phrase> <phrase>speech recognition</phrase>. the contribution of <phrase>this work</phrase> is two fold. first we suggest to remove the reset gate in the gru design resulting in a <phrase>more efficient</phrase> single gate architecture. second we propose to replace tanh with relu activations in the state update equations. <phrase>results show</phrase> that in our implementation the revised architecture reduces the per epoch training time with <phrase>more than</phrase> 30 and consistently improves recognition performance across different tasks <phrase>input features</phrase> and noisy conditions when <phrase>compared to</phrase> a standard gru.
integrating planning for task completion dialogue policy learning
training a task completion dialogue agent with real users via <phrase>reinforcement learning</phrase> rl could be prohibitively expensive because it requires many interactions with users. one alternative is to resort to a user simulator while the discrepancy of between simulated and real users makes the learned policy unreliable <phrase>in practice</phrase>. <phrase>this paper</phrase> addresses these challenges by integrating planning into the dialogue policy learning <phrase>based on</phrase> dyna q framework and provides a more sample efficient <phrase>approach to</phrase> learn the dialogue polices. <phrase>the proposed</phrase> agent <phrase>consists of</phrase> a planner <phrase>trained on</phrase> line with limited real <phrase>user experience</phrase> that can generate large <phrase>amounts of</phrase> simulated experience to supplement with limited real <phrase>user experience</phrase> and a policy model <phrase>trained on</phrase> these hybrid experiences. <phrase>the effectiveness of</phrase> our approach is validated on a movie booking task in both a simulation setting and a human in the loop setting.
building dnn <phrase>acoustic models</phrase> for <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>
<phrase>deep neural networks</phrase> dnns are now a central component of nearly all <phrase>state of</phrase> <phrase>the art</phrase> <phrase>speech recognition</phrase> systems. building <phrase>neural network</phrase> <phrase>acoustic models</phrase> requires several design decisions including <phrase>network architecture</phrase> size and training <phrase>loss function</phrase>. <phrase>this paper</phrase> offers an empirical investigation on which <phrase>aspects of</phrase> dnn acoustic model design are most important <phrase>for speech recognition</phrase> system performance. we report dnn classifier performance and final speech recognizer word <phrase>error rates</phrase> and compare dnns using several metrics to quantify factors influencing differences in task performance. our first <phrase>set of</phrase> experiments use the standard switchboard benchmark corpus which contains approximately 300 hours of conversational telephone speech. we compare standard dnns to convolutional networks and present the first experiments using locally connected untied <phrase>neural networks</phrase> for acoustic modeling. we additionally build systems on a corpus of 2 100 hours of <phrase>training data</phrase> by combining the switchboard and fisher corpora. this larger corpus allows us to more thoroughly examine performance of large dnn models with up to ten times more parameters than those typically used in <phrase>speech recognition</phrase> systems. our <phrase>results suggest</phrase> that a relatively simple dnn architecture and optimization technique produces strong results. these findings <phrase>along with</phrase> <phrase>previous work</phrase> help establish <phrase>a set of</phrase> best practices for building dnn hybrid <phrase>speech recognition</phrase> systems with <phrase>maximum likelihood</phrase> training. our experiments in dnn optimization additionally serve as a case study for training dnns with discriminative loss functions for speech tasks <phrase>as well as</phrase> dnn classifiers more generally.
deep <phrase>recurrent neural networks</phrase> for acoustic modelling
we present <phrase>a novel</phrase> deep <phrase>recurrent neural network rnn</phrase> model for acoustic modelling in <phrase>automatic speech recognition</phrase> asr . we term our contribution as a tc dnn blstm dnn model <phrase>the model</phrase> combines <phrase>a deep neural network</phrase> dnn with time convolution tc followed by a bidirectional <phrase>long short term memory</phrase> blstm and a final dnn. the first dnn acts as a feature processor to our model the blstm then generates a context from the sequence acoustic signal and <phrase>the final</phrase> dnn takes the context and models the posterior probabilities of the acoustic states. we achieve a 3.47 wer on the <phrase>wall street</phrase> journal wsj eval92 task or <phrase>more than</phrase> 8 relative improvement over the baseline dnn models.
regularizing rnns by stabilizing activations
we stabilize the activations of <phrase>recurrent neural networks</phrase> rnns by penalizing the squared distance between successive hidden states norms. this penalty term is <phrase>an effective</phrase> regularizer for rnns including lstms and irnns improving <phrase>performance on</phrase> <phrase>character level</phrase> <phrase>language modeling</phrase> and <phrase>phoneme recognition</phrase> and outperforming weight noise and dropout. we achieve competitive performance 18.6 per on the timit <phrase>phoneme recognition</phrase> task for rnns evaluated without <phrase>beam search</phrase> or an rnn transducer. with this penalty term irnn can achieve similar performance to lstm on <phrase>language modeling</phrase> although adding the penalty term to the lstm results in superior performance. our penalty term also prevents the <phrase>exponential growth</phrase> of irnn s activations outside of their training horizon allowing them to generalize to much longer sequences.
outrageously large <phrase>neural networks</phrase> the sparsely gated mixture of experts layer
the capacity of <phrase>a neural network</phrase> to absorb information is limited by its <phrase>number of</phrase> parameters. conditional computation where <phrase>parts of</phrase> <phrase>the network</phrase> are active on a per example basis has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. <phrase>in practice</phrase> however there are significant algorithmic and performance challenges. in <phrase>this work</phrase> we address these challenges and finally realize the promise of conditional computation achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern gpu clusters. we introduce a sparsely gated mixture of experts layer moe <phrase>consisting of</phrase> up to thousands of <phrase>feed forward</phrase> sub networks. a trainable gating network determines a sparse <phrase>combination of</phrase> these experts to use for each example. we apply the moe to the tasks of <phrase>language modeling</phrase> and <phrase>machine translation</phrase> where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. we present model architectures in which a moe with up to 137 billion parameters is applied convolutionally between stacked lstm layers. on large <phrase>language modeling</phrase> and <phrase>machine translation</phrase> benchmarks <phrase>these models</phrase> achieve significantly better results than <phrase>state of</phrase> <phrase>the art</phrase> at lower <phrase>computational cost</phrase>.
discourse based objectives for fast unsupervised sentence <phrase>representation learning</phrase>
<phrase>this work</phrase> presents <phrase>a novel</phrase> <phrase>objective function</phrase> for the unsupervised training of <phrase>neural network</phrase> sentence encoders. it exploits signals from paragraph level discourse coherence <phrase>to train</phrase> <phrase>these models</phrase> <phrase>to understand</phrase> text. our objective is purely discriminative allowing us <phrase>to train</phrase> models many times <phrase>faster than</phrase> was possible under prior methods and it yields models which perform well in extrinsic evaluations.
learning convolutional text representations for <phrase>visual question answering</phrase>
<phrase>visual question answering</phrase> is a <phrase>recently proposed</phrase> <phrase>artificial intelligence</phrase> task that requires a deep understanding of both images and texts. in <phrase>deep learning</phrase> images are typically modeled through <phrase>convolutional neural networks</phrase> and texts are typically modeled through <phrase>recurrent neural networks</phrase>. while the requirement for modeling images is <phrase>similar to</phrase> traditional <phrase>computer vision</phrase> <phrase>tasks such as</phrase> <phrase>object recognition</phrase> and <phrase>image classification</phrase> <phrase>visual question answering</phrase> raises a different need for textual representation as <phrase>compared to</phrase> other <phrase>natural language</phrase> processing tasks. in <phrase>this work</phrase> we perform a detailed analysis on <phrase>natural language</phrase> questions in <phrase>visual question answering</phrase>. <phrase>based on</phrase> the analysis we propose to <phrase>rely on</phrase> <phrase>convolutional neural networks</phrase> for learning textual representations. by exploring the various <phrase>properties of</phrase> <phrase>convolutional neural networks</phrase> specialized for text data <phrase>such as</phrase> width and depth we present our cnn inception gate model. we show that our model improves question representations and thus the overall accuracy of <phrase>visual question answering</phrase> models. we <phrase>also show</phrase> that the text representation requirement in <phrase>visual question answering</phrase> is more complicated and comprehensive than that in conventional <phrase>natural language</phrase> processing tasks making it a better task to evaluate textual representation methods. shallow models like fasttext which can obtain comparable results with <phrase>deep learning</phrase> models in tasks like <phrase>text classification</phrase> are not suitable in <phrase>visual question answering</phrase>.
learning phrase representations using rnn <phrase>encoder decoder</phrase> for <phrase>statistical machine translation</phrase>
in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> <phrase>neural network</phrase> model called rnn <phrase>encoder decoder</phrase> that <phrase>consists of</phrase> two <phrase>recurrent neural networks</phrase> rnn . one rnn encodes a sequence of symbols into <phrase>a fixed</phrase> length vector representation and the other decodes the representation into another sequence of symbols. the encoder and decoder of <phrase>the proposed</phrase> model are jointly trained to maximize the <phrase>conditional probability</phrase> of a target sequence given a source sequence. <phrase>the performance of</phrase> a <phrase>statistical machine translation</phrase> system is empirically found <phrase>to improve</phrase> <phrase>by using</phrase> the conditional probabilities of phrase pairs computed by the rnn <phrase>encoder decoder</phrase> as an additional feature in the existing log <phrase>linear model</phrase>. qualitatively we show that <phrase>the proposed</phrase> model learns a semantically and syntactically meaningful representation of linguistic phrases.
<phrase>recurrent neural network</phrase> training with dark <phrase>knowledge transfer</phrase>
<phrase>recurrent neural networks</phrase> rnns particularly <phrase>long short term memory lstm</phrase> have gained much attention in <phrase>automatic speech recognition</phrase> asr . although some successful stories have been reported training rnns remains highly challenging especially with limited <phrase>training data</phrase>. recent research found that a well trained model can be <phrase>used as</phrase> a teacher <phrase>to train</phrase> other child models <phrase>by using</phrase> the predictions generated by the teacher model as supervision. this <phrase>knowledge transfer</phrase> learning has been employed <phrase>to train</phrase> simple neural nets with a complex one so that <phrase>the final</phrase> performance can reach <phrase>a level</phrase> that is infeasible <phrase>to obtain</phrase> by regular training. in <phrase>this paper</phrase> we employ the <phrase>knowledge transfer</phrase> <phrase>learning approach</phrase> <phrase>to train</phrase> rnns precisely lstm using <phrase>a deep neural network</phrase> dnn model as the teacher. this is different from most of the existing research on <phrase>knowledge transfer</phrase> learning since the teacher dnn is assumed to be weaker than the child rnn however our <phrase>experiments on</phrase> an asr task showed that it works fairly well without applying any tricks on the learning scheme <phrase>this approach</phrase> can train rnns successfully even with limited <phrase>training data</phrase>.
<phrase>long short term memory</phrase> based <phrase>recurrent neural network</phrase> architectures for <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>
<phrase>long short term memory lstm</phrase> is <phrase>a recurrent neural network</phrase> rnn architecture that has been designed <phrase>to address</phrase> the vanishing and exploding gradient problems of conventional rnns. unlike feedforward <phrase>neural networks</phrase> rnns have cyclic connections making them powerful for modeling sequences. they have been successfully used for <phrase>sequence labeling</phrase> and sequence prediction <phrase>tasks such as</phrase> <phrase>handwriting recognition</phrase> <phrase>language modeling</phrase> phonetic labeling of acoustic frames. however <phrase>in contrast to</phrase> the <phrase>deep neural networks</phrase> <phrase>the use of</phrase> rnns in <phrase>speech recognition</phrase> has been limited to phone recognition in small scale tasks. in <phrase>this paper</phrase> we present novel lstm based rnn architectures which make <phrase>more effective</phrase> use of <phrase>model parameters</phrase> <phrase>to train</phrase> <phrase>acoustic models</phrase> for <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>. we train and compare <phrase>lstm rnn</phrase> and dnn models at various numbers of parameters and configurations. we show that lstm models converge quickly and give <phrase>state of</phrase> <phrase>the art</phrase> <phrase>speech recognition</phrase> performance for relatively small sized models.
monitoring term drift <phrase>based on</phrase> semantic consistency in an evolving <phrase>vector field</phrase>
<phrase>based on</phrase> the aristotelian concept of potentiality vs. actuality allowing for the study of energy and dynamics in language we propose a field <phrase>approach to</phrase> <phrase>lexical analysis</phrase>. falling back on the distributional hypothesis to statistically model word meaning we used evolving fields as a metaphor to express time dependent changes in a <phrase>vector space</phrase> model by a <phrase>combination of</phrase> random indexing and evolving self organizing maps esom . to monitor semantic drifts within the observation period an experiment was carried out on the term space of a collection of 12.8 million amazon book reviews. for evaluation the semantic consistency of esom term clusters was <phrase>compared with</phrase> their respective neighbourhoods in wordnet and contrasted with distances among term vectors by random indexing. we found that at 0.05 level of significance the terms in the clusters showed a <phrase>high level</phrase> of semantic consistency. tracking the drift of distributional patterns in the term space across time periods we found that consistency decreased but not at a statistically significant level. our method is highly scalable with interpretations in philosophy.
towards better decoding and <phrase>language model</phrase> integration in <phrase>sequence to sequence</phrase> models
the <phrase>recently proposed</phrase> <phrase>sequence to sequence</phrase> seq2seq framework advocates replacing complex <phrase>data processing</phrase> pipelines <phrase>such as</phrase> an entire <phrase>automatic speech recognition</phrase> system with <phrase>a single</phrase> <phrase>neural network</phrase> trained in <phrase>an end to end</phrase> fashion. in this contribution we analyse an <phrase>attention based</phrase> seq2seq <phrase>speech recognition</phrase> system that directly transcribes recordings into characters. we observe two shortcomings overconfidence in its predictions and a tendency <phrase>to produce</phrase> incomplete transcriptions when <phrase>language models</phrase> are used. we propose practical solutions to both problems achieving competitive speaker independent word <phrase>error rates</phrase> on the <phrase>wall street</phrase> journal dataset without separate <phrase>language models</phrase> we reach 10.6 wer while together with a trigram <phrase>language model</phrase> we reach 6.7 wer.
<phrase>neural machine translation</phrase> by jointly learning to align and translate
<phrase>neural machine translation</phrase> is a <phrase>recently proposed</phrase> <phrase>approach to</phrase> <phrase>machine translation</phrase>. unlike the traditional <phrase>statistical machine translation</phrase> the <phrase>neural machine translation</phrase> aims at building <phrase>a single</phrase> <phrase>neural network</phrase> that can be jointly tuned to maximize the translation performance. the models proposed recently for <phrase>neural machine translation</phrase> often belong to a <phrase>family of</phrase> encoder decoders and <phrase>consists of</phrase> an encoder that encodes a <phrase>source sentence</phrase> into <phrase>a fixed</phrase> length vector from which a decoder generates a translation. in <phrase>this paper</phrase> we conjecture that <phrase>the use of</phrase> <phrase>a fixed</phrase> length vector is a bottleneck in improving <phrase>the performance of</phrase> this basic <phrase>encoder decoder</phrase> architecture and propose to extend this by allowing a model to automatically soft search for <phrase>parts of</phrase> a <phrase>source sentence</phrase> that are relevant to predicting a target word without having to form these parts as a hard segment explicitly. with this new approach we achieve a translation performance <phrase>comparable to</phrase> the existing <phrase>state of</phrase> <phrase>the art</phrase> phrase based system on <phrase>the task of</phrase> english to french translation. furthermore qualitative analysis reveals that the soft alignments found by <phrase>the model</phrase> agree well with our intuition.
overcoming the curse of sentence length for <phrase>neural machine translation</phrase> using automatic segmentation
the authors of cho <phrase>et al</phrase>. 2014a have shown that the recently introduced <phrase>neural network</phrase> translation systems <phrase>suffer from</phrase> a significant drop in translation quality when translating long sentences unlike existing phrase based translation systems. in <phrase>this paper</phrase> we propose a way <phrase>to address</phrase> <phrase>this issue</phrase> by automatically segmenting an input sentence into phrases that can be easily translated by the <phrase>neural network</phrase> translation model. once each segment has been independently translated by the <phrase>neural machine translation</phrase> model the translated clauses are concatenated to form a final translation. empirical <phrase>results show</phrase> a <phrase>significant improvement</phrase> in translation quality for long sentences.
transferring knowledge from a rnn to a dnn
<phrase>deep neural network</phrase> dnn <phrase>acoustic models</phrase> have yielded many <phrase>state of</phrase> <phrase>the art</phrase> results in <phrase>automatic speech recognition</phrase> asr tasks. more recently <phrase>recurrent neural network rnn</phrase> models have been <phrase>shown to</phrase> outperform dnns counterparts. however <phrase>state of</phrase> <phrase>the art</phrase> dnn and rnn models <phrase>tend to</phrase> be impractical to deploy on <phrase>embedded systems</phrase> with limited computational capacity. traditionally the approach for embedded platforms is to either train <phrase>a small</phrase> dnn directly or <phrase>to train</phrase> <phrase>a small</phrase> dnn that learns the output distribution of <phrase>a large</phrase> dnn. in <phrase>this paper</phrase> we utilize a <phrase>state of</phrase> <phrase>the art</phrase> rnn to transfer knowledge to small dnn. we use the rnn model <phrase>to generate</phrase> soft alignments and minimize the kullback leibler divergence against the small dnn. the small dnn <phrase>trained on</phrase> the soft rnn alignments achieved a 3.93 wer on the <phrase>wall street</phrase> journal wsj eval92 task <phrase>compared to</phrase> a baseline 4.54 wer or <phrase>more than</phrase> 13 relative improvement.
correlational <phrase>neural networks</phrase>
common <phrase>representation learning</phrase> crl wherein different descriptions or views of the data are embedded in a common subspace is receiving a lot of attention recently. two popular paradigms here are canonical correlation analysis cca <phrase>based approaches</phrase> and autoencoder ae <phrase>based approaches</phrase>. cca <phrase>based approaches</phrase> learn a joint representation by maximizing correlation of the views when projected to the common subspace. ae <phrase>based methods</phrase> learn a common representation by minimizing the error of reconstructing the two views. each of <phrase>these approaches</phrase> has its own advantages and disadvantages. for example while cca <phrase>based approaches</phrase> outperform ae <phrase>based approaches</phrase> for <phrase>the task of</phrase> <phrase>transfer learning</phrase> they are not as scalable as <phrase>the latter</phrase>. in <phrase>this work</phrase> we propose an ae <phrase>based approach</phrase> called correlational <phrase>neural network</phrase> corrnet that explicitly maximizes correlation among the views when projected to the common subspace. through <phrase>a series of</phrase> experiments we demonstrate that <phrase>the proposed</phrase> corrnet is <phrase>better than</phrase> the above mentioned approaches <phrase>with respect to</phrase> its <phrase>ability to</phrase> learn correlated common representations. further we employ corrnet for several cross language tasks and show that the representations learned using corrnet perform <phrase>better than</phrase> the ones learned using other <phrase>state of</phrase> <phrase>the art</phrase> approaches.
<phrase>attention based</phrase> models <phrase>for speech recognition</phrase>
recurrent sequence generators <phrase>conditioned on</phrase> <phrase>input data</phrase> through an <phrase>attention mechanism</phrase> have recently shown very good <phrase>performance on</phrase> <phrase>a range of</phrase> tasks in cluding <phrase>machine translation</phrase> handwriting synthesis and image caption gen eration. we extend the <phrase>attention mechanism</phrase> with features needed <phrase>for speech recognition</phrase>. we show that while an adaptation of <phrase>the model</phrase> used for <phrase>machine translation</phrase> in reaches a competitive 18.7 phoneme <phrase>error rate</phrase> per on the timit <phrase>phoneme recognition</phrase> task it can only be <phrase>applied to</phrase> utterances which are roughly as long as the ones it was <phrase>trained on</phrase>. we offer a qualitative explanation of this failure and propose <phrase>a novel</phrase> and generic method of adding location awareness to the <phrase>attention mechanism</phrase> to alleviate <phrase>this issue</phrase>. the new method yields a model that is robust to long inputs and achieves 18 per in single utterances and 20 in 10 times longer repeated utterances. finally we propose a change to the at tention mechanism that prevents it from concentrating too much on single frames which further reduces per to 17.6 level.
fast and accurate <phrase>recurrent neural network</phrase> <phrase>acoustic models</phrase> <phrase>for speech recognition</phrase>
we have recently shown that deep <phrase>long short term memory lstm</phrase> <phrase>recurrent neural networks</phrase> rnns outperform <phrase>feed forward</phrase> <phrase>deep neural networks</phrase> dnns as <phrase>acoustic models</phrase> <phrase>for speech recognition</phrase>. more recently we have shown that <phrase>the performance of</phrase> sequence trained context dependent cd <phrase>hidden markov model</phrase> hmm <phrase>acoustic models</phrase> using such lstm rnns can be equaled by sequence trained phone models initialized with connectionist temporal classification ctc . in <phrase>this paper</phrase> we present techniques that further <phrase>improve performance</phrase> of <phrase>lstm rnn</phrase> <phrase>acoustic models</phrase> for <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>. we show that frame stacking and reduced <phrase>frame rate</phrase> <phrase>lead to</phrase> <phrase>more accurate</phrase> models and faster decoding. cd phone modeling <phrase>leads to</phrase> further improvements. we <phrase>also present</phrase> initial results for <phrase>lstm rnn</phrase> models outputting words directly.
listen attend and spell
we present listen attend and spell las <phrase>a neural network</phrase> that learns to transcribe speech utterances to characters. unlike traditional dnn hmm models this model learns all the components of a speech recognizer jointly. our system has two components a listener and a speller. the listener is a pyramidal <phrase>recurrent network</phrase> encoder that accepts filter bank spectra as inputs. the speller is an <phrase>attention based</phrase> <phrase>recurrent network</phrase> decoder that emits characters as outputs. <phrase>the network</phrase> produces character sequences without making any independence assumptions between the characters. this is the key improvement of las over previous <phrase>end to end</phrase> ctc models. on <phrase>a subset of</phrase> the <phrase>google voice</phrase> search task las achieves a <phrase>word error rate</phrase> wer of 14.1 without a dictionary or a <phrase>language model</phrase> and 10.3 with <phrase>language model</phrase> rescoring over the top 32 beams. by comparison the <phrase>state of</phrase> <phrase>the art</phrase> cldnn hmm <phrase>model achieves</phrase> a wer of 8.0 .
blackout speeding up <phrase>recurrent neural network</phrase> <phrase>language models</phrase> with very large vocabularies
we propose blackout an <phrase>approximation algorithm</phrase> to efficiently train massive <phrase>recurrent neural network</phrase> <phrase>language models</phrase> rnnlms with million word vocabularies. blackout is <phrase>motivated by</phrase> using a discriminative loss and we describe <phrase>a new</phrase> sampling strategy which significantly reduces computation while improving stability sample efficiency and rate of convergence. one way <phrase>to understand</phrase> blackout is to view it as an extension of the dropout strategy to <phrase>the output layer</phrase> wherein we use a discriminative training loss and a weighted sampling scheme. we also establish close connections between blackout <phrase>importance sampling</phrase> and noise contrastive estimation nce . our <phrase>experiments on</phrase> the recently released one billion word <phrase>language modeling</phrase> benchmark demonstrate scalability and accuracy of blackout we outperform the <phrase>state of</phrase> <phrase>the art</phrase> and achieve the lowest perplexity scores on this dataset. moreover unlike other established methods which typically require gpus or cpu clusters we show that a carefully implemented <phrase>version of</phrase> blackout requires only 1 10 days on <phrase>a single</phrase> machine <phrase>to train</phrase> a rnnlm with a million word vocabulary and billions of parameters on one billion words. although we describe blackout in <phrase>the context of</phrase> rnnlm training it can be used to any networks with large softmax output layers.
character based <phrase>neural machine translation</phrase>
<phrase>neural machine translation</phrase> mt has reached <phrase>state of</phrase> <phrase>the art</phrase> results. however one of the main challenges that neural mt still faces is dealing with very large vocabularies and morphologically rich languages. in <phrase>this paper</phrase> we propose a neural mt system using character based embeddings in combination with convolutional and highway layers to replace the standard lookup based word representations. the resulting unlimited vocabulary and affix aware source <phrase>word embeddings</phrase> are tested in a <phrase>state of</phrase> <phrase>the art</phrase> neural mt <phrase>based on</phrase> an <phrase>attention based</phrase> bidirectional <phrase>recurrent neural network</phrase>. <phrase>the proposed</phrase> mt scheme provides improved results even when the source language is not morphologically rich. improvements up to 3 bleu points are obtained in the german english wmt task.
a <phrase>latent variable</phrase> <phrase>recurrent neural network</phrase> for discourse relation <phrase>language models</phrase>
<phrase>this paper</phrase> presents <phrase>a novel</phrase> <phrase>latent variable</phrase> <phrase>recurrent neural network</phrase> architecture for jointly modeling sequences of words and possibly latent discourse <phrase>relations between</phrase> adjacent sentences. <phrase>a recurrent neural network</phrase> generates individual words thus reaping the benefits of discriminatively trained <phrase>vector representations</phrase>. the discourse relations are represented with a <phrase>latent variable</phrase> which can be predicted or marginalized depending on the task. the resulting model can therefore employ a training objective that includes <phrase>not only</phrase> discourse <phrase>relation classification</phrase> <phrase>but also</phrase> word prediction. as a result it outperforms <phrase>state of</phrase> <phrase>the art</phrase> alternatives for two tasks implicit discourse <phrase>relation classification</phrase> in the penn discourse treebank and dialog act classification in the switchboard corpus. furthermore by marginalizing over latent discourse relations at <phrase>test time</phrase> we obtain a discourse informed <phrase>language model</phrase> which improves over a strong lstm baseline.
<phrase>multi task</phrase> recurrent model for speech and <phrase>speaker recognition</phrase>
although highly correlated speech and <phrase>speaker recognition</phrase> have been regarded as two independent tasks and studied by two communities. this is certainly not the way that people behave we decipher both speech content and speaker traits at <phrase>the same</phrase> time. <phrase>this paper</phrase> presents <phrase>a unified</phrase> model <phrase>to perform</phrase> speech and <phrase>speaker recognition</phrase> simultaneously and altogether. <phrase>the model</phrase> is <phrase>based on</phrase> <phrase>a unified</phrase> <phrase>neural network</phrase> where the output of one task is fed to <phrase>the input</phrase> of the other <phrase>leading to</phrase> a <phrase>multi task</phrase> <phrase>recurrent network</phrase>. <phrase>experiments show</phrase> that the joint <phrase>model outperforms</phrase> the <phrase>task specific</phrase> models on both the two tasks.
hierarchical <phrase>memory networks</phrase>
<phrase>memory networks</phrase> are <phrase>neural networks</phrase> with an <phrase>explicit memory</phrase> component that can be both read and written to by <phrase>the network</phrase>. the memory is often addressed in a soft way using a softmax function making <phrase>end to end</phrase> training with backpropagation possible. however this is not computationally scalable for applications which require <phrase>the network</phrase> to read from extremely large memories. on the other hand it is <phrase>well known</phrase> that hard attention mechanisms <phrase>based on</phrase> <phrase>reinforcement learning</phrase> are challenging <phrase>to train</phrase> successfully. in <phrase>this paper</phrase> we explore a form of hierarchical <phrase>memory network</phrase> which can be considered as a hybrid between hard and soft attention <phrase>memory networks</phrase>. the memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory while also being easier <phrase>to train</phrase> than hard attention over a flat memory. specifically we propose to incorporate maximum inner product search mips in the training and inference procedures for our hierarchical <phrase>memory network</phrase>. we explore <phrase>the use of</phrase> various <phrase>state of</phrase> <phrase>the art</phrase> approximate mips techniques and report <phrase>results on</phrase> simplequestions a challenging <phrase>large scale</phrase> factoid <phrase>question answering</phrase> task.
<phrase>sequence to sequence</phrase> learning as <phrase>beam search</phrase> optimization
<phrase>sequence to sequence</phrase> seq2seq modeling has rapidly become <phrase>an important</phrase> <phrase>general purpose</phrase> nlp tool that has proven effective for many text generation and <phrase>sequence labeling</phrase> tasks. seq2seq builds on <phrase>deep neural</phrase> <phrase>language modeling</phrase> and inherits its remarkable accuracy in estimating local next word distributions. in <phrase>this work</phrase> we introduce a model and <phrase>beam search</phrase> training scheme <phrase>based on</phrase> the work of daume iii and marcu 2005 that extends seq2seq <phrase>to learn</phrase> global sequence scores. this structured approach avoids classical biases <phrase>associated with</phrase> local training and unifies the training loss with the <phrase>test time</phrase> usage while preserving the proven model architecture of seq2seq and its efficient training approach. we show that our system outperforms a highly optimized <phrase>attention based</phrase> seq2seq system and other baselines on <phrase>three different</phrase> <phrase>sequence to sequence</phrase> tasks word ordering parsing and <phrase>machine translation</phrase>.
grounded <phrase>recurrent neural networks</phrase>
in <phrase>this work</phrase> we present the grounded <phrase>recurrent neural network</phrase> grnn <phrase>a recurrent neural network</phrase> architecture <phrase>for multi label</phrase> prediction which explicitly ties labels to specific dimensions of the recurrent hidden state we call this process grounding . the approach is particularly well suited for extracting large numbers of concepts from text. we apply the new model <phrase>to address</phrase> <phrase>an important</phrase> problem in healthcare of understanding what medical concepts are discussed in clinical text. using a <phrase>publicly available</phrase> dataset <phrase>derived from</phrase> intensive care units we learn to label a patient s diagnoses and procedures from their discharge summary. our evaluation shows a clear advantage to using our proposed architecture over <phrase>a variety of</phrase> strong baselines.
latent intention dialogue models
developing a dialogue agent that is <phrase>capable of</phrase> making autonomous decisions and communicating by <phrase>natural language</phrase> is one of the <phrase>long term</phrase> goals of <phrase>machine learning</phrase> research. traditional approaches either <phrase>rely on</phrase> hand crafting <phrase>a small</phrase> state action set for applying <phrase>reinforcement learning</phrase> that is not scalable or constructing deterministic models for learning dialogue sentences that fail <phrase>to capture</phrase> natural conversational variability. in <phrase>this paper</phrase> we propose a latent intention dialogue model lidm that employs a discrete <phrase>latent variable</phrase> <phrase>to learn</phrase> underlying dialogue intentions in the framework of neural <phrase>variational inference</phrase>. in a <phrase>goal oriented</phrase> dialogue scenario these latent intentions can be interpreted as actions guiding <phrase>the generation of</phrase> machine responses which can be further refined autonomously by <phrase>reinforcement learning</phrase>. the experimental evaluation of lidm shows that <phrase>the model</phrase> out performs published benchmarks for both corpus based and human evaluation demonstrating <phrase>the effectiveness of</phrase> discrete <phrase>latent variable</phrase> models for learning <phrase>goal oriented</phrase> dialogues.
<phrase>transfer learning</phrase> <phrase>for speech recognition</phrase> on a budget
<phrase>end to end</phrase> training of automated <phrase>speech recognition</phrase> asr systems requires massive data and compute resources. we explore <phrase>transfer learning</phrase> <phrase>based on</phrase> model adaptation as an approach for training asr models under constrained gpu memory throughput and <phrase>training data</phrase>. we conduct several systematic experiments adapting a wav2letter <phrase>convolutional neural network</phrase> originally trained for english asr to the <phrase>german language</phrase>. we show that this technique allows faster training on consumer grade resources while requiring less <phrase>training data</phrase> <phrase>in order to</phrase> achieve <phrase>the same</phrase> accuracy thereby lowering the cost of training asr models in other languages. model introspection revealed that small adaptations to <phrase>the network</phrase> s weights were sufficient for good performance especially for inner layers.
optimizing expected <phrase>word error rate</phrase> via sampling <phrase>for speech recognition</phrase>
state level minimum bayes risk smbr training has become the de facto standard for sequence level training of <phrase>speech recognition</phrase> <phrase>acoustic models</phrase>. it has an elegant formulation using the expectation semiring and gives large improvements in <phrase>word error rate</phrase> wer over models trained solely using <phrase>cross entropy</phrase> ce or connectionist temporal classification ctc . smbr training optimizes the expected <phrase>number of</phrase> frames at which the reference and hypothesized acoustic states differ. it may be preferable to optimize the expected wer but wer <phrase>does not</phrase> interact well with the expectation semiring and previous approaches <phrase>based on</phrase> computing expected wer exactly involve expanding the lattices used <phrase>during training</phrase>. in <phrase>this paper</phrase> we show how <phrase>to perform</phrase> optimization of the expected wer by sampling paths from the lattices used during conventional smbr training. the gradient of the expected wer is itself an expectation and so may be approximated using <phrase>monte carlo</phrase> sampling. we show experimentally that optimizing wer during acoustic model training gives 5 relative improvement in wer over a well tuned smbr baseline on a 2 channel query <phrase>recognition task</phrase> google home .
<phrase>neural networks</phrase> compression for <phrase>language modeling</phrase>
in <phrase>this paper</phrase> we consider several compression techniques for the <phrase>language modeling</phrase> problem <phrase>based on</phrase> <phrase>recurrent neural networks</phrase> rnns . it is known that conventional rnns e.g lstm based networks in <phrase>language modeling</phrase> are characterized with either high space complexity or substantial inference time. <phrase>this problem</phrase> is especially crucial for mobile applications in which the constant interaction with the remote server is inappropriate. <phrase>by using</phrase> the <phrase>penn treebank</phrase> ptb dataset we compare pruning quantization low rank factorization tensor train decomposition for <phrase>lstm networks</phrase> <phrase>in terms of</phrase> model size and suitability for fast inference.
avoiding your teacher s mistakes training <phrase>neural networks</phrase> with controlled weak supervision
<phrase>training deep neural networks</phrase> requires massive <phrase>amounts of</phrase> <phrase>training data</phrase> but for many tasks only limited labeled data is available. this makes weak supervision attractive using weak or noisy signals like the output of heuristic methods or user click through data for training. in a <phrase>semi supervised</phrase> setting we can use <phrase>a large</phrase> <phrase>set of</phrase> data with weak labels to pretrain <phrase>a neural network</phrase> and then fine tune the parameters with <phrase>a small</phrase> <phrase>amount of</phrase> data with true labels. this feels intuitively sub optimal as these two independent stages leave <phrase>the model</phrase> unaware about the varying label quality. what if we could somehow inform <phrase>the model</phrase> about the label quality in <phrase>this paper</phrase> we propose a <phrase>semi supervised</phrase> learning method where we train two <phrase>neural networks</phrase> in a <phrase>multi task</phrase> fashion a target network and a confidence network . the target network is optimized <phrase>to perform</phrase> a given task and is trained using <phrase>a large</phrase> <phrase>set of</phrase> unlabeled data that are weakly annotated. we propose to weight the gradient updates to the target network using the scores provided by the second confidence network which is <phrase>trained on</phrase> <phrase>a small</phrase> <phrase>amount of</phrase> supervised data. thus we avoid that the weight updates computed from noisy labels harm the quality of the target network model. we evaluate our learning strategy on two different tasks document ranking and sentiment classification. the <phrase>results demonstrate</phrase> that our approach <phrase>not only</phrase> enhances the performance <phrase>compared to</phrase> the baselines <phrase>but also</phrase> speeds up the learning process from weak labels.
uncertainty estimates for efficient <phrase>neural network</phrase> based dialogue policy optimisation
in statistical dialogue management the dialogue manager learns a policy that maps a belief state to an action for the system <phrase>to perform</phrase>. efficient exploration is key to successful policy optimisation. current <phrase>deep reinforcement learning</phrase> methods are very promising but <phrase>rely on</phrase> epsilon greedy exploration thus subjecting the user to a random <phrase>choice of</phrase> action during learning. alternative approaches <phrase>such as</phrase> <phrase>gaussian process</phrase> sarsa gpsarsa estimate uncertainties and are sample efficient <phrase>leading to</phrase> better <phrase>user experience</phrase> but on the expense of a greater <phrase>computational complexity</phrase>. <phrase>this paper</phrase> examines approaches <phrase>to extract</phrase> uncertainty estimates from <phrase>deep q</phrase> networks dqn in <phrase>the context of</phrase> dialogue management. we perform an extensive benchmark of deep bayesian methods <phrase>to extract</phrase> uncertainty estimates namely bayes by backprop dropout its concrete variation bootstrapped ensemble and alpha divergences combining it with dqn algorithm.
on extended <phrase>long short term memory</phrase> and dependent bidirectional <phrase>recurrent neural network</phrase>
in <phrase>this work</phrase> we investigate the memory capability of <phrase>recurrent neural networks</phrase> rnns where this capability is defined as a function that maps an element in a sequence to the current output. we first analyze the system function of <phrase>a recurrent neural network</phrase> rnn cell and provide analytical results for three rnns. they are the simple <phrase>recurrent neural network</phrase> srn the <phrase>long short term memory lstm</phrase> and the <phrase>gated recurrent</phrase> unit gru . <phrase>based on</phrase> the analysis we propose <phrase>a new</phrase> design to extend the memory length of a cell and call it the extended <phrase>long short term memory</phrase> elstm . next we present a dependent bidirectional <phrase>recurrent neural network</phrase> dbrnn for the sequence in sequence out siso problem which is <phrase>more robust</phrase> to previous erroneous predictions. <phrase>extensive experiments</phrase> are carried out on different language tasks to demonstrate the superiority of our proposed elstm and dbrnn solutions.
learning to answer questions from image using <phrase>convolutional neural network</phrase>
in <phrase>this paper</phrase> we propose to employ the <phrase>convolutional neural network</phrase> cnn for the image <phrase>question answering</phrase> qa . our proposed cnn provides <phrase>an end to end</phrase> framework with convolutional architectures for learning <phrase>not only</phrase> the image and question representations <phrase>but also</phrase> their inter modal interactions <phrase>to produce</phrase> the answer. more specifically our model <phrase>consists of</phrase> three cnns one image cnn to encode the image content one sentence cnn to compose the words of the question and one multimodal convolution layer <phrase>to learn</phrase> their joint representation for the classification in the space of candidate answer words. we demonstrate <phrase>the efficacy of</phrase> our <phrase>proposed model</phrase> on the daquar and coco qa datasets which are two <phrase>benchmark datasets</phrase> for the image qa with the performances significantly outperforming the <phrase>state of</phrase> <phrase>the art</phrase>.
stacked attention networks for image <phrase>question answering</phrase>
<phrase>this paper</phrase> presents stacked attention networks sans that learn to answer <phrase>natural language</phrase> questions from images. sans use semantic representation of a question as query to search for the regions in <phrase>an image</phrase> that are <phrase>related to</phrase> the answer. we argue that image <phrase>question answering</phrase> qa often requires multiple steps of reasoning. thus we develop a multiple layer san in which we query <phrase>an image</phrase> multiple times to infer the answer progressively. experiments conducted on four image qa <phrase>data sets</phrase> demonstrate that <phrase>the proposed</phrase> sans <phrase>significantly outperform</phrase> <phrase>previous state of</phrase> <phrase>the art</phrase> approaches. the visualization of the attention layers illustrates the progress that the san locates the relevant visual clues that <phrase>lead to</phrase> the answer of the question layer by layer.
neural module networks
<phrase>visual question answering</phrase> is fundamentally compositional in nature a question like where is the dog shares substructure with questions like what color is the dog and where is the cat <phrase>this paper</phrase> seeks to simultaneously exploit the representational capacity of <phrase>deep networks</phrase> and the compositional linguistic structure of questions. we describe a procedure for constructing and learning neural module networks which compose collections of jointly trained neural modules into <phrase>deep networks</phrase> for <phrase>question answering</phrase>. our approach decomposes questions into their linguistic substructures and uses these structures to dynamically instantiate modular networks with reusable components for recognizing dogs classifying colors etc. . the resulting compound networks are jointly trained. we evaluate our approach on two challenging datasets for <phrase>visual question answering</phrase> achieving <phrase>state of</phrase> <phrase>the art results</phrase> on both the vqa natural image dataset and <phrase>a new</phrase> dataset of complex <phrase>questions about</phrase> abstract shapes.
symbol grounding association in multimodal sequences with missing elements
in <phrase>this paper</phrase> we extend a symbolic association <phrase>framework for</phrase> being <phrase>able to</phrase> handle missing elements in multimodal sequences. the general scope of the work is the symbolic associations of object word mappings as it happens in <phrase>language development</phrase> in infants. in other words two different representations of <phrase>the same</phrase> abstract concepts can associate in both directions. this scenario has been long interested in <phrase>artificial intelligence</phrase> psychology and neuroscience. in <phrase>this work</phrase> we extend a recent approach for multimodal sequences visual and audio to also cope with missing elements in one or both modalities. our method uses two parallel <phrase>long short term</phrase> memories lstms with a learning rule <phrase>based on</phrase> em algorithm. it aligns both lstm outputs via dynamic time warping dtw . we propose to include an extra step for the combination with the max operation for exploiting the common elements between both sequences. the motivation behind is that the combination acts as a condition selector for choosing <phrase>the best</phrase> representation from both lstms. we evaluated <phrase>the proposed</phrase> extension in the following scenarios missing elements in one modality visual or audio and missing elements in both modalities visual and sound . <phrase>the performance of</phrase> our extension reaches better results than <phrase>the original</phrase> model and similar results to individual lstm trained in each modality.
using trusted data <phrase>to train</phrase> <phrase>deep networks</phrase> on labels corrupted by severe noise
the growing importance of massive datasets with the advent of <phrase>deep learning</phrase> makes robustness to label noise a critical property for classifiers to have. sources of label noise include automatic labeling for large datasets non expert labeling and label corruption by data poisoning adversaries. in <phrase>the latter</phrase> case corruptions may be arbitrarily bad even so bad that a classifier predicts the wrong labels with high confidence. to protect against such sources of noise we leverage the fact that <phrase>a small</phrase> <phrase>set of</phrase> clean labels is often <phrase>easy to</phrase> procure. we demonstrate that robustness to label noise up to severe strengths can be <phrase>achieved by</phrase> using <phrase>a set of</phrase> trusted data with clean labels and propose a loss correction that utilizes trusted examples in a data efficient manner to mitigate the effects of label noise on <phrase>deep neural network</phrase> classifiers. across vision and <phrase>natural language</phrase> processing tasks we experiment with various label noises at several strengths and show that our method <phrase>significantly outperforms</phrase> <phrase>existing methods</phrase>.
describing multimedia content using <phrase>attention based</phrase> <phrase>encoder decoder</phrase> networks
whereas <phrase>deep neural networks</phrase> were first mostly used for <phrase>classification tasks</phrase> they are rapidly expanding in the realm of structured output problems where the observed target is <phrase>composed of</phrase> multiple <phrase>random variables</phrase> that have a rich joint distribution given <phrase>the input</phrase>. we focus in <phrase>this paper</phrase> on the case where <phrase>the input</phrase> also has a rich structure and <phrase>the input</phrase> and output structures are somehow related. we describe systems that learn to attend to different places in <phrase>the input</phrase> for each element of the output for <phrase>a variety of</phrase> tasks <phrase>machine translation</phrase> image caption generation video clip description and <phrase>speech recognition</phrase>. all these systems are <phrase>based on</phrase> a shared <phrase>set of</phrase> <phrase>building blocks</phrase> <phrase>gated recurrent</phrase> <phrase>neural networks</phrase> and <phrase>convolutional neural networks</phrase> <phrase>along with</phrase> trained attention mechanisms. we report on <phrase>experimental results</phrase> with these systems showing impressively good performance and the <phrase>advantage of</phrase> the <phrase>attention mechanism</phrase>.
multilingual image description with neural sequence models
in <phrase>this paper</phrase> we present an <phrase>approach to</phrase> multi language image description bringing together insights from <phrase>neural machine translation</phrase> and neural image description. to create a description of <phrase>an image</phrase> for a given <phrase>target language</phrase> our sequence generation models condition on feature vectors from the image the description from the source language and or a multimodal vector computed over the image and a description in the source language. in image description <phrase>experiments on</phrase> the iapr tc12 dataset of images aligned with english and german sentences we find significant and substantial improvements in bleu4 and meteor scores for models trained over multiple languages <phrase>compared to</phrase> a monolingual baseline.
deep embedding for spatial role labeling
<phrase>this paper</phrase> introduces the visually informed embedding of word view a continuous vector representation for a word <phrase>extracted from</phrase> a <phrase>deep neural</phrase> model trained using the microsoft coco <phrase>data set</phrase> to forecast the spatial arrangements between visual objects given a textual description. <phrase>the model</phrase> is <phrase>composed of</phrase> a deep <phrase>multilayer perceptron</phrase> mlp stacked on the top of a <phrase>long short term memory lstm</phrase> network <phrase>the latter</phrase> being preceded by an embedding layer. the view is <phrase>applied to</phrase> transferring multimodal background knowledge to spatial role labeling sprl algorithms which recognize spatial <phrase>relations between</phrase> objects mentioned in the text. <phrase>this work</phrase> also contributes with <phrase>a new</phrase> method <phrase>to select</phrase> complementary features and a fine tuning <phrase>method for</phrase> mlp that improves the f1 measure in classifying the words into spatial roles. the view is evaluated with the task 3 of semeval 2013 benchmark <phrase>data set</phrase> spaceeval.
image to markup generation with coarse to fine attention
we present a neural <phrase>encoder decoder</phrase> model to convert images into presentational markup <phrase>based on</phrase> a scalable coarse to fine <phrase>attention mechanism</phrase>. our method is evaluated in <phrase>the context of</phrase> image to latex generation and we introduce <phrase>a new</phrase> dataset of <phrase>real world</phrase> rendered mathematical expressions paired with latex markup. we show that unlike neural ocr techniques using ctc based models <phrase>attention based</phrase> approaches can tackle this non standard ocr task. our approach outperforms classical mathematical ocr systems by <phrase>a large</phrase> margin on in domain rendered data and with pretraining also performs well on out of domain handwritten data. <phrase>to reduce</phrase> the inference complexity <phrase>associated with</phrase> the <phrase>attention based</phrase> approaches we introduce <phrase>a new</phrase> coarse to fine attention layer that selects a support region before applying attention.
teaching machines to code neural markup generation with visual attention
we present a deep <phrase>recurrent neural network</phrase> model with soft visual attention that learns <phrase>to generate</phrase> latex markup of <phrase>real world</phrase> math formulas given their images. applying neural sequence generation techniques that have been very successful in the fields of <phrase>machine translation</phrase> and image handwriting speech captioning recognition transcription and synthesis we construct <phrase>an image</phrase> to markup model that learns <phrase>to produce</phrase> syntactically and semantically correct latex markup code of over 150 words long and achieves a bleu score of 89 <phrase>the best</phrase> reported <phrase>so far</phrase> for the im2latex problem. we also visually demonstrate that <phrase>the model</phrase> learns to scan the image left right up down much as a human would read it.
evolution in groups a deeper look at synaptic cluster driven evolution of <phrase>deep neural networks</phrase>
a promising paradigm for achieving highly efficient <phrase>deep neural networks</phrase> is the idea of evolutionary deep intelligence which mimics <phrase>biological evolution</phrase> processes to progressively synthesize <phrase>more efficient</phrase> networks. a crucial design factor in evolutionary deep intelligence is the genetic encoding scheme used to simulate heredity and determine the architectures of offspring networks. in <phrase>this study</phrase> we take a deeper look at the <phrase>notion of</phrase> synaptic cluster driven evolution of <phrase>deep neural networks</phrase> which guides the evolution process towards the formation of a highly sparse <phrase>set of</phrase> synaptic clusters in offspring networks. utilizing a synaptic cluster driven genetic encoding the probabilistic encoding of synaptic traits considers <phrase>not only</phrase> individual synaptic properties <phrase>but also</phrase> inter synaptic relationships within <phrase>a deep neural network</phrase>. this process results in highly sparse offspring networks which are particularly tailored for parallel computational devices <phrase>such as</phrase> gpus and <phrase>deep neural network</phrase> accelerator chips. comprehensive <phrase>experimental results</phrase> using four <phrase>well known</phrase> <phrase>deep neural network</phrase> architectures lenet 5 alexnet resnet 56 and detectnet on two different tasks object categorization and <phrase>object detection</phrase> demonstrate the efficiency of <phrase>the proposed</phrase> method. cluster driven genetic encoding scheme synthesizes networks that can <phrase>achieve state of</phrase> <phrase>the art</phrase> performance with significantly smaller <phrase>number of</phrase> synapses than that of <phrase>the original</phrase> ancestor network. sim 125 fold <phrase>decrease in</phrase> synapses for mnist . furthermore the improved cluster efficiency in the generated offspring networks sim 9.71 fold <phrase>decrease in</phrase> clusters for mnist and a sim 8.16 fold <phrase>decrease in</phrase> clusters for kitti is particularly useful for accelerated <phrase>performance on</phrase> <phrase>parallel computing</phrase> hardware architectures <phrase>such as</phrase> those in gpus and <phrase>deep neural network</phrase> accelerator chips.
mesh learning for classifying <phrase>cognitive processes</phrase>
a relatively recent advance in <phrase>cognitive neuroscience</phrase> has been multi voxel pattern analysis mvpa which enables researchers to decode brain states and or the <phrase>type of</phrase> information represented in the brain during a cognitive operation. mvpa methods utilize <phrase>machine learning</phrase> algorithms to distinguish among <phrase>types of</phrase> information or cognitive states represented in the brain <phrase>based on</phrase> distributed patterns of neural activity. in the current investigation we propose <phrase>a new</phrase> approach for representation of neural data for pattern analysis namely a mesh learning model. in <phrase>this approach</phrase> at each time instant a star mesh is formed around each voxel such that the voxel corresponding to the center node is surrounded by its p nearest neighbors. the arc weights of each mesh are estimated from the voxel intensity values by least squares method. the estimated arc weights of all the meshes called mesh arc descriptors mads are then used <phrase>to train</phrase> a classifier <phrase>such as</phrase> <phrase>neural networks</phrase> k nearest neighbor na ive bayes and <phrase>support vector machines</phrase>. <phrase>the proposed</phrase> mesh model was <phrase>tested on</phrase> neuroimaging data acquired via <phrase>functional magnetic resonance imaging</phrase> fmri during a recognition memory experiment using categorized word lists employing a previously established experimental paradigm oztekin badre 2011 . <phrase>results suggest</phrase> that <phrase>the proposed</phrase> mesh <phrase>learning approach</phrase> can provide <phrase>an effective</phrase> algorithm for pattern analysis of brain activity during cognitive processing.
synthesizing <phrase>deep neural network</phrase> architectures using biological synaptic strength distributions
in <phrase>this work</phrase> we perform an exploratory study on synthesizing <phrase>deep neural networks</phrase> using biological synaptic strength distributions and the potential influence of different distributions on modelling performance particularly for the scenario <phrase>associated with</phrase> small <phrase>data sets</phrase>. surprisingly a cnn with convolutional layer synaptic strengths drawn from biologically inspired distributions <phrase>such as</phrase> <phrase>log normal</phrase> or correlated center surround distributions performed relatively well suggesting a possibility for designing <phrase>deep neural network</phrase> architectures that <phrase>do not</phrase> require many data samples <phrase>to learn</phrase> and can sidestep current training procedures while maintaining or boosting modelling performance.
a pso and pattern search based memetic algorithm for svms parameters optimization
addressing the issue of svms parameters optimization <phrase>this study</phrase> proposes an efficient memetic algorithm <phrase>based on</phrase> <phrase>particle swarm optimization</phrase> algorithm pso and pattern search ps . in <phrase>the proposed</phrase> memetic algorithm pso is responsible for exploration of the search space and the detection of the potential regions with optimum solutions while pattern search ps is used <phrase>to produce</phrase> <phrase>an effective</phrase> exploitation on the potential regions <phrase>obtained by</phrase> pso. moreover <phrase>a novel</phrase> probabilistic selection strategy is proposed <phrase>to select</phrase> the appropriate individuals among the current population to undergo local refinement keeping a well balance between exploration and exploitation. <phrase>experimental results</phrase> confirm that the local refinement with ps and our proposed selection strategy are effective and finally demonstrate effectiveness and robustness of <phrase>the proposed</phrase> pso ps based ma for svms parameters optimization.
<phrase>density estimation</phrase> using real nvp
<phrase>unsupervised learning</phrase> of probabilistic models is a central yet challenging problem in <phrase>machine learning</phrase>. specifically designing models with tractable learning sampling inference and evaluation is crucial in solving <phrase>this task</phrase>. we extend the space of such models using <phrase>real valued</phrase> non volume preserving real nvp transformations <phrase>a set of</phrase> powerful invertible and learnable transformations resulting in an <phrase>unsupervised learning</phrase> algorithm with exact log likelihood computation exact sampling exact inference of <phrase>latent variables</phrase> and an interpretable <phrase>latent space</phrase>. we demonstrate its <phrase>ability to</phrase> model natural images on four datasets through sampling log likelihood evaluation and <phrase>latent variable</phrase> manipulations.
evolution strategies as a scalable alternative to <phrase>reinforcement learning</phrase>
we explore <phrase>the use of</phrase> evolution strategies es a class of <phrase>black box</phrase> optimization algorithms as <phrase>an alternative</phrase> to popular mdp based rl techniques <phrase>such as</phrase> q learning and policy gradients. <phrase>experiments on</phrase> mujoco and atari show that es is a viable solution strategy that scales extremely well with <phrase>the number of</phrase> cpus available <phrase>by using</phrase> <phrase>a novel</phrase> communication strategy <phrase>based on</phrase> common random numbers our es implementation only <phrase>needs to</phrase> communicate scalars making it possible to scale to over a thousand parallel workers. this allows us <phrase>to solve</phrase> 3d humanoid walking in 10 minutes and obtain <phrase>competitive results</phrase> on most <phrase>atari games</phrase> after one hour of training. <phrase>in addition</phrase> we highlight several advantages of es as a <phrase>black box</phrase> optimization technique it is invariant to action frequency and delayed rewards tolerant of extremely long horizons and <phrase>does not</phrase> need temporal discounting or <phrase>value function</phrase> approximation.
qmdp net <phrase>deep learning</phrase> for planning under partial observability
<phrase>this paper</phrase> introduces the qmdp net <phrase>a neural network</phrase> architecture for planning under partial observability. the qmdp net combines the strengths of model free learning and <phrase>model based</phrase> planning. it is a recurrent policy network but it represents a policy for a parameterized <phrase>set of</phrase> tasks by connecting a model with a planning algorithm that solves <phrase>the model</phrase> thus embedding the solution structure of planning in a network learning architecture. the qmdp net is fully differentiable and allows for <phrase>end to end</phrase> training. we train a qmdp net on different tasks so that it can generalize to new ones in the parameterized task set and transfer to other similar tasks beyond the set. in preliminary experiments qmdp net showed strong <phrase>performance on</phrase> several robotic tasks in simulation. interestingly while qmdp net encodes the qmdp algorithm it sometimes outperforms the qmdp algorithm in the experiments as a result of <phrase>end to end</phrase> learning.
treeqn and atreec differentiable tree structured models for <phrase>deep reinforcement learning</phrase>
combining deep model free <phrase>reinforcement learning</phrase> with <phrase>on line</phrase> planning is a promising <phrase>approach to</phrase> building on the successes of deep rl. <phrase>on line</phrase> planning with look ahead trees has proven successful in environments where transition models are known a priori. however in complex environments where transition models <phrase>need to</phrase> be learned from data the deficiencies of learned models have limited their utility for planning. <phrase>to address</phrase> these challenges we propose treeqn a differentiable recursive tree structured model that serves as a drop in replacement for any <phrase>value function</phrase> network in deep rl with discrete actions. treeqn dynamically constructs a tree by recursively applying a transition model in a learned abstract <phrase>state space</phrase> and then aggregating predicted rewards and state values using a tree backup to estimate q values. we also propose atreec an <phrase>actor critic</phrase> variant that augments treeqn with a softmax layer to form a stochastic policy network. both approaches are <phrase>trained end to end</phrase> such that the learned model is optimised for its actual use in the tree. we show that treeqn and atreec outperform n step dqn and a2c on a box pushing task <phrase>as well as</phrase> n step dqn and value prediction networks oh <phrase>et al</phrase>. 2017 on multiple <phrase>atari games</phrase>. furthermore we present ablation studies that demonstrate <phrase>the effect of</phrase> different auxiliary losses on learning transition models.
sparse attentive backtracking <phrase>long range</phrase> credit assignment in recurrent networks
a major drawback of backpropagation through time bptt is the difficulty of learning <phrase>long term</phrase> dependencies coming from having to propagate credit information backwards through every single step of the forward computation. this makes bptt both computationally impractical and biologically implausible. for this reason full backpropagation through time is rarely used on long sequences and truncated backpropagation through time is <phrase>used as</phrase> a heuristic. however this usually <phrase>leads to</phrase> biased estimates of the gradient in which longer term dependencies are ignored. addressing <phrase>this issue</phrase> we propose <phrase>an alternative</phrase> algorithm sparse attentive backtracking which might also be <phrase>related to</phrase> principles used by brains <phrase>to learn</phrase> <phrase>long term</phrase> dependencies. sparse attentive backtracking learns an <phrase>attention mechanism</phrase> over the hidden states of <phrase>the past</phrase> and selectively backpropagates through paths with high attention weights. this allows <phrase>the model</phrase> <phrase>to learn</phrase> <phrase>long term</phrase> dependencies while only backtracking for <phrase>a small</phrase> <phrase>number of</phrase> time steps not just from the recent past <phrase>but also</phrase> from attended relevant past states.
stochastic <phrase>deep learning</phrase> in memristive networks
we study <phrase>the performance of</phrase> stochastically trained <phrase>deep neural networks</phrase> dnns whose synaptic weights are implemented using emerging memristive devices that exhibit limited <phrase>dynamic range</phrase> resolution and variability in their programming characteristics. we show that a key device parameter to optimize the learning efficiency of dnns is the variability in its programming characteristics. dnns with such memristive synapses even with <phrase>dynamic range</phrase> as low as 15 and only 32 discrete levels when trained <phrase>based on</phrase> stochastic updates suffer less than 3 loss in accuracy <phrase>compared to</phrase> <phrase>floating point</phrase> software baseline. we also study <phrase>the performance of</phrase> stochastic memristive dnns when <phrase>used as</phrase> inference engines with noise corrupted data and find that if the device variability can be minimized the relative degradation in performance for the stochastic dnn is <phrase>better than</phrase> that of the software baseline. hence our study presents <phrase>a new</phrase> optimization corner for memristive devices for building large noise immune <phrase>deep learning</phrase> systems.
pso mismo modeling strategy for multi step ahead <phrase>time series</phrase> prediction
multi step ahead <phrase>time series</phrase> prediction is one of the most challenging research topics in <phrase>the field of</phrase> <phrase>time series</phrase> modeling and prediction and is continually under research. recently the multiple input several multiple outputs mismo modeling strategy has been proposed as a promising alternative for multi step ahead <phrase>time series</phrase> prediction exhibiting advantages <phrase>compared with</phrase> the two currently dominating strategies the iterated and the direct strategies. built on the established mismo strategy <phrase>this study</phrase> proposes a <phrase>particle swarm optimization</phrase> pso based mismo modeling strategy which is <phrase>capable of</phrase> determining <phrase>the number of</phrase> sub models in a self adaptive mode with varying prediction horizons. <phrase>rather than</phrase> deriving crisp divides with equal size s prediction horizons from the established mismo <phrase>the proposed</phrase> pso mismo strategy implemented with <phrase>neural networks</phrase> employs a heuristic to create flexible divides with varying sizes of prediction horizons and <phrase>to generate</phrase> corresponding sub models providing considerable flexibility in model construction which has been validated with simulated and real datasets.
norm based capacity control in <phrase>neural networks</phrase>
we investigate the capacity convexity and characterization of a general <phrase>family of</phrase> norm constrained <phrase>feed forward</phrase> networks.
improving <phrase>the performance of</phrase> <phrase>neural networks</phrase> in regression tasks using drawering
the method presented extends a given regression <phrase>neural network</phrase> to make its performance improve. the modification affects the learning procedure only hence the extension may be easily omitted during evaluation without any change in prediction. it means that the modified model may be evaluated as quickly as <phrase>the original</phrase> one but tends <phrase>to perform</phrase> better. this improvement is possible because the modification gives better expressive power provides better behaved gradients and works as a regularization. the knowledge gained by the temporarily extended <phrase>neural network</phrase> is contained in the parameters shared with <phrase>the original</phrase> <phrase>neural network</phrase>. the only cost is an increase in learning time.
learning unbiased features
a key element in <phrase>transfer learning</phrase> is <phrase>representation learning</phrase> if representations can be developed that expose the relevant factors underlying the data then new tasks and domains can be learned readily <phrase>based on</phrase> mappings of these salient factors. we propose that <phrase>an important</phrase> aim for these representations are to be unbiased. different forms of <phrase>representation learning</phrase> can be <phrase>derived from</phrase> alternative definitions of unwanted bias e.g. bias to particular tasks domains or irrelevant underlying data dimensions. one very useful <phrase>approach to</phrase> estimating the <phrase>amount of</phrase> bias in a representation comes from maximum mean discrepancy mmd 5 a measure of distance between <phrase>probability distributions</phrase>. we are not the first to suggest that mmd can be a useful criterion in developing representations that apply across multiple domains or tasks 1 . however in <phrase>this paper</phrase> we describe <phrase>a number of</phrase> novel applications of this criterion that we have devised all <phrase>based on</phrase> the idea of developing unbiased representations. these formulations include a standard <phrase>domain adaptation</phrase> framework a method of learning invariant representations an <phrase>approach based on</phrase> noise insensitive autoencoders and <phrase>a novel</phrase> form of <phrase>generative model</phrase>.
compatible value gradients for <phrase>reinforcement learning</phrase> of continuous deep policies
<phrase>this paper</phrase> proposes gprop a <phrase>deep reinforcement learning</phrase> algorithm for continuous policies with compatible function approximation. the algorithm is <phrase>based on</phrase> two innovations. firstly we present a temporal difference based <phrase>method for</phrase> learning the gradient of the <phrase>value function</phrase>. secondly we present the deviator <phrase>actor critic</phrase> dac model which comprises three <phrase>neural networks</phrase> that estimate the <phrase>value function</phrase> its gradient and determine the actor s policy respectively. we evaluate gprop on two challenging tasks a contextual bandit problem constructed from nonparametric regression datasets that is designed to probe the ability of <phrase>reinforcement learning</phrase> algorithms to accurately estimate gradients and the octopus arm a challenging <phrase>reinforcement learning</phrase> benchmark. gprop is competitive with fully supervised methods on the bandit task and achieves <phrase>the best</phrase> performance <phrase>to date</phrase> on the octopus arm.
learning dynamic <phrase>boltzmann machines</phrase> with spike timing dependent plasticity
we propose a particularly structured boltzmann machine which we refer to as a dynamic boltzmann machine dybm as a stochastic model of a multi dimensional <phrase>time series</phrase>. the dybm can have infinitely many layers of units but allows exact and efficient inference and learning when its parameters have a proposed structure. this proposed structure is <phrase>motivated by</phrase> postulates and observations from biological <phrase>neural networks</phrase> that the synaptic weight is strengthened or weakened depending on the timing of spikes i.e. spike timing dependent plasticity or stdp . we show that the learning rule of updating <phrase>the parameters of</phrase> the dybm in the direction of maximizing the likelihood of given <phrase>time series</phrase> can be interpreted as stdp with <phrase>long term potentiation</phrase> and <phrase>long term depression</phrase>. the learning rule has a guarantee of convergence and can be performed in a distributed matter i.e. local in space with limited memory i.e. local in time .
gated graph sequence <phrase>neural networks</phrase>
graph structured data appears frequently in domains including chemistry <phrase>natural language</phrase> semantics <phrase>social networks</phrase> and knowledge bases. in <phrase>this work</phrase> we study <phrase>feature learning</phrase> techniques for graph structured inputs. our starting point is <phrase>previous work</phrase> on graph <phrase>neural networks</phrase> scarselli <phrase>et al</phrase>. 2009 which we modify to use <phrase>gated recurrent</phrase> units and modern optimization techniques and then extend to output sequences. the result is a flexible and broadly useful class of <phrase>neural network</phrase> models that has favorable inductive biases relative to purely sequence based models e.g. lstms when the problem is graph structured. we demonstrate the capabilities on some simple ai babi and graph algorithm <phrase>learning tasks</phrase>. we then show it <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> a problem from program verification in which subgraphs <phrase>need to</phrase> be matched to abstract <phrase>data structures</phrase>.
<phrase>deep reinforcement learning</phrase> in large discrete action spaces
being <phrase>able to</phrase> reason in an environment with <phrase>a large number of</phrase> discrete actions is essential to bringing <phrase>reinforcement learning</phrase> to a larger class of problems. recommender systems industrial plants and <phrase>language models</phrase> are only some of the many <phrase>real world</phrase> tasks involving large numbers of discrete actions for which current methods are difficult or even often impossible to apply. an <phrase>ability to</phrase> generalize over the <phrase>set of</phrase> actions <phrase>as well as</phrase> sub linear complexity relative to the size of the set are both necessary to handle such tasks. current approaches are not <phrase>able to</phrase> provide both of these which motivates the work in <phrase>this paper</phrase>. our <phrase>proposed approach</phrase> leverages prior <phrase>information about</phrase> the actions to embed them in a continuous space upon which it can generalize. additionally approximate nearest neighbor methods allow for logarithmic time lookup complexity relative to <phrase>the number of</phrase> actions which is necessary for time wise tractable training. this combined approach allows <phrase>reinforcement learning</phrase> methods to be <phrase>applied to</phrase> <phrase>large scale</phrase> learning problems previously intractable with current methods. we demonstrate our algorithm s abilities on <phrase>a series of</phrase> tasks having up to one million actions.
value iteration networks
we introduce the value iteration network vin a fully differentiable <phrase>neural network</phrase> with a planning module embedded within. vins can learn to plan and are <phrase>suitable for</phrase> predicting outcomes that involve planning based reasoning <phrase>such as</phrase> policies for <phrase>reinforcement learning</phrase>. key to our approach is <phrase>a novel</phrase> differentiable approximation of the value iteration algorithm which can be represented as <phrase>a convolutional neural network</phrase> and <phrase>trained end to end</phrase> using standard backpropagation. we evaluate vin based policies on discrete and continuous path planning domains and on a <phrase>natural language</phrase> based search task. we show that by learning an explicit planning computation vin policies generalize better to new unseen domains.
recurrent orthogonal networks and long memory tasks
although rnns have been <phrase>shown to</phrase> be powerful tools for processing sequential data finding architectures or optimization strategies that allow them to model very <phrase>long term</phrase> dependencies is still an active area of research. in <phrase>this work</phrase> we carefully analyze two synthetic datasets originally outlined in hochreiter and schmidhuber 1997 which are used to evaluate the ability of rnns to store information over many time steps. we explicitly construct rnn solutions to these problems and using these constructions illuminate both the problems themselves and the way in which rnns store different <phrase>types of</phrase> information in their hidden states. these constructions furthermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices.
learning values across many orders <phrase>of magnitude</phrase>
most <phrase>learning algorithms</phrase> are not invariant to the scale of the function that is being approximated. we propose to adaptively normalize the targets used in learning. this is useful in value based <phrase>reinforcement learning</phrase> where the magnitude of appropriate value approximations can change over time when we update the policy of behavior. our main motivation is prior work on learning <phrase>to play</phrase> <phrase>atari games</phrase> where the rewards were all clipped to a predetermined range. this clipping facilitates learning across many different games with <phrase>a single</phrase> <phrase>learning algorithm</phrase> but a clipped reward function can result in qualitatively different behavior. using the adaptive normalization we can remove this <phrase>domain specific</phrase> heuristic without diminishing overall performance.
genetic architect discovering genomic structure with learned <phrase>neural architectures</phrase>
each <phrase>human genome</phrase> is a 3 billion <phrase>base pair</phrase> <phrase>set of</phrase> encoding instructions. decoding the genome using <phrase>deep learning</phrase> fundamentally differs from most tasks as we <phrase>do not</phrase> know the full structure of the data and therefore cannot design architectures to suit it. as such architectures that fit the structure of genomics should be learned not prescribed. here we develop <phrase>a novel</phrase> <phrase>search algorithm</phrase> applicable across domains that discovers an optimal architecture which simultaneously learns general genomic patterns and identifies the most important sequence motifs in predicting functional genomic outcomes. the architectures we find using this algorithm succeed at using only rna expression data <phrase>to predict</phrase> gene regulatory structure learn human interpretable visualizations of key sequence motifs and surpass <phrase>state of</phrase> <phrase>the art results</phrase> on benchmark genomics challenges.
deep successor <phrase>reinforcement learning</phrase>
learning robust value functions given raw observations and rewards is now possible with model free and <phrase>model based</phrase> <phrase>deep reinforcement learning</phrase> algorithms. there is a third alternative called successor representations sr which decomposes the <phrase>value function</phrase> into two components a reward predictor and a successor map. the successor map represents the expected future state occupancy from any given state and the reward predictor maps states to scalar rewards. the <phrase>value function</phrase> of a state can be computed as the inner product between the successor map and the reward weights. in <phrase>this paper</phrase> we present dsr which generalizes sr within <phrase>an end to end</phrase> <phrase>deep reinforcement learning</phrase> framework. dsr has several appealing properties including increased sensitivity to distal reward changes <phrase>due to</phrase> factorization of reward and world dynamics and the <phrase>ability to</phrase> extract bottleneck states subgoals given successor maps trained under a random policy. we show <phrase>the efficacy of</phrase> our approach on two diverse environments given raw pixel observations simple grid world domains mazebase and the doom <phrase>game engine</phrase>.
rl 2 fast <phrase>reinforcement learning</phrase> via slow <phrase>reinforcement learning</phrase>
<phrase>deep reinforcement learning</phrase> deep rl has been successful in learning sophisticated behaviors automatically however the learning process requires a huge <phrase>number of</phrase> trials. <phrase>in contrast</phrase> animals can learn new tasks in just a few trials benefiting from their <phrase>prior knowledge</phrase> about the world. <phrase>this paper</phrase> seeks to bridge this gap. <phrase>rather than</phrase> designing a fast <phrase>reinforcement learning</phrase> algorithm we propose <phrase>to represent</phrase> it as <phrase>a recurrent neural network</phrase> rnn and learn it from data. in our <phrase>proposed method</phrase> rl 2 the algorithm is encoded in the weights of the rnn which are learned slowly through a <phrase>general purpose</phrase> slow rl algorithm. the rnn receives all information a typical rl algorithm would receive including observations actions rewards and termination flags and it retains its state across episodes in a given <phrase>markov decision process</phrase> mdp . the activations of the rnn store the <phrase>state of</phrase> the fast rl algorithm on the current previously unseen mdp. we evaluate rl 2 experimentally on both small scale and <phrase>large scale</phrase> problems. on the small scale side we train it <phrase>to solve</phrase> randomly generated multi arm bandit problems and finite mdps. after rl 2 is trained its <phrase>performance on</phrase> new mdps is <phrase>close to</phrase> human designed algorithms with optimality guarantees. on the <phrase>large scale</phrase> side we test rl 2 on a vision based navigation task and show that it scales up to <phrase>high dimensional</phrase> problems.
capacity and trainability in <phrase>recurrent neural networks</phrase>
two potential bottlenecks on the expressiveness of <phrase>recurrent neural networks</phrase> rnns are their <phrase>ability to</phrase> store <phrase>information about</phrase> the task in their parameters and to store <phrase>information about</phrase> <phrase>the input</phrase> history in their units. we show experimentally that all common rnn architectures achieve nearly <phrase>the same</phrase> per task and per unit capacity bounds with careful training for <phrase>a variety of</phrase> tasks and stacking depths. they can store an <phrase>amount of</phrase> task information which is linear in <phrase>the number of</phrase> parameters and is approximately 5 bits per parameter. they can additionally store approximately one <phrase>real number</phrase> from their input history per hidden unit. we further find that for several tasks it is the per task parameter capacity bound that determines performance. these <phrase>results suggest</phrase> that many previous results comparing rnn architectures are driven primarily by differences in training effectiveness <phrase>rather than</phrase> differences in capacity. supporting this observation we compare training difficulty for several architectures and show that vanilla rnns are far more difficult <phrase>to train</phrase> yet have slightly higher capacity. finally we propose two novel rnn architectures one of which is easier <phrase>to train</phrase> than the lstm or gru for deeply stacked architectures.
causal regularization
in application <phrase>domains such as</phrase> healthcare we want accurate predictive models that are also causally interpretable. in pursuit of such models we propose a causal regularizer to steer predictive models towards causally interpretable solutions and theoretically study its properties. in <phrase>a large</phrase> scale analysis of <phrase>electronic health records</phrase> ehr our causally regularized <phrase>model outperforms</phrase> its l1 regularized counterpart in causal accuracy and is competitive in predictive performance. we perform <phrase>non linear</phrase> causality analysis by causally regularizing <phrase>a special</phrase> <phrase>neural network</phrase> architecture. we <phrase>also show</phrase> that <phrase>the proposed</phrase> causal regularizer can be used together with neural <phrase>representation learning</phrase> algorithms to yield up to 20 improvement over <phrase>multilayer perceptron</phrase> in detecting multivariate causation a situation common in healthcare where many causal factors should occur simultaneously to have an effect on the target variable.
on the behavior of convolutional nets for <phrase>feature extraction</phrase>
<phrase>deep neural networks</phrase> are <phrase>representation learning</phrase> techniques. <phrase>during training</phrase> a deep net is <phrase>capable of</phrase> generating a descriptive language of unprecedented size and detail in <phrase>machine learning</phrase>. extracting the descriptive language coded within a trained cnn model in the case of image data and reusing it for other purposes is a field of interest as it provides access to the visual descriptors previously learnt by the cnn after processing millions of images <phrase>without requiring</phrase> an expensive training phase. contributions to this field commonly <phrase>known as</phrase> feature representation transfer or <phrase>transfer learning</phrase> have been purely empirical <phrase>so far</phrase> extracting all cnn features from <phrase>a single</phrase> layer <phrase>close to</phrase> the output and testing their performance by feeding them to a classifier. <phrase>this approach</phrase> has provided consistent results although its relevance is limited to <phrase>classification tasks</phrase>. in a completely different approach in <phrase>this paper</phrase> we statistically measure the discriminative power of every single feature found within a deep cnn when used for characterizing every class of 11 datasets. we <phrase>seek to</phrase> provide new insights into the behavior of cnn features particularly the ones from convolutional layers as this can be relevant for their <phrase>application to</phrase> <phrase>knowledge representation</phrase> and reasoning. our results confirm that low and middle level features may behave differently to <phrase>high level</phrase> features but only under certain conditions. we find that all cnn features can be used for <phrase>knowledge representation</phrase> purposes both by their presence or by their absence doubling the information <phrase>a single</phrase> cnn feature may provide. we also study how much noise these features may include and propose a thresholding <phrase>approach to</phrase> discard most of it. all these insights have a direct <phrase>application to</phrase> <phrase>the generation of</phrase> cnn embedding spaces.
flow gan combining <phrase>maximum likelihood</phrase> and adversarial learning in <phrase>generative models</phrase>
adversarial learning of probabilistic models has recently emerged as a promising alternative to <phrase>maximum likelihood</phrase>. implicit models <phrase>such as</phrase> <phrase>generative adversarial networks</phrase> gan often generate better samples <phrase>compared to</phrase> explicit models trained by <phrase>maximum likelihood</phrase>. yet gans sidestep the characterization of an explicit density which makes quantitative evaluations challenging. to bridge this gap we propose flow gans a <phrase>generative adversarial</phrase> network for which we can perform exact likelihood evaluation thus supporting both adversarial and <phrase>maximum likelihood</phrase> training. when trained adversarially flow gans generate <phrase>high quality</phrase> samples but attain extremely poor log likelihood scores inferior even to a <phrase>mixture model</phrase> memorizing <phrase>the training data</phrase> the opposite is true when trained by <phrase>maximum likelihood</phrase>. <phrase>results on</phrase> mnist and <phrase>cifar 10</phrase> demonstrate that hybrid training can attain high held out likelihoods while retaining visual fidelity in the generated samples.
filtering variational objectives
when <phrase>used as</phrase> a surrogate objective for <phrase>maximum likelihood</phrase> estimation in <phrase>latent variable</phrase> models the evidence lower bound elbo produces <phrase>state of</phrase> <phrase>the art</phrase> results. <phrase>inspired by</phrase> this we consider the extension of the elbo to a <phrase>family of</phrase> lower bounds defined by a <phrase>particle filter</phrase> s estimator of the marginal likelihood the filtering variational objectives fivos . fivos take <phrase>the same</phrase> arguments as the elbo but can exploit a model s sequential structure to form tighter bounds. we present results that relate the tightness of fivo s bound to the variance of the <phrase>particle filter</phrase> s estimator by considering the generic case of bounds defined as log transformed likelihood estimators. experimentally we show that training with fivo results in substantial improvements over training <phrase>the same</phrase> model architecture with the elbo on sequential data.
kernel implicit <phrase>variational inference</phrase>
recent progress in <phrase>variational inference</phrase> has paid much attention to the flexibility of variational posteriors. one promising direction is to use implicit distributions i.e. distributions without tractable densities as the variational posterior. however <phrase>existing methods</phrase> on implicit posteriors still face challenges of noisy estimation and computational infeasibility when <phrase>applied to</phrase> models with <phrase>high dimensional</phrase> <phrase>latent variables</phrase>. in <phrase>this paper</phrase> we present <phrase>a new</phrase> approach named kernel implicit <phrase>variational inference</phrase> that addresses these challenges. as far as we know for the first time implicit <phrase>variational inference</phrase> is successfully <phrase>applied to</phrase> bayesian <phrase>neural networks</phrase> which shows <phrase>promising results</phrase> on both regression and <phrase>classification tasks</phrase>.
non markovian control with gated <phrase>end to end</phrase> memory policy networks
<phrase>partially observable</phrase> environments present <phrase>an important</phrase> open challenge in the domain of sequential control learning with delayed rewards. despite numerous attempts during the two last decades the majority of <phrase>reinforcement learning</phrase> algorithms and associated approximate models <phrase>applied to</phrase> this context still assume markovian state transitions. in <phrase>this paper</phrase> we explore <phrase>the use of</phrase> a <phrase>recently proposed</phrase> <phrase>attention based</phrase> model the gated <phrase>end to end</phrase> <phrase>memory network</phrase> for sequential control. we call the resulting model the gated <phrase>end to end</phrase> memory policy network. more precisely we use a model free value based algorithm <phrase>to learn</phrase> policies for partially observed domains using this memory enhanced <phrase>neural network</phrase>. this model is <phrase>end to end</phrase> learnable and it features unbounded memory. indeed because of its <phrase>attention mechanism</phrase> and associated non parametric memory <phrase>the proposed</phrase> model allows us to define an <phrase>attention mechanism</phrase> over the observation stream unlike recurrent models. we show encouraging results that illustrate the capability of our <phrase>attention based</phrase> model in <phrase>the context of</phrase> the continuous state non stationary control problem of stock trading. we <phrase>also present</phrase> an openai gym environment for simulated <phrase>stock exchange</phrase> and explain its relevance as a benchmark for <phrase>the field of</phrase> non markovian decision process learning.
automated problem identification regression vs classification via evolutionary <phrase>deep networks</phrase>
regression or classification this is perhaps the most basic question faced when tackling <phrase>a new</phrase> <phrase>supervised learning</phrase> problem. we present an evolutionary <phrase>deep learning</phrase> edl algorithm that automatically solves this by identifying the question type with high accuracy <phrase>along with</phrase> a proposed deep architecture. typically a significant <phrase>amount of</phrase> human insight and preparation is required prior to executing <phrase>machine learning</phrase> algorithms. for example when creating <phrase>deep neural networks</phrase> <phrase>the number of</phrase> parameters must be selected in advance and furthermore a lot of these choices are made based upon pre existing knowledge of the data <phrase>such as</phrase> <phrase>the use of</phrase> a categorical <phrase>cross entropy</phrase> <phrase>loss function</phrase>. humans are <phrase>able to</phrase> study a dataset and decide whether it represents a classification or a regression problem and consequently make decisions which will be <phrase>applied to</phrase> the execution of the <phrase>neural network</phrase>. we propose the automated problem identification api algorithm which uses an <phrase>evolutionary algorithm</phrase> interface to tensorflow to manipulate <phrase>a deep neural network</phrase> to decide if a dataset represents a classification or a regression problem. we test api on 16 different classification regression and <phrase>sentiment analysis</phrase> datasets with up to 10 000 features and up to 17 000 unique target values. api achieves an average accuracy of 96.3 in identifying the problem type without hardcoding any insights about the general characteristics of regression or <phrase>classification problems</phrase>. for example api successfully identifies <phrase>classification problems</phrase> even with 1000 target values. furthermore the algorithm recommends which <phrase>loss function</phrase> to use and also recommends <phrase>a neural network</phrase> architecture. our work is therefore a <phrase>step towards</phrase> fully automated <phrase>machine learning</phrase>.
<phrase>a simple</phrase> neural attentive meta learner
<phrase>deep neural networks</phrase> excel in regimes with large <phrase>amounts of</phrase> data but <phrase>tend to</phrase> struggle when data is scarce or when they <phrase>need to</phrase> adapt quickly to changes in the task. in response <phrase>recent work</phrase> in <phrase>meta learning</phrase> proposes training a meta learner on a distribution of similar tasks in the hopes of generalization to novel but related tasks by learning a <phrase>high level</phrase> strategy that captures the essence of the problem it is asked <phrase>to solve</phrase>. however many recent <phrase>meta learning</phrase> approaches are extensively hand designed either using architectures specialized to a particular application or hard coding algorithmic components that constrain how the meta learner solves the task. we propose a class of simple and generic meta learner architectures that use <phrase>a novel</phrase> <phrase>combination of</phrase> temporal convolutions and soft attention the former to aggregate information from past experience and <phrase>the latter</phrase> to pinpoint specific pieces of information. in the most extensive <phrase>set of</phrase> <phrase>meta learning</phrase> experiments <phrase>to date</phrase> we evaluate the resulting simple neural attentive learner or snail on several heavily benchmarked tasks. on all tasks in both supervised and <phrase>reinforcement learning</phrase> snail attains <phrase>state of</phrase> <phrase>the art</phrase> performance by significant margins.
kafnets kernel based non parametric <phrase>activation functions</phrase> for <phrase>neural networks</phrase>
<phrase>neural networks</phrase> are generally built by interleaving adaptable linear layers with fixed nonlinear <phrase>activation functions</phrase>. to increase their flexibility several authors have proposed methods for adapting the <phrase>activation functions</phrase> themselves endowing them with varying degrees of flexibility. none of <phrase>these approaches</phrase> however have gained wide acceptance <phrase>in practice</phrase> and research in this topic remains open. in <phrase>this paper</phrase> we introduce <phrase>a novel</phrase> <phrase>family of</phrase> flexible <phrase>activation functions</phrase> that are <phrase>based on</phrase> an inexpensive kernel expansion at every neuron. leveraging over several <phrase>properties of</phrase> kernel based models we propose multiple variations for designing and initializing these kernel <phrase>activation functions</phrase> kafs including a multidimensional scheme allowing to nonlinearly combine information from different paths in <phrase>the network</phrase>. the resulting kafs can approximate any mapping defined over <phrase>a subset of</phrase> the <phrase>real line</phrase> either convex or nonconvex. furthermore they are smooth over their entire domain linear in their parameters and they can be regularized using any known scheme including <phrase>the use of</phrase> ell 1 penalties to enforce sparseness. to <phrase>the best</phrase> of our knowledge no other known model satisfies all these properties simultaneously. <phrase>in addition</phrase> we provide a relatively complete overview on alternative techniques for adapting the <phrase>activation functions</phrase> which is currently lacking in the literature. <phrase>a large</phrase> <phrase>set of</phrase> experiments validates our proposal.
learning <phrase>model based</phrase> planning <phrase>from scratch</phrase>
<phrase>conventional wisdom</phrase> holds that <phrase>model based</phrase> planning is a powerful <phrase>approach to</phrase> sequential <phrase>decision making</phrase>. it is often very challenging <phrase>in practice</phrase> however because while a model can be used to evaluate a plan it <phrase>does not</phrase> prescribe how to construct a plan. here we introduce the imagination based planner the first <phrase>model based</phrase> sequential <phrase>decision making</phrase> agent that can learn to construct evaluate and execute plans. before any action it can perform a variable <phrase>number of</phrase> imagination steps which involve proposing an imagined action and evaluating it with its <phrase>model based</phrase> imagination. all imagined actions and outcomes are aggregated iteratively into a plan context which conditions future real and imagined actions. the agent can even decide how to imagine testing out alternative imagined actions chaining sequences of actions together or building a more complex imagination tree by navigating flexibly among the previously imagined states using a learned policy. and our agent can learn to plan economically jointly optimizing for external rewards and computational costs <phrase>associated with</phrase> using its imagination. we show that our architecture can learn <phrase>to solve</phrase> a challenging continuous control problem and also learn elaborate planning strategies in a discrete maze solving task. our work opens <phrase>a new</phrase> direction toward learning the components of a <phrase>model based</phrase> planning system and how to use them.
recurrent ladder networks
we propose a recurrent extension of the ladder networks whose structure is <phrase>motivated by</phrase> the inference required in hierarchical <phrase>latent variable</phrase> models. we demonstrate that the recurrent ladder is <phrase>able to</phrase> handle a wide <phrase>variety of</phrase> complex <phrase>learning tasks</phrase> that benefit from iterative inference and temporal modeling. the architecture shows <phrase>close to</phrase> optimal <phrase>results on</phrase> temporal modeling of video data <phrase>competitive results</phrase> on music modeling and improved perceptual grouping <phrase>based on</phrase> higher order abstractions <phrase>such as</phrase> stochastic textures and motion cues. we present results for fully supervised <phrase>semi supervised</phrase> and unsupervised tasks. the <phrase>results suggest</phrase> that <phrase>the proposed</phrase> architecture and principles are powerful tools for learning a hierarchy of abstractions learning iterative inference and handling temporal information.
generalization in <phrase>deep learning</phrase>
with a direct analysis of <phrase>neural networks</phrase> <phrase>this paper</phrase> presents a mathematically tight generalization theory to partially address an <phrase>open problem</phrase> regarding the generalization of <phrase>deep learning</phrase>. unlike previous bound based theory our main theory is quantitatively as tight as possible for every dataset individually while producing qualitative insights competitively. our results give insight into why and how <phrase>deep learning</phrase> can generalize well despite its large capacity complexity possible algorithmic instability nonrobustness and sharp minima answering to an open question in the literature. we also discuss limitations of our results and propose additional open problems.
parametrizing filters of a cnn with a gan
it is commonly agreed that <phrase>the use of</phrase> relevant invariances as a good statistical bias is important in <phrase>machine learning</phrase>. however most approaches that explicitly incorporate invariances into a model architecture only make use of very simple transformations <phrase>such as</phrase> translations and rotations. hence there is a need for methods to model and extract richer transformations that capture much <phrase>higher level</phrase> invariances. to that end we introduce a tool allowing to parametrize the <phrase>set of</phrase> filters of a trained <phrase>convolutional neural network</phrase> with the <phrase>latent space</phrase> of a <phrase>generative adversarial</phrase> network. we then show that the method can capture highly <phrase>non linear</phrase> invariances of the data by visualizing their effect in the data space.
wider and deeper cheaper and faster tensorized lstms for <phrase>sequence learning</phrase>
<phrase>long short term memory lstm</phrase> is a popular <phrase>approach to</phrase> boosting the ability of <phrase>recurrent neural networks</phrase> to store longer term temporal information. the capacity of an lstm network can be increased by widening and adding layers. however usually the former introduces additional parameters while <phrase>the latter</phrase> increases the runtime. as <phrase>an alternative</phrase> we propose the tensorized lstm in which the hidden states are represented by tensors and updated via a cross layer convolution. by increasing the tensor size <phrase>the network</phrase> can be widened efficiently without additional parameters since the parameters are shared across different locations in the tensor by delaying the output <phrase>the network</phrase> can be deepened implicitly with little additional runtime since deep computations for each timestep are merged into temporal computations of the sequence. experiments conducted on five challenging <phrase>sequence learning</phrase> tasks show the potential of <phrase>the proposed</phrase> model.
learning and <phrase>real time</phrase> classification of hand written digits with <phrase>spiking neural networks</phrase>
we describe <phrase>a novel</phrase> spiking <phrase>neural network</phrase> snn for automated <phrase>real time</phrase> handwritten digit classification and its implementation on a gp gpu platform. <phrase>information processing</phrase> within <phrase>the network</phrase> from <phrase>feature extraction</phrase> to classification is implemented by mimicking the basic <phrase>aspects of</phrase> neuronal spike initiation and propagation in the brain. the <phrase>feature extraction</phrase> layer of the snn uses fixed synaptic weight maps <phrase>to extract</phrase> the key features of the image and the classifier layer uses the recently developed normad approximate <phrase>gradient descent</phrase> based <phrase>supervised learning</phrase> algorithm for <phrase>spiking neural networks</phrase> to adjust the synaptic weights. on the standard mnist database images of handwritten digits our network achieves an accuracy of 99.80 on the <phrase>training set</phrase> and 98.06 on the <phrase>test set</phrase> with nearly 7x <phrase>fewer parameters</phrase> <phrase>compared to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> spiking networks. we further use this network in a gpu based <phrase>user interface</phrase> system demonstrating <phrase>real time</phrase> snn simulation to infer digits written by different users. on a <phrase>test set</phrase> of 500 such images this <phrase>real time</phrase> platform achieves an accuracy exceeding 97 while making a prediction within an snn emulation time of less than 100ms.
overcoming catastrophic forgetting with hard attention to the task
catastrophic forgetting occurs when <phrase>a neural network</phrase> loses the information learned in a previous task after training on subsequent tasks. <phrase>this problem</phrase> remains a hurdle for <phrase>artificial intelligence</phrase> systems with sequential learning capabilities. in <phrase>this paper</phrase> we propose a task based hard <phrase>attention mechanism</phrase> that preserves previous tasks information without affecting the current task s learning. a hard attention mask is learned concurrently to every task through <phrase>stochastic gradient descent</phrase> and previous masks are exploited to condition such learning. we show that <phrase>the proposed</phrase> mechanism is effective for reducing catastrophic forgetting cutting current rates by 45 to 80 . we <phrase>also show</phrase> that it is robust to different hyperparameter choices and that it offers <phrase>a number of</phrase> monitoring capabilities. the approach features the possibility to control both the stability and compactness of the learned knowledge which we believe makes it also attractive for online learning or network compression applications.
detecting and correcting for label shift with <phrase>black box</phrase> predictors
faced with distribution shift between training and <phrase>test set</phrase> we wish to detect and quantify the shift and to correct our classifiers without <phrase>test set</phrase> labels. <phrase>motivated by</phrase> <phrase>medical diagnosis</phrase> where diseases targets cause symptoms observations we <phrase>focus on</phrase> label shift where the label marginal p y changes but the conditional p x y <phrase>does not</phrase>. we propose <phrase>black box</phrase> shift estimation bbse to estimate the test distribution p y . bbse exploits arbitrary <phrase>black box</phrase> predictors <phrase>to reduce</phrase> dimensionality prior to shift correction. while better predictors give tighter estimates bbse works even when predictors are biased inaccurate or uncalibrated so long as their confusion matrices are invertible. we prove bbse s consistency bound its error and introduce a statistical test that uses bbse to detect shift. we also leverage bbse to correct classifiers. <phrase>experiments demonstrate</phrase> accurate estimates and improved prediction even on <phrase>high dimensional</phrase> datasets of natural images.
generalization in <phrase>machine learning</phrase> via analytical learning theory
<phrase>this paper</phrase> introduces <phrase>a novel</phrase> measure theoretic learning theory to analyze generalization behaviors of practical interest. <phrase>the proposed</phrase> learning theory has the following abilities 1 to utilize the qualities of each learned representation on the path <phrase>from raw</phrase> inputs to outputs in <phrase>representation learning</phrase> 2 to guarantee good generalization errors possibly with arbitrarily rich hypothesis spaces e.g. arbitrarily large capacity and rademacher complexity and non stable non robust <phrase>learning algorithms</phrase> and 3 to clearly distinguish each individual problem instance from each other. our generalization bounds are relative to a representation of the data and hold true even if the representation is learned. we discuss several consequences of our <phrase>results on</phrase> <phrase>deep learning</phrase> one <phrase>shot learning</phrase> and <phrase>curriculum learning</phrase>. unlike statistical learning theory <phrase>the proposed</phrase> learning theory analyzes each problem instance individually via <phrase>measure theory</phrase> <phrase>rather than</phrase> <phrase>a set of</phrase> problem instances via statistics. because of the differences in the assumptions and the objectives <phrase>the proposed</phrase> learning theory is meant to be complementary to previous learning theory and is not designed to compete with it.
sensitivity and generalization in <phrase>neural networks</phrase> an empirical study
<phrase>in practice</phrase> it is often found that large over parameterized <phrase>neural networks</phrase> generalize <phrase>better than</phrase> their smaller counterparts an observation that appears to conflict with classical notions of function complexity which typically favor smaller models. in <phrase>this work</phrase> we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity <phrase>related to</phrase> sensitivity to input perturbations. our experiments survey thousands of models with various fully connected architectures optimizers and other hyper parameters <phrase>as well as</phrase> four different <phrase>image classification</phrase> datasets. we find that trained <phrase>neural networks</phrase> are <phrase>more robust</phrase> to input perturbations in the vicinity of <phrase>the training data</phrase> manifold as measured by the norm of <phrase>the input</phrase> output jacobian of <phrase>the network</phrase> and that it correlates well with generalization. we further establish that factors <phrase>associated with</phrase> poor generalization <phrase>such as</phrase> full batch training or using random labels correspond to lower robustness while factors <phrase>associated with</phrase> good generalization <phrase>such as</phrase> <phrase>data augmentation</phrase> and relu non linearities give rise to <phrase>more robust</phrase> functions. finally we demonstrate how <phrase>the input</phrase> output jacobian norm can be predictive of generalization at the level of individual test points.
on the importance of single directions for generalization
despite their <phrase>ability to</phrase> memorize large datasets <phrase>deep neural networks</phrase> often achieve good generalization performance. however the differences between the learned solutions of networks which generalize and those which <phrase>do not</phrase> remain unclear. additionally the tuning <phrase>properties of</phrase> single directions defined as the activation of <phrase>a single</phrase> unit or some <phrase>linear combination</phrase> of units in response to some input have been highlighted but their importance has not been evaluated. here we connect these lines of inquiry to demonstrate that a network s reliance on single directions is a good predictor of its generalization performance across networks <phrase>trained on</phrase> datasets with different fractions of corrupted labels across ensembles of networks <phrase>trained on</phrase> datasets with unmodified labels across different hyperparameters and over the course of training. while dropout only regularizes this quantity up to a point <phrase>batch normalization</phrase> implicitly discourages single direction reliance in part by decreasing the class selectivity of individual units. finally we find that class selectivity is a poor predictor of task importance suggesting <phrase>not only</phrase> that networks which generalize well minimize their dependence on individual units by reducing their selectivity <phrase>but also</phrase> that individually selective units may not be necessary for strong network performance.
maximin affinity learning of <phrase>image segmentation</phrase>
images can be segmented by first using a classifier <phrase>to predict</phrase> an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. <phrase>machine learning</phrase> has been <phrase>applied to</phrase> the affinity classifier <phrase>to produce</phrase> affinity graphs that are good in the sense of minimizing edge misclassification rates. however this error measure is only indirectly <phrase>related to</phrase> the quality of segmentations <phrase>produced by</phrase> ultimately partitioning the affinity graph. we present the first <phrase>machine learning</phrase> algorithm for training a classifier <phrase>to produce</phrase> affinity graphs that are good in the sense of producing segmentations that directly minimize the rand index a <phrase>well known</phrase> segmentation performance measure. the rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. <phrase>by using</phrase> the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph we are <phrase>able to</phrase> train an affinity classifier to directly minimize the rand index of segmentations resulting from the graph partitioning. our <phrase>learning algorithm</phrase> corresponds to the learning of maximin affinities between image pixel pairs which are predictive of the pixel pair connectivity.
a general <phrase>framework for</phrase> development of the cortex like visual <phrase>object recognition</phrase> system waves of spikes predictive coding and universal dictionary of features
<phrase>this study</phrase> is <phrase>focused on</phrase> the development of the cortex like visual <phrase>object recognition</phrase> system. we propose a general framework which <phrase>consists of</phrase> three hierarchical levels modules . these modules functionally correspond to the v1 v4 and it areas. both bottom up and top down connections between the hierarchical levels v4 and it are employed. the higher the degree of matching between <phrase>the input</phrase> and the preferred stimulus the shorter the response time of the neuron. therefore <phrase>information about</phrase> <phrase>a single</phrase> stimulus is distributed in time and is transmitted by the waves of spikes. the reciprocal connections and waves of spikes implement predictive coding an initial hypothesis is generated on the basis of information delivered by the first wave of spikes and is tested with the information carried by the consecutive waves. the development is considered as extraction and accumulation of features in v4 and objects in it. once stored a feature can be disposed if rarely activated. this cause update of feature repository. consequently objects in it are also updated. this illustrates the growing process and dynamical change of topological structures of v4 it and connections between these areas.
handwritten digit recognition with a committee of <phrase>deep neural</phrase> nets on gpus
the competitive mnist handwritten digit recognition benchmark has a long history of broken records since 1998. the most recent substantial improvement by others dates back 7 years <phrase>error rate</phrase> 0.4 . recently we were <phrase>able to</phrase> significantly improve this result using <phrase>graphics cards</phrase> to greatly speed up training of simple but deep mlps which achieved 0.35 outperforming all the previous more complex methods. here we report another substantial improvement 0.31 obtained using a committee of mlps.
eclectic extraction of propositional rules from <phrase>neural networks</phrase>
<phrase>artificial neural network</phrase> is among the most popular algorithm for <phrase>supervised learning</phrase>. however <phrase>neural networks</phrase> have a <phrase>well known</phrase> drawback of being a <phrase>black box</phrase> learner that is not comprehensible to the users. this lack of transparency makes it unsuitable for many high risk <phrase>tasks such as</phrase> <phrase>medical diagnosis</phrase> that requires a rational justification for making a decision. rule extraction methods <phrase>attempt to</phrase> curb this limitation by extracting comprehensible rules from a trained network. many such extraction algorithms have been developed over the years with their respective strengths and weaknesses. they have been broadly categorized into three types <phrase>based on</phrase> their <phrase>approach to</phrase> use internal model of <phrase>the network</phrase>. eclectic methods are hybrid algorithms that combine the other approaches to attain more performance. in <phrase>this paper</phrase> we present an eclectic method called heretic. our algorithm uses inductive <phrase>decision tree</phrase> learning <phrase>combined with</phrase> information of the <phrase>neural network</phrase> structure for extracting logical rules. experiments and theoretical analysis show heretic to be better <phrase>in terms of</phrase> speed and performance.
<phrase>message passing</phrase> <phrase>multi agent</phrase> gans
communicating and sharing intelligence among agents is <phrase>an important</phrase> facet of achieving <phrase>artificial general intelligence</phrase>. as a first <phrase>step towards</phrase> this challenge we introduce <phrase>a novel</phrase> <phrase>framework for</phrase> image generation <phrase>message passing</phrase> <phrase>multi agent</phrase> <phrase>generative adversarial networks</phrase> mpm gans . while gans have recently been <phrase>shown to</phrase> be very effective for image generation and other tasks these networks have been limited to mostly single generator discriminator networks. we show that we can obtain <phrase>multi agent</phrase> gans that communicate through <phrase>message passing</phrase> to achieve better image generation. the objectives of the individual agents in this framework are two fold a co operation objective and a competing objective. the co operation objective ensures that the message sharing mechanism guides the other generator <phrase>to generate</phrase> <phrase>better than</phrase> itself while the competing objective encourages each generator <phrase>to generate</phrase> <phrase>better than</phrase> its counterpart. we analyze and visualize the messages that these gans share among themselves in various scenarios. we quantitatively show that the message sharing formulation serves as a regularizer for the adversarial training. qualitatively we show that the different generators capture different traits of the underlying data distribution.
mode regularized <phrase>generative adversarial networks</phrase>
although <phrase>generative adversarial networks</phrase> <phrase>achieve state of</phrase> <phrase>the art results</phrase> on <phrase>a variety of</phrase> generative tasks they are regarded as highly unstable and prone to miss modes. we argue that these bad behaviors of gans are <phrase>due to</phrase> the very particular functional shape of the trained discriminators in <phrase>high dimensional</phrase> spaces which can easily make training stuck or push probability mass in the wrong direction towards that of higher concentration than that of the data generating distribution. we introduce several ways of regularizing the objective which can dramatically stabilize the training of gan models. we <phrase>also show</phrase> that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution during the early phases of training and thus providing <phrase>a unified</phrase> solution to the missing modes problem.
layer specific adaptive learning rates for <phrase>deep networks</phrase>
the increasing complexity of <phrase>deep learning</phrase> architectures is resulting in training time requiring weeks or even months. this slow training is due in part to vanishing gradients in which the gradients used by <phrase>back propagation</phrase> are extremely large for weights connecting deep layers layers near <phrase>the output layer</phrase> and extremely small for shallow layers near <phrase>the input</phrase> layer this results in slow learning in the shallow layers. additionally it has also been shown that in highly <phrase>non convex</phrase> problems <phrase>such as</phrase> <phrase>deep neural networks</phrase> there is a proliferation of high error low curvature saddle points which slows down learning dramatically. in <phrase>this paper</phrase> we <phrase>attempt to</phrase> overcome the two above problems by proposing an optimization <phrase>method for</phrase> <phrase>training deep neural networks</phrase> which uses learning rates which are both specific to <phrase>each layer</phrase> in <phrase>the network</phrase> and adaptive to the curvature of the function increasing the <phrase>learning rate</phrase> at low curvature points. this enables us to speed up learning in the shallow layers of <phrase>the network</phrase> and quickly escape high error low curvature saddle points. we test our method on standard <phrase>image classification</phrase> datasets <phrase>such as</phrase> mnist cifar10 and imagenet and demonstrate that our method increases accuracy <phrase>as well as</phrase> reduces the required training time over standard algorithms.
return of frustratingly easy <phrase>domain adaptation</phrase>
unlike human learning <phrase>machine learning</phrase> often fails to handle changes between training source and test target input distributions. such domain shifts common in practical scenarios severely damage <phrase>the performance of</phrase> conventional <phrase>machine learning</phrase> methods. supervised <phrase>domain adaptation</phrase> methods have been proposed for the case when the target data have labels including some that perform very well despite being frustratingly <phrase>easy to</phrase> implement. however <phrase>in practice</phrase> the target domain is often unlabeled requiring unsupervised adaptation. we propose <phrase>a simple</phrase> effective and efficient <phrase>method for</phrase> unsupervised <phrase>domain adaptation</phrase> called correlation alignment coral . coral minimizes domain shift by aligning the second order statistics of source and target distributions <phrase>without requiring</phrase> any target labels. even though it is extraordinarily simple it can be implemented in four lines of matlab code coral performs remarkably well in extensive evaluations on standard <phrase>benchmark datasets</phrase>.
origami a 803 gop s w convolutional network accelerator
an ever increasing <phrase>number of</phrase> <phrase>computer vision</phrase> and image <phrase>video processing</phrase> challenges are being approached using <phrase>deep convolutional neural networks</phrase> obtaining <phrase>state of</phrase> <phrase>the art</phrase> results in <phrase>object recognition</phrase> and detection <phrase>semantic segmentation</phrase> action recognition <phrase>optical flow</phrase> and superresolution. <phrase>hardware acceleration</phrase> of these algorithms is essential to adopt these improvements in embedded and mobile <phrase>computer vision</phrase> systems. we present <phrase>a new</phrase> architecture design and implementation <phrase>as well as</phrase> the first reported silicon measurements of such an accelerator outperforming <phrase>previous work</phrase> <phrase>in terms of</phrase> power area and i o efficiency. the manufactured device provides up to 196 gop s on 3.09 mm 2 of silicon in umc 65nm technology and can achieve a power efficiency of 803 gop s w. the massively reduced bandwidth requirements make it the first architecture scalable to top s performance.
option discovery in hierarchical <phrase>reinforcement learning</phrase> using spatio temporal clustering
<phrase>this paper</phrase> introduces an automated skill acquisition framework in <phrase>reinforcement learning</phrase> which involves identifying a hierarchical description of the given task <phrase>in terms of</phrase> abstract states and extended actions between abstract states. identifying such structures present in the task provides ways to simplify and speed up <phrase>reinforcement learning</phrase> algorithms. these structures also help to generalize such algorithms over multiple tasks without relearning policies <phrase>from scratch</phrase>. we use ideas from <phrase>dynamical systems</phrase> to find metastable regions in the <phrase>state space</phrase> and associate them with abstract states. the <phrase>spectral clustering</phrase> algorithm pcca is used to identify suitable abstractions aligned to the underlying structure. skills are defined <phrase>in terms of</phrase> the sequence of actions that <phrase>lead to</phrase> transitions between such abstract states. the connectivity information from pcca is used <phrase>to generate</phrase> these skills or options. these skills are independent of the learning task and can be efficiently reused across <phrase>a variety of</phrase> tasks defined over <phrase>the same</phrase> model. <phrase>this approach</phrase> works well even without the exact model of the environment <phrase>by using</phrase> sample trajectories to construct an approximate estimate. we <phrase>also present</phrase> our <phrase>approach to</phrase> scaling the skill acquisition framework to complex tasks with large state spaces for which we perform state aggregation using the representation learned from an action conditional video prediction network and use the skill acquisition framework on the aggregated <phrase>state space</phrase>.
<phrase>residual networks</phrase> behave like ensembles of relatively shallow networks
in <phrase>this work</phrase> we propose <phrase>a novel</phrase> interpretation of <phrase>residual networks</phrase> showing that they can be seen as a collection of many paths of differing length. moreover <phrase>residual networks</phrase> seem to enable very <phrase>deep networks</phrase> by leveraging only the short paths <phrase>during training</phrase>. to support this observation we rewrite <phrase>residual networks</phrase> as an explicit collection of paths. unlike traditional models paths through <phrase>residual networks</phrase> vary in length. further a lesion study reveals that these paths show ensemble like behavior in the sense that they <phrase>do not</phrase> strongly depend on each other. finally and most surprising most paths are shorter than one might expect and only the short paths are needed <phrase>during training</phrase> as longer paths <phrase>do not</phrase> contribute any gradient. for example most of the gradient in a residual network with 110 layers comes from paths that are only 10 34 layers deep. our results reveal one of the key characteristics that seem to enable the training of very <phrase>deep networks</phrase> <phrase>residual networks</phrase> avoid the vanishing gradient problem <phrase>by introducing</phrase> short paths which can carry gradient throughout the extent of very <phrase>deep networks</phrase>.
synthesizing the preferred inputs for neurons in <phrase>neural networks</phrase> via deep generator networks
<phrase>deep neural networks</phrase> dnns have demonstrated <phrase>state of</phrase> <phrase>the art results</phrase> on many <phrase>pattern recognition</phrase> tasks especially vision <phrase>classification problems</phrase>. understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right <phrase>similar to</phrase> why we study the <phrase>human brain</phrase> and will enable researchers to further improve dnns. one path to understanding how <phrase>a neural network</phrase> functions internally is to study what each of its neurons has learned to detect. one such method is called activation maximization am which synthesizes an input e.g. <phrase>an image</phrase> that highly activates a neuron. here we dramatically improve the qualitative <phrase>state of</phrase> <phrase>the art</phrase> of activation maximization by harnessing a powerful learned prior a deep generator network dgn . the algorithm 1 generates qualitatively <phrase>state of</phrase> <phrase>the art</phrase> synthetic images that look almost real 2 reveals the features learned by each neuron in an interpretable way 3 generalizes well to new datasets and somewhat well to different <phrase>network architectures</phrase> <phrase>without requiring</phrase> the prior to be relearned and 4 can be considered as a <phrase>high quality</phrase> generative method in this case by generating novel creative interesting recognizable images .
structured convolution matrices for energy efficient <phrase>deep learning</phrase>
we derive a relationship between network representation in energy efficient neuromorphic architectures and block toplitz convolutional matrices. <phrase>inspired by</phrase> this connection we develop <phrase>deep convolutional</phrase> networks using a <phrase>family of</phrase> structured convolutional matrices and <phrase>achieve state of</phrase> <phrase>the art</phrase> trade off between energy efficiency and <phrase>classification accuracy</phrase> for <phrase>well known</phrase> image <phrase>recognition tasks</phrase>. we also put forward <phrase>a novel</phrase> method <phrase>to train</phrase> binary convolutional networks by utilising an existing connection between noisy <phrase>rectified linear</phrase> units and binary activations.
deep coral correlation alignment for deep <phrase>domain adaptation</phrase>
<phrase>deep neural networks</phrase> are <phrase>able to</phrase> learn powerful representations from large quantities of labeled <phrase>input data</phrase> however they cannot always generalize well across changes in input distributions. <phrase>domain adaptation</phrase> algorithms have been proposed to compensate for the degradation in performance <phrase>due to</phrase> domain shift. in <phrase>this paper</phrase> we address the case when the target domain is unlabeled requiring unsupervised adaptation. coral is a frustratingly easy unsupervised <phrase>domain adaptation</phrase> method that aligns the second order statistics of the source and target distributions with a <phrase>linear transformation</phrase>. here we extend coral <phrase>to learn</phrase> a nonlinear transformation that aligns correlations of layer activations in <phrase>deep neural networks</phrase> deep coral . <phrase>experiments on</phrase> standard <phrase>benchmark datasets</phrase> show <phrase>state of</phrase> <phrase>the art</phrase> performance.
spatio temporal lstm with trust gates for 3d human action recognition
3d action recognition analysis of human actions <phrase>based on</phrase> 3d skeleton data becomes popular recently <phrase>due to</phrase> its succinctness robustness and view invariant representation. recent attempts on <phrase>this problem</phrase> suggested to develop <phrase>rnn based</phrase> <phrase>learning methods</phrase> to model the contextual dependency in the temporal domain. in <phrase>this paper</phrase> we extend this idea to spatio temporal domains to analyze the hidden sources of action related information within <phrase>the input</phrase> data over both domains concurrently. <phrase>inspired by</phrase> the graphical structure of the <phrase>human skeleton</phrase> we further propose a <phrase>more powerful</phrase> <phrase>tree structure</phrase> based traversal method. to handle the noise and occlusion in 3d skeleton data we introduce new gating mechanism within lstm <phrase>to learn</phrase> the reliability of the sequential <phrase>input data</phrase> and accordingly adjust its effect on updating the <phrase>long term</phrase> context information stored in the memory cell. our method <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> 4 challenging <phrase>benchmark datasets</phrase> for 3d human action analysis.
generalized dropout
<phrase>deep neural networks</phrase> often require good regularizers to generalize well. dropout is one such regularizer that is <phrase>widely used</phrase> among <phrase>deep learning</phrase> practitioners. <phrase>recent work</phrase> has shown that dropout can also be viewed as performing approximate <phrase>bayesian inference</phrase> over <phrase>the network</phrase> parameters. in <phrase>this work</phrase> we generalize this notion and introduce a rich <phrase>family of</phrase> regularizers which we call generalized dropout. one <phrase>set of</phrase> methods in this family called dropout is a <phrase>version of</phrase> dropout with trainable parameters. classical dropout emerges as <phrase>a special</phrase> case of this method. another member of this family selects the width of <phrase>neural network</phrase> layers. <phrase>experiments show</phrase> that these methods help in improving generalization performance over dropout.
parsimonious inference on <phrase>convolutional neural networks</phrase> learning and applying <phrase>on line</phrase> kernel activation rules
<phrase>a new</phrase> radical cnn design approach is presented in <phrase>this paper</phrase> considering the reduction of the total computational load during inference. this is <phrase>achieved by</phrase> <phrase>a new</phrase> holistic intervention on both the cnn architecture and the training procedure which targets to the parsimonious inference by learning to exploit or remove the redundant capacity of a cnn architecture. this is accomplished by the introduction of <phrase>a new</phrase> structural element that can be inserted as an add on to any contemporary cnn architecture whilst preserving or even improving its recognition accuracy. our approach formulates a systematic and <phrase>data driven</phrase> <phrase>method for</phrase> developing cnns that are trained to eventually change size and form in <phrase>real time</phrase> during inference targeting to the smaller possible computational footprint. results are provided for the optimal implementation on a few modern high end <phrase>mobile computing</phrase> platforms indicating a significant speed up of up to x3 times.
model agnostic <phrase>meta learning</phrase> for fast adaptation of <phrase>deep networks</phrase>
we propose an algorithm for <phrase>meta learning</phrase> that is model agnostic in the sense that it is compatible with any model trained with <phrase>gradient descent</phrase> and <phrase>applicable to</phrase> <phrase>a variety of</phrase> different learning problems including classification regression and <phrase>reinforcement learning</phrase>. <phrase>the goal of</phrase> <phrase>meta learning</phrase> is <phrase>to train</phrase> a model on <phrase>a variety of</phrase> <phrase>learning tasks</phrase> such that it can solve new <phrase>learning tasks</phrase> using only <phrase>a small</phrase> <phrase>number of</phrase> <phrase>training samples</phrase>. in our approach <phrase>the parameters of</phrase> <phrase>the model</phrase> are explicitly trained such that <phrase>a small</phrase> <phrase>number of</phrase> gradient steps with <phrase>a small</phrase> <phrase>amount of</phrase> <phrase>training data</phrase> from <phrase>a new</phrase> task will produce good generalization <phrase>performance on</phrase> that task. in effect our method trains <phrase>the model</phrase> to be <phrase>easy to</phrase> fine tune. we demonstrate that <phrase>this approach</phrase> <phrase>leads to</phrase> <phrase>state of</phrase> <phrase>the art performance on</phrase> two few shot <phrase>image classification</phrase> benchmarks produces good <phrase>results on</phrase> few shot regression and accelerates fine tuning for policy gradient <phrase>reinforcement learning</phrase> with <phrase>neural network</phrase> policies.
wrpn training and inference using wide reduced precision networks
for <phrase>computer vision</phrase> applications prior works have shown <phrase>the efficacy of</phrase> reducing the numeric precision of <phrase>model parameters</phrase> network weights in <phrase>deep neural networks</phrase> <phrase>but also</phrase> that reducing the precision of activations hurts model accuracy much <phrase>more than</phrase> reducing the precision of <phrase>model parameters</phrase>. we study schemes <phrase>to train</phrase> networks <phrase>from scratch</phrase> using reduced precision activations without hurting <phrase>the model</phrase> accuracy. we reduce the precision of activation maps <phrase>along with</phrase> <phrase>model parameters</phrase> using <phrase>a novel</phrase> quantization scheme and increase <phrase>the number of</phrase> filter maps in a layer and find that this scheme compensates or surpasses the accuracy of the baseline full precision network. as a result one can significantly reduce the dynamic <phrase>memory footprint</phrase> memory bandwidth computational energy and speed up the training and inference process with appropriate hardware support. we call our scheme wrpn wide reduced precision networks. we report results using our proposed schemes and show that our results are <phrase>better than</phrase> previously reported accuracies on ilsvrc 12 dataset while being computationally less expensive <phrase>compared to</phrase> previously reported reduced precision networks.
<phrase>deep learning</phrase> is robust to massive label noise
<phrase>deep neural networks</phrase> <phrase>trained on</phrase> large supervised datasets have led to impressive results in <phrase>image classification</phrase> and other tasks. however well annotated datasets can be time consuming and expensive to collect lending increased interest to larger but noisy datasets that are more easily obtained. in <phrase>this paper</phrase> we show that <phrase>deep neural networks</phrase> are <phrase>capable of</phrase> generalizing from <phrase>training data</phrase> for which true labels are massively outnumbered by incorrect labels. we demonstrate remarkably high test performance after training on corrupted data from mnist cifar and imagenet. for example on mnist we obtain test accuracy above 90 percent even after each clean training example has been diluted with 100 randomly labeled examples. such behavior holds across multiple patterns of label noise even when erroneous labels are biased towards confusing classes. we show that training in this regime requires a significant but manageable increase in dataset size that is <phrase>related to</phrase> the factor by which correct labels have been diluted. finally we provide an analysis of our results that shows how increasing noise decreases the effective <phrase>batch size</phrase>.
improving content invariance in gated autoencoders for 2d and 3d object rotation
content invariance in mapping codes learned by gaes is a useful feature for various relation <phrase>learning tasks</phrase>. in <phrase>this paper</phrase> we show that the content invariance of mapping codes for images of 2d and 3d rotated objects can be substantially improved by extending the standard gae loss symmetric reconstruction error with a regularization term that penalizes the symmetric cross reconstruction error. this error term involves reconstruction of pairs with mapping codes obtained from other pairs exhibiting similar transformations. although this would principally require knowledge of the transformations exhibited by training pairs our <phrase>experiments show</phrase> that a bootstrapping approach can sidestep <phrase>this issue</phrase> and that the regularization term can effectively be used in an unsupervised setting.
<phrase>deep learning</phrase> for sensor based activity recognition a survey
sensor based activity recognition seeks the profound <phrase>high level</phrase> knowledge about human activities from multitudes of low level sensor readings. conventional <phrase>pattern recognition</phrase> approaches have made tremendous progress in <phrase>the past</phrase> years. however those methods often heavily <phrase>rely on</phrase> heuristic <phrase>hand crafted</phrase> <phrase>feature extraction</phrase> which could hinder their generalization performance. additionally <phrase>existing methods</phrase> are undermined for unsupervised and incremental <phrase>learning tasks</phrase>. recently the recent advancement of <phrase>deep learning</phrase> makes it possible <phrase>to perform</phrase> automatic <phrase>high level</phrase> <phrase>feature extraction</phrase> thus achieves promising performance in many areas. since then <phrase>deep learning</phrase> <phrase>based methods</phrase> have been widely adopted for the sensor based activity <phrase>recognition tasks</phrase>. <phrase>this paper</phrase> surveys the recent advance of <phrase>deep learning</phrase> based sensor based activity recognition. we summarize existing literature from three aspects sensor modality deep model and application. we <phrase>also present</phrase> detailed insights on existing work and propose grand challenges for future research.
on the importance of consistency in <phrase>training deep neural networks</phrase>
we explain that the difficulties of <phrase>training deep neural networks</phrase> come from a syndrome of three consistency issues. <phrase>this paper</phrase> describes our efforts in their analysis and treatment. the first issue is the training speed inconsistency in different layers. we propose <phrase>to address</phrase> it with an intuitive simple to implement low footprint second order method. the second issue is the scale inconsistency between the layer inputs and the layer residuals. we explain how second order information provides favorable convenience in removing this roadblock. the third and most challenging issue is the inconsistency in residual propagation. <phrase>based on</phrase> the fundamental theorem of <phrase>linear algebra</phrase> we provide a mathematical characterization of the famous vanishing gradient problem. thus <phrase>an important</phrase> design principle for future optimization and <phrase>neural network</phrase> design is derived. we conclude <phrase>this paper</phrase> with the construction of <phrase>a novel</phrase> contractive <phrase>neural network</phrase>.
ui net interactive <phrase>artificial neural networks</phrase> for iterative <phrase>image segmentation</phrase> <phrase>based on</phrase> a user model
for complex segmentation tasks fully automatic systems are inherently limited in their achievable accuracy for extracting relevant objects. especially in cases where only few <phrase>data sets</phrase> <phrase>need to</phrase> be processed for a highly accurate result <phrase>semi automatic</phrase> segmentation techniques exhibit a clear benefit for the user. one area of application is medical <phrase>image processing</phrase> during an intervention for <phrase>a single</phrase> patient. we propose a learning based cooperative segmentation approach which includes the computing entity <phrase>as well as</phrase> the user into the task. our system builds upon a <phrase>state of</phrase> <phrase>the art</phrase> fully convolutional <phrase>artificial neural network</phrase> fcn <phrase>as well as</phrase> an active user model for training. during the segmentation process a user of the trained system can iteratively add additional hints in form of pictorial scribbles as seed points into the fcn system to achieve an interactive and precise segmentation result. the segmentation quality of interactive fcns is evaluated. iterative fcn approaches can yield superior results <phrase>compared to</phrase> networks without the user input channel component <phrase>due to</phrase> a consistent improvement in segmentation quality after each interaction.
lightweight <phrase>neural networks</phrase>
most of the weights in a lightweight <phrase>neural network</phrase> have a value of zero while the remaining ones are either 1 or 1. these universal approximators require approximately 1.1 bits weight of storage posses a quick <phrase>forward pass</phrase> and achieve classification accuracies <phrase>similar to</phrase> conventional continuous weight networks. their training regimen <phrase>focuses on</phrase> error reduction initially but later emphasizes discretization of weights. they ignore insignificant inputs remove unnecessary weights and drop unneeded hidden neurons. we have successfully tested them on the mnist <phrase>credit card</phrase> fraud and <phrase>credit card</phrase> defaults <phrase>data sets</phrase> using networks having 2 to 16 <phrase>hidden layers</phrase> and up to 4.4 million weights.
<phrase>tensor field</phrase> networks rotation and translation equivariant <phrase>neural networks</phrase> for 3d point clouds
we introduce <phrase>tensor field</phrase> networks which are locally equivariant to 3d rotations translations and permutations of points at every layer. 3d rotation equivariance removes <phrase>the need for</phrase> <phrase>data augmentation</phrase> to identify features in arbitrary orientations. our network uses filters built from <phrase>spherical harmonics</phrase> <phrase>due to</phrase> the mathematical consequences of this filter choice <phrase>each layer</phrase> accepts as input and guarantees as output scalars vectors and higher order tensors in the geometric sense of these terms. we demonstrate how <phrase>tensor field</phrase> networks learn to model simple physics newtonian gravitation and moment of inertia classify simple 3d shapes <phrase>trained on</phrase> one orientation and <phrase>tested on</phrase> shapes in arbitrary orientations and given <phrase>a small</phrase> organic molecule with an atom removed replace the correct element at the correct location in space.
knowledge matters importance of prior information for optimization
we explore <phrase>the effect of</phrase> introducing prior information into the intermediate level of <phrase>neural networks</phrase> for a learning task on which all the <phrase>state of</phrase> <phrase>the art</phrase> <phrase>machine learning</phrase> algorithms tested failed <phrase>to learn</phrase>. we motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. the experiments we have conducted provide positive evidence in favor of this hypothesis. in our experiments a two tiered mlp architecture is <phrase>trained on</phrase> a dataset with 64x64 binary inputs images each image with three sprites. <phrase>the final</phrase> task is to decide whether all the sprites are <phrase>the same</phrase> or one of them is different. sprites are pentomino tetris shapes and they are placed in <phrase>an image</phrase> with different locations using scaling and rotation transformations. the first part of the two tiered mlp is <phrase>pre trained</phrase> with intermediate level targets being the presence of sprites at each location while the second part takes the output of the first part as input and predicts <phrase>the final</phrase> task s target binary event. the two tiered mlp architecture with a few tens of thousand examples was <phrase>able to</phrase> learn the task perfectly whereas all other algorithms include unsupervised <phrase>pre training</phrase> <phrase>but also</phrase> traditional algorithms like svms decision trees and boosting all perform no <phrase>better than</phrase> chance. we hypothesize that the optimization difficulty involved when the intermediate <phrase>pre training</phrase> is not performed is <phrase>due to</phrase> the em composition of two highly <phrase>non linear</phrase> tasks. our findings are also consistent with hypotheses on cultural learning <phrase>inspired by</phrase> the observations of optimization problems with <phrase>deep learning</phrase> presumably because of effective <phrase>local minima</phrase>.
zero bias autoencoders and the benefits of co adapting features
regularized training of an autoencoder typically results in hidden unit biases that take on large negative values. we show that negative biases are a natural result of using a <phrase>hidden layer</phrase> whose responsibility is to both represent <phrase>the input</phrase> data and act as a selection mechanism that ensures sparsity of the representation. we then show that negative biases impede the learning of data distributions whose intrinsic dimensionality is high. we also propose <phrase>a new</phrase> <phrase>activation function</phrase> that decouples the two roles of the <phrase>hidden layer</phrase> and that allows us <phrase>to learn</phrase> representations on data with very high intrinsic dimensionality where standard autoencoders typically fail. since the decoupled <phrase>activation function</phrase> acts like an implicit regularizer <phrase>the model</phrase> can be trained by minimizing the reconstruction error of <phrase>training data</phrase> <phrase>without requiring</phrase> any additional regularization.
theory and tools for the conversion of analog to spiking <phrase>convolutional neural networks</phrase>
<phrase>deep convolutional neural networks</phrase> cnns have shown great potential for numerous <phrase>real world</phrase> <phrase>machine learning</phrase> applications but performing inference in large cnns in <phrase>real time</phrase> remains a challenge. we have previously demonstrated that traditional cnns can be converted into deep <phrase>spiking neural networks</phrase> snns which exhibit similar accuracy while reducing both latency and computational load as a consequence of their <phrase>data driven</phrase> event based style of computing. here we provide <phrase>a novel</phrase> theory that explains why this conversion is successful and derive from it several new tools to convert a larger and <phrase>more powerful</phrase> class of <phrase>deep networks</phrase> into snns. we identify the main sources of approximation errors in previous conversion methods and propose simple mechanisms to fix these issues. furthermore we develop spiking implementations of common cnn operations <phrase>such as</phrase> max pooling softmax and <phrase>batch normalization</phrase> which allow almost loss less conversion of arbitrary cnn architectures into the spiking domain. empirical evaluation of different <phrase>network architectures</phrase> on the mnist and cifar10 benchmarks <phrase>leads to</phrase> <phrase>the best</phrase> snn results reported <phrase>to date</phrase>.
stacked <phrase>generative adversarial networks</phrase>
in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> <phrase>generative model</phrase> named stacked <phrase>generative adversarial networks</phrase> sgan which is trained to invert the hierarchical representations of a bottom up discriminative network. our model <phrase>consists of</phrase> a top down stack of gans each learned <phrase>to generate</phrase> lower level representations <phrase>conditioned on</phrase> <phrase>higher level</phrase> representations. a representation discriminator is introduced at each feature hierarchy to encourage the representation manifold of the generator to align with that of the bottom up discriminative network leveraging the powerful discriminative representations to guide the <phrase>generative model</phrase>. <phrase>in addition</phrase> we introduce a conditional loss that encourages <phrase>the use of</phrase> conditional information from the layer above and <phrase>a novel</phrase> entropy loss that maximizes a variational lower bound on the conditional entropy of generator outputs. we first train each stack independently and then train the whole model <phrase>end to end</phrase>. unlike <phrase>the original</phrase> gan that uses <phrase>a single</phrase> noise vector <phrase>to represent</phrase> all the variations our sgan decomposes variations into multiple levels and gradually resolves uncertainties in the top down generative process. <phrase>based on</phrase> visual inspection inception scores and visual <phrase>turing test</phrase> we demonstrate that sgan is <phrase>able to</phrase> generate images of much higher quality than gans without stacking.
self informed <phrase>neural network</phrase> structure learning
we study <phrase>the problem of</phrase> <phrase>large scale</phrase> <phrase>multi label</phrase> visual recognition with <phrase>a large number of</phrase> possible classes. we propose a <phrase>method for</phrase> augmenting a trained <phrase>neural network</phrase> classifier with auxiliary capacity in a manner designed to significantly improve upon an already well performing model while minimally impacting its computational footprint. using the predictions of <phrase>the network</phrase> itself as a descriptor for assessing visual similarity we define a partitioning of the label space into groups of visually similar entities. we then augment <phrase>the network</phrase> with auxilliary <phrase>hidden layer</phrase> pathways with connectivity only to these groups of label units. we report a <phrase>significant improvement</phrase> in mean average precision on <phrase>a large</phrase> scale <phrase>object recognition</phrase> task with the augmented model while increasing <phrase>the number of</phrase> multiply adds by less than 3 .
learning <phrase>activation functions</phrase> <phrase>to improve</phrase> <phrase>deep neural networks</phrase>
<phrase>artificial neural networks</phrase> typically have <phrase>a fixed</phrase> <phrase>non linear</phrase> <phrase>activation function</phrase> at each neuron. we have designed <phrase>a novel</phrase> form of piecewise linear <phrase>activation function</phrase> that is learned independently for each neuron using <phrase>gradient descent</phrase>. with this adaptive <phrase>activation function</phrase> we are <phrase>able to</phrase> improve upon <phrase>deep neural network</phrase> architectures <phrase>composed of</phrase> static <phrase>rectified linear</phrase> units achieving <phrase>state of</phrase> <phrase>the art performance on</phrase> <phrase>cifar 10</phrase> 7.51 cifar 100 30.83 and a benchmark from <phrase>high energy physics</phrase> involving <phrase>higgs boson</phrase> decay modes.
denoising autoencoder with modulated lateral connections learns invariant representations of natural images
suitable lateral connections between encoder and decoder are <phrase>shown to</phrase> allow higher layers of a denoising autoencoder dae to <phrase>focus on</phrase> invariant representations. in regular autoencoders detailed information <phrase>needs to</phrase> be carried through the highest layers but lateral connections from encoder to decoder relieve this pressure. it is shown that abstract invariant features can be translated to detailed reconstructions when invariant features are allowed to modulate the strength of the lateral connection. three dae structures with modulated and additive lateral connections and without lateral connections were compared in experiments using <phrase>real world</phrase> images. the experiments verify that adding modulated lateral connections to <phrase>the model</phrase> 1 improves the accuracy of the probability model for inputs as measured by denoising performance 2 results in representations whose degree of invariance grows faster towards the higher layers and 3 supports the formation of diverse invariant poolings.
a probabilistic theory of <phrase>deep learning</phrase>
a grand challenge in <phrase>machine learning</phrase> is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation. for instance visual <phrase>object recognition</phrase> involves the unknown object position orientation and scale in <phrase>object recognition</phrase> while <phrase>speech recognition</phrase> involves the unknown voice pronunciation pitch and speed. recently <phrase>a new</phrase> breed of <phrase>deep learning</phrase> algorithms have emerged for high nuisance inference tasks that routinely yield <phrase>pattern recognition</phrase> systems with near or super human capabilities. but a fundamental question remains why do they work intuitions abound but a coherent <phrase>framework for</phrase> understanding analyzing and synthesizing <phrase>deep learning</phrase> architectures has remained elusive. we answer this question by developing <phrase>a new</phrase> probabilistic <phrase>framework for</phrase> <phrase>deep learning</phrase> <phrase>based on</phrase> the deep rendering model a generative probabilistic model that explicitly captures latent nuisance variation. by relaxing the <phrase>generative model</phrase> to a discriminative one we can recover two of the current leading <phrase>deep learning</phrase> systems <phrase>deep convolutional neural networks</phrase> and random decision forests providing insights into their successes and shortcomings <phrase>as well as</phrase> a principled route to their improvement.
integrated inference and learning of neural factors in structural <phrase>support vector machines</phrase>
tackling <phrase>pattern recognition</phrase> problems in areas <phrase>such as</phrase> <phrase>computer vision</phrase> bioinformatics speech or text recognition is often done best by taking into account <phrase>task specific</phrase> statistical <phrase>relations between</phrase> output variables. in <phrase>structured prediction</phrase> this internal structure is used <phrase>to predict</phrase> multiple outputs simultaneously <phrase>leading to</phrase> <phrase>more accurate</phrase> and coherent predictions. structural <phrase>support vector machines</phrase> ssvms are nonprobabilistic models that optimize a joint <phrase>input output</phrase> function through margin based learning. because ssvms generally disregard the interplay between unary and interaction factors during the training phase final parameters are suboptimal. moreover its factors are often restricted to linear combinations of <phrase>input features</phrase> limiting its generalization power. <phrase>to improve</phrase> prediction accuracy <phrase>this paper</phrase> proposes i joint inference and learning by integration of <phrase>back propagation</phrase> and loss augmented inference in ssvm subgradient <phrase>descent ii</phrase> extending ssvm factors to <phrase>neural networks</phrase> that form highly nonlinear functions of <phrase>input features</phrase>. <phrase>image segmentation</phrase> benchmark <phrase>results demonstrate</phrase> improvements over conventional ssvm training methods <phrase>in terms of</phrase> accuracy highlighting the feasibility of <phrase>end to end</phrase> ssvm training with neural factors.
what happened to my dog in that network unraveling top down generators in <phrase>convolutional neural networks</phrase>
top down information plays a central <phrase>role in</phrase> <phrase>human perception</phrase> but plays relatively little <phrase>role in</phrase> many current <phrase>state of</phrase> <phrase>the art</phrase> <phrase>deep networks</phrase> <phrase>such as</phrase> <phrase>convolutional neural networks</phrase> cnns . <phrase>this work</phrase> seeks to explore a path by which top down information can have a direct impact within current <phrase>deep networks</phrase>. we explore this path by learning and using generators corresponding to <phrase>the network</phrase> internal effects of three <phrase>types of</phrase> transformation each a restriction of a general <phrase>affine transformation</phrase> rotation scaling and translation. we demonstrate how these learned generators can be used to transfer top down information to novel settings as mediated by the feature flows that the transformations and the associated generators correspond to inside <phrase>the network</phrase>. specifically we explore three aspects 1 using generators as part of a <phrase>method for</phrase> synthesizing transformed images given a previously unseen image produce versions of that image corresponding to one or more specified transformations 2 <phrase>zero shot</phrase> learning when provided with a feature flow corresponding to <phrase>the effect of</phrase> a transformation of unknown amount leverage learned generators as part of a method by which <phrase>to perform</phrase> an accurate categorization of the <phrase>amount of</phrase> transformation even for amounts never observed <phrase>during training</phrase> and 3 inside cnn <phrase>data augmentation</phrase> improve the <phrase>classification performance</phrase> of an existing network <phrase>by using</phrase> the learned generators to directly provide additional training inside the cnn .
<phrase>virtual worlds</phrase> as proxy for multi object tracking analysis
modern <phrase>computer vision</phrase> algorithms typically require expensive <phrase>data acquisition</phrase> and accurate manual labeling. in <phrase>this work</phrase> we instead leverage the recent progress in computer graphics <phrase>to generate</phrase> fully labeled dynamic and photo realistic proxy <phrase>virtual worlds</phrase>. we propose an efficient real to <phrase>virtual world</phrase> cloning method and validate our approach by building and publicly releasing <phrase>a new</phrase> video dataset called virtual kitti see http www.xrce.xerox.com research development <phrase>computer vision</phrase> proxy <phrase>virtual worlds</phrase> automatically labeled with accurate ground truth for <phrase>object detection</phrase> tracking scene and instance segmentation depth and <phrase>optical flow</phrase>. we provide quantitative experimental evidence suggesting that i modern <phrase>deep learning</phrase> algorithms <phrase>pre trained</phrase> on real data behave similarly in real and <phrase>virtual worlds</phrase> and ii <phrase>pre training</phrase> on virtual data improves performance. as the gap between real and <phrase>virtual worlds</phrase> is small <phrase>virtual worlds</phrase> enable measuring the impact of various weather and imaging conditions on recognition performance all other things being equal. we show these factors may affect drastically otherwise high performing deep models for tracking.
synthesizing dynamic patterns by spatial temporal generative convnet
video sequences contain rich dynamic patterns <phrase>such as</phrase> dynamic texture patterns that exhibit stationarity in the temporal domain and action patterns that are non stationary in either spatial or temporal domain. we show that a spatial temporal generative convnet can be used to model and synthesize dynamic patterns. <phrase>the model</phrase> defines a <phrase>probability distribution</phrase> on the video sequence and the log probability is defined by a spatial temporal convnet that <phrase>consists of</phrase> multiple layers of spatial temporal filters <phrase>to capture</phrase> spatial temporal patterns of different scales. <phrase>the model</phrase> can be learned from the training video sequences by an analysis by synthesis <phrase>learning algorithm</phrase> that iterates the following two steps. step 1 synthesizes video sequences from the currently learned model. step 2 then updates <phrase>the model</phrase> parameters <phrase>based on</phrase> the difference between the synthesized video sequences and the observed training sequences. we show that the <phrase>learning algorithm</phrase> can synthesize realistic dynamic patterns.
<phrase>deep learning</phrase> with darwin evolutionary synthesis of <phrase>deep neural networks</phrase>
taking inspiration from <phrase>biological evolution</phrase> we explore the idea of can <phrase>deep neural networks</phrase> evolve naturally over successive generations into highly efficient <phrase>deep neural networks</phrase> <phrase>by introducing</phrase> the <phrase>notion of</phrase> synthesizing new highly efficient yet powerful <phrase>deep neural networks</phrase> over successive generations via an evolutionary process from ancestor <phrase>deep neural networks</phrase>. the architectural traits of ancestor <phrase>deep neural networks</phrase> are encoded using synaptic probability models which can be viewed as the dna of these networks. new descendant networks with differing <phrase>network architectures</phrase> are synthesized <phrase>based on</phrase> these synaptic probability models from the ancestor networks and computational environmental factor models in a random manner to mimic heredity <phrase>natural selection</phrase> and random mutation. these offspring networks are then trained into fully functional networks like one would train a newborn and have <phrase>more efficient</phrase> more diverse <phrase>network architectures</phrase> than their ancestor networks while achieving powerful modeling capabilities. <phrase>experimental results</phrase> for <phrase>the task of</phrase> visual saliency demonstrated that the synthesized evolved offspring networks can <phrase>achieve state of</phrase> <phrase>the art</phrase> performance while having <phrase>network architectures</phrase> that are significantly <phrase>more efficient</phrase> with a staggering sim 48 fold <phrase>decrease in</phrase> synapses by the fourth generation <phrase>compared to</phrase> <phrase>the original</phrase> ancestor network.
alternating <phrase>back propagation</phrase> for generator network
<phrase>this paper</phrase> proposes an alternating <phrase>back propagation</phrase> algorithm for learning the generator network model. <phrase>the model</phrase> is a <phrase>non linear</phrase> generalization of <phrase>factor analysis</phrase>. in this model the mapping from the continuous latent factors to the observed signal is parametrized by <phrase>a convolutional neural network</phrase>. the alternating <phrase>back propagation</phrase> algorithm iterates the following two steps 1 inferential <phrase>back propagation</phrase> which infers the latent factors by langevin dynamics or <phrase>gradient descent</phrase>. 2 learning <phrase>back propagation</phrase> which updates the parameters given the inferred latent factors by <phrase>gradient descent</phrase>. the gradient computations in both steps are powered by <phrase>back propagation</phrase> and they share most of their code in common. we show that the alternating <phrase>back propagation</phrase> algorithm can learn realistic generator models of natural images video sequences and sounds. moreover it can also be used <phrase>to learn</phrase> from incomplete or indirect <phrase>training data</phrase>.
hyperparameter <phrase>transfer learning</phrase> through surrogate alignment for efficient <phrase>deep neural network</phrase> training
recently several optimization methods have been successfully <phrase>applied to</phrase> the hyperparameter optimization of <phrase>deep neural networks</phrase> dnns . the methods work by modeling the joint distribution of hyperparameter values and corresponding error. those methods become less practical when <phrase>applied to</phrase> modern dnns whose training may take a few days and thus one cannot collect sufficient observations to accurately model the distribution. <phrase>to address</phrase> this challenging issue we propose a method that learns to transfer optimal hyperparameter values for <phrase>a small</phrase> source dataset to hyperparameter values with comparable <phrase>performance on</phrase> a dataset of interest. as opposed to existing <phrase>transfer learning</phrase> methods our <phrase>proposed method</phrase> <phrase>does not</phrase> use hand designed features. instead it uses surrogates to model the hyperparameter error distributions of the two datasets and trains <phrase>a neural network</phrase> <phrase>to learn</phrase> the <phrase>transfer function</phrase>. <phrase>extensive experiments</phrase> on three cv <phrase>benchmark datasets</phrase> clearly demonstrate the efficiency of our method.
towards <phrase>bayesian deep learning</phrase> a framework and some <phrase>existing methods</phrase>
while perception <phrase>tasks such as</phrase> visual <phrase>object recognition</phrase> and text understanding play <phrase>an important</phrase> <phrase>role in</phrase> <phrase>human intelligence</phrase> the subsequent tasks that involve inference reasoning and planning require an even <phrase>higher level</phrase> of intelligence. <phrase>the past</phrase> few years have seen major <phrase>advances in</phrase> many perception tasks using <phrase>deep learning</phrase> models. for <phrase>higher level</phrase> inference however probabilistic <phrase>graphical models</phrase> with their bayesian nature are still <phrase>more powerful</phrase> and flexible. to achieve integrated intelligence that involves both perception and inference it is naturally desirable to tightly integrate <phrase>deep learning</phrase> and bayesian models within a principled probabilistic framework which we call <phrase>bayesian deep learning</phrase>. in this unified framework the perception of text or images using <phrase>deep learning</phrase> can boost <phrase>the performance of</phrase> <phrase>higher level</phrase> inference and in return the feedback from the inference process is <phrase>able to</phrase> enhance the perception of text or images. <phrase>this paper</phrase> proposes a general <phrase>framework for</phrase> <phrase>bayesian deep learning</phrase> and reviews its recent applications on recommender systems topic models and control. in <phrase>this paper</phrase> we also discuss the relationship and differences between <phrase>bayesian deep learning</phrase> and other related topics like bayesian treatment of <phrase>neural networks</phrase>.
deciding how to decide dynamic routing in <phrase>artificial neural networks</phrase>
we propose and systematically evaluate three strategies for training dynamically routed <phrase>artificial neural networks</phrase> graphs of learned transformations through which different input signals may take different paths. though some approaches have advantages over others the resulting networks are often qualitatively similar. we find that in dynamically routed networks trained to classify images layers and branches become specialized to process distinct categories of images. additionally given <phrase>a fixed</phrase> computational budget dynamically routed networks <phrase>tend to</phrase> perform <phrase>better than</phrase> comparable statically routed networks.
pixel deconvolutional networks
deconvolutional layers have been <phrase>widely used</phrase> in <phrase>a variety of</phrase> deep models for up sampling including <phrase>encoder decoder</phrase> networks for <phrase>semantic segmentation</phrase> and deep <phrase>generative models</phrase> for <phrase>unsupervised learning</phrase>. one of the key limitations of deconvolutional operations is that they result in the so called checkerboard problem. this is caused by the fact that no direct relationship exists among adjacent pixels on the output feature map. <phrase>to address</phrase> <phrase>this problem</phrase> we propose the pixel deconvolutional layer pixeldcl to establish direct relationships among adjacent pixels on the up sampled feature map. our method is <phrase>based on</phrase> a fresh interpretation of the regular deconvolution operation. the resulting pixeldcl can be used to replace any deconvolutional layer in a plug and play manner without compromising the fully trainable capabilities of original models. <phrase>the proposed</phrase> pixeldcl may result in slight <phrase>decrease in</phrase> efficiency but this can be overcome by an implementation trick. <phrase>experimental results</phrase> on <phrase>semantic segmentation</phrase> demonstrate that pixeldcl can consider spatial features <phrase>such as</phrase> edges and shapes and yields <phrase>more accurate</phrase> segmentation outputs than deconvolutional layers. when used in image generation tasks our pixeldcl can largely overcome the checkerboard problem suffered by regular deconvolution operations.
gaussian prototypical networks for few <phrase>shot learning</phrase> on omniglot
we propose <phrase>a novel</phrase> architecture for k shot classification on the omniglot dataset. building on prototypical networks we extend their architecture to what we call gaussian prototypical networks. prototypical networks learn a map between images and embedding vectors and use their clustering for classification. in our model a part of the encoder output is interpreted as a confidence region estimate about the embedding point and expressed as a gaussian <phrase>covariance matrix</phrase>. our network then constructs a direction and class dependent distance metric on the embedding space using uncertainties of individual data points as weights. we show that gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent <phrase>number of</phrase> parameters. we report <phrase>state of</phrase> <phrase>the art</phrase> performance in 1 shot and 5 shot classification both in 5 way and 20 way regime for 5 shot 5 way we are <phrase>comparable to</phrase> <phrase>previous state of</phrase> <phrase>the art</phrase> on the omniglot dataset. we explore artificially down sampling a fraction of images in the <phrase>training set</phrase> which improves our performance even further. we therefore hypothesize that gaussian prototypical networks might perform better in less homogeneous noisier datasets which are commonplace in <phrase>real world</phrase> applications.
super convergence very fast training of <phrase>residual networks</phrase> using large learning rates
in <phrase>this paper</phrase> we show a phenomenon which we named super convergence where <phrase>residual networks</phrase> can be trained using an order <phrase>of magnitude</phrase> fewer iterations than is used with standard training methods. <phrase>the existence of</phrase> super convergence is relevant to understanding why <phrase>deep networks</phrase> generalize well. one of the key elements of super convergence is training with cyclical learning rates and <phrase>a large</phrase> maximum <phrase>learning rate</phrase>. furthermore we present evidence that training with large learning rates improves performance by regularizing <phrase>the network</phrase>. <phrase>in addition</phrase> we show that super convergence provides a greater boost in performance relative to standard training when the <phrase>amount of</phrase> labeled <phrase>training data</phrase> is limited. we also derive a simplification of the hessian free optimization method to compute an estimate of the optimal <phrase>learning rate</phrase>. the architectures and code to replicate the figures in <phrase>this paper</phrase> are <phrase>available at</phrase> github.com lnsmith54 super convergence.
generative learning for <phrase>deep networks</phrase>
learning taking into account full distribution of the data referred to as generative is not feasible with <phrase>deep neural networks</phrase> dnns because they model only the conditional distribution of the outputs given the inputs. current solutions are either <phrase>based on</phrase> joint probability models facing difficult estimation problems or learn two separate networks mapping inputs to outputs recognition and vice versa generation . we propose an intermediate approach. first we show that forward computation in dnns with logistic sigmoid activations corresponds to a simplified approximate <phrase>bayesian inference</phrase> in a directed probabilistic <phrase>multi layer</phrase> model. this connection allows to interpret dnn as a probabilistic model of the output and all hidden units given <phrase>the input</phrase>. second we propose that in order for the recognition and generation networks to be more consistent with the joint model of the data weights of the recognition and generator network should be related by transposition. we demonstrate in a tentative experiment that such a coupled pair can be learned generatively modelling the full distribution of the data and has enough capacity <phrase>to perform</phrase> well in both recognition and generation.
hierarchical representations for efficient architecture search
we explore efficient neural architecture search methods and show that <phrase>a simple</phrase> yet powerful <phrase>evolutionary algorithm</phrase> can discover new architectures with excellent performance. our approach combines <phrase>a novel</phrase> hierarchical genetic representation scheme that imitates the modularized <phrase>design pattern</phrase> commonly adopted by human experts and an expressive search space that supports complex topologies. our algorithm efficiently discovers architectures that outperform <phrase>a large number of</phrase> manually designed models for <phrase>image classification</phrase> obtaining top 1 error of 3.6 on <phrase>cifar 10</phrase> and 20.3 when transferred to imagenet which is competitive with <phrase>the best</phrase> existing neural architecture search approaches. we <phrase>also present</phrase> results using random search achieving 0.3 less top 1 accuracy on <phrase>cifar 10</phrase> and 0.1 less on imagenet whilst reducing the search time from 36 hours down to 1 hour.
<phrase>data augmentation</phrase> <phrase>generative adversarial networks</phrase>
effective training of <phrase>neural networks</phrase> requires much data. in the low data regime parameters are underdetermined and learnt networks generalise poorly. <phrase>data augmentation</phrase> alleviates this <phrase>by using</phrase> existing data more effectively. however standard <phrase>data augmentation</phrase> produces only limited plausible alternative data. given there is potential <phrase>to generate</phrase> a much broader <phrase>set of</phrase> augmentations we design and train a <phrase>generative model</phrase> to do <phrase>data augmentation</phrase>. <phrase>the model</phrase> <phrase>based on</phrase> image conditional <phrase>generative adversarial networks</phrase> takes data from a source domain and learns to take any data item and generalise it <phrase>to generate</phrase> other within class data items. as this generative process <phrase>does not</phrase> depend on the classes themselves it can be <phrase>applied to</phrase> novel unseen classes of data. we show that a <phrase>data augmentation</phrase> <phrase>generative adversarial</phrase> network dagan augments standard vanilla classifiers well. we <phrase>also show</phrase> a dagan can enhance few <phrase>shot learning</phrase> systems <phrase>such as</phrase> matching networks. we demonstrate <phrase>these approaches</phrase> on omniglot on emnist having learnt the dagan on omniglot and vgg face data. in our experiments we can see over 13 increase in accuracy in the low data regime experiments in omniglot from 69 to 82 emnist 73.9 to 76 and vgg face 4.5 to 12 in matching networks for omniglot we observe an increase of 0.5 from 96.9 to 97.4 and an increase of 1.8 in emnist from 59.5 to 61.3 .
dnn buddies <phrase>a deep neural network</phrase> based estimation metric for the <phrase>jigsaw puzzle</phrase> problem
<phrase>this paper</phrase> introduces the first <phrase>deep neural network</phrase> based estimation metric for the <phrase>jigsaw puzzle</phrase> problem. given two puzzle piece edges the <phrase>neural network</phrase> predicts whether or not they should be adjacent in the correct assembly of the puzzle using nothing but the pixels of each piece. <phrase>the proposed</phrase> metric exhibits an extremely high precision even though no manual <phrase>feature extraction</phrase> is performed. when incorporated into an existing puzzle solver the solution s accuracy increases significantly achieving thereby <phrase>a new</phrase> <phrase>state of</phrase> <phrase>the art</phrase> standard.
deeppainter painter classification using <phrase>deep convolutional</phrase> autoencoders
in <phrase>this paper</phrase> we describe <phrase>the problem of</phrase> painter classification and propose <phrase>a novel</phrase> <phrase>approach based on</phrase> <phrase>deep convolutional</phrase> autoencoder <phrase>neural networks</phrase>. while previous approaches relied on <phrase>image processing</phrase> and manual <phrase>feature extraction</phrase> from paintings our approach operates on the raw pixel level without any preprocessing or manual <phrase>feature extraction</phrase>. we first train a <phrase>deep convolutional</phrase> autoencoder on a dataset of paintings and subsequently use it to initialize a supervised <phrase>convolutional neural network</phrase> for the classification phase. <phrase>the proposed</phrase> approach substantially outperforms previous methods improving the <phrase>previous state of</phrase> <phrase>the art</phrase> for the 3 painter classification problem from 90.44 accuracy <phrase>previous state of</phrase> <phrase>the art</phrase> to 96.52 accuracy i.e. a 63 <phrase>reduction in</phrase> <phrase>error rate</phrase>.
deepbrain functional representation of neural in situ hybridization images for <phrase>gene ontology</phrase> classification using <phrase>deep convolutional</phrase> autoencoders
<phrase>this paper</phrase> presents <phrase>a novel</phrase> <phrase>deep learning</phrase> based <phrase>method for</phrase> learning a functional representation of mammalian neural images. the method uses a <phrase>deep convolutional</phrase> denoising autoencoder cdae for generating an invariant compact representation of in situ hybridization ish images. while most <phrase>existing methods</phrase> for bio imaging analysis were not developed to handle images with highly complex anatomical structures the results presented in <phrase>this paper</phrase> show that functional representation extracted by cdae can help learn features of functional <phrase>gene ontology</phrase> categories for their classification in a highly accurate manner. using this cdae representation our method outperforms the <phrase>previous state of</phrase> <phrase>the art</phrase> classification rate by improving the average auc from 0.92 to 0.98 i.e. achieving 75 <phrase>reduction in</phrase> error. the method operates on input images that were downsampled significantly <phrase>with respect to</phrase> <phrase>the original</phrase> ones to make it computationally feasible.
<phrase>generative adversarial</phrase> perturbations
in <phrase>this paper</phrase> we propose novel <phrase>generative models</phrase> for creating <phrase>adversarial examples</phrase> slightly perturbed images resembling natural images but maliciously crafted to fool <phrase>pre trained</phrase> models. we present trainable <phrase>deep neural networks</phrase> for transforming images to <phrase>adversarial perturbations</phrase>. our proposed models can produce image agnostic and image dependent perturbations for both targeted and non targeted attacks. we also demonstrate that similar architectures can achieve impressive results in fooling classification and <phrase>semantic segmentation</phrase> models obviating <phrase>the need for</phrase> hand crafting attack methods for each task. using <phrase>extensive experiments</phrase> on challenging high resolution datasets <phrase>such as</phrase> imagenet and cityscapes we show that our perturbations achieve high fooling rates with small perturbation norms. moreover our attacks are considerably <phrase>faster than</phrase> current iterative methods at inference time.
a rotation and a translation suffice fooling cnns with simple transformations
we show that simple transformations namely translations and rotations alone are sufficient to fool <phrase>neural network</phrase> based vision models on a significant fraction of inputs. this is in sharp contrast to <phrase>previous work</phrase> that relied on more complicated optimization approaches that are unlikely to appear outside of a truly adversarial setting. moreover fooling rotations and translations are <phrase>easy to</phrase> find and require only a few <phrase>black box</phrase> queries to the target model. overall our findings emphasize <phrase>the need for</phrase> designing robust classifiers even in natural benign contexts.
peephole predicting network performance before training
the quest for performant networks has been a significant force that drives the advancements of <phrase>deep learning</phrase> <phrase>in recent years</phrase>. while rewarding improving network design has never been an easy journey. the large design space <phrase>combined with</phrase> the tremendous cost required for <phrase>network training</phrase> poses a major obstacle to this endeavor. in <phrase>this work</phrase> we propose <phrase>a new approach</phrase> to <phrase>this problem</phrase> namely predicting <phrase>the performance of</phrase> a network before training <phrase>based on</phrase> its architecture. specifically we develop <phrase>a unified</phrase> way to encode individual layers into vectors and bring them together to form an integrated description via lstm. taking <phrase>advantage of</phrase> the <phrase>recurrent network</phrase> s strong expressive power this method can reliably predict the performances of various <phrase>network architectures</phrase>. our empirical studies showed that it <phrase>not only</phrase> achieved accurate predictions <phrase>but also</phrase> produced consistent rankings across datasets a key desideratum in performance prediction.
an architecture combining <phrase>convolutional neural network</phrase> cnn and <phrase>support vector machine</phrase> svm for <phrase>image classification</phrase>
<phrase>convolutional neural networks</phrase> cnns are <phrase>similar to</phrase> ordinary <phrase>neural networks</phrase> in the sense that they are made up of <phrase>hidden layers</phrase> <phrase>consisting of</phrase> neurons with learnable parameters. these neurons receive inputs performs a <phrase>dot product</phrase> and then follows it with a non linearity. the whole network expresses the mapping between raw image pixels and their class scores. conventionally the softmax function is the classifier used at the last layer of this network. however there have been studies alalshekmubarak and smith 2013 agarap 2017 tang 2013 conducted to challenge this norm. the cited studies introduce the usage of linear <phrase>support vector machine</phrase> svm in an <phrase>artificial neural network</phrase> architecture. this project is yet another take on the subject and is <phrase>inspired by</phrase> tang 2013 . empirical data has shown that the cnn svm model was <phrase>able to</phrase> achieve a test accuracy of 99.04 using the mnist dataset lecun cortes and burges 2010 . on the other hand the cnn softmax was <phrase>able to</phrase> achieve a test accuracy of 99.23 using <phrase>the same</phrase> dataset. both models were also <phrase>tested on</phrase> the recently published fashion mnist dataset xiao rasul and vollgraf 2017 which is suppose to be a more difficult <phrase>image classification</phrase> dataset than mnist zalandoresearch 2017 . this proved to be the case as cnn svm reached a test accuracy of 90.72 while the cnn softmax reached a test accuracy of 91.86 . the said results may be improved if data preprocessing techniques were employed on the datasets and if the base cnn model was a relatively more sophisticated than the one used in <phrase>this study</phrase>.
benchmarking decoupled neural interfaces with synthetic gradients
artifical <phrase>neural networks</phrase> are a particular class of learning systems modeled after biological neural functions with an interesting penchant for hebbian learning that is neurons that wire together fire together . however unlike their natural counterparts <phrase>artificial neural networks</phrase> have a close and stringent coupling between the modules of neurons in <phrase>the network</phrase>. this coupling or locking imposes upon <phrase>the network</phrase> a strict and inflexible structure that prevent layers in <phrase>the network</phrase> from updating their weights until a full <phrase>feed forward</phrase> and backward pass has occurred. such a constraint though may have sufficed for a while is now no longer feasible in the era of very <phrase>large scale</phrase> <phrase>machine learning</phrase> coupled with the increased desire for parallelization of the learning process across multiple computing infrastructures. <phrase>to solve</phrase> <phrase>this problem</phrase> synthetic gradients sg with decoupled neural interfaces dni are introduced as a viable alternative to the backpropagation algorithm. <phrase>this paper</phrase> performs a speed benchmark to compare the speed and accuracy capabilities of sg dni as opposed to a standard neural interface using <phrase>multilayer perceptron</phrase> mlp. sg dni shows good promise in that it <phrase>not only</phrase> captures the learning problem it is also over 3 fold faster <phrase>due to</phrase> it asynchronous learning capabilities.
segmentation hi rarchique faiblement supervis e
<phrase>image segmentation</phrase> is the process of partitioning <phrase>an image</phrase> into <phrase>a set of</phrase> meaningful regions <phrase>according to</phrase> some criteria. hierarchical segmentation has emerged as a major trend in this regard as it favors the emergence of important regions at different scales. on the other hand many methods allow us to have prior information on the position of structures of interest in the images. in <phrase>this paper</phrase> we present a versatile hierarchical segmentation method that takes into account any prior spatial information and outputs a hierarchical segmentation that emphasizes the contours or regions of interest while preserving the important structures in the image. an <phrase>application of</phrase> this method to the <phrase>weakly supervised</phrase> segmentation problem is presented.
training wide <phrase>residual networks</phrase> for deployment using <phrase>a single</phrase> bit for each weight
for fast and energy efficient deployment of trained <phrase>deep neural networks</phrase> on resource constrained embedded hardware each learned weight parameter should ideally be represented and stored using <phrase>a single</phrase> bit. <phrase>error rates</phrase> usually increase when this requirement is imposed. here we report large improvements in <phrase>error rates</phrase> on multiple datasets for <phrase>deep convolutional neural networks</phrase> deployed with 1 bit per weight. using wide <phrase>residual networks</phrase> as our main baseline our approach simplifies <phrase>existing methods</phrase> that binarize weights by applying the <phrase>sign function</phrase> in training we apply scaling factors for <phrase>each layer</phrase> with constant unlearned values equal to the layer specific standard deviations used for initialization. for <phrase>cifar 10</phrase> cifar 100 and imagenet and models with 1 bit per weight requiring less than 10 mb of parameter memory we achieve <phrase>error rates</phrase> of 3.9 18.5 and 26.0 8.5 top 1 top 5 respectively. we also considered mnist svhn and imagenet32 achieving 1 bit per weight test results of 0.27 1.9 and 41.3 19.1 respectively. for cifar our <phrase>error rates</phrase> halve previously reported values and are within about 1 of our <phrase>error rates</phrase> for <phrase>the same</phrase> network with full precision weights. for networks that overfit we <phrase>also show</phrase> <phrase>significant improvements</phrase> in <phrase>error rate</phrase> by not learning <phrase>batch normalization</phrase> scale and offset parameters. this applies to both full precision and 1 bit per weight networks. using a warm restart <phrase>learning rate</phrase> schedule we found that training for 1 bit per weight is just as fast as full precision networks with better accuracy than standard schedules and achieved about 98 99 of peak performance in just 62 training epochs for <phrase>cifar 10</phrase> 100. for full training code and trained models in matlab keras and pytorch see https github.com mcdonnell lab 1 bit per weight .
<phrase>deep learning</phrase> using <phrase>rectified linear</phrase> units relu 
we introduce <phrase>the use of</phrase> <phrase>rectified linear</phrase> units relu as the classification function in <phrase>a deep neural network</phrase> dnn . conventionally relu is <phrase>used as</phrase> an <phrase>activation function</phrase> in dnns with softmax function as their classification function. however there have been several studies on using a classification function other than softmax and <phrase>this study</phrase> is an addition to those. we accomplish this by taking the activation of the penultimate layer h n 1 in <phrase>a neural network</phrase> then multiply it by weight parameters theta to get the raw scores o i . afterwards we threshold the raw scores o i by 0 i.e. f o max 0 o i where f o is the relu function. we provide class predictions hat y through argmax function i.e. argmax f x .
rectified factor networks
we propose rectified factor networks rfns to efficiently construct very sparse <phrase>non linear</phrase> <phrase>high dimensional</phrase> representations of <phrase>the input</phrase>. rfn models identify rare and small events in <phrase>the input</phrase> have a low interference between code units have <phrase>a small</phrase> reconstruction error and explain the data covariance structure. rfn learning is a generalized alternating minimization algorithm <phrase>derived from</phrase> the posterior regularization method which enforces non negative and normalized posterior means. we proof convergence and correctness of the rfn <phrase>learning algorithm</phrase>. on benchmarks rfns are <phrase>compared to</phrase> other unsupervised methods like autoencoders rbms <phrase>factor analysis</phrase> ica and pca. <phrase>in contrast to</phrase> previous sparse coding methods rfns yield sparser codes capture the data s covariance structure more precisely and have a significantly smaller reconstruction error. we test rfns as pretraining technique for <phrase>deep networks</phrase> on different vision datasets where rfns were superior to rbms and autoencoders. on <phrase>gene expression</phrase> data from two <phrase>pharmaceutical drug</phrase> discovery studies rfns detected small and rare gene modules that revealed highly relevant new biological insights which were <phrase>so far</phrase> missed by other unsupervised methods.
from maxout to channel out encoding information on sparse pathways
<phrase>motivated by</phrase> <phrase>an important</phrase> insight from neural science we propose <phrase>a new</phrase> <phrase>framework for</phrase> understanding the success of the <phrase>recently proposed</phrase> maxout networks. the framework is <phrase>based on</phrase> encoding information on sparse pathways and recognizing the correct pathway at inference time. elaborating further on this insight we propose <phrase>a novel</phrase> <phrase>deep network</phrase> architecture called channel out network which takes a much better <phrase>advantage of</phrase> sparse pathway encoding. in channel out networks pathways are <phrase>not only</phrase> formed a posteriori but they are also actively selected <phrase>according to</phrase> the inference outputs from the lower layers. from a mathematical perspective channel out networks can represent a wider class of piece wise continuous functions thereby endowing <phrase>the network</phrase> with more expressive power than that of maxout networks. we test our channel out networks on several <phrase>well known</phrase> <phrase>image classification</phrase> benchmarks setting new <phrase>state of</phrase> <phrase>the art performance on</phrase> cifar 100 and stl 10 which represent some of the harder <phrase>image classification</phrase> benchmarks.
competitive learning with feedforward supervisory signal for <phrase>pre trained</phrase> multilayered networks
we propose <phrase>a novel</phrase> learning <phrase>method for</phrase> multilayered <phrase>neural networks</phrase> which uses feedforward supervisory signal and associates classification of <phrase>a new</phrase> input with that of <phrase>pre trained</phrase> input. <phrase>the proposed</phrase> method effectively uses rich input information in the earlier layer for robust leaning and revising internal representation in a multilayer <phrase>neural network</phrase>.
deeply supervised nets
our proposed deeply supervised nets dsn method simultaneously minimizes classification error while making the learning process of <phrase>hidden layers</phrase> direct and transparent. we make an <phrase>attempt to</phrase> boost the <phrase>classification performance</phrase> by studying <phrase>a new</phrase> formulation in <phrase>deep networks</phrase>. three aspects in <phrase>convolutional neural networks</phrase> cnn style architectures are being looked at 1 transparency of the intermediate layers to the overall classification 2 discriminativeness and robustness of learned features especially in the early layers 3 effectiveness in training <phrase>due to</phrase> the presence of the exploding and vanishing gradients. we introduce companion objective to the individual <phrase>hidden layers</phrase> <phrase>in addition</phrase> to the overall objective at <phrase>the output layer</phrase> a different strategy to <phrase>layer wise</phrase> <phrase>pre training</phrase> . we extend techniques from <phrase>stochastic gradient</phrase> methods to analyze our algorithm. the <phrase>advantage of</phrase> our method is evident and our experimental result on <phrase>benchmark datasets</phrase> shows significant performance gain over <phrase>existing methods</phrase> e.g. all <phrase>state of</phrase> <phrase>the art results</phrase> on mnist <phrase>cifar 10</phrase> cifar 100 and svhn .
path sgd path normalized optimization in <phrase>deep neural networks</phrase>
we revisit the <phrase>choice of</phrase> sgd for <phrase>training deep neural networks</phrase> by reconsidering the appropriate geometry in which to optimize the weights. we argue for a geometry invariant to rescaling of weights that <phrase>does not</phrase> affect the output of <phrase>the network</phrase> and suggest path sgd which is an approximate steepest descent method <phrase>with respect to</phrase> a path wise regularizer <phrase>related to</phrase> max norm regularization. path sgd is easy and efficient to implement and <phrase>leads to</phrase> empirical gains over sgd and adagrad.
adapting resilient propagation for <phrase>deep learning</phrase>
the resilient propagation rprop algorithm has been very popular for backpropagation training of multilayer <phrase>feed forward</phrase> <phrase>neural networks</phrase> in various applications. the standard rprop however encounters difficulties in <phrase>the context of</phrase> <phrase>deep neural networks</phrase> as typically happens with <phrase>gradient based</phrase> <phrase>learning algorithms</phrase>. in <phrase>this paper</phrase> we propose a modification of the rprop that combines standard rprop steps with <phrase>a special</phrase> drop out technique. we apply the <phrase>method for</phrase> <phrase>training deep neural networks</phrase> as standalone components and in ensemble formulations. <phrase>results on</phrase> the mnist dataset show that <phrase>the proposed</phrase> modification alleviates standard rprop s problems demonstrating improved learning speed and accuracy.
<phrase>convolutional neural network</phrase> for stereotypical motor movement detection in autism
<phrase>autism spectrum</phrase> disorders asds are often <phrase>associated with</phrase> specific atypical postural or motor behaviors of which stereotypical motor movements smms have a specific visibility. while the identification and the quantification of smm patterns remain complex its automation would provide support to accurate tuning of the intervention in the therapy of autism. therefore it is essential to develop automatic smm detection systems in a <phrase>real world</phrase> setting taking care of strong inter subject and intra subject variability. wireless accelerometer sensing technology can provide a valid infrastructure for <phrase>real time</phrase> smm detection however such variability remains a problem also for <phrase>machine learning</phrase> methods <phrase>in particular</phrase> whenever handcrafted features <phrase>extracted from</phrase> accelerometer signal are considered. here we propose to employ the <phrase>deep learning</phrase> paradigm <phrase>in order to</phrase> learn discriminating features from multi sensor accelerometer signals. our results provide preliminary evidence that <phrase>feature learning</phrase> and <phrase>transfer learning</phrase> embedded in the deep architecture achieve higher accurate smm detectors in longitudinal scenarios.
resnet in resnet generalizing residual architectures
<phrase>residual networks</phrase> resnets have recently achieved <phrase>state of</phrase> <phrase>the art</phrase> on challenging <phrase>computer vision</phrase> tasks. we introduce resnet in resnet rir a deep dual stream architecture that generalizes resnets and standard cnns and is easily implemented with no computational overhead. rir consistently improves performance over resnets outperforms architectures with similar <phrase>amounts of</phrase> augmentation on <phrase>cifar 10</phrase> and establishes <phrase>a new</phrase> <phrase>state of</phrase> <phrase>the art</phrase> on cifar 100.
evolutionary synthesis of <phrase>deep neural networks</phrase> via synaptic cluster driven genetic encoding
there has been significant recent interest towards achieving highly efficient <phrase>deep neural network</phrase> architectures. a promising paradigm for achieving this is the concept of evolutionary deep intelligence which attempts to mimic <phrase>biological evolution</phrase> processes to synthesize highly efficient <phrase>deep neural networks</phrase> over successive generations. <phrase>an important</phrase> aspect of evolutionary deep intelligence is the genetic encoding scheme used to mimic heredity which can have a significant impact on the quality of offspring <phrase>deep neural networks</phrase>. <phrase>motivated by</phrase> the neurobiological phenomenon of synaptic clustering we introduce <phrase>a new</phrase> genetic encoding scheme where synaptic probability is driven towards the formation of a highly sparse <phrase>set of</phrase> synaptic clusters. <phrase>experimental results</phrase> for <phrase>the task of</phrase> <phrase>image classification</phrase> demonstrated that the synthesized offspring networks using this synaptic cluster driven genetic encoding scheme can <phrase>achieve state of</phrase> <phrase>the art</phrase> performance while having <phrase>network architectures</phrase> that are <phrase>not only</phrase> significantly <phrase>more efficient</phrase> with a 125 fold <phrase>decrease in</phrase> synapses for mnist <phrase>compared to</phrase> <phrase>the original</phrase> ancestor network <phrase>but also</phrase> tailored for gpu accelerated <phrase>machine learning</phrase> applications.
neural photo editing with introspective <phrase>adversarial networks</phrase>
the increasingly photorealistic sample quality of generative image models suggests their feasibility in applications beyond image generation. we present the neural photo editor an interface that leverages the power of generative <phrase>neural networks</phrase> to make large semantically coherent changes to existing images. <phrase>to tackle</phrase> the challenge of achieving accurate reconstructions without loss of feature quality we introduce the introspective adversarial network <phrase>a novel</phrase> hybridization of the vae and gan. our model efficiently captures <phrase>long range</phrase> dependencies through use of a computational block <phrase>based on</phrase> weight shared dilated convolutions and improves generalization performance with orthogonal regularization <phrase>a novel</phrase> weight regularization method. we validate our contributions on celeba svhn and cifar 100 and produce samples and reconstructions with high visual fidelity.
adaptive <phrase>neural networks</phrase> for efficient inference
we present an <phrase>approach to</phrase> adaptively utilize <phrase>deep neural networks</phrase> <phrase>in order to</phrase> reduce the evaluation time on new examples without loss of accuracy. <phrase>rather than</phrase> attempting to redesign or approximate existing networks we propose two schemes that adaptively utilize networks. we first pose an adaptive network evaluation scheme where we learn a system to adaptively choose the components of a <phrase>deep network</phrase> to be evaluated for each example. by allowing examples correctly classified using early layers of the system to exit we avoid the computational time <phrase>associated with</phrase> full evaluation of <phrase>the network</phrase>. we extend this <phrase>to learn</phrase> a network selection system that adaptively selects <phrase>the network</phrase> to be evaluated for each example. we show that computational time can be dramatically reduced by exploiting the fact that many examples can be correctly classified using relatively efficient networks and that complex computationally costly networks are only necessary for <phrase>a small</phrase> fraction of examples. we pose a global objective for learning an adaptive early exit or network selection policy and solve it by reducing the policy learning problem to a layer by layer weighted <phrase>binary classification</phrase> problem. empirically <phrase>these approaches</phrase> yield dramatic reductions in <phrase>computational cost</phrase> with up to a 2.8x speedup on <phrase>state of</phrase> <phrase>the art</phrase> networks from the imagenet image recognition challenge <phrase>with minimal</phrase> 1 loss of top5 accuracy.
spatial variational auto encoding via matrix variate normal distributions
the key idea of variational auto encoders vaes resembles that of traditional auto encoder models in which spatial information is supposed to be explicitly encoded in the <phrase>latent space</phrase>. however the <phrase>latent variables</phrase> in vaes are vectors which are commonly interpreted as multiple feature maps of size 1x1. such representations can only convey spatial information implicitly when coupled with powerful decoders. in <phrase>this work</phrase> we propose spatial vaes that use <phrase>latent variables</phrase> as feature maps of larger size to explicitly capture spatial information. this is <phrase>achieved by</phrase> allowing the <phrase>latent variables</phrase> to be sampled from matrix variate normal mvn distributions whose parameters are computed from the encoder network. to increase dependencies among locations on latent feature maps and reduce <phrase>the number of</phrase> parameters we further propose spatial vaes via low rank mvn distributions. <phrase>experimental results</phrase> show that <phrase>the proposed</phrase> spatial vaes outperform original vaes in capturing rich structural and spatial information.
dense transformer networks
the key idea of current <phrase>deep learning</phrase> methods for dense prediction is to apply a model on a regular patch centered on each pixel to make pixel wise predictions. these methods are limited in the sense that the patches are determined by <phrase>network architecture</phrase> <phrase>instead of</phrase> learned from data. in <phrase>this work</phrase> we propose the dense transformer networks which can learn the shapes and sizes of patches from data. the dense transformer networks employ an <phrase>encoder decoder</phrase> architecture and a pair of dense transformer modules are inserted into each of the encoder and decoder paths. the novelty of <phrase>this work</phrase> is that we provide technical solutions for learning the shapes and sizes of patches from data and efficiently restoring the spatial correspondence required for dense prediction. <phrase>the proposed</phrase> dense transformer modules are differentiable thus the entire network can be trained. we apply <phrase>the proposed</phrase> networks on natural and biological <phrase>image segmentation</phrase> tasks and show superior performance is achieved in comparison to baseline methods.
progressive learning for systematic design of large <phrase>neural networks</phrase>
we develop an algorithm for systematic design of <phrase>a large</phrase> <phrase>artificial neural network</phrase> using a progression property. we find that some <phrase>non linear</phrase> functions <phrase>such as</phrase> the rectifier linear unit and its derivatives hold the property. the systematic design addresses the <phrase>choice of</phrase> network size and regularization of parameters. <phrase>the number of</phrase> nodes and layers in network increases in progression with the objective of consistently reducing an appropriate cost. <phrase>each layer</phrase> is optimized at a time where appropriate parameters are learned using <phrase>convex optimization</phrase>. regularization parameters for <phrase>convex optimization</phrase> <phrase>do not</phrase> need a significant manual effort for tuning. we also use random instances for some weight matrices and that helps <phrase>to reduce</phrase> <phrase>the number of</phrase> parameters we learn. the developed network is expected to show good generalization power <phrase>due to</phrase> appropriate regularization and use of random weights in the layers. this expectation is verified by <phrase>extensive experiments</phrase> for classification and regression problems using standard databases.
a classification based perspective on gan distributions
a fundamental and still largely unanswered question in <phrase>the context of</phrase> <phrase>generative adversarial networks</phrase> gans is whether gans are actually <phrase>able to</phrase> capture the key characteristics of the datasets they are <phrase>trained on</phrase>. the current approaches to examining <phrase>this issue</phrase> require significant human supervision <phrase>such as</phrase> visual inspection of sampled images and often offer only fairly limited scalability. in <phrase>this paper</phrase> we propose new techniques that employ a classification based perspective to evaluate synthetic gan distributions and their capability to accurately reflect the essential <phrase>properties of</phrase> <phrase>the training data</phrase>. these techniques require only minimal human supervision and can easily be scaled and adapted to evaluate <phrase>a variety of</phrase> <phrase>state of</phrase> <phrase>the art</phrase> gans on large popular datasets. our analysis indicates that gans have significant problems in reproducing the more distributional <phrase>properties of</phrase> the training dataset. <phrase>in particular</phrase> when seen through the lens of classification the diversity of gan data is orders <phrase>of magnitude</phrase> less than that of <phrase>the original</phrase> data.
learning visual reasoning without strong priors
achieving artificial visual reasoning the <phrase>ability to</phrase> answer image related questions which require a multi step <phrase>high level</phrase> process is <phrase>an important</phrase> <phrase>step towards</phrase> <phrase>artificial general intelligence</phrase>. this multi modal task requires learning a question dependent structured reasoning process over images from language. standard <phrase>deep learning</phrase> approaches <phrase>tend to</phrase> exploit biases in the data <phrase>rather than</phrase> learn this underlying structure while leading methods learn to visually reason successfully but are <phrase>hand crafted</phrase> for reasoning. we show that a <phrase>general purpose</phrase> conditional <phrase>batch normalization</phrase> approach <phrase>achieves state of</phrase> <phrase>the art results</phrase> on the clevr visual reasoning benchmark with a 2.4 <phrase>error rate</phrase>. we outperform the next best <phrase>end to end</phrase> method 4.5 and even methods that use extra supervision 3.1 . we probe our model to shed light on how it reasons showing it has learned a question dependent multi step process. <phrase>previous work</phrase> has operated under the assumption that visual reasoning calls for a specialized architecture but we show that a general architecture with proper conditioning can learn to visually reason effectively.
men also like shopping reducing gender bias amplification using corpus level constraints
language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. <phrase>structured prediction</phrase> models are used in these tasks to take <phrase>advantage of</phrase> correlations between co occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. in <phrase>this work</phrase> we study data and models <phrase>associated with</phrase> multilabel object classification and visual semantic role labeling. we find that a datasets for these tasks contain significant gender bias and b models <phrase>trained on</phrase> these datasets further amplify existing bias. for example the activity cooking is over 33 more likely to involve females than males in a <phrase>training set</phrase> and a trained model further amplifies the disparity to 68 at <phrase>test time</phrase>. we propose to inject corpus level constraints for calibrating existing <phrase>structured prediction</phrase> models and design an algorithm <phrase>based on</phrase> lagrangian relaxation for collective inference. our method results in almost no performance loss for the underlying <phrase>recognition task</phrase> but decreases the magnitude of bias amplification by 47.5 and 40.5 for multilabel classification and visual semantic role labeling respectively.
acquiring common sense spatial knowledge through implicit spatial templates
spatial understanding is a fundamental problem with wide reaching <phrase>real world</phrase> applications. the representation of spatial knowledge is often modeled with spatial templates i.e. regions of acceptability of two objects under an explicit spatial relationship e.g. on below etc. . <phrase>in contrast</phrase> with prior work that restricts spatial templates to explicit spatial prepositions e.g. glass on table here we extend this concept to implicit spatial language i.e. those relationships generally actions for which the spatial arrangement of the objects is only implicitly implied e.g. man riding horse . <phrase>in contrast</phrase> with explicit relationships predicting spatial arrangements from implicit spatial language requires significant common sense spatial understanding. here we introduce <phrase>the task of</phrase> predicting spatial templates for two objects under a relationship which can be seen as a spatial <phrase>question answering</phrase> task with a 2d continuous output where is the man w.r.t. a horse when the man is walking the horse . we present two simple neural based models that leverage annotated images and structured text <phrase>to learn</phrase> <phrase>this task</phrase>. the good performance of <phrase>these models</phrase> reveals that spatial locations are to <phrase>a large</phrase> extent predictable from implicit spatial language. crucially the models attain similar performance in a challenging generalized setting where the object relation object combinations e.g. man walking dog have never been seen before. next we go one step further by presenting the models with unseen objects e.g. dog . in this scenario we show that leveraging <phrase>word embeddings</phrase> enables the models to output accurate spatial predictions proving that the models acquire solid common sense spatial knowledge allowing for such generalization.
film visual reasoning with a general conditioning layer
we introduce a <phrase>general purpose</phrase> conditioning <phrase>method for</phrase> <phrase>neural networks</phrase> called film feature wise linear modulation. film layers influence <phrase>neural network</phrase> computation via <phrase>a simple</phrase> feature wise <phrase>affine transformation</phrase> <phrase>based on</phrase> conditioning information. we show that film layers are highly effective for visual reasoning answering image related questions which require a multi step <phrase>high level</phrase> process a task which has proven difficult for standard <phrase>deep learning</phrase> methods that <phrase>do not</phrase> explicitly model reasoning. specifically we show on visual reasoning tasks that film layers 1 halve <phrase>state of</phrase> <phrase>the art</phrase> error for the clevr benchmark 2 modulate features in a coherent manner 3 are robust to ablations and architectural modifications and 4 generalize well to challenging new data from few examples or even <phrase>zero shot</phrase>.
unsupervised induction of semantic roles within a reconstruction error minimization framework
we introduce <phrase>a new approach</phrase> to unsupervised estimation of feature rich semantic role labeling models. our model <phrase>consists of</phrase> two components 1 an encoding component a semantic role labeling model which predicts roles given a rich <phrase>set of</phrase> syntactic and lexical features 2 a reconstruction component a tensor factorization model which relies on roles <phrase>to predict</phrase> argument fillers. when the components are estimated jointly to minimize errors in argument reconstruction the induced roles largely correspond to roles defined in annotated resources. our method performs on par with most accurate role induction methods on english and german even though unlike these previous approaches we <phrase>do not</phrase> incorporate any prior linguistic knowledge about the languages.
man is to computer programmer as woman is to homemaker debiasing <phrase>word embeddings</phrase>
the blind <phrase>application of</phrase> <phrase>machine learning</phrase> runs the risk of amplifying biases present in data. such a danger is facing us with <phrase>word embedding</phrase> a popular framework <phrase>to represent</phrase> text data as vectors which has been used in many <phrase>machine learning</phrase> and <phrase>natural language</phrase> processing tasks. we show that even <phrase>word embeddings</phrase> <phrase>trained on</phrase> <phrase>google news</phrase> articles exhibit female male gender stereotypes to a disturbing extent. this raises concerns because their widespread use as we describe often tends to amplify these biases. geometrically gender bias is first <phrase>shown to</phrase> be captured by a direction in the <phrase>word embedding</phrase>. second gender neutral words are <phrase>shown to</phrase> be linearly separable from gender definition words in the <phrase>word embedding</phrase>. using these properties we provide a methodology for modifying an embedding to remove gender stereotypes <phrase>such as</phrase> the association between between the words receptionist and female while maintaining desired associations <phrase>such as</phrase> between the words queen and female. we define metrics to quantify both direct and indirect gender biases in embeddings and develop algorithms to debias the embedding. using crowd worker evaluation <phrase>as well as</phrase> standard benchmarks we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties <phrase>such as</phrase> the <phrase>ability to</phrase> cluster related concepts and <phrase>to solve</phrase> analogy tasks. the resulting embeddings can be used in applications without amplifying gender bias.
topicrnn <phrase>a recurrent neural network</phrase> with <phrase>long range</phrase> semantic dependency
in <phrase>this paper</phrase> we propose topicrnn <phrase>a recurrent neural network</phrase> <phrase>rnn based</phrase> <phrase>language model</phrase> designed to directly capture the global semantic meaning relating words in a document via latent topics. because of their sequential nature rnns are good at capturing the local structure of a word sequence both semantic and syntactic but might face difficulty remembering <phrase>long range</phrase> dependencies. intuitively these <phrase>long range</phrase> dependencies are of semantic nature. <phrase>in contrast</phrase> latent topic models are <phrase>able to</phrase> capture the global underlying semantic structure of a document but <phrase>do not</phrase> account for word ordering. <phrase>the proposed</phrase> topicrnn model integrates the merits of rnns and latent topic models it captures local syntactic dependencies using an rnn and global semantic dependencies using latent topics. unlike <phrase>previous work</phrase> on contextual rnn <phrase>language modeling</phrase> our model is learned <phrase>end to end</phrase>. empirical <phrase>results on</phrase> word prediction show that topicrnn outperforms existing contextual rnn baselines. <phrase>in addition</phrase> topicrnn can be <phrase>used as</phrase> an unsupervised feature extractor for documents. we do this for <phrase>sentiment analysis</phrase> on the imdb movie review dataset and report an <phrase>error rate</phrase> of 6.28 . this is <phrase>comparable to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> 5.91 resulting from a <phrase>semi supervised</phrase> approach. finally topicrnn also yields sensible topics making it a useful alternative to document models <phrase>such as</phrase> <phrase>latent dirichlet allocation</phrase>.
gaussian <phrase>attention model</phrase> and its <phrase>application to</phrase> <phrase>knowledge base</phrase> embedding and <phrase>question answering</phrase>
we propose the gaussian <phrase>attention model</phrase> for content based neural memory access. with <phrase>the proposed</phrase> <phrase>attention model</phrase> <phrase>a neural network</phrase> has the additional degree of freedom to control the focus of its attention from a laser sharp attention to a broad attention. it is applicable whenever we can assume that the distance in the <phrase>latent space</phrase> reflects some <phrase>notion of</phrase> semantics. we use <phrase>the proposed</phrase> <phrase>attention model</phrase> as a scoring function for the embedding of a <phrase>knowledge base</phrase> into a continuous <phrase>vector space</phrase> and then train a model that performs <phrase>question answering</phrase> about the entities in the <phrase>knowledge base</phrase>. <phrase>the proposed</phrase> <phrase>attention model</phrase> can handle both the propagation of uncertainty when following <phrase>a series of</phrase> relations and also the conjunction of conditions in a natural way. on a dataset of soccer players who participated in the <phrase>fifa world cup</phrase> 2014 we demonstrate that our model can handle both path queries and conjunctive queries well.
variable computation in <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> rnns have been used extensively and with increasing success to model various <phrase>types of</phrase> sequential data. much of this progress has been achieved through devising recurrent units and architectures with the flexibility <phrase>to capture</phrase> complex statistics in the data <phrase>such as</phrase> <phrase>long range</phrase> dependency or localized attention phenomena. however while many sequential data <phrase>such as</phrase> video speech or language can have highly variable information flow most recurrent models still consume <phrase>input features</phrase> at a constant rate and perform a constant <phrase>number of</phrase> computations per time step which can be detrimental to both speed and model capacity. in <phrase>this paper</phrase> we explore a modification to existing recurrent units which allows them <phrase>to learn</phrase> to vary the <phrase>amount of</phrase> computation they perform at each step without <phrase>prior knowledge</phrase> of the sequence s time structure. we show experimentally that <phrase>not only</phrase> do our models require fewer operations they also <phrase>lead to</phrase> <phrase>better performance</phrase> overall on evaluation tasks.
learning <phrase>to learn</phrase> from weak supervision by full supervision
in <phrase>this paper</phrase> we propose a <phrase>method for</phrase> training <phrase>neural networks</phrase> when we have <phrase>a large</phrase> <phrase>set of</phrase> data with weak labels and <phrase>a small</phrase> <phrase>amount of</phrase> data with true labels. in our <phrase>proposed model</phrase> we train two <phrase>neural networks</phrase> a target network the learner and a confidence network the meta learner. the target network is optimized <phrase>to perform</phrase> a given task and is trained using <phrase>a large</phrase> <phrase>set of</phrase> unlabeled data that are weakly annotated. we propose to control the magnitude of the gradient updates to the target network using the scores provided by the second confidence network which is <phrase>trained on</phrase> <phrase>a small</phrase> <phrase>amount of</phrase> supervised data. thus we avoid that the weight updates computed from noisy labels harm the quality of the target network model.
smiles2vec an interpretable <phrase>general purpose</phrase> <phrase>deep neural network</phrase> for predicting chemical properties
chemical databases store information in text representations and the smiles format is a universal standard used in many cheminformatics software. encoded in each smiles string is structural information that can be used <phrase>to predict</phrase> complex chemical properties. in <phrase>this work</phrase> we develop smiles2vec a deep rnn that automatically learns features from smiles <phrase>to predict</phrase> chemical properties without <phrase>the need for</phrase> additional explicit feature engineering. using bayesian optimization methods to tune <phrase>the network</phrase> architecture we show that an optimized smiles2vec model can serve as a <phrase>general purpose</phrase> <phrase>neural network</phrase> for predicting distinct chemical properties including toxicity activity solubility and solvation energy while also outperforming contemporary mlp <phrase>neural networks</phrase> that uses engineered features. furthermore we demonstrate proof of concept of interpretability by developing an explanation mask that localizes on the most important characters used in making a prediction. when <phrase>tested on</phrase> the solubility dataset it identified specific <phrase>parts of</phrase> a chemical that is consistent with established first principles knowledge with an accuracy of 88 . our work demonstrates that <phrase>neural networks</phrase> can learn technically accurate chemical concept and provide <phrase>state of</phrase> <phrase>the art</phrase> accuracy making interpretable <phrase>deep neural networks</phrase> a useful tool of relevance to the <phrase>chemical industry</phrase>.
sample efficient <phrase>deep reinforcement learning</phrase> for <phrase>dialogue systems</phrase> with large action spaces
in spoken <phrase>dialogue systems</phrase> we aim to deploy <phrase>artificial intelligence</phrase> to build automated dialogue agents that can converse with humans. a part of this effort is the policy optimisation task which attempts to find a policy describing how to respond to humans in the form of a function taking <phrase>the current state of</phrase> the dialogue and returning the response of the system. in <phrase>this paper</phrase> we investigate <phrase>deep reinforcement learning</phrase> approaches <phrase>to solve</phrase> <phrase>this problem</phrase>. particular attention is given to <phrase>actor critic</phrase> methods off policy <phrase>reinforcement learning</phrase> with experience replay and various methods aimed at reducing the bias and variance of estimators. when combined these methods result in the previously proposed acer algorithm that gave <phrase>competitive results</phrase> in gaming environments. these environments however are fully observable and have a relatively small action set so in <phrase>this paper</phrase> we examine the <phrase>application of</phrase> acer to dialogue policy optimisation. we show that this method beats <phrase>the current state of</phrase> <phrase>the art</phrase> in <phrase>deep learning</phrase> approaches for spoken <phrase>dialogue systems</phrase>. this <phrase>not only</phrase> <phrase>leads to</phrase> a more sample efficient algorithm that can train faster <phrase>but also</phrase> allows us to apply the algorithm in more difficult environments than before. we thus experiment with learning in a very large action space which has two orders <phrase>of magnitude</phrase> more actions than previously considered. we find that acer trains significantly <phrase>faster than</phrase> <phrase>the current state of</phrase> <phrase>the art</phrase>.
<phrase>high dimensional</phrase> vector semantics
in <phrase>this paper</phrase> we explore the vector semantics problem from the perspective of almost orthogonal property of <phrase>high dimensional</phrase> random vectors. we show that this intriguing property can be used to memorize random vectors by simply adding them and we provide an efficient probabilistic solution to the set membership problem. also we discuss several applications to word context vector embeddings document sentences similarity and spam filtering.
learning semantic script knowledge with event embeddings
induction of common sense knowledge about prototypical sequences of events has recently received much attention. <phrase>instead of</phrase> inducing this knowledge in the form of graphs as in much of the <phrase>previous work</phrase> in our method distributed representations of event realizations are computed <phrase>based on</phrase> distributed representations of predicates and their arguments and then these representations are used <phrase>to predict</phrase> prototypical event orderings. <phrase>the parameters of</phrase> the compositional process for computing the event representations and the ranking component of <phrase>the model</phrase> are jointly estimated from texts. we show that <phrase>this approach</phrase> results in a substantial boost in ordering performance <phrase>with respect to</phrase> previous methods.
mathematical <phrase>language processing</phrase> automatic grading and feedback for open response mathematical questions
while computer and communication technologies have provided effective means to scale up many <phrase>aspects of</phrase> education the submission and grading of assessments <phrase>such as</phrase> homework assignments and tests remains a weak link. in <phrase>this paper</phrase> we study <phrase>the problem of</phrase> automatically grading the kinds of open response mathematical questions that figure prominently in stem science technology engineering and mathematics courses. our <phrase>data driven</phrase> <phrase>framework for</phrase> mathematical <phrase>language processing</phrase> mlp leverages solution data from <phrase>a large number of</phrase> learners to evaluate the correctness of their solutions assign partial credit scores and provide feedback to each learner on the likely locations of any errors. mlp takes inspiration from the success of <phrase>natural language</phrase> processing for text data and comprises three main steps. first we convert each solution to an open response mathematical question into <phrase>a series of</phrase> numerical features. second we cluster the features from several solutions to uncover the structures of correct partially correct and incorrect solutions. we develop two different clustering approaches one that leverages generic clustering algorithms and one <phrase>based on</phrase> bayesian nonparametrics. third we automatically grade the remaining potentially <phrase>large number of</phrase> solutions <phrase>based on</phrase> their assigned cluster and one instructor provided grade per cluster. as a bonus we can track the cluster assignment of each step of a multistep solution and determine when it departs from a cluster of correct solutions which enables us to indicate the likely locations of errors to learners. we test and validate mlp on <phrase>real world</phrase> mooc data to demonstrate how it can substantially reduce the human effort required in <phrase>large scale</phrase> educational platforms.
nonparametric bayesian double articulation analyzer for direct <phrase>language acquisition</phrase> from <phrase>continuous speech</phrase> signals
human infants can discover words directly from unsegmented speech signals without any explicitly labeled data. in <phrase>this paper</phrase> we develop <phrase>a novel</phrase> <phrase>machine learning</phrase> method called nonparametric bayesian double articulation analyzer npb daa that can directly acquire language and <phrase>acoustic models</phrase> from observed <phrase>continuous speech</phrase> signals. for this purpose we propose an integrative <phrase>generative model</phrase> that combines a <phrase>language model</phrase> and an acoustic model into <phrase>a single</phrase> <phrase>generative model</phrase> called the hierarchical dirichlet process hidden <phrase>language model</phrase> hdp hlm . the hdp hlm is <phrase>obtained by</phrase> extending the hierarchical dirichlet process hidden semi markov model hdp hsmm proposed by johnson <phrase>et al</phrase>. an inference procedure for the hdp hlm is derived using the blocked gibbs sampler originally proposed for the hdp hsmm. this procedure enables the simultaneous and direct inference of language and <phrase>acoustic models</phrase> from <phrase>continuous speech</phrase> signals. <phrase>based on</phrase> the hdp hlm and its inference procedure we developed <phrase>a novel</phrase> double articulation analyzer. by assuming hdp hlm as a <phrase>generative model</phrase> of observed <phrase>time series</phrase> data and by inferring <phrase>latent variables</phrase> of <phrase>the model</phrase> the method can analyze latent double articulation structure i.e. hierarchically organized latent words and phonemes of the data in an unsupervised manner. the novel unsupervised double articulation analyzer is called npb daa. the npb daa can automatically estimate double articulation structure embedded in speech signals. we also carried out two evaluation experiments using synthetic data and actual human <phrase>continuous speech</phrase> signals representing japanese vowel sequences. in the word acquisition and phoneme categorization tasks the npb daa outperformed a conventional double articulation analyzer daa and baseline <phrase>automatic speech recognition</phrase> system whose acoustic model was trained in a supervised manner.
harnessing <phrase>deep neural networks</phrase> with logic rules
combining <phrase>deep neural networks</phrase> with structured logic rules is desirable to harness flexibility and reduce uninterpretability of the <phrase>neural models</phrase>. we propose a general framework <phrase>capable of</phrase> enhancing various <phrase>types of</phrase> <phrase>neural networks</phrase> e.g. cnns and rnns with declarative <phrase>first order logic</phrase> rules. specifically we develop an iterative distillation method that transfers the structured information of logic rules into the weights of <phrase>neural networks</phrase>. we deploy the framework on a cnn for <phrase>sentiment analysis</phrase> and an rnn for <phrase>named entity recognition</phrase>. with a few highly intuitive rules we obtain substantial improvements and <phrase>achieve state of</phrase> <phrase>the art</phrase> or comparable results to previous best performing systems.
toward controlled generation of text
generic generation and manipulation of text is challenging and has limited success <phrase>compared to</phrase> recent deep generative modeling in visual domain. <phrase>this paper</phrase> aims at generating plausible <phrase>natural language</phrase> sentences whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. we propose <phrase>a new</phrase> neural <phrase>generative model</phrase> which combines variational auto encoders and holistic attribute discriminators for effective imposition of semantic structures. with differentiable approximation to discrete text samples explicit constraints on independent attribute controls and efficient <phrase>collaborative learning</phrase> of generator and discriminators our model learns highly interpretable representations from even only word annotations and produces realistic sentences with desired attributes. quantitative evaluation validates the accuracy of sentence and attribute generation.
adversarial connective exploiting networks for implicit discourse <phrase>relation classification</phrase>
implicit discourse <phrase>relation classification</phrase> is of great challenge <phrase>due to</phrase> <phrase>the lack of</phrase> connectives as strong linguistic cues which motivates <phrase>the use of</phrase> annotated implicit connectives <phrase>to improve</phrase> the recognition. we propose a feature imitation framework in which an implicit relation network is driven <phrase>to learn</phrase> from another <phrase>neural network</phrase> with access to connectives and thus encouraged <phrase>to extract</phrase> similarly salient features for accurate classification. we develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator. our method effectively transfers discriminability of connectives to the implicit features and <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> the pdtb benchmark.
abstract syntax networks for code generation and semantic parsing
tasks like code generation and semantic parsing require mapping unstructured or partially structured inputs to well formed executable outputs. we introduce abstract syntax networks a modeling <phrase>framework for</phrase> these problems. the outputs are represented as abstract syntax trees asts and constructed by a decoder with a dynamically determined modular structure paralleling the structure of the output tree. on the benchmark hearthstone dataset for code generation our model obtains 79.2 bleu and 22.7 exact match accuracy <phrase>compared to</phrase> <phrase>previous state of</phrase> <phrase>the art</phrase> values of 67.1 and 6.1 . furthermore we perform competitively on the atis jobs and geo semantic parsing datasets with no <phrase>task specific</phrase> engineering.
multimodal word distributions
<phrase>word embeddings</phrase> provide point representations of words containing useful semantic information. we introduce multimodal word distributions formed from gaussian mixtures for multiple word meanings entailment and rich uncertainty information. <phrase>to learn</phrase> these distributions we propose an energy based max margin objective. we show that the resulting approach captures uniquely expressive semantic information and outperforms alternatives <phrase>such as</phrase> word2vec skip grams and gaussian embeddings on <phrase>benchmark datasets</phrase> <phrase>such as</phrase> word similarity and entailment.
guiding <phrase>reinforcement learning</phrase> exploration using <phrase>natural language</phrase>
in <phrase>this work</phrase> we present a technique to use <phrase>natural language</phrase> to help <phrase>reinforcement learning</phrase> generalize to unseen environments. this technique uses <phrase>neural machine translation</phrase> specifically <phrase>the use of</phrase> <phrase>encoder decoder</phrase> networks <phrase>to learn</phrase> associations between <phrase>natural language</phrase> behavior descriptions and state action information. we then use this learned model to guide agent exploration using a modified <phrase>version of</phrase> policy shaping to make it <phrase>more effective</phrase> at learning in unseen environments. we evaluate this technique using the popular <phrase>arcade game</phrase> frogger under ideal and non ideal conditions. this evaluation shows that our modified policy shaping algorithm improves over a q learning agent <phrase>as well as</phrase> a baseline <phrase>version of</phrase> policy shaping.
robust task clustering for deep many task learning
we investigate task clustering for <phrase>deep learning</phrase> based <phrase>multi task</phrase> and few <phrase>shot learning</phrase> in a many task setting. we propose <phrase>a new</phrase> method to measure task similarities with cross task transfer performance matrix for the <phrase>deep learning</phrase> scenario. although this matrix provides us critical information regarding similarity between tasks its asymmetric property and unreliable performance scores can affect conventional clustering methods adversely. additionally the uncertain task pairs i.e. the ones with extremely asymmetric transfer scores may collectively mislead clustering algorithms to output an inaccurate task partition. <phrase>to overcome</phrase> these limitations we propose <phrase>a novel</phrase> task clustering algorithm <phrase>by using</phrase> the matrix completion technique. <phrase>the proposed</phrase> algorithm constructs a partially observed similarity matrix <phrase>based on</phrase> the certainty of cluster membership of the task pairs. we then use a matrix completion algorithm to complete the similarity matrix. our theoretical analysis shows that under mild constraints <phrase>the proposed</phrase> algorithm will perfectly recover the underlying true similarity matrix with a high probability. our <phrase>results show</phrase> that the new task clustering method can discover task clusters for training flexible and superior <phrase>neural network</phrase> models in a <phrase>multi task learning</phrase> setup for sentiment classification and dialog intent <phrase>classification tasks</phrase>. our task clustering approach also extends metric based few <phrase>shot learning</phrase> methods to adapt multiple metrics which demonstrates empirical advantages when the tasks are diverse.
<phrase>natural language</phrase> multitasking analyzing and improving syntactic saliency of hidden representations
we train <phrase>multi task</phrase> autoencoders on linguistic tasks and analyze the learned hidden sentence representations. the representations change significantly when translation and part of speech decoders are added. the more decoders a model employs the better it clusters sentences <phrase>according to</phrase> their syntactic similarity as the representation space becomes less entangled. we explore the structure of the representation space by interpolating between sentences which yields interesting pseudo english sentences many of which have recognizable syntactic structure. lastly we point out an interesting property of our models the difference vector between two sentences can be added to change a third sentence with similar features in a meaningful way.
multimodal <phrase>sentiment analysis</phrase> with <phrase>word level</phrase> fusion and <phrase>reinforcement learning</phrase>
with the increasing popularity of video sharing websites <phrase>such as</phrase> youtube and facebook multimodal <phrase>sentiment analysis</phrase> has received increasing attention from the scientific community. contrary to previous works in multimodal <phrase>sentiment analysis</phrase> which <phrase>focus on</phrase> holistic information in speech segments <phrase>such as</phrase> bag of words representations and average <phrase>facial expression</phrase> intensity we develop <phrase>a novel</phrase> deep architecture for multimodal <phrase>sentiment analysis</phrase> that performs modality fusion at the <phrase>word level</phrase>. in <phrase>this paper</phrase> we propose the gated multimodal embedding lstm with temporal attention gme lstm a model that is <phrase>composed of</phrase> 2 modules. the gated multimodal embedding alleviates the difficulties of fusion when there are noisy modalities. the lstm with temporal attention performs <phrase>word level</phrase> fusion at a finer fusion resolution between input modalities and attends to the most important time steps. as a result the gme lstm a is <phrase>able to</phrase> better model the multimodal structure of speech through time and perform better sentiment comprehension. we demonstrate <phrase>the effectiveness of</phrase> <phrase>this approach</phrase> on the <phrase>publicly available</phrase> multimodal corpus of sentiment intensity and subjectivity analysis cmu mosi dataset by achieving <phrase>state of</phrase> <phrase>the art</phrase> sentiment classification and regression results. qualitative analysis on our model emphasizes the importance of the temporal attention layer in sentiment prediction because the additional acoustic and visual modalities are noisy. we also demonstrate <phrase>the effectiveness of</phrase> the gated multimodal embedding in selectively filtering these noisy modalities out. our results and analysis open new areas in the study of <phrase>sentiment analysis</phrase> in human communication and provide new models for multimodal fusion.
a supervised <phrase>approach to</phrase> extractive summarisation of scientific papers
automatic summarisation is a popular <phrase>approach to</phrase> reduce a document to its main arguments. recent research in the area has <phrase>focused on</phrase> neural approaches to summarisation which can be very data hungry. however few large datasets exist and none for the traditionally popular domain of scientific publications which opens up challenging research avenues centered on encoding large complex documents. in <phrase>this paper</phrase> we introduce <phrase>a new</phrase> dataset for summarisation of computer science publications by exploiting <phrase>a large</phrase> resource of author provided summaries and show straightforward ways of extending it further. we develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences <phrase>as well as</phrase> their local and global context perform best significantly outperforming well established baseline methods.
<phrase>language models</phrase> for image captioning the quirks and what works
two recent approaches have achieved <phrase>state of</phrase> <phrase>the art</phrase> results in image captioning. the first uses a pipelined process where <phrase>a set of</phrase> candidate words is generated by <phrase>a convolutional neural network</phrase> cnn <phrase>trained on</phrase> images and then a maximum entropy me <phrase>language model</phrase> is used to arrange these words into a coherent sentence. the second uses the penultimate activation layer of the cnn as input to <phrase>a recurrent neural network</phrase> rnn that then generates the caption sequence. in <phrase>this paper</phrase> we compare the merits of these different <phrase>language modeling</phrase> approaches for the first time <phrase>by using</phrase> <phrase>the same</phrase> <phrase>state of</phrase> <phrase>the art</phrase> cnn as input. we examine issues in the different approaches including linguistic irregularities caption repetition and <phrase>data set</phrase> overlap. by combining key <phrase>aspects of</phrase> the me and rnn methods we achieve <phrase>a new</phrase> record performance over previously published <phrase>results on</phrase> the benchmark coco dataset. however the gains we see in bleu <phrase>do not</phrase> translate to human judgments.
exploring models and data for image <phrase>question answering</phrase>
<phrase>this work</phrase> aims <phrase>to address</phrase> <phrase>the problem of</phrase> image based <phrase>question answering</phrase> qa with new models and datasets. in our work we propose to use <phrase>neural networks</phrase> and visual semantic embeddings without intermediate stages <phrase>such as</phrase> <phrase>object detection</phrase> and <phrase>image segmentation</phrase> <phrase>to predict</phrase> answers to simple <phrase>questions about</phrase> images. our model performs 1.8 times <phrase>better than</phrase> the only published <phrase>results on</phrase> an existing image qa dataset. we <phrase>also present</phrase> a question generation algorithm that converts image descriptions which are widely available into qa form. we used this algorithm <phrase>to produce</phrase> an order <phrase>of magnitude</phrase> larger dataset with more evenly distributed answers. a suite of baseline <phrase>results on</phrase> this new dataset are also presented.
making the v in vqa matter elevating <phrase>the role of</phrase> image understanding in <phrase>visual question answering</phrase>
problems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich <phrase>set of</phrase> applications they enable. however inherent structure in our world and bias in our language <phrase>tend to</phrase> be a simpler signal for learning than visual modalities resulting in models that ignore visual information <phrase>leading to</phrase> an inflated sense of their capability. we propose to counter these language priors for <phrase>the task of</phrase> <phrase>visual question answering</phrase> vqa and make vision the v in vqa matter specifically we balance the popular vqa dataset by collecting complementary images such that every question in our balanced dataset is <phrase>associated with</phrase> not just <phrase>a single</phrase> image but rather a pair of similar images that result in two different answers to the question. our dataset is by construction more balanced than <phrase>the original</phrase> vqa dataset and has approximately twice <phrase>the number of</phrase> image question pairs. our complete balanced dataset is <phrase>publicly available</phrase> at www.visualqa.org as part of the 2nd iteration of the <phrase>visual question answering</phrase> dataset and challenge vqa v2.0 . we further benchmark <phrase>a number of</phrase> <phrase>state of</phrase> art <phrase>vqa models</phrase> on our balanced dataset. all models perform significantly worse on our balanced dataset suggesting that <phrase>these models</phrase> have indeed learned to exploit language priors. this finding provides the first concrete <phrase>empirical evidence</phrase> for what seems to be a qualitative sense among practitioners. finally our data collection protocol for identifying complementary images enables us to develop <phrase>a novel</phrase> interpretable model which <phrase>in addition</phrase> to providing an answer to the given image question pair also provides a counter example based explanation. specifically it identifies <phrase>an image</phrase> that is <phrase>similar to</phrase> <phrase>the original</phrase> image but it believes has a different answer to <phrase>the same</phrase> question. this can help in building trust for machines among their users.
a multi world <phrase>approach to</phrase> <phrase>question answering</phrase> about <phrase>real world</phrase> scenes <phrase>based on</phrase> uncertain input
we propose a <phrase>method for</phrase> automatically answering <phrase>questions about</phrase> images by bringing together <phrase>recent advances</phrase> from <phrase>natural language</phrase> processing and <phrase>computer vision</phrase>. we combine discrete reasoning with uncertain predictions by a multi world approach that represents uncertainty about the perceived world in a bayesian framework. our approach can handle human questions of high complexity about realistic scenes and replies with range of answer like counts object classes instances and lists of them. the system is directly trained from <phrase>question answer</phrase> pairs. we establish a first benchmark for <phrase>this task</phrase> that can be seen as a modern attempt at a visual <phrase>turing test</phrase>.
hard to cheat a <phrase>turing test</phrase> <phrase>based on</phrase> answering <phrase>questions about</phrase> images
progress in language and image understanding by machines has sparkled the interest of the research community in more open ended holistic tasks and refueled an old ai dream of building intelligent machines. we discuss a few prominent challenges that characterize such holistic tasks and argue for <phrase>question answering</phrase> about images as a particular appealing instance of such a holistic task. <phrase>in particular</phrase> we point out that it is a <phrase>version of</phrase> a <phrase>turing test</phrase> that is likely to be <phrase>more robust</phrase> to over interpretations and contrast it with tasks like grounding and generation of descriptions. finally we discuss tools to measure progress in this field.
analyzing the behavior of <phrase>visual question answering</phrase> models
recently <phrase>a number of</phrase> <phrase>deep learning</phrase> based models have been proposed for <phrase>the task of</phrase> <phrase>visual question answering</phrase> vqa . <phrase>the performance of</phrase> most models is clustered around 60 70 . in <phrase>this paper</phrase> we propose systematic methods to analyze the behavior of <phrase>these models</phrase> as a first <phrase>step towards</phrase> recognizing their strengths and weaknesses and identifying the most fruitful directions for progress. we analyze two models one each from two major classes of <phrase>vqa models</phrase> with attention and without attention and show the similarities and differences in the behavior of <phrase>these models</phrase>. we also analyze the winning entry of the vqa challenge 2016. our <phrase>behavior analysis</phrase> reveals that despite recent progress today s <phrase>vqa models</phrase> are myopic <phrase>tend to</phrase> fail on sufficiently novel instances often jump to conclusions converge on a predicted answer after listening to just half the question and are stubborn <phrase>do not</phrase> change their answers across images .
sort story sorting jumbled images and captions into stories
temporal common sense has applications in ai <phrase>tasks such as</phrase> qa multi document summarization and human ai communication. we propose <phrase>the task of</phrase> sequencing given a jumbled <phrase>set of</phrase> aligned image caption pairs that belong to a story the task is to sort them such that the output sequence forms a coherent story. we present multiple approaches via unary position and pairwise order predictions and their ensemble based combinations achieving strong <phrase>results on</phrase> <phrase>this task</phrase>. we use both text based and image based features which depict complementary improvements. using qualitative examples we demonstrate that our models have learnt interesting <phrase>aspects of</phrase> temporal common sense.
mean box pooling a rich image representation and output embedding for the visual madlibs task
we present mean box pooling <phrase>a novel</phrase> visual representation that pools over cnn representations of <phrase>a large</phrase> number highly overlapping object proposals. we show that such representation together with ncca a successful multimodal embedding technique <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> the visual madlibs task. moreover <phrase>inspired by</phrase> the ncca s <phrase>objective function</phrase> we extend classical cnn lstm <phrase>approach to</phrase> train <phrase>the network</phrase> by directly maximizing the similarity between the internal representation of the <phrase>deep learning</phrase> architecture and candidate answers. again such approach achieves a <phrase>significant improvement</phrase> over the prior work that also uses cnn lstm approach on visual madlibs.
learning to generalize to new compositions in image understanding
<phrase>recurrent neural networks</phrase> have recently been used for learning to describe images using <phrase>natural language</phrase>. however it has been observed that <phrase>these models</phrase> generalize poorly to scenes that were not observed <phrase>during training</phrase> possibly depending too strongly on the statistics of the text in <phrase>the training data</phrase>. here we propose to describe images using short structured representations aiming <phrase>to capture</phrase> the crux of a description. these structured representations allow us to tease out and evaluate separately two <phrase>types of</phrase> generalization standard generalization to new images with similar scenes and generalization to new combinations of known entities. we compare two <phrase>learning approaches</phrase> on the ms coco dataset a <phrase>state of</phrase> <phrase>the art</phrase> <phrase>recurrent network</phrase> <phrase>based on</phrase> an lstm show attend and tell and <phrase>a simple</phrase> <phrase>structured prediction</phrase> model on top of a <phrase>deep network</phrase>. we find that the structured model generalizes to new compositions substantially <phrase>better than</phrase> the lstm 7 times the accuracy of predicting structured representations. by providing a concrete method to quantify generalization for unseen combinations we argue that structured representations and compositional splits are a useful benchmark for image captioning and advocate compositional models that capture linguistic and visual structure.
measuring machine intelligence through <phrase>visual question answering</phrase>
as machines have become more intelligent there has been a renewed interest in methods for measuring their intelligence. a common approach is to propose tasks for which a human excels but one which machines find difficult. however an ideal task should also be <phrase>easy to</phrase> evaluate and not be easily gameable. we begin with a case study exploring the recently popular task of image captioning and its limitations as a task for measuring machine intelligence. <phrase>an alternative</phrase> and more promising task is <phrase>visual question answering</phrase> that tests a machine s <phrase>ability to</phrase> reason about language and vision. we describe a dataset unprecedented in size created for the task that contains over 760 000 human generated <phrase>questions about</phrase> images. using around 10 million human generated answers machines may be easily evaluated.
towards transparent ai systems interpreting <phrase>visual question answering</phrase> models
<phrase>deep neural networks</phrase> have shown striking progress and obtained <phrase>state of</phrase> <phrase>the art</phrase> results in many ai research fields in the <phrase>recent years</phrase>. however it is often unsatisfying to not know why they predict what they do. in <phrase>this paper</phrase> we address <phrase>the problem of</phrase> interpreting <phrase>visual question answering</phrase> <phrase>vqa models</phrase>. specifically we are interested in finding what part of <phrase>the input</phrase> pixels in images or words in questions the vqa model <phrase>focuses on</phrase> while answering the question. <phrase>to tackle</phrase> <phrase>this problem</phrase> we use two visualization techniques guided backpropagation and occlusion to find important words in the question and important regions in the image. we then present qualitative and quantitative analyses of these importance maps. we found that even without explicit attention mechanisms <phrase>vqa models</phrase> may sometimes be implicitly attending to relevant regions in the image and often to appropriate words in the question.
<phrase>visual dialog</phrase>
we introduce <phrase>the task of</phrase> <phrase>visual dialog</phrase> which requires an ai agent to hold a meaningful dialog with humans in natural conversational language about visual content. specifically given <phrase>an image</phrase> a dialog history and a question about the image the agent has to ground the question in image infer context from history and answer the question accurately. <phrase>visual dialog</phrase> is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. we develop <phrase>a novel</phrase> two person chat data collection protocol to curate <phrase>a large</phrase> scale <phrase>visual dialog</phrase> dataset visdial . visdial v0.9 has been released and contains 1 dialog with 10 <phrase>question answer</phrase> pairs on 120k images from coco with a total of 1.2m dialog <phrase>question answer</phrase> pairs. we introduce a <phrase>family of</phrase> neural <phrase>encoder decoder</phrase> models for <phrase>visual dialog</phrase> with 3 encoders late fusion hierarchical recurrent encoder and <phrase>memory network</phrase> and 2 decoders generative and discriminative which outperform <phrase>a number of</phrase> sophisticated baselines. we propose a retrieval based evaluation protocol for <phrase>visual dialog</phrase> where the ai agent is asked to sort <phrase>a set of</phrase> candidate answers and evaluated on metrics <phrase>such as</phrase> mean reciprocal rank of human response. we quantify gap between machine and human <phrase>performance on</phrase> the <phrase>visual dialog</phrase> task via human studies. putting it all together we demonstrate the first visual chatbot our dataset code trained models and visual chatbot are available on https visualdialog.org
<phrase>multi task learning</phrase> of <phrase>deep neural networks</phrase> for audio visual <phrase>automatic speech recognition</phrase>
<phrase>multi task learning</phrase> mtl involves the simultaneous training of two or more related tasks over shared representations. in <phrase>this work</phrase> we apply mtl to audio visual <phrase>automatic speech recognition</phrase> av asr . our primary task is <phrase>to learn</phrase> a mapping between audio visual fused features and frame labels obtained from acoustic gmm hmm model. this is <phrase>combined with</phrase> an auxiliary task which maps visual features to frame labels obtained from a separate visual gmm hmm model. the mtl model is tested at various levels of babble noise and the results are <phrase>compared with</phrase> a base line hybrid dnn hmm av asr model. our results indicate that mtl is especially useful at <phrase>higher level</phrase> of noise. <phrase>compared to</phrase> base line upto 7 relative improvement in wer is reported at 3 snr db
learning cooperative <phrase>visual dialog</phrase> agents with <phrase>deep reinforcement learning</phrase>
we introduce the first goal driven training for <phrase>visual question answering</phrase> and dialog agents. specifically we pose a cooperative image guessing game between two agents qbot and abot who communicate in <phrase>natural language</phrase> dialog so that qbot can select an unseen image from a lineup of images. we use <phrase>deep reinforcement learning</phrase> rl <phrase>to learn</phrase> the policies of these agents <phrase>end to end</phrase> from pixels to <phrase>multi agent</phrase> multi round dialog to game reward. we demonstrate two <phrase>experimental results</phrase>. first as a sanity check demonstration of pure rl <phrase>from scratch</phrase> we show <phrase>results on</phrase> a synthetic world where the agents communicate in ungrounded vocabulary i.e. symbols with no pre specified meanings x y z . we find that two bots invent their own communication protocol and start using certain symbols to ask answer about certain visual attributes shape color style . thus we demonstrate the emergence of grounded language and communication among <phrase>visual dialog</phrase> agents with no human supervision. second we conduct <phrase>large scale</phrase> real image <phrase>experiments on</phrase> the visdial dataset where we pretrain with supervised dialog data and show that the rl fine tuned agents <phrase>significantly outperform</phrase> sl agents. interestingly the rl qbot learns to ask questions that abot is good at ultimately resulting in more informative dialog and a better team.
being negative but constructively lessons learnt from creating better <phrase>visual question answering</phrase> datasets
<phrase>visual question answering</phrase> qa has attracted a lot of attention lately seen essentially as a form of visual <phrase>turing test</phrase> that <phrase>artificial intelligence</phrase> should strive to achieve. in <phrase>this paper</phrase> we study a crucial component of <phrase>this task</phrase> how can we design good datasets for the task we <phrase>focus on</phrase> the design of <phrase>multiple choice</phrase> based datasets where the learner has <phrase>to select</phrase> the right answer from <phrase>a set of</phrase> candidate ones including the target i.e. the correct one and the decoys i.e. the incorrect ones . through careful analysis of the results attained by <phrase>state of</phrase> <phrase>the art</phrase> <phrase>learning models</phrase> and human annotators on existing datasets we show the design of the decoy answers has a significant impact on how and what the <phrase>learning models</phrase> learn from the datasets. <phrase>in particular</phrase> the resulting learner can ignore the visual information the question or the both while still doing well on the task. <phrase>inspired by</phrase> this we propose automatic procedures to remedy such design deficiencies. we apply the procedures to re construct decoy answers for two popular visual qa datasets <phrase>as well as</phrase> to create <phrase>a new</phrase> visual qa dataset from the visual genome project resulting in the largest dataset for <phrase>this task</phrase>. extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the <phrase>performance on</phrase> them is likely a more faithful indicator of the difference among <phrase>learning models</phrase>. the datasets are released and <phrase>publicly available</phrase> via http www.teds.usc.edu website vqa .
c vqa a compositional split of the <phrase>visual question answering</phrase> vqa v1.0 dataset
<phrase>visual question answering</phrase> vqa has received a lot of attention over <phrase>the past</phrase> couple of years. <phrase>a number of</phrase> <phrase>deep learning</phrase> models have been proposed for <phrase>this task</phrase>. however it has been shown that <phrase>these models</phrase> are heavily driven by superficial correlations in <phrase>the training data</phrase> and lack compositionality the <phrase>ability to</phrase> answer <phrase>questions about</phrase> unseen compositions of seen concepts. this compositionality is desirable and central to intelligence. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> setting for <phrase>visual question answering</phrase> where the test <phrase>question answer</phrase> pairs are compositionally novel <phrase>compared to</phrase> training <phrase>question answer</phrase> pairs. to facilitate developing models under this setting we present <phrase>a new</phrase> compositional split of the vqa v1.0 dataset which we call compositional vqa c vqa . we analyze the distribution of questions and answers in the c vqa splits. finally we evaluate several existing <phrase>vqa models</phrase> under this new setting and show that the performances of <phrase>these models</phrase> degrade by a significant amount <phrase>compared to</phrase> <phrase>the original</phrase> vqa setting.
<phrase>deep learning</phrase> evaluation using deep linguistic processing
we discuss problems with the standard approaches to evaluation for tasks like <phrase>visual question answering</phrase> and argue that artificial data can be used <phrase>to address</phrase> these as a complement to current practice. we demonstrate that with the help of existing deep linguistic processing technology we are <phrase>able to</phrase> create challenging abstract datasets which enable us to investigate the <phrase>language understanding</phrase> abilities of multimodal <phrase>deep learning</phrase> models in detail.
meprop sparsified <phrase>back propagation</phrase> for accelerated <phrase>deep learning</phrase> with reduced overfitting
we propose <phrase>a simple</phrase> yet effective technique for <phrase>neural network</phrase> learning. the forward propagation is computed as usual. in <phrase>back propagation</phrase> only <phrase>a small</phrase> <phrase>subset of</phrase> the full gradient is computed to update <phrase>the model</phrase> parameters. the gradient vectors are sparsified in such a way that only the top k elements <phrase>in terms of</phrase> magnitude are kept. as a result only k rows or columns depending on the layout of the weight matrix are modified <phrase>leading to</phrase> a linear reduction k divided by the vector dimension in the <phrase>computational cost</phrase>. surprisingly <phrase>experimental results</phrase> demonstrate that we can update only 1 4 of the weights at each <phrase>back propagation</phrase> pass. this <phrase>does not</phrase> result in a larger <phrase>number of</phrase> training iterations. more interestingly the accuracy of the resulting models is actually improved <phrase>rather than</phrase> degraded and a detailed analysis is given. the code is <phrase>available at</phrase> https github.com jklj077 meprop
towards crafting text adversarial samples
adversarial samples are strategically modified samples which are crafted with the purpose of fooling a classifier at hand. an attacker introduces specially crafted adversarial samples to a deployed classifier which are being mis classified by the classifier. however the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. most of the prior works have been <phrase>focused on</phrase> synthesizing adversarial samples in the image domain. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> method of crafting adversarial text samples by modification of <phrase>the original</phrase> samples. modifications of <phrase>the original</phrase> text samples are done by deleting or replacing the important or salient words in the text or <phrase>by introducing</phrase> new words in the text sample. our algorithm works best for the datasets which have sub categories within each of the classes of examples. while crafting adversarial samples one of the key constraint is <phrase>to generate</phrase> meaningful sentences which can at pass off as legitimate from language english viewpoint. <phrase>experimental results</phrase> on imdb movie review dataset for <phrase>sentiment analysis</phrase> and twitter dataset for gender detection show the efficiency of our <phrase>proposed method</phrase>.
reinforced video captioning with entailment rewards
<phrase>sequence to sequence</phrase> models have shown promising improvements on the temporal task of video captioning but they optimize <phrase>word level</phrase> <phrase>cross entropy</phrase> loss <phrase>during training</phrase>. first using policy gradient and mixed loss methods for <phrase>reinforcement learning</phrase> we directly optimize <phrase>sentence level</phrase> task based metrics as rewards achieving <phrase>significant improvements</phrase> over the baseline <phrase>based on</phrase> both automatic metrics and human evaluation on multiple datasets. next we propose <phrase>a novel</phrase> entailment enhanced reward cident that corrects phrase matching based metrics <phrase>such as</phrase> cider to only allow for logically implied partial matches and avoid contradictions achieving further <phrase>significant improvements</phrase> over the cider reward model. overall our cident reward <phrase>model achieves</phrase> the new <phrase>state of</phrase> <phrase>the art</phrase> on the msr vtt dataset.
hierarchically attentive rnn for album summarization and storytelling
we address <phrase>the problem of</phrase> <phrase>end to end</phrase> visual storytelling. given a photo album our model first selects the most representative summary photos and then composes a <phrase>natural language</phrase> story for the album. for <phrase>this task</phrase> we make use of the visual storytelling dataset and a model <phrase>composed of</phrase> three hierarchically attentive <phrase>recurrent neural</phrase> nets rnns to encode the album photos select representative summary photos and compose the story. automatic and human evaluations show our <phrase>model achieves</phrase> <phrase>better performance</phrase> on selection generation and retrieval than baselines.
generating natural <phrase>adversarial examples</phrase>
<phrase>due to</phrase> their complex nature it is hard to characterize the ways in which <phrase>machine learning</phrase> models can misbehave or be exploited when deployed. <phrase>recent work</phrase> on <phrase>adversarial examples</phrase> i.e. inputs with minor perturbations that result in substantially different model predictions is helpful in evaluating <phrase>the robustness of</phrase> <phrase>these models</phrase> by exposing the adversarial scenarios where they fail. however these malicious perturbations are often unnatural not semantically meaningful and not <phrase>applicable to</phrase> complicated <phrase>domains such as</phrase> language. in <phrase>this paper</phrase> we propose a framework <phrase>to generate</phrase> natural and legible <phrase>adversarial examples</phrase> that lie on the data manifold by searching in semantic space of dense and continuous data representation utilizing the <phrase>recent advances in</phrase> <phrase>generative adversarial networks</phrase>. we present generated adversaries to demonstrate the potential of <phrase>the proposed</phrase> approach for <phrase>black box</phrase> classifiers for <phrase>a wide range of</phrase> <phrase>applications such as</phrase> <phrase>image classification</phrase> <phrase>textual entailment</phrase> and <phrase>machine translation</phrase>. we include experiments to show that the generated adversaries are natural legible to humans and useful in evaluating and analyzing <phrase>black box</phrase> classifiers.
training simplification and model simplification for <phrase>deep learning</phrase> a minimal effort <phrase>back propagation</phrase> method
we propose <phrase>a simple</phrase> yet effective technique to simplify the training and the resulting model of <phrase>neural networks</phrase>. in <phrase>back propagation</phrase> only <phrase>a small</phrase> <phrase>subset of</phrase> the full gradient is computed to update <phrase>the model</phrase> parameters. the gradient vectors are sparsified in such a way that only the top k elements <phrase>in terms of</phrase> magnitude are kept. as a result only k rows or columns depending on the layout of the weight matrix are modified <phrase>leading to</phrase> a linear <phrase>reduction in</phrase> the <phrase>computational cost</phrase>. <phrase>based on</phrase> the sparsified gradients we further simplify <phrase>the model</phrase> by eliminating the rows or columns that are seldom updated which will reduce the <phrase>computational cost</phrase> both in the training and decoding and potentially accelerate decoding in <phrase>real world</phrase> applications. surprisingly <phrase>experimental results</phrase> demonstrate that most of time we only <phrase>need to</phrase> update fewer than 5 of the weights at each <phrase>back propagation</phrase> pass. more interestingly the accuracy of the resulting models is actually improved <phrase>rather than</phrase> degraded and a detailed analysis is given. <phrase>the model</phrase> simplification <phrase>results show</phrase> that we could adaptively simplify <phrase>the model</phrase> which could often be reduced by around 9x without any loss on accuracy or even with improved accuracy.
embodied <phrase>question answering</phrase>
we present <phrase>a new</phrase> ai task embodied <phrase>question answering</phrase> embodiedqa where <phrase>an agent</phrase> is spawned at a random location in a 3d environment and asked a question what color is the car . <phrase>in order to</phrase> answer the agent must first intelligently navigate to explore the environment gather information through first person egocentric vision and then answer the question orange . this <phrase>challenging task</phrase> requires <phrase>a range of</phrase> ai skills active perception <phrase>language understanding</phrase> goal driven navigation commonsense reasoning and grounding of language into actions. in <phrase>this work</phrase> we develop the environments <phrase>end to end</phrase> trained <phrase>reinforcement learning</phrase> agents and evaluation protocols for embodiedqa.
don t just assume look and answer overcoming priors for <phrase>visual question answering</phrase>
<phrase>a number of</phrase> studies have found that today s <phrase>visual question answering</phrase> <phrase>vqa models</phrase> are heavily driven by superficial correlations in <phrase>the training data</phrase> and lack sufficient image grounding. to encourage development of models geared towards <phrase>the latter</phrase> we propose <phrase>a new</phrase> setting for vqa where for every question type train and test sets have different prior distributions of answers. specifically we present new splits of the vqa v1 and vqa v2 datasets which we call <phrase>visual question answering</phrase> under changing priors vqa cp v1 and vqa cp v2 respectively . first we evaluate several existing <phrase>vqa models</phrase> under this new setting and show that their performance degrades significantly <phrase>compared to</phrase> <phrase>the original</phrase> vqa setting. second we propose <phrase>a novel</phrase> grounded <phrase>visual question answering</phrase> model gvqa that contains inductive biases and restrictions in the architecture specifically designed to prevent <phrase>the model</phrase> from cheating by primarily relying on priors in <phrase>the training data</phrase>. specifically gvqa explicitly disentangles the recognition of <phrase>visual concepts</phrase> present in the image from the identification of plausible answer space for a given question enabling <phrase>the model</phrase> to more robustly generalize across different distributions of answers. gvqa is built off an existing vqa model stacked attention networks san . our <phrase>experiments demonstrate</phrase> that gvqa <phrase>significantly outperforms</phrase> san on both vqa cp v1 and vqa cp v2 datasets. interestingly it also outperforms <phrase>more powerful</phrase> <phrase>vqa models</phrase> <phrase>such as</phrase> multimodal compact bilinear pooling mcb in several cases. gvqa offers strengths complementary to san when trained and evaluated on <phrase>the original</phrase> vqa v1 and vqa v2 datasets. finally gvqa is more transparent and interpretable than existing <phrase>vqa models</phrase>.
codraw <phrase>visual dialog</phrase> for collaborative drawing
in <phrase>this work</phrase> we propose a goal driven collaborative task that contains vision language and action in a <phrase>virtual environment</phrase> as its core components. specifically we develop a collaborative image drawing game between two agents called codraw. our game is grounded in a <phrase>virtual world</phrase> that contains movable <phrase>clip art</phrase> objects. two players teller and drawer are involved. the teller sees an abstract scene containing multiple clip arts in a semantically meaningful configuration while the drawer tries to reconstruct the scene on an empty canvas using available clip arts. the two players communicate via two way communication using <phrase>natural language</phrase>. we collect the codraw dataset of 10k dialogs <phrase>consisting of</phrase> 138k messages exchanged between a teller and a drawer from <phrase>amazon mechanical turk</phrase> amt . we analyze our dataset and present three models to model the players behaviors including an <phrase>attention model</phrase> to describe and draw multiple clip arts at each round. the attention models are quantitatively <phrase>compared to</phrase> the other models to show how the conventional approaches work for this new task. we <phrase>also present</phrase> qualitative visualizations.
answerer in questioner s mind for <phrase>goal oriented</phrase> visual dialogue
<phrase>goal oriented</phrase> dialogue has been paid attention for its numerous applications in <phrase>artificial intelligence</phrase>. <phrase>to solve</phrase> <phrase>this task</phrase> <phrase>deep learning</phrase> and <phrase>reinforcement learning</phrase> have recently been applied. however <phrase>these approaches</phrase> struggle to find a competent <phrase>recurrent neural</phrase> questioner owing to <phrase>the complexity of</phrase> learning <phrase>a series of</phrase> sentences. <phrase>motivated by</phrase> theory of mind we propose answerer in questioner s mind aqm <phrase>a novel</phrase> algorithm for <phrase>goal oriented</phrase> dialogue. with aqm a questioner asks and infers <phrase>based on</phrase> an approximated probabilistic model of the answerer. the questioner figures out the answerer s intent via selecting a plausible question by explicitly calculating the information gain of the candidate intentions and possible answers to each question. we test our framework on two <phrase>goal oriented</phrase> visual dialogue tasks mnist counting dialog and guesswhat . in our experiments aqm outperforms comparative algorithms and makes human like dialogue. we further use aqm as a tool for analyzing the mechanism of <phrase>deep reinforcement learning</phrase> approach and discuss the future direction of practical <phrase>goal oriented</phrase> neural <phrase>dialogue systems</phrase>.
resource constrained <phrase>structured prediction</phrase>
we study <phrase>the problem of</phrase> <phrase>structured prediction</phrase> under <phrase>test time</phrase> budget constraints. we propose <phrase>a novel</phrase> approach <phrase>applicable to</phrase> <phrase>a wide range of</phrase> <phrase>structured prediction</phrase> problems <phrase>in computer vision</phrase> and <phrase>natural language</phrase> processing. our approach seeks to adaptively generate computationally costly features during <phrase>test time</phrase> <phrase>in order to</phrase> reduce the <phrase>computational cost</phrase> of prediction while maintaining prediction performance. we show that training the adaptive feature generation system can be reduced to <phrase>a series of</phrase> structured learning problems resulting in efficient training using existing structured <phrase>learning algorithms</phrase>. this framework provides theoretical justification for several existing heuristic approaches found in literature. we evaluate our proposed adaptive system on two <phrase>structured prediction</phrase> tasks <phrase>optical character recognition</phrase> ocr and dependency parsing and show strong performance in reduction of the feature costs without degrading accuracy.
listen attend and walk neural mapping of navigational instructions to action sequences
we propose a neural <phrase>sequence to sequence</phrase> model for direction following a task that is essential to realizing effective autonomous agents. our alignment based <phrase>encoder decoder</phrase> model with <phrase>long short term memory</phrase> <phrase>recurrent neural networks</phrase> <phrase>lstm rnn</phrase> translates <phrase>natural language</phrase> instructions to action sequences based upon a representation of the observable world state. we introduce a multi level aligner that empowers our model to <phrase>focus on</phrase> sentence regions salient to the current world state <phrase>by using</phrase> multiple abstractions of <phrase>the input</phrase> sentence. <phrase>in contrast to</phrase> <phrase>existing methods</phrase> our model uses no specialized linguistic resources e.g. parsers or <phrase>task specific</phrase> annotations e.g. seed lexicons . it is therefore generalizable yet still achieves <phrase>the best</phrase> results reported <phrase>to date</phrase> on a benchmark single sentence dataset and <phrase>competitive results</phrase> for the limited training multi sentence setting. we analyze our model through <phrase>a series of</phrase> ablations that elucidate the contributions of the primary components of our model.
coupling distributed and symbolic execution for <phrase>natural language</phrase> queries
building <phrase>neural networks</phrase> to query a <phrase>knowledge base</phrase> a table with <phrase>natural language</phrase> is an emerging research topic in <phrase>deep learning</phrase>. an executor for table querying typically requires multiple steps of execution because queries may have complicated structures. in previous studies researchers have developed either fully distributed executors or symbolic executors for table querying. a distributed executor can be trained in <phrase>an end to end</phrase> fashion but is weak <phrase>in terms of</phrase> execution efficiency and explicit interpretability. a symbolic executor is efficient in execution but is very difficult <phrase>to train</phrase> especially at initial stages. in <phrase>this paper</phrase> we propose to couple distributed and symbolic execution for <phrase>natural language</phrase> queries where the symbolic executor is pretrained with the distributed executor s intermediate execution results in a step by step fashion. <phrase>experiments show</phrase> that our approach <phrase>significantly outperforms</phrase> both distributed and symbolic executors exhibiting high accuracy high learning efficiency high execution efficiency and high interpretability.
<phrase>an agent</phrase> driven semantical identifier using radial basis <phrase>neural networks</phrase> and <phrase>reinforcement learning</phrase>
<phrase>due to</phrase> the huge availability of documents in digital form and the deception possibility raise bound to the essence of digital documents and the way they are spread the authorship attribution problem has constantly increased its relevance. nowadays authorship attribution for both <phrase>information retrieval</phrase> and analysis has gained great importance in <phrase>the context of</phrase> security trust and copyright preservation. <phrase>this work</phrase> proposes an innovative <phrase>multi agent</phrase> driven <phrase>machine learning</phrase> technique that has been developed for authorship attribution. by means of a preprocessing for word grouping and time period related analysis of the common lexicon we determine a bias reference level for the recurrence frequency of the words within analysed texts and then train a radial basis <phrase>neural networks</phrase> rbpnn based classifier to identify the correct author. the main <phrase>advantage of</phrase> <phrase>the proposed</phrase> approach lies in the generality of the semantic analysis which can be <phrase>applied to</phrase> different contexts and lexical domains <phrase>without requiring</phrase> any modification. moreover <phrase>the proposed</phrase> system is <phrase>able to</phrase> incorporate an external input meant to tune the classifier and then self adjust by means of continuous learning reinforcement.
where is my forearm clustering of body parts from simultaneous tactile and linguistic input using sequential mapping
humans and animals are constantly exposed to a continuous stream of sensory information from different modalities. at <phrase>the same</phrase> time they form more compressed representations like concepts or symbols. in species that use language this process is further structured by this interaction where a mapping between the sensorimotor concepts and linguistic elements <phrase>needs to</phrase> be established. there is evidence that children might be learning language by simply disambiguating potential meanings <phrase>based on</phrase> multiple exposures to utterances in different contexts cross situational learning . in existing models the mapping between modalities is usually found in <phrase>a single</phrase> step by directly using frequencies of referent and meaning co occurrences. in <phrase>this paper</phrase> we present an extension of this one step mapping and introduce a newly proposed sequential mapping algorithm together with a <phrase>publicly available</phrase> matlab implementation. for demonstration we have chosen a less typical scenario <phrase>instead of</phrase> learning to associate objects with their names we <phrase>focus on</phrase> body representations. a <phrase>humanoid robot</phrase> is receiving tactile stimulations on its body while at <phrase>the same</phrase> time listening to utterances of the body part names e.g. hand forearm and torso . with the goal at arriving at the correct body categories we demonstrate how a sequential mapping algorithm outperforms one step mapping. <phrase>in addition</phrase> <phrase>the effect of</phrase> <phrase>data set</phrase> size and noise in the linguistic input are studied.
improvements to <phrase>deep convolutional neural networks</phrase> for lvcsr
<phrase>deep convolutional neural networks</phrase> cnns are <phrase>more powerful</phrase> than <phrase>deep neural networks</phrase> dnn as they are <phrase>able to</phrase> better reduce spectral variation in <phrase>the input</phrase> signal. this has also been confirmed experimentally with cnns showing improvements in <phrase>word error rate</phrase> wer between 4 12 relative <phrase>compared to</phrase> dnns across <phrase>a variety of</phrase> lvcsr tasks. in <phrase>this paper</phrase> we describe different methods to further improve cnn performance. first we conduct a deep analysis comparing limited weight sharing and full weight sharing with <phrase>state of</phrase> <phrase>the art</phrase> features. second we apply various pooling strategies that have shown improvements <phrase>in computer vision</phrase> to an lvcsr speech task. third we introduce a method to effectively incorporate speaker adaptation namely fmllr into log mel features. fourth we introduce <phrase>an effective</phrase> strategy to use dropout during hessian free sequence training. we find that with these improvements particularly with fmllr and dropout we are <phrase>able to</phrase> achieve an additional 2 3 relative improvement in wer on a 50 hour broadcast news task over our previous best cnn baseline. on a larger 400 hour bn task we find an additional 4 5 relative improvement over our previous best cnn baseline.
collaborative <phrase>deep learning</phrase> for recommender systems
<phrase>collaborative filtering</phrase> cf is a successful approach commonly used by many recommender systems. conventional cf <phrase>based methods</phrase> use the ratings given to items by users as the sole source of information for learning to make recommendation. however the ratings are often very sparse in <phrase>many applications</phrase> causing cf <phrase>based methods</phrase> to degrade significantly in their recommendation performance. <phrase>to address</phrase> this sparsity problem auxiliary information <phrase>such as</phrase> item content information may be utilized. collaborative topic regression ctr is an appealing recent method taking <phrase>this approach</phrase> which tightly couples the two components that learn from two different sources of information. nevertheless the latent representation learned by ctr may not be very effective when the auxiliary information is very sparse. <phrase>to address</phrase> <phrase>this problem</phrase> we generalize <phrase>recent advances in</phrase> <phrase>deep learning</phrase> from i.i.d. input to non i.i.d. cf based input and propose in <phrase>this paper</phrase> a hierarchical bayesian model called collaborative <phrase>deep learning</phrase> cdl which jointly performs deep <phrase>representation learning</phrase> for the content information and <phrase>collaborative filtering</phrase> for the ratings feedback matrix. <phrase>extensive experiments</phrase> on three <phrase>real world</phrase> datasets from different domains show that cdl can significantly advance the <phrase>state of</phrase> <phrase>the art</phrase>.
explaining predictions of <phrase>non linear</phrase> classifiers in nlp
<phrase>layer wise</phrase> relevance propagation lrp is a <phrase>recently proposed</phrase> technique for explaining predictions of complex <phrase>non linear</phrase> classifiers <phrase>in terms of</phrase> input variables. in <phrase>this paper</phrase> we apply lrp for the first time to <phrase>natural language</phrase> processing nlp . more precisely we use it to explain the predictions of <phrase>a convolutional neural network</phrase> cnn <phrase>trained on</phrase> a topic categorization task. our analysis highlights which words are relevant for a specific prediction of the cnn. we compare our technique to standard <phrase>sensitivity analysis</phrase> both qualitatively and quantitatively using a word deleting perturbation experiment a pca analysis and various visualizations. all experiments validate the suitability of lrp for explaining the cnn predictions which is also in line with results reported in recent <phrase>image classification</phrase> studies.
tensor network <phrase>language model</phrase>
we propose <phrase>a new</phrase> <phrase>statistical model</phrase> <phrase>suitable for</phrase> <phrase>machine learning</phrase> of systems with long distance correlations <phrase>such as</phrase> natural languages. <phrase>the model</phrase> is <phrase>based on</phrase> <phrase>directed acyclic graph</phrase> decorated by multi linear tensor maps in the vertices and <phrase>vector spaces</phrase> in the edges called tensor network. such tensor networks have been previously employed for effective numerical computation of the <phrase>renormalization group</phrase> flow on the space of effective <phrase>quantum field</phrase> theories and lattice models of <phrase>statistical mechanics</phrase>. we provide explicit algebro <phrase>geometric analysis</phrase> of the parameter <phrase>moduli space</phrase> for tree graphs discuss model properties and <phrase>applications such as</phrase> statistical translation.
language as a matrix product state
we propose a <phrase>statistical model</phrase> for <phrase>natural language</phrase> that begins by considering language as a monoid then representing it in complex matrices with a compatible translation invariant <phrase>probability measure</phrase>. we interpret the <phrase>probability measure</phrase> as arising via the <phrase>born rule</phrase> from a translation invariant matrix product state.
accelerating hessian free optimization for <phrase>deep neural networks</phrase> by implicit preconditioning and sampling
hessian free training has become a popular parallel second or der optimization technique for <phrase>deep neural network</phrase> training. <phrase>this study</phrase> aims at speeding up hessian free training both by means of decreasing the <phrase>amount of</phrase> data used for training <phrase>as well as</phrase> through reduction of <phrase>the number of</phrase> krylov subspace solver iterations used for implicit estimation of the hessian. in <phrase>this paper</phrase> we develop an l bfgs based preconditioning scheme that avoids the <phrase>need to</phrase> access the hessian explicitly. since l bfgs cannot be regarded as <phrase>a fixed</phrase> point iteration we further propose the employment of flexible krylov subspace solvers that retain the desired theoretical convergence guarantees of their conventional counterparts. second we propose <phrase>a new</phrase> sampling algorithm which geometrically increases the <phrase>amount of</phrase> data utilized for gradient and krylov subspace iteration calculations. on a 50 hr english broadcast news task we find that these methodologies provide roughly a 1.5x speed up whereas on a 300 hr switchboard task these techniques provide over a 2.3x speedup with no loss in wer. these <phrase>results suggest</phrase> that even further speed up is expected as problems scale and complexity grows.
is a picture worth ten thousand words in a review dataset 
while textual reviews have become prominent in many recommendation based systems automated frameworks to provide relevant visual cues against text reviews where pictures are not available is <phrase>a new</phrase> form of task confronted by <phrase>data mining</phrase> and <phrase>machine learning</phrase> researchers. suggestions of pictures that are relevant to the content of a review could significantly benefit the users by increasing <phrase>the effectiveness of</phrase> a review. we propose a <phrase>deep learning</phrase> based framework to automatically 1 tag the images available in a review dataset 2 generate a caption for each image that <phrase>does not</phrase> have one and 3 enhance each review by recommending relevant images that might not be uploaded by the corresponding reviewer. we evaluate <phrase>the proposed</phrase> framework using the yelp challenge dataset. while <phrase>a subset of</phrase> the images in this particular dataset are correctly captioned the majority of the pictures <phrase>do not</phrase> have any associated text. moreover there is no mapping between reviews and images. each image has a corresponding business tag where the picture was taken though. the overall data setting and unavailability of crucial pieces required for a mapping make <phrase>the problem of</phrase> recommending images for reviews a major challenge. qualitative and quantitative evaluations indicate that our <phrase>proposed framework</phrase> provides <phrase>high quality</phrase> enhancements through automatic captioning tagging and recommendation for mapping reviews and images.
validation of nonlinear pca
linear <phrase>principal component analysis</phrase> pca can be extended to a nonlinear pca <phrase>by using</phrase> <phrase>artificial neural networks</phrase>. but the benefit of curved components requires a careful control of <phrase>the model</phrase> complexity. moreover standard techniques for <phrase>model selection</phrase> including cross validation and more generally <phrase>the use of</phrase> an independent <phrase>test set</phrase> fail when <phrase>applied to</phrase> nonlinear pca because of its inherent unsupervised characteristics. <phrase>this paper</phrase> presents <phrase>a new</phrase> approach for validating <phrase>the complexity of</phrase> nonlinear pca models <phrase>by using</phrase> the error in missing data estimation as a criterion for <phrase>model selection</phrase>. it is <phrase>motivated by</phrase> the idea that only <phrase>the model</phrase> of optimal complexity is <phrase>able to</phrase> predict missing values with the highest accuracy. while standard <phrase>test set</phrase> validation usually favours over fitted nonlinear pca models <phrase>the proposed</phrase> model validation approach correctly selects the optimal model complexity.
graph approximation and clustering on a budget
we consider <phrase>the problem of</phrase> learning from a similarity matrix <phrase>such as</phrase> <phrase>spectral clustering</phrase> and lowd imensional embedding when computing pairwise similarities are costly and only a limited <phrase>number of</phrase> entries can be observed. we provide a theoretical analysis using standard notions of graph approximation significantly generalizing previous results which <phrase>focused on</phrase> <phrase>spectral clustering</phrase> with two clusters . we also propose <phrase>a new</phrase> algorithmic <phrase>approach based on</phrase> adaptive sampling which experimentally matches or improves on previous methods while being considerably more general and computationally cheaper.
shareboost efficient multiclass learning with feature sharing
multiclass prediction is <phrase>the problem of</phrase> classifying an object into a relevant target class. we consider <phrase>the problem of</phrase> learning a multiclass predictor that uses only few features and <phrase>in particular</phrase> <phrase>the number of</phrase> used features should increase sub linearly with <phrase>the number of</phrase> possible classes. this implies that features should be shared by several classes. we describe and analyze the shareboost algorithm for learning a multiclass predictor that uses few shared features. we prove that shareboost efficiently finds a predictor that uses few shared features if such a predictor exists and that it has <phrase>a small</phrase> generalization error. we also describe how to use shareboost for learning a <phrase>non linear</phrase> predictor that has a fast evaluation time. in <phrase>a series of</phrase> experiments with natural <phrase>data sets</phrase> we demonstrate the benefits of shareboost and evaluate its success relatively to other <phrase>state of</phrase> <phrase>the art</phrase> approaches.
functional <phrase>principal component analysis</phrase> and randomized sparse clustering algorithm for medical <phrase>image analysis</phrase>
<phrase>due to</phrase> <phrase>advances in</phrase> sensors growing large and complex medical image data have the <phrase>ability to</phrase> visualize the pathological change in the cellular or even the molecular level or anatomical changes in tissues and organs. as a consequence the medical images have the potential to enhance diagnosis of disease prediction of clinical outcomes characterization of disease progression management of <phrase>health care</phrase> and development of treatments <phrase>but also</phrase> pose great methodological and computational challenges for representation and selection of features in image <phrase>cluster analysis</phrase>. <phrase>to address</phrase> these challenges we first extend one dimensional functional <phrase>principal component analysis</phrase> to the two dimensional functional principle component analyses 2dfpca to fully capture space variation of image signals. image signals contain <phrase>a large number of</phrase> redundant and irrelevant features which provide no additional or no useful information for <phrase>cluster analysis</phrase>. <phrase>widely used</phrase> methods for removing redundant and irrelevant features are sparse clustering algorithms using a lasso type penalty <phrase>to select</phrase> the features. however the accuracy of clustering using a lasso type penalty <phrase>depends on</phrase> how <phrase>to select</phrase> penalty parameters and a threshold for selecting features. <phrase>in practice</phrase> they are difficult to determine. recently randomized algorithms have received a great deal of attention in <phrase>big data</phrase> analysis. <phrase>this paper</phrase> presents a <phrase>randomized algorithm</phrase> for accurate <phrase>feature selection</phrase> in image <phrase>cluster analysis</phrase>. <phrase>the proposed</phrase> method is <phrase>applied to</phrase> ovarian and <phrase>kidney cancer</phrase> histology image data from the tcga database. the <phrase>results demonstrate</phrase> that the randomized <phrase>feature selection</phrase> method coupled with functional <phrase>principal component analysis</phrase> substantially outperforms the current sparse clustering algorithms in image <phrase>cluster analysis</phrase>.
jointly learning multiple measures of similarities from triplet comparisons
similarity between objects is multi faceted and it can be easier for human annotators to measure it when the focus is on a specific aspect. we consider <phrase>the problem of</phrase> mapping objects into view specific embeddings where the distance between them is consistent with the similarity comparisons of the form from the t th view object a is more <phrase>similar to</phrase> b than to c . our framework jointly learns view specific embeddings exploiting correlations between views. <phrase>experiments on</phrase> <phrase>a number of</phrase> datasets including one of <phrase>multi view</phrase> crowdsourced comparison on bird images show <phrase>the proposed</phrase> method achieves lower triplet generalization error when <phrase>compared to</phrase> both learning embeddings independently for each view and all views pooled into one view. our method can also be used <phrase>to learn</phrase> multiple measures of similarity over <phrase>input features</phrase> taking class labels into account and compares favorably to <phrase>existing approaches</phrase> for <phrase>multi task</phrase> metric learning on the isolet dataset.
<phrase>variational inference</phrase> for uncertainty on the inputs of <phrase>gaussian process</phrase> models
the <phrase>gaussian process</phrase> <phrase>latent variable</phrase> model gp lvm provides a flexible approach for <phrase>non linear</phrase> <phrase>dimensionality reduction</phrase> that has been widely applied. however the current approach for training gp lvms is <phrase>based on</phrase> <phrase>maximum likelihood</phrase> where the latent projection variables are maximized over <phrase>rather than</phrase> integrated out. in <phrase>this paper</phrase> we present a bayesian <phrase>method for</phrase> training gp lvms <phrase>by introducing</phrase> a non standard <phrase>variational inference</phrase> framework that allows to approximately integrate out the <phrase>latent variables</phrase> and subsequently train a gp lvm by maximizing an analytic lower bound on the exact marginal likelihood. we apply this <phrase>method for</phrase> learning a gp lvm from iid observations and for learning <phrase>non linear</phrase> <phrase>dynamical systems</phrase> where the observations are temporally correlated. we show that a benefit of the variational bayesian procedure is its robustness to overfitting and its <phrase>ability to</phrase> automatically select the dimensionality of the nonlinear <phrase>latent space</phrase>. the resulting framework is generic flexible and <phrase>easy to</phrase> extend for other purposes <phrase>such as</phrase> <phrase>gaussian process</phrase> regression with uncertain inputs and <phrase>semi supervised</phrase> gaussian processes. we demonstrate our method on synthetic data and standard <phrase>machine learning</phrase> benchmarks <phrase>as well as</phrase> challenging <phrase>real world</phrase> datasets including high resolution video data.
conditional <phrase>generative adversarial</phrase> nets
<phrase>generative adversarial</phrase> nets 8 were recently introduced as <phrase>a novel</phrase> way <phrase>to train</phrase> <phrase>generative models</phrase>. in <phrase>this work</phrase> we introduce the conditional <phrase>version of</phrase> <phrase>generative adversarial</phrase> nets which can be constructed by simply feeding the data y we wish to condition on to both the generator and discriminator. we show that this model can generate mnist digits <phrase>conditioned on</phrase> class labels. we also illustrate how this model could be used <phrase>to learn</phrase> a multi modal model and provide preliminary examples of an <phrase>application to</phrase> image tagging in which we demonstrate how <phrase>this approach</phrase> can generate descriptive tags which are not part of training labels.
visual causal <phrase>feature learning</phrase>
we provide a rigorous definition of the visual cause of a behavior that is broadly <phrase>applicable to</phrase> the visually driven behavior in humans animals neurons robots and other perceiving systems. our framework generalizes standard accounts of causal learning to settings in which the causal variables <phrase>need to</phrase> be constructed from micro variables. we prove the causal coarsening theorem which allows us to gain causal knowledge from observational data <phrase>with minimal</phrase> experimental effort. the theorem provides a connection to standard inference techniques in <phrase>machine learning</phrase> that identify features of <phrase>an image</phrase> that correlate with but may not cause the target behavior. finally we propose an <phrase>active learning</phrase> scheme <phrase>to learn</phrase> a manipulator function that performs optimal manipulations on the image to automatically identify the visual cause of a target behavior. we illustrate our inference and <phrase>learning algorithms</phrase> in experiments <phrase>based on</phrase> both synthetic and real data.
in search of the real inductive bias on <phrase>the role of</phrase> implicit regularization in <phrase>deep learning</phrase>
we present experiments demonstrating that some other form of capacity control different from network size plays a central <phrase>role in</phrase> learning multilayer <phrase>feed forward</phrase> networks. we argue partially through analogy to matrix factorization that this is an inductive bias that can help shed light on <phrase>deep learning</phrase>.
domain generalization for <phrase>object recognition</phrase> with <phrase>multi task</phrase> autoencoders
<phrase>the problem of</phrase> domain generalization is to take knowledge acquired from <phrase>a number of</phrase> related domains where <phrase>training data</phrase> is available and to then successfully apply it to previously unseen domains. we propose <phrase>a new</phrase> <phrase>feature learning</phrase> algorithm <phrase>multi task</phrase> autoencoder mtae that provides good generalization performance for cross domain <phrase>object recognition</phrase>. our algorithm extends the standard denoising autoencoder framework by substituting artificially induced corruption with naturally occurring inter domain variability in the appearance of objects. <phrase>instead of</phrase> reconstructing images from noisy versions mtae learns to transform <phrase>the original</phrase> image into analogs in multiple related domains. it thereby learns features that are robust to variations across domains. the learnt features are then <phrase>used as</phrase> inputs to a classifier. we evaluated <phrase>the performance of</phrase> the algorithm on benchmark image recognition datasets where the task is <phrase>to learn</phrase> features from multiple datasets and to then predict the image label from unseen datasets. we found that denoising mtae outperforms alternative autoencoder based models <phrase>as well as</phrase> <phrase>the current state of</phrase> <phrase>the art</phrase> algorithms for domain generalization.
data efficient learning of feedback policies from image pixels using deep dynamical models
data efficient <phrase>reinforcement learning</phrase> rl in continuous state action spaces using very <phrase>high dimensional</phrase> observations remains a key challenge in developing fully autonomous systems. we consider a particularly important instance of this challenge the pixels to torques problem where an rl agent learns a closed loop control policy torques from pixel information only. we introduce a data efficient <phrase>model based</phrase> <phrase>reinforcement learning</phrase> algorithm that learns such a closed loop policy directly from pixel information. the key ingredient is a deep dynamical model for learning a <phrase>low dimensional</phrase> feature embedding of images jointly with a predictive model in this <phrase>low dimensional</phrase> <phrase>feature space</phrase>. joint learning is crucial for <phrase>long term</phrase> predictions which lie at the core of the adaptive nonlinear model predictive control strategy that we use for closed loop control. <phrase>compared to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> rl methods for continuous states and actions our approach learns quickly scales to <phrase>high dimensional</phrase> state spaces is lightweight and <phrase>an important</phrase> step toward fully autonomous <phrase>end to end</phrase> learning from pixels to torques.
scatter component analysis <phrase>a unified</phrase> <phrase>framework for</phrase> <phrase>domain adaptation</phrase> and domain generalization
<phrase>this paper</phrase> addresses <phrase>classification tasks</phrase> on a particular target domain in which labeled <phrase>training data</phrase> are only available from source domains different from but <phrase>related to</phrase> the target. two closely related frameworks <phrase>domain adaptation</phrase> and domain generalization are concerned with such tasks where the only difference between those frameworks is the availability of the unlabeled target data <phrase>domain adaptation</phrase> can leverage unlabeled target information while domain generalization cannot. we propose scatter component analyis sca a fast <phrase>representation learning</phrase> algorithm that can be <phrase>applied to</phrase> both <phrase>domain adaptation</phrase> and domain generalization. sca is <phrase>based on</phrase> <phrase>a simple</phrase> geometrical measure i.e. scatter which operates on <phrase>reproducing kernel hilbert space</phrase>. sca finds a representation that trades between maximizing the separability of classes minimizing the mismatch between domains and maximizing the separability of data each of which is quantified through scatter. the <phrase>optimization problem</phrase> of sca can be reduced to a generalized eigenvalue problem which results in a fast and exact solution. comprehensive <phrase>experiments on</phrase> benchmark cross domain <phrase>object recognition</phrase> datasets verify that sca performs much <phrase>faster than</phrase> several <phrase>state of</phrase> <phrase>the art</phrase> algorithms and also provides <phrase>state of</phrase> <phrase>the art</phrase> <phrase>classification accuracy</phrase> in both <phrase>domain adaptation</phrase> and domain generalization. we <phrase>also show</phrase> that scatter can be used to establish a theoretical generalization bound in the case of <phrase>domain adaptation</phrase>.
robust subspace clustering via tighter rank approximation
matrix rank minimization problem is in general np hard. the nuclear norm is used to substitute the rank function in many recent studies. nevertheless the nuclear norm approximation adds all singular values together and the approximation error may depend heavily on the magnitudes of singular values. this might restrict its capability in dealing with many practical problems. in <phrase>this paper</phrase> an arctangent function is <phrase>used as</phrase> a tighter approximation to the rank function. we use it on the challenging subspace clustering problem. for this nonconvex minimization problem we develop <phrase>an effective</phrase> optimization procedure <phrase>based on</phrase> a <phrase>type of</phrase> augmented lagrange multipliers alm method. <phrase>extensive experiments</phrase> on face clustering and motion segmentation show that <phrase>the proposed</phrase> method is effective for rank approximation.
recognizing semantic features in faces using <phrase>deep learning</phrase>
the human face constantly conveys information both consciously and subconsciously. however as basic as it is for humans to visually interpret this information it is quite a big challenge for machines. conventional semantic facial feature recognition and analysis techniques are already in use and are <phrase>based on</phrase> physiological heuristics but they <phrase>suffer from</phrase> lack of robustness and high computation time. this thesis aims to explore ways for machines <phrase>to learn</phrase> to interpret semantic information available in faces in an automated manner <phrase>without requiring</phrase> manual design of feature detectors using the approach of <phrase>deep learning</phrase>. this thesis provides a study of the effects of various factors and hyper parameters of <phrase>deep neural networks</phrase> in the process of determining an optimal network configuration for <phrase>the task of</phrase> semantic facial feature recognition. this thesis explores <phrase>the effectiveness of</phrase> the system to recognize the various semantic features like emotions age gender ethnicity etc. present in faces. furthermore the relation between <phrase>the effect of</phrase> <phrase>high level</phrase> concepts on low level features is explored through an analysis of the similarities in low level descriptors of different semantic features. this thesis also demonstrates <phrase>a novel</phrase> idea of using a <phrase>deep network</phrase> <phrase>to generate</phrase> 3 d active appearance models of faces from <phrase>real world</phrase> 2 d images. for a more detailed report on <phrase>this work</phrase> please see arxiv 1512.00743v1 .
deep reconstruction classification networks for unsupervised <phrase>domain adaptation</phrase>
in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> unsupervised <phrase>domain adaptation</phrase> algorithm <phrase>based on</phrase> <phrase>deep learning</phrase> for visual <phrase>object recognition</phrase>. specifically we design <phrase>a new</phrase> model called deep reconstruction classification network drcn which jointly learns a shared encoding representation for two tasks i supervised classification of labeled source data and ii unsupervised reconstruction of unlabeled target data.in this way the learnt representation <phrase>not only</phrase> preserves discriminability <phrase>but also</phrase> encodes useful information from the target domain. our new drcn model can be optimized <phrase>by using</phrase> backpropagation similarly as the standard <phrase>neural networks</phrase>. we evaluate <phrase>the performance of</phrase> drcn on <phrase>a series of</phrase> cross domain <phrase>object recognition</phrase> tasks where drcn provides a considerable improvement up to 8 in accuracy over the prior <phrase>state of</phrase> <phrase>the art</phrase> algorithms. interestingly we also observe that the reconstruction pipeline of drcn transforms images from the source domain into images whose appearance resembles the target dataset. this suggests that drcn s performance is <phrase>due to</phrase> constructing <phrase>a single</phrase> composite representation that encodes <phrase>information about</phrase> both the structure of target images and the classification of source images. finally we provide a formal analysis to justify the algorithm s objective in <phrase>domain adaptation</phrase> context.
a convolutional autoencoder for multi subject fmri data aggregation
finding the most effective way to aggregate multi subject fmri data is a long standing and challenging problem. it is of increasing interest in contemporary fmri studies of human cognition <phrase>due to</phrase> the scarcity of data per subject and the variability of brain anatomy and functional response across subjects. <phrase>recent work</phrase> on latent factor models shows <phrase>promising results</phrase> in <phrase>this task</phrase> but <phrase>this approach</phrase> <phrase>does not</phrase> preserve spatial locality in the brain. we examine two ways to combine the ideas of a factor model and a searchlight based analysis to aggregate multi subject fmri data while preserving spatial locality. we first do this directly by combining a recent factor method <phrase>known as</phrase> a shared response model with searchlight analysis. then we design a <phrase>multi view</phrase> convolutional autoencoder for <phrase>the same</phrase> task. both approaches preserve spatial locality and have competitive or <phrase>better performance</phrase> <phrase>compared with</phrase> standard searchlight analysis and the shared response model applied across the whole brain. we also report a system design to handle the computational challenge of training the convolutional autoencoder.
feedback controlled sequential lasso screening
one way <phrase>to solve</phrase> lasso problems when the dictionary <phrase>does not</phrase> fit into available memory is to first screen the dictionary to remove unneeded features. prior research has shown that sequential screening methods offer the greatest promise in this endeavor. most existing work on sequential screening targets <phrase>the context of</phrase> tuning parameter selection where one screens and solves a sequence of n lasso problems with <phrase>a fixed</phrase> grid of geometrically spaced regularization parameters. <phrase>in contrast</phrase> we <phrase>focus on</phrase> the scenario where a target regularization parameter has already been chosen via cross validated <phrase>model selection</phrase> and we then <phrase>need to</phrase> solve many lasso instances using this fixed value. in this context we propose and explore a feedback controlled sequential screening scheme. feedback is used at each iteration <phrase>to select</phrase> the next problem to be solved. this allows the sequence of problems to be adapted to the instance presented and <phrase>the number of</phrase> intermediate problems to be automatically selected. we demonstrate our feedback scheme using several datasets including a dictionary of approximate size 100 000 by 300 000.
the symmetry of <phrase>a simple</phrase> <phrase>optimization problem</phrase> in lasso screening
recently dictionary screening has been proposed as <phrase>an effective</phrase> way <phrase>to improve</phrase> the computational efficiency of solving the lasso problem which is one of the most commonly used <phrase>method for</phrase> learning sparse representations. <phrase>to address</phrase> today s ever increasing large dataset effective screening relies on a tight region bound on the solution to the dual lasso. typical region bounds are in the form of an intersection of a sphere and multiple half spaces. one way to tighten the region bound is using more half spaces which however adds to the overhead of solving the <phrase>high dimensional</phrase> <phrase>optimization problem</phrase> in lasso screening. <phrase>this paper</phrase> reveals the interesting property that the <phrase>optimization problem</phrase> only <phrase>depends on</phrase> the projection of features onto the subspace spanned by the normals of the half spaces. this property converts an <phrase>optimization problem</phrase> in high dimension to much lower dimension and thus sheds light on reducing the computation overhead of lasso screening <phrase>based on</phrase> tighter region bounds.
hard negative mining for metric learning based <phrase>zero shot</phrase> classification
<phrase>zero shot</phrase> learning has been <phrase>shown to</phrase> be an efficient strategy for <phrase>domain adaptation</phrase>. in this context <phrase>this paper</phrase> builds on the <phrase>recent work</phrase> of bucher <phrase>et al</phrase>. 1 which proposed an <phrase>approach to</phrase> solve <phrase>zero shot</phrase> <phrase>classification problems</phrase> zsc <phrase>by introducing</phrase> <phrase>a novel</phrase> metric learning based <phrase>objective function</phrase>. this <phrase>objective function</phrase> allows <phrase>to learn</phrase> an optimal embedding of the attributes jointly with a measure of similarity between images and attributes. <phrase>this paper</phrase> extends their approach by proposing several schemes to control <phrase>the generation of</phrase> the negative pairs resulting in a <phrase>significant improvement</phrase> of the performance and giving above <phrase>state of</phrase> <phrase>the art results</phrase> on three challenging zsc datasets.
pose selective max pooling for measuring similarity
in <phrase>this paper</phrase> we deal with two challenges for measuring the similarity of the subject identities in practical video based face recognition the variation of the head pose in uncontrolled environments and the computational expense of processing videos. since the frame wise feature mean is unable to characterize the pose diversity among frames we define and preserve the overall pose diversity and closeness in a video. then identity will be the only source of variation across videos since the pose varies even within <phrase>a single</phrase> video. <phrase>instead of</phrase> simply using all the frames we select those faces whose pose point is closest to the centroid of the k means cluster containing that pose point. then we represent a video as a bag of frame wise deep face features while <phrase>the number of</phrase> features has been reduced from hundreds to k. since the video representation can well represent the identity now we measure the subject similarity between two videos as the max correlation among all possible pairs in the two bags of features. on the official 5 000 video pairs of the youtube face dataset for face verification our algorithm achieves a comparable performance with vgg face that averages over deep features of all frames. other vision tasks can also benefit from the generic idea of employing geometric cues <phrase>to improve</phrase> the descriptiveness of deep features.
detecting unseen falls from wearable devices using channel wise ensemble of autoencoders
a fall is an abnormal activity that occurs rarely so it is hard to collect real data for falls. it is therefore difficult to use <phrase>supervised learning</phrase> methods to automatically detect falls. another challenge in using <phrase>machine learning</phrase> methods to automatically detect falls is the <phrase>choice of</phrase> engineered features. in <phrase>this paper</phrase> we propose to use an ensemble of autoencoders <phrase>to extract</phrase> features from different channels of wearable sensor data trained only on normal activities. we show that the traditional approach of choosing a threshold as the maximum of the reconstruction error on the training normal data is not the right way to identify unseen falls. we propose two methods for automatic tightening of reconstruction error from only the normal activities for better identification of unseen falls. we present our <phrase>results on</phrase> two activity recognition datasets and show <phrase>the efficacy of</phrase> our <phrase>proposed method</phrase> against traditional autoencoder models and two standard one class classification methods.
generalization error of invariant classifiers
<phrase>this paper</phrase> studies the generalization error of invariant classifiers. <phrase>in particular</phrase> we consider the common scenario where the <phrase>classification task</phrase> is invariant to certain transformations of <phrase>the input</phrase> and that the classifier is constructed or learned to be invariant to these transformations. our approach relies on factoring <phrase>the input</phrase> space into a product of a base space and <phrase>a set of</phrase> transformations. we show that whereas the generalization error of a non invariant classifier is proportional to <phrase>the complexity of</phrase> <phrase>the input</phrase> space the generalization error of an invariant classifier is proportional to <phrase>the complexity of</phrase> the base space. we also derive <phrase>a set of</phrase> sufficient conditions on the geometry of the base space and the <phrase>set of</phrase> transformations that ensure that <phrase>the complexity of</phrase> the base space is much smaller than <phrase>the complexity of</phrase> <phrase>the input</phrase> space. our analysis applies to general classifiers <phrase>such as</phrase> <phrase>convolutional neural networks</phrase>. we demonstrate the implications of the developed theory for such classifiers with <phrase>experiments on</phrase> the mnist and <phrase>cifar 10</phrase> datasets.
universal <phrase>adversarial perturbations</phrase>
given a <phrase>state of</phrase> <phrase>the art</phrase> <phrase>deep neural network</phrase> classifier we show <phrase>the existence of</phrase> a universal image agnostic and very small perturbation vector that causes natural images to be misclassified with high probability. we propose a systematic algorithm for computing <phrase>universal perturbations</phrase> and show that <phrase>state of</phrase> <phrase>the art</phrase> <phrase>deep neural networks</phrase> are highly vulnerable to such perturbations albeit being quasi imperceptible to the <phrase>human eye</phrase>. we further empirically analyze these <phrase>universal perturbations</phrase> and show <phrase>in particular</phrase> that they generalize very well across <phrase>neural networks</phrase>. the surprising <phrase>existence of</phrase> <phrase>universal perturbations</phrase> reveals important geometric correlations among the <phrase>high dimensional</phrase> decision boundary of classifiers. it further outlines potential security breaches with <phrase>the existence of</phrase> single directions in <phrase>the input</phrase> space that adversaries can possibly exploit to break a classifier on most natural images.
linear disentangled <phrase>representation learning</phrase> for facial actions
limited annotated data available for the recognition of <phrase>facial expression</phrase> and action units embarrasses the training of <phrase>deep networks</phrase> which can learn disentangled invariant features. however a <phrase>linear model</phrase> with just several parameters normally is not demanding <phrase>in terms of</phrase> <phrase>training data</phrase>. in <phrase>this paper</phrase> we propose an elegant <phrase>linear model</phrase> to untangle confounding factors in challenging realistic multichannel signals <phrase>such as</phrase> 2d face videos. the simple yet powerful model <phrase>does not</phrase> <phrase>rely on</phrase> huge <phrase>training data</phrase> and is natural for recognizing facial actions without explicitly disentangling the identity. base on well understood intuitive linear models <phrase>such as</phrase> sparse representation based classification src previous attempts require a prepossessing of explicit decoupling which is practically inexact. instead we exploit the low rank property across frames to subtract the underlying neutral faces which are modeled jointly with sparse representation on the action components with group sparsity enforced. on the extended cohn kanade dataset ck our one shot automatic method on raw face videos performs as competitive as src applied on manually prepared action components and performs even <phrase>better than</phrase> src <phrase>in terms of</phrase> true positive rate. we apply <phrase>the model</phrase> to the even more <phrase>challenging task</phrase> of facial action unit recognition verified on the mpi face video database mpi vdb achieving a decent performance. all the programs and data have been made <phrase>publicly available</phrase>.
on detecting <phrase>adversarial perturbations</phrase>
<phrase>machine learning</phrase> and <phrase>deep learning</phrase> <phrase>in particular</phrase> has advanced tremendously on perceptual tasks <phrase>in recent years</phrase>. however it remains vulnerable against <phrase>adversarial perturbations</phrase> of <phrase>the input</phrase> that have been crafted specifically to fool the system while being quasi imperceptible to a human. in <phrase>this work</phrase> we propose to augment <phrase>deep neural networks</phrase> with <phrase>a small</phrase> detector subnetwork which is <phrase>trained on</phrase> the <phrase>binary classification</phrase> task of distinguishing genuine data from data containing <phrase>adversarial perturbations</phrase>. our method is orthogonal to prior work on addressing <phrase>adversarial perturbations</phrase> which has mostly <phrase>focused on</phrase> making the classification network itself <phrase>more robust</phrase>. we show empirically that <phrase>adversarial perturbations</phrase> can be detected surprisingly well even though they are quasi imperceptible to humans. moreover while the detectors have been trained to detect only a specific adversary they generalize to similar and weaker adversaries. <phrase>in addition</phrase> we propose an adversarial attack that fools both the classifier and the detector and <phrase>a novel</phrase> training procedure for the detector that counteracts this attack.
activation maximization <phrase>generative adversarial</phrase> nets
class labels have been empirically shown useful in improving the sample quality of <phrase>generative adversarial</phrase> nets gans . in <phrase>this paper</phrase> we mathematically study the <phrase>properties of</phrase> the current variants of gans that make use of class label information. with class aware gradient and <phrase>cross entropy</phrase> decomposition we reveal how class labels and associated losses influence gan s training. <phrase>based on</phrase> that we propose activation maximization <phrase>generative adversarial networks</phrase> am gan as an advanced solution. comprehensive experiments have been conducted to validate our analysis and evaluate <phrase>the effectiveness of</phrase> our solution where am gan outperforms other strong baselines and <phrase>achieves state of</phrase> <phrase>the art</phrase> inception score 8.91 on <phrase>cifar 10</phrase>. <phrase>in addition</phrase> we demonstrate that with the inception imagenet classifier inception score mainly tracks the diversity of the generator and there is however no reliable evidence that it can reflect the true sample quality. we thus propose <phrase>a new</phrase> metric called am score to provide <phrase>more accurate</phrase> estimation on the sample quality. our <phrase>proposed model</phrase> also outperforms the baseline methods in the new metric.
interpretable explanations of black boxes by meaningful perturbation
as <phrase>machine learning</phrase> algorithms are increasingly <phrase>applied to</phrase> high impact yet high risk <phrase>tasks such as</phrase> <phrase>medical diagnosis</phrase> or autonomous driving it is critical that researchers can explain how such algorithms arrived at their predictions. <phrase>in recent years</phrase> <phrase>a number of</phrase> image saliency methods have been developed to summarize where highly complex <phrase>neural networks</phrase> look in <phrase>an image</phrase> for evidence for their predictions. however these techniques are limited by their heuristic nature and architectural constraints. in <phrase>this paper</phrase> we make two main contributions first we propose a general <phrase>framework for</phrase> learning different kinds of explanations for any <phrase>black box</phrase> algorithm. second we specialise the framework to find the part of <phrase>an image</phrase> most responsible for a classifier decision. unlike previous works our method is model agnostic and testable because it is grounded in explicit and interpretable image perturbations.
a general theory for training learning machine
though the <phrase>deep learning</phrase> is pushing the <phrase>machine learning</phrase> to <phrase>a new</phrase> stage basic theories of <phrase>machine learning</phrase> are still limited. the principle of learning <phrase>the role of</phrase> the a <phrase>prior knowledge</phrase> <phrase>the role of</phrase> neuron bias and the basis for choosing neural <phrase>transfer function</phrase> and cost function etc. are still far from clear. in <phrase>this paper</phrase> we present a general theoretical <phrase>framework for</phrase> <phrase>machine learning</phrase>. we classify the <phrase>prior knowledge</phrase> into common and problem dependent parts and consider that the aim of learning is to maximally incorporate them. the principle we suggested for maximizing the former is the design risk minimization principle while the neural <phrase>transfer function</phrase> the cost function <phrase>as well as</phrase> pretreatment of samples are endowed with the role for maximizing <phrase>the latter</phrase>. <phrase>the role of</phrase> the neuron bias is explained from a different angle. we develop a <phrase>monte carlo</phrase> algorithm to establish <phrase>the input</phrase> output responses and we control <phrase>the input</phrase> output sensitivity of a learning machine by controlling that of individual neurons. applications of function approaching and smoothing <phrase>pattern recognition</phrase> and classification are provided to illustrate how <phrase>to train</phrase> general <phrase>learning machines</phrase> <phrase>based on</phrase> our theory and algorithm. our method may <phrase>in addition</phrase> induce new <phrase>applications such as</phrase> the transductive inference.
a generalization of <phrase>convolutional neural networks</phrase> to graph structured data
<phrase>this paper</phrase> introduces a generalization of <phrase>convolutional neural networks</phrase> cnns from <phrase>low dimensional</phrase> grid data <phrase>such as</phrase> images to graph structured data. we propose <phrase>a novel</phrase> spatial convolution utilizing a <phrase>random walk</phrase> to uncover the relations within <phrase>the input</phrase> analogous to the way the standard convolution uses the spatial neighborhood of a pixel on the grid. the convolution has an intuitive interpretation is efficient and scalable and can also be used on data with varying graph structure. furthermore this generalization can be <phrase>applied to</phrase> many standard regression or <phrase>classification problems</phrase> by learning the the underlying graph. we empirically demonstrate <phrase>the performance of</phrase> <phrase>the proposed</phrase> cnn on mnist and challenge the <phrase>state of</phrase> <phrase>the art</phrase> on merck molecular activity <phrase>data set</phrase>.
formal guarantees on <phrase>the robustness of</phrase> a classifier against adversarial manipulation
<phrase>recent work</phrase> has shown that <phrase>state of</phrase> <phrase>the art</phrase> classifiers are quite brittle in the sense that <phrase>a small</phrase> adversarial change of an originally with high confidence correctly classified input <phrase>leads to</phrase> a wrong classification again with high confidence. this raises concerns that such classifiers are vulnerable to attacks and calls into question their usage in safety critical systems. we show in <phrase>this paper</phrase> for the first time formal guarantees on <phrase>the robustness of</phrase> a classifier by giving instance specific lower bounds on the norm of <phrase>the input</phrase> manipulation required to change the classifier decision. <phrase>based on</phrase> this analysis we propose the cross lipschitz regularization functional. we show that using this form of regularization in kernel methods resp. <phrase>neural networks</phrase> improves <phrase>the robustness of</phrase> the classifier without any loss in prediction performance.
classification regions of <phrase>deep neural networks</phrase>
<phrase>the goal of</phrase> <phrase>this paper</phrase> is to analyze the geometric <phrase>properties of</phrase> <phrase>deep neural network</phrase> classifiers in <phrase>the input</phrase> space. we specifically study the topology of classification regions created by <phrase>deep networks</phrase> <phrase>as well as</phrase> their associated decision boundary. through a systematic empirical investigation we show that <phrase>state of</phrase> <phrase>the art</phrase> deep nets learn connected classification regions and that the decision boundary in the vicinity of datapoints is flat along most directions. we further draw an essential connection between two seemingly unrelated <phrase>properties of</phrase> <phrase>deep networks</phrase> their sensitivity to additive perturbations in the inputs and the curvature of their decision boundary. the directions where the decision boundary is curved in fact remarkably characterize the directions to which the classifier is the most vulnerable. we finally leverage a fundamental asymmetry in the curvature of the decision boundary of deep nets and propose a method to discriminate between original images and images perturbed with small <phrase>adversarial examples</phrase>. we show <phrase>the effectiveness of</phrase> this purely geometric approach for detecting small <phrase>adversarial perturbations</phrase> in images and for recovering the labels of perturbed images.
analysis of universal <phrase>adversarial perturbations</phrase>
<phrase>deep networks</phrase> have recently been <phrase>shown to</phrase> be vulnerable to <phrase>universal perturbations</phrase> there exist very small image agnostic perturbations that cause most natural images to be misclassified by such classifiers. in <phrase>this paper</phrase> we propose the first quantitative analysis of <phrase>the robustness of</phrase> classifiers to <phrase>universal perturbations</phrase> and draw a formal link between the robustness to <phrase>universal perturbations</phrase> and the geometry of the decision boundary. specifically we establish theoretical bounds on <phrase>the robustness of</phrase> classifiers under two decision boundary models flat and curved models . we show <phrase>in particular</phrase> that <phrase>the robustness of</phrase> <phrase>deep networks</phrase> to <phrase>universal perturbations</phrase> is driven by a key property of their curvature there exists shared directions along which the decision boundary of <phrase>deep networks</phrase> is systematically positively curved. under such conditions we prove <phrase>the existence of</phrase> small <phrase>universal perturbations</phrase>. our analysis further provides <phrase>a novel</phrase> geometric <phrase>method for</phrase> computing <phrase>universal perturbations</phrase> <phrase>in addition</phrase> to explaining their properties.
bayesian gan
<phrase>generative adversarial networks</phrase> gans can implicitly learn rich distributions over images audio and data which are hard to model with an explicit likelihood. we present a practical bayesian formulation for unsupervised and <phrase>semi supervised</phrase> learning with gans. within this framework we use <phrase>stochastic gradient</phrase> hamiltonian <phrase>monte carlo</phrase> to marginalize the weights of the generator and discriminator networks. the resulting approach is straightforward and obtains good performance without any standard interventions <phrase>such as</phrase> feature matching or mini batch discrimination. by exploring an expressive posterior over <phrase>the parameters of</phrase> the generator the bayesian gan avoids mode collapse produces interpretable and diverse candidate samples and provides <phrase>state of</phrase> <phrase>the art</phrase> quantitative results for <phrase>semi supervised</phrase> learning on benchmarks including svhn celeba and <phrase>cifar 10</phrase> outperforming dcgan wasserstein gans and dcgan ensembles.
<phrase>unsupervised learning</phrase> of disentangled representations from video
we present <phrase>a new</phrase> model drnet that learns disentangled image representations from video. our approach leverages the temporal coherence of video and <phrase>a novel</phrase> adversarial loss <phrase>to learn</phrase> a representation that factorizes each frame into a stationary part and a temporally varying component. the disentangled representation can be used for <phrase>a range of</phrase> tasks. for example applying a standard lstm to the time vary components enables prediction of future frames. we evaluate our approach on <phrase>a range of</phrase> synthetic and real videos demonstrating the <phrase>ability to</phrase> coherently generate hundreds of steps into the future.
dualing gans
<phrase>generative adversarial</phrase> nets gans are a promising technique for modeling a distribution from samples. it is however <phrase>well known</phrase> that gan training suffers from instability <phrase>due to</phrase> the nature of its maximin formulation. in <phrase>this paper</phrase> we explore ways <phrase>to tackle</phrase> the instability problem by dualizing the discriminator. we start from linear discriminators in which case conjugate duality provides a mechanism to reformulate the <phrase>saddle point</phrase> objective into a maximization problem such that both the generator and the discriminator of this dualing gan act in concert. we then demonstrate how to extend this intuition to <phrase>non linear</phrase> formulations. for gans with linear discriminators our approach is <phrase>able to</phrase> remove the instability in training while for gans with nonlinear discriminators our approach provides <phrase>an alternative</phrase> to the commonly used gan training algorithm.
wavelet residual network for low dose ct via <phrase>deep convolutional</phrase> framelets
<phrase>model based</phrase> iterative reconstruction mbir algorithms for low dose <phrase>x ray</phrase> ct are computationally expensive. <phrase>to address</phrase> <phrase>this problem</phrase> we <phrase>recently proposed</phrase> the world first <phrase>deep convolutional</phrase> <phrase>neural network</phrase> cnn for low dose <phrase>x ray</phrase> ct and won the second place in 2016 aapm low dose ct grand challenge. however some of the texture were not fully recovered. to cope with <phrase>this problem</phrase> here we propose a deep residual <phrase>learning approach</phrase> in directional wavelet domain. <phrase>the proposed</phrase> method is <phrase>motivated by</phrase> an observation that a <phrase>deep convolutional</phrase> <phrase>neural network</phrase> can be interpreted as a multilayer convolutional framelets expansion using non local basis convolved with <phrase>data driven</phrase> local basis. we further extend the idea to derive a <phrase>deep convolutional</phrase> framelet expansion by combining global redundant transforms and signal boosting from multiple signal representations. extensive <phrase>experimental results</phrase> confirm that <phrase>the proposed</phrase> network has significantly improved performance and preserves the detail texture of <phrase>the original</phrase> images
3d prnn generating shape primitives with <phrase>recurrent neural networks</phrase>
the success of various applications including robotics digital content creation and visualization demand a structured and abstract representation of the 3d world from limited sensor data. <phrase>inspired by</phrase> the nature of <phrase>human perception</phrase> of 3d shapes as a collection of simple parts we explore such an abstract shape representation <phrase>based on</phrase> primitives. given <phrase>a single</phrase> depth image of an object we present 3d prnn a generative <phrase>recurrent neural network</phrase> that synthesizes multiple plausible shapes <phrase>composed of</phrase> <phrase>a set of</phrase> primitives. our <phrase>generative model</phrase> encodes symmetry characteristics of common man made objects preserves <phrase>long range</phrase> structural coherence and describes objects of varying complexity with a compact representation. we also propose a method <phrase>based on</phrase> gaussian fields <phrase>to generate</phrase> <phrase>a large</phrase> scale dataset of primitive based shape representations <phrase>to train</phrase> our network. we evaluate our approach on <phrase>a wide range of</phrase> examples and show that it outperforms nearest neighbor based shape retrieval methods and is on par with voxel based <phrase>generative models</phrase> while using a significantly reduced parameter space.
inception score label smoothing gradient vanishing and log d x alternative
in this article we mathematically study several gan related topics including inception score label smoothing gradient vanishing and the log d x alternative. an advanced version is included in arxiv 1703.02000 activation maximization <phrase>generative adversarial</phrase> nets . please refer section 6 in 1703.02000 for detailed analysis on inception score and refer its appendix for the discussions on label smoothing gradient vanishing and log d x alternative. 
a brief survey of <phrase>deep reinforcement learning</phrase>
<phrase>deep reinforcement learning</phrase> is poised to revolutionise <phrase>the field of</phrase> ai and represents a <phrase>step towards</phrase> building autonomous systems with a <phrase>higher level</phrase> understanding of the visual world. currently <phrase>deep learning</phrase> is enabling <phrase>reinforcement learning</phrase> to scale to problems that were previously intractable <phrase>such as</phrase> learning <phrase>to play</phrase> <phrase>video games</phrase> directly from pixels. <phrase>deep reinforcement learning</phrase> algorithms are also <phrase>applied to</phrase> robotics allowing control policies for robots to be learned directly from camera inputs in the <phrase>real world</phrase>. in this survey we begin with an introduction to the general field of <phrase>reinforcement learning</phrase> then progress to the main streams of value based and policy <phrase>based methods</phrase>. our survey will cover central algorithms in <phrase>deep reinforcement learning</phrase> including the <phrase>deep q</phrase> network trust region policy optimisation and asynchronous advantage <phrase>actor critic</phrase>. in parallel we highlight the unique advantages of <phrase>deep neural networks</phrase> focusing on visual understanding via <phrase>reinforcement learning</phrase>. to conclude we describe several current areas of research within the field.
circnn accelerating and compressing <phrase>deep neural networks</phrase> using block circulantweight matrices
<phrase>large scale</phrase> <phrase>deep neural networks</phrase> dnns are both compute and memory intensive. as the size of dnns continues to grow it is critical <phrase>to improve</phrase> the energy efficiency and performance while maintaining accuracy. for dnns <phrase>the model</phrase> size is <phrase>an important</phrase> factor affecting performance scalability and energy efficiency. weight pruning achieves good compression ratios but suffers from three drawbacks 1 the irregular <phrase>network structure</phrase> after pruning 2 the increased training complexity and 3 <phrase>the lack of</phrase> rigorous guarantee of <phrase>compression ratio</phrase> and inference accuracy. <phrase>to overcome</phrase> these limitations <phrase>this paper</phrase> proposes circnn a principled <phrase>approach to</phrase> represent weights and process <phrase>neural networks</phrase> using block circulant matrices. circnn utilizes the <phrase>fast fourier transform</phrase> fft based fast multiplication simultaneously reducing the <phrase>computational complexity</phrase> both in inference and training from o n2 to o nlogn and the storage complexity from o n2 to o n with negligible accuracy loss. <phrase>compared to</phrase> other approaches circnn is distinct <phrase>due to</phrase> its mathematical rigor it can converge to <phrase>the same</phrase> effectiveness as dnns without compression. the circnn architecture a universal dnn <phrase>inference engine</phrase> that can be implemented on various hardware software platforms with configurable <phrase>network architecture</phrase>. to demonstrate the performance and energy efficiency we test circnn in fpga asic and embedded processors. our <phrase>results show</phrase> that circnn architecture achieves very high energy efficiency and performance with <phrase>a small</phrase> hardware footprint. <phrase>based on</phrase> the fpga implementation and asic synthesis results circnn achieves 6 102x energy efficiency improvements <phrase>compared with</phrase> <phrase>the best</phrase> <phrase>state of</phrase> <phrase>the art</phrase> results.
xflow 1d 2d cross modal <phrase>deep neural networks</phrase> for audiovisual classification
we propose two multimodal <phrase>deep learning</phrase> architectures that allow for cross modal dataflow xflow between the feature extractors thereby extracting more interpretable features and obtaining a better representation than through unimodal learning for <phrase>the same</phrase> <phrase>amount of</phrase> <phrase>training data</phrase>. <phrase>these models</phrase> can usefully exploit correlations between audio and visual data which have a different dimensionality and are therefore nontrivially exchangeable. our work improves on existing multimodal <phrase>deep learning</phrase> metholodogies in two essential ways 1 it presents <phrase>a novel method</phrase> for performing cross modality before features are learned from individual modalities and 2 extends the previously proposed cross connections which only transfer information between streams that process compatible data. both cross modal architectures outperformed their baselines by up to 7.5 when evaluated on the avletters dataset.
context embedding networks
<phrase>low dimensional</phrase> embeddings that capture the main variations of interest in collections of data are important for <phrase>many applications</phrase>. one way to construct these embeddings is to acquire estimates of similarity from the crowd. however similarity is a multi dimensional concept that varies from individual to individual. existing models for learning embeddings from the crowd typically make simplifying assumptions <phrase>such as</phrase> all individuals estimate similarity using <phrase>the same</phrase> criteria the list of criteria is known in advance or that the crowd workers are not influenced by the data that they see. <phrase>to overcome</phrase> these limitations we introduce context embedding networks cens . <phrase>in addition</phrase> to learning interpretable embeddings from images cens also model worker biases for different attributes <phrase>along with</phrase> the visual context i.e. the visual attributes highlighted by <phrase>a set of</phrase> images. <phrase>experiments on</phrase> two noisy crowd annotated datasets show that modeling both worker bias and visual context results in more interpretable embeddings <phrase>compared to</phrase> <phrase>existing approaches</phrase>.
how much chemistry does <phrase>a deep neural network</phrase> <phrase>need to</phrase> know to make accurate predictions 
the meteoric rise of <phrase>deep learning</phrase> models <phrase>in computer vision</phrase> research having achieved human level accuracy in image <phrase>recognition tasks</phrase> is firm evidence of the impact of <phrase>representation learning</phrase> of <phrase>deep neural networks</phrase>. in the chemistry domain <phrase>recent advances</phrase> have also led to the development of similar cnn models <phrase>such as</phrase> chemception that is trained <phrase>to predict</phrase> chemical properties using images of molecular drawings. in <phrase>this work</phrase> we investigate the effects of systematically removing and adding localized <phrase>domain specific</phrase> information to the image channels of <phrase>the training data</phrase>. by augmenting images with only 3 additional basic information and without introducing any architectural changes we demonstrate that an augmented chemception augchemception outperforms <phrase>the original</phrase> model in the prediction of toxicity activity and solvation <phrase>free energy</phrase>. then by altering the information content in the images and examining the resulting model s performance we also identify two distinct learning patterns in predicting toxicity activity as <phrase>compared to</phrase> solvation <phrase>free energy</phrase>. these patterns suggest that chemception is learning about its tasks in the manner that is consistent with established knowledge. thus our work demonstrates that advanced chemical knowledge is not a pre requisite for <phrase>deep learning</phrase> models to accurately predict complex chemical properties.
<phrase>variational inference</phrase> of disentangled latent concepts from unlabeled observations
disentangled representations where the <phrase>higher level</phrase> data generative factors are reflected in disjoint latent dimensions offer several benefits <phrase>such as</phrase> ease of deriving invariant representations transferability to other tasks interpretability etc. we consider <phrase>the problem of</phrase> <phrase>unsupervised learning</phrase> of disentangled representations from large pool of unlabeled observations and propose a <phrase>variational inference</phrase> <phrase>based approach</phrase> to infer disentangled latent factors. we introduce a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement. we evaluate <phrase>the proposed</phrase> approach using several quantitative metrics and empirically observe significant gains over <phrase>existing methods</phrase> <phrase>in terms of</phrase> both disentanglement and data likelihood reconstruction quality .
three factors influencing minima in sgd
we study the <phrase>properties of</phrase> the endpoint of <phrase>stochastic gradient descent</phrase> sgd . by approximating sgd as a <phrase>stochastic differential equation</phrase> sde we consider the boltzmann gibbs equilibrium distribution of that sde under the assumption of isotropic variance in loss gradients. through this analysis we find that three factors <phrase>learning rate</phrase> <phrase>batch size</phrase> and the variance of the loss gradients control the trade off between the depth and width of the minima found by sgd with wider minima favoured by a higher ratio of <phrase>learning rate</phrase> to <phrase>batch size</phrase>. we have direct control over the <phrase>learning rate</phrase> and <phrase>batch size</phrase> while the variance is determined by the <phrase>choice of</phrase> model architecture model parameterization and dataset. in the equilibrium distribution only the ratio of <phrase>learning rate</phrase> to <phrase>batch size</phrase> appears implying that the equilibrium distribution is invariant under a simultaneous rescaling of <phrase>learning rate</phrase> and <phrase>batch size</phrase> by <phrase>the same</phrase> amount. we then explore experimentally how <phrase>learning rate</phrase> and <phrase>batch size</phrase> affect sgd from two perspectives the endpoint of sgd and the dynamics that lead up to it. for the endpoint the experiments suggest the endpoint of sgd is invariant under simultaneous rescaling of <phrase>batch size</phrase> and <phrase>learning rate</phrase> and also that a higher ratio <phrase>leads to</phrase> flatter minima both findings are consistent with our theoretical analysis. we note experimentally that the dynamics also seem to be invariant under <phrase>the same</phrase> rescaling of <phrase>learning rate</phrase> and <phrase>batch size</phrase> which we explore showing that one can exchange <phrase>batch size</phrase> and <phrase>learning rate</phrase> for cyclical <phrase>learning rate</phrase> schedule. next we illustrate how noise affects memorization showing that high noise levels <phrase>lead to</phrase> better generalization. finally we find experimentally that the invariance under simultaneous rescaling of <phrase>learning rate</phrase> and <phrase>batch size</phrase> breaks down if the <phrase>learning rate</phrase> gets too large or the <phrase>batch size</phrase> gets too small.
learning <phrase>to play</phrase> othello with <phrase>deep neural networks</phrase>
achieving superhuman playing level by alphago corroborated the capabilities of convolutional <phrase>neural architectures</phrase> cnns for capturing complex spatial patterns. this result was to a great extent <phrase>due to</phrase> several analogies between go board states and 2d images cnns have been designed for <phrase>in particular</phrase> translational invariance and a relatively large board. in <phrase>this paper</phrase> we verify whether cnn based move predictors prove effective for othello a game with significantly different characteristics including a much smaller board size and complete lack of translational invariance. we compare several cnn architectures and board encodings augment them with <phrase>state of</phrase> <phrase>the art</phrase> extensions train on an extensive database of experts moves and examine them <phrase>with respect to</phrase> move prediction accuracy and playing strength. the empirical evaluation confirms high capabilities of neural move predictors and suggests a strong correlation between prediction accuracy and playing strength. <phrase>the best</phrase> cnns <phrase>not only</phrase> surpass all other 1 ply othello players proposed <phrase>to date</phrase> but defeat 2 ply edax <phrase>the best</phrase> <phrase>open source</phrase> othello player.
<phrase>deep learning</phrase> can reverse photon migration for diffuse optical tomography
can <phrase>artificial intelligence</phrase> ai learn complicated <phrase>non linear</phrase> physics here we propose <phrase>a novel</phrase> <phrase>deep learning</phrase> approach that learns <phrase>non linear</phrase> photon scattering physics and obtains accurate 3d distribution of optical anomalies. <phrase>in contrast to</phrase> the traditional <phrase>black box</phrase> <phrase>deep learning</phrase> approaches to inverse problems our <phrase>deep network</phrase> learns to invert the lippmann schwinger <phrase>integral equation</phrase> which describes the essential physics of photon migration of diffuse near infrared nir photons in turbid media. as an example for clinical relevance we applied the method to our prototype diffuse optical tomography dot . we show that our <phrase>deep neural network</phrase> trained with only simulation data can accurately recover the location of anomalies within biomimetic phantoms and live animals without <phrase>the use of</phrase> an exogenous contrast agent.
using rule based labels for weak <phrase>supervised learning</phrase> a chemnet for transferable chemical property prediction
with access to large datasets <phrase>deep neural networks</phrase> dnn have achieved human level accuracy in image and <phrase>speech recognition</phrase> tasks. however in chemistry data is inherently small and fragmented. in <phrase>this work</phrase> we develop an approach of using rule based knowledge for training chemnet a transferable and generalizable <phrase>deep neural network</phrase> for chemical property prediction that learns in a weak supervised manner from large unlabeled chemical databases. when coupled with <phrase>transfer learning</phrase> approaches <phrase>to predict</phrase> other smaller datasets for chemical properties that it was not originally <phrase>trained on</phrase> we show that chemnet s accuracy outperforms contemporary dnn models that were trained using conventional <phrase>supervised learning</phrase>. furthermore we demonstrate that the chemnet <phrase>pre training</phrase> approach is equally effective on both cnn chemception and rnn smiles2vec models indicating that <phrase>this approach</phrase> is <phrase>network architecture</phrase> agnostic and is effective across multiple data modalities. our results indicate a <phrase>pre trained</phrase> chemnet that incorporates chemistry <phrase>domain knowledge</phrase> enables the development of generalizable <phrase>neural networks</phrase> for <phrase>more accurate</phrase> prediction of novel chemical properties.
<phrase>deep learning</phrase> in rf sub sampled b mode ultrasound imaging
in portable three dimensional and ultra fast ultrasound us imaging systems there is an increasing <phrase>need to</phrase> reconstruct <phrase>high quality</phrase> images from a limited <phrase>number of</phrase> rf data from receiver rx or <phrase>scan line</phrase> sc sub sampling. however <phrase>due to</phrase> the severe side lobe artifacts from rf sub sampling the standard beam former often produces blurry images with less contrast that are not <phrase>suitable for</phrase> diagnostic purpose. <phrase>to address</phrase> <phrase>this problem</phrase> some researchers have studied <phrase>compressed sensing</phrase> cs to exploit the sparsity of the image or rf data in some domains. however the existing cs approaches require either hardware changes or computationally expensive algorithms. <phrase>to overcome</phrase> these limitations here we propose <phrase>a novel</phrase> <phrase>deep learning</phrase> approach that directly interpolates the missing rf data by utilizing redundancy in the rx sc plane. <phrase>in particular</phrase> <phrase>the network</phrase> design principle derives from <phrase>a novel</phrase> interpretation of the <phrase>deep neural network</phrase> as a cascaded convolution framelets that learns the <phrase>data driven</phrase> bases for hankel <phrase>matrix decomposition</phrase>. our extensive <phrase>experimental results</phrase> from sub sampled rf data from a real us system confirmed that <phrase>the proposed</phrase> method can effectively reduce the data rate without sacrificing the image quality.
<phrase>deep learning</phrase> interior tomography for region of interest reconstruction
interior tomography for the region of interest roi imaging has advantages of using <phrase>a small</phrase> detector and reducing <phrase>x ray</phrase> <phrase>radiation dose</phrase>. however standard analytic reconstruction suffers from severe cupping artifacts <phrase>due to</phrase> <phrase>existence of</phrase> null space in the truncated <phrase>radon transform</phrase>. existing penalized reconstruction methods may address <phrase>this problem</phrase> but they require extensive computations <phrase>due to</phrase> the iterative reconstruction. <phrase>inspired by</phrase> the recent <phrase>deep learning</phrase> approaches to low dose and sparse view ct here we propose a <phrase>deep learning</phrase> architecture that removes null space signals from the fbp reconstruction. <phrase>experimental results</phrase> have shown that <phrase>the proposed</phrase> method provides near perfect reconstruction with about 7 10 db improvement in psnr over <phrase>existing methods</phrase> in spite of significantly reduced run time complexity.
<phrase>deep learning</phrase> reconstruction for 9 view dual energy ct baggage scanner
for homeland and transportation security applications 2d <phrase>x ray</phrase> explosive detection system eds have been <phrase>widely used</phrase> but they have limitations in recognizing 3d shape of the hidden objects. among various <phrase>types of</phrase> 3d <phrase>computed tomography</phrase> ct systems <phrase>to address</phrase> <phrase>this issue</phrase> <phrase>this paper</phrase> is interested in a stationary ct using fixed <phrase>x ray</phrase> sources and detectors. however <phrase>due to</phrase> the limited <phrase>number of</phrase> projection views analytic reconstruction algorithms produce severe streaking artifacts. <phrase>inspired by</phrase> recent success of <phrase>deep learning</phrase> approach for sparse view ct reconstruction here we propose <phrase>a novel</phrase> image and sinogram domain <phrase>deep learning</phrase> architecture for 3d reconstruction from very sparse view measurement. the algorithm has been tested with the real data from a prototype 9 view dual energy stationary ct eds carry on baggage scanner developed by gemss medical systems korea which confirms the superior reconstruction performance over the <phrase>existing approaches</phrase>.
effective building <phrase>block design</phrase> for <phrase>deep convolutional neural networks</phrase> using search
<phrase>deep learning</phrase> has shown <phrase>promising results</phrase> on many <phrase>machine learning</phrase> tasks but dl models are often complex networks with <phrase>large number of</phrase> neurons and layers and recently complex layer structures <phrase>known as</phrase> <phrase>building blocks</phrase>. finding <phrase>the best</phrase> deep model requires a <phrase>combination of</phrase> finding both the right architecture and the correct <phrase>set of</phrase> parameters appropriate for that architecture. <phrase>in addition</phrase> this complexity <phrase>in terms of</phrase> layer types <phrase>number of</phrase> neurons and <phrase>number of</phrase> layers <phrase>also present</phrase> problems with generalization since larger networks are easier to overfit to the data. in <phrase>this paper</phrase> we propose a search <phrase>framework for</phrase> finding effective architectural <phrase>building blocks</phrase> for <phrase>convolutional neural networks</phrase> cnn . our approach is much faster at finding models that are <phrase>close to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> in performance. <phrase>in addition</phrase> the models discovered by our approach are also smaller than models discovered by similar techniques. we achieve these twin advantages by designing our search space in such a way that it searches over a reduced <phrase>set of</phrase> <phrase>state of</phrase> <phrase>the art</phrase> <phrase>building blocks</phrase> for cnns including residual block inception block inception residual block resnext block and many others. we apply this technique <phrase>to generate</phrase> models for multiple image datasets and show that <phrase>these models</phrase> achieve performance <phrase>comparable to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> and even surpassing the <phrase>state of</phrase> <phrase>the art</phrase> in one case . we <phrase>also show</phrase> that learned models are transferable between datasets.
tvae triplet based variational autoencoder using metric learning
deep metric learning has been demonstrated to be highly effective in learning semantic representation and encoding information that can be used to measure data similarity by relying on the embedding learned from metric learning. at <phrase>the same</phrase> time variational autoencoder vae has widely been used to approximate inference and proved to have a good performance for directed probabilistic models. however for traditional vae the data label or feature information are intractable. similarly traditional <phrase>representation learning</phrase> approaches fail <phrase>to represent</phrase> many salient <phrase>aspects of</phrase> the data. in this project we propose <phrase>a novel</phrase> integrated framework <phrase>to learn</phrase> latent embedding in vae by incorporating deep metric learning. the features are learned by optimizing a triplet loss on the mean vectors of vae in conjunction with standard evidence lower bound elbo of vae. <phrase>this approach</phrase> which we call triplet based variational autoencoder tvae allows us <phrase>to capture</phrase> more <phrase>fine grained</phrase> information in the latent embedding. our model is <phrase>tested on</phrase> mnist <phrase>data set</phrase> and achieves a high triplet accuracy of 95.60 while the traditional vae kingma welling 2013 achieves triplet accuracy of 75.08 .
learning <phrase>to play</phrase> with intrinsically motivated self aware agents
infants are experts at playing with an amazing <phrase>ability to</phrase> generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. we <phrase>seek to</phrase> mathematically formalize these abilities using <phrase>a neural network</phrase> that implements curiosity driven intrinsic motivation. using <phrase>a simple</phrase> but ecologically naturalistic simulated environment in which <phrase>an agent</phrase> can move and interact with objects it sees we propose a world model network that learns <phrase>to predict</phrase> the dynamic consequences of the agent s actions. simultaneously we train a separate explicit self model that allows the agent to track the error map of its own world model and then uses the self model to adversarially challenge the developing world model. we demonstrate that this policy causes the agent to explore novel and informative interactions with its environment <phrase>leading to</phrase> <phrase>the generation of</phrase> a spectrum of complex behaviors including ego motion prediction object attention and object gathering. moreover the world model that the agent learns supports improved <phrase>performance on</phrase> object dynamics prediction detection localization and <phrase>recognition tasks</phrase>. taken together our results are initial steps toward creating flexible autonomous agents that self supervise in complex novel physical environments.
emergence of structured behaviors from curiosity based intrinsic motivation
infants are experts at playing with an amazing <phrase>ability to</phrase> generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. we <phrase>seek to</phrase> replicate some of these abilities with <phrase>a neural network</phrase> that implements curiosity driven intrinsic motivation. using <phrase>a simple</phrase> but ecologically naturalistic simulated environment in which the agent can move and interact with objects it sees the agent learns a world model predicting the dynamic consequences of its actions. simultaneously the agent learns to take actions that adversarially challenge the developing world model pushing the agent to explore novel and informative interactions with its environment. we demonstrate that this policy <phrase>leads to</phrase> the self supervised emergence of a spectrum of complex behaviors including ego motion prediction object attention and object gathering. moreover the world model that the agent learns supports improved <phrase>performance on</phrase> object dynamics prediction and localization tasks. our results are a proof of principle that computational models of intrinsic motivation might account for key features of developmental visuomotor learning in infants.
stochastic video generation with a learned prior
generating video frames that accurately predict future world states is challenging. <phrase>existing approaches</phrase> either fail <phrase>to capture</phrase> the full distribution of outcomes or yield blurry generations or both. in <phrase>this paper</phrase> we introduce an unsupervised video generation model that learns a prior model of uncertainty in a given environment. video frames are generated by drawing samples from this prior and combining them with a deterministic estimate of the future frame. the approach is simple and easily <phrase>trained end to end</phrase> on <phrase>a variety of</phrase> datasets. sample generations are both varied and sharp even many frames into the future and compare favorably to those from <phrase>existing approaches</phrase>.
multi evidence filtering and fusion <phrase>for multi label</phrase> classification <phrase>object detection</phrase> and <phrase>semantic segmentation</phrase> <phrase>based on</phrase> <phrase>weakly supervised</phrase> learning
supervised <phrase>object detection</phrase> and <phrase>semantic segmentation</phrase> require object or even pixel level annotations. when there exist image level labels only it is challenging for <phrase>weakly supervised</phrase> algorithms to achieve accurate predictions. the accuracy <phrase>achieved by</phrase> top <phrase>weakly supervised</phrase> algorithms is still significantly lower than their fully supervised counterparts. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> <phrase>weakly supervised</phrase> <phrase>curriculum learning</phrase> pipeline <phrase>for multi label</phrase> <phrase>object recognition</phrase> detection and <phrase>semantic segmentation</phrase>. in this pipeline we first obtain intermediate object localization and pixel labeling results for the training images and then use such results <phrase>to train</phrase> <phrase>task specific</phrase> <phrase>deep networks</phrase> in a fully supervised manner. the entire process <phrase>consists of</phrase> four stages including object localization in the training images filtering and fusing object instances pixel labeling for the training images and <phrase>task specific</phrase> <phrase>network training</phrase>. <phrase>to obtain</phrase> clean object instances in the training images we propose <phrase>a novel</phrase> algorithm for filtering fusing and classifying object instances collected from multiple solution mechanisms. in this algorithm we incorporate both metric learning and density based clustering to filter detected object instances. <phrase>experiments show</phrase> that our <phrase>weakly supervised</phrase> pipeline <phrase>achieves state of</phrase> <phrase>the art</phrase> results in <phrase>multi label</phrase> <phrase>image classification</phrase> <phrase>as well as</phrase> <phrase>weakly supervised</phrase> <phrase>object detection</phrase> and very <phrase>competitive results</phrase> in <phrase>weakly supervised</phrase> <phrase>semantic segmentation</phrase> on ms coco pascal voc 2007 and pascal voc 2012.
<phrase>neural networks</phrase> should be wide enough <phrase>to learn</phrase> disconnected decision regions
in the recent literature the important role of depth in <phrase>deep learning</phrase> has been emphasized. in <phrase>this paper</phrase> we argue that sufficient width of a feedforward network is equally important by answering the simple question under which conditions the decision regions of <phrase>a neural network</phrase> are connected. it turns out that for a class of <phrase>activation functions</phrase> including leaky relu <phrase>neural networks</phrase> having a pyramidal structure that is no layer has more hidden units than <phrase>the input</phrase> dimension produce necessarily connected decision regions. this implies that a sufficiently wide layer is necessary <phrase>to produce</phrase> disconnected decision regions. we discuss the implications of this result for the construction of <phrase>neural networks</phrase> <phrase>in particular</phrase> the relation to <phrase>the problem of</phrase> adversarial manipulation of classifiers.
visual explanations from deep 3d <phrase>convolutional neural networks</phrase> for alzheimer s disease classification
we develop three efficient approaches for generating visual explanations from 3d <phrase>convolutional neural networks</phrase> 3d cnns for alzheimer s disease classification. one approach conducts <phrase>sensitivity analysis</phrase> on hierarchical 3d <phrase>image segmentation</phrase> and the other two visualize network activations on a spatial map. visual checks and a quantitative localization benchmark indicate that all approaches identify important brain parts for alzheimer s disease diagnosis. comparative analysis show that the <phrase>sensitivity analysis</phrase> <phrase>based approach</phrase> has difficulty handling loosely distributed <phrase>cerebral cortex</phrase> and approaches <phrase>based on</phrase> visualization of activations are constrained by the resolution of the convolutional layer. the complementarity of these methods improves the understanding of 3d cnns in alzheimer s disease classification from different perspectives.
averaging weights <phrase>leads to</phrase> wider optima and better generalization
<phrase>deep neural networks</phrase> are typically trained by optimizing a <phrase>loss function</phrase> with an sgd variant in conjunction with a decaying <phrase>learning rate</phrase> until convergence. we show that simple averaging of multiple points along the trajectory of sgd with a cyclical or constant <phrase>learning rate</phrase> <phrase>leads to</phrase> better generalization than conventional training. we <phrase>also show</phrase> that this stochastic weight averaging swa procedure finds much broader optima than sgd and approximates the recent fast geometric ensembling fge approach with <phrase>a single</phrase> model. using swa we achieve notable improvement in test accuracy over conventional sgd training on <phrase>a range of</phrase> <phrase>state of</phrase> <phrase>the art</phrase> <phrase>residual networks</phrase> pyramidnets densenets and shake shake networks on <phrase>cifar 10</phrase> cifar 100 and imagenet. in short swa is extremely <phrase>easy to</phrase> implement improves generalization and has almost no computational overhead.
senns sparse extraction <phrase>neural networks</phrase> for <phrase>feature extraction</phrase>
by drawing on ideas from optimisation theory <phrase>artificial neural networks</phrase> ann graph embeddings and sparse representations i develop <phrase>a novel</phrase> technique termed senns sparse extraction <phrase>neural networks</phrase> aimed at addressing the <phrase>feature extraction</phrase> problem. <phrase>the proposed</phrase> method uses preferably deep anns for projecting input attribute vectors to an output space wherein pairwise distances are maximized for vectors belonging to different classes but minimized for those belonging to <phrase>the same</phrase> class while simultaneously enforcing sparsity on the ann outputs. the vectors that result from the projection can then be <phrase>used as</phrase> features in any classifier of choice. mathematically i formulate <phrase>the proposed</phrase> method as the minimisation of an <phrase>objective function</phrase> which can be interpreted in the ann output space as a negative factor of the sum of the squares of the pair wise distances between output vectors belonging to different classes added to a positive factor of the sum of squares of the pair wise distances between output vectors belonging to <phrase>the same</phrase> classes plus sparsity and weight decay terms. to derive an algorithm for minimizing the <phrase>objective function</phrase> via <phrase>gradient descent</phrase> i use the multi variate <phrase>version of</phrase> the <phrase>chain rule</phrase> <phrase>to obtain</phrase> the partial derivatives of the function <phrase>with respect to</phrase> ann weights and biases and find that each of the required partial derivatives can be expressed as a sum of six terms. as it turns out four of those six terms can be computed using the standard <phrase>back propagation</phrase> algorithm the fifth can be computed via a slight modification of the standard backpropagation algorithm while the sixth one can be computed via simple arithmetic. finally i propose <phrase>experiments on</phrase> the arabase arabic corpora of digits and letters the cmu pie database of faces the mnist digits database and other standard <phrase>machine learning</phrase> databases.
<phrase>generative models</phrase> and model criticism via optimized maximum mean discrepancy
we propose a method to optimize the representation and distinguishability of samples from two <phrase>probability distributions</phrase> by maximizing the estimated power of a statistical test <phrase>based on</phrase> the maximum mean discrepancy mmd . this optimized mmd is <phrase>applied to</phrase> the setting of <phrase>unsupervised learning</phrase> by <phrase>generative adversarial networks</phrase> gan in which a model attempts <phrase>to generate</phrase> realistic samples and a discriminator attempts to tell these apart from data samples. in this context the mmd may be used in two roles first as a discriminator either directly on the samples or on features of the samples. second the mmd can be used to evaluate <phrase>the performance of</phrase> a <phrase>generative model</phrase> by testing <phrase>the model</phrase> s samples against a reference <phrase>data set</phrase>. in <phrase>the latter</phrase> role the optimized mmd is particularly helpful as it gives an interpretable indication of how <phrase>the model</phrase> and data distributions differ even in cases where individual model samples are not easily distinguished either by eye or by classifier.
<phrase>deep learning</phrase> approximation for stochastic control problems
many <phrase>real world</phrase> stochastic control problems <phrase>suffer from</phrase> the curse of dimensionality . <phrase>to overcome</phrase> this difficulty we develop a <phrase>deep learning</phrase> approach that directly solves <phrase>high dimensional</phrase> stochastic control problems <phrase>based on</phrase> <phrase>monte carlo</phrase> sampling. we approximate the time dependent controls as feedforward <phrase>neural networks</phrase> and stack these networks together through model dynamics. the <phrase>objective function</phrase> for the control problem plays <phrase>the role of</phrase> the <phrase>loss function</phrase> for the <phrase>deep neural network</phrase>. we test <phrase>this approach</phrase> using examples from the areas of optimal trading and <phrase>energy storage</phrase>. our <phrase>results suggest</phrase> that the algorithm presented here achieves satisfactory accuracy and at <phrase>the same</phrase> time can handle rather <phrase>high dimensional</phrase> problems.
generating focussed molecule libraries for <phrase>drug discovery</phrase> with <phrase>recurrent neural networks</phrase>
in de novo <phrase>drug design</phrase> computational strategies are used <phrase>to generate</phrase> novel molecules with good affinity to the desired <phrase>biological target</phrase>. in <phrase>this work</phrase> we show that <phrase>recurrent neural networks</phrase> can be trained as <phrase>generative models</phrase> for molecular structures <phrase>similar to</phrase> statistical <phrase>language models</phrase> in <phrase>natural language</phrase> processing. we demonstrate that the <phrase>properties of</phrase> the generated molecules correlate very well with the <phrase>properties of</phrase> the molecules used <phrase>to train</phrase> <phrase>the model</phrase>. <phrase>in order to</phrase> enrich libraries with molecules active towards a given <phrase>biological target</phrase> we propose to fine tune <phrase>the model</phrase> with small sets of molecules which are known to be active against that target. against <phrase>staphylococcus aureus</phrase> <phrase>the model</phrase> reproduced 14 of 6051 hold out test molecules that medicinal chemists designed whereas against <phrase>plasmodium falciparum</phrase> malaria it reproduced 28 of 1240 test molecules. when coupled with a scoring function our model can perform the complete de novo <phrase>drug design</phrase> cycle <phrase>to generate</phrase> large sets of novel molecules for <phrase>drug discovery</phrase>.
parameter space noise for exploration
<phrase>deep reinforcement learning</phrase> rl methods generally engage in exploratory behavior through noise injection in the action space. <phrase>an alternative</phrase> is to add noise directly to the agent s parameters which can <phrase>lead to</phrase> more consistent exploration and a richer <phrase>set of</phrase> behaviors. methods <phrase>such as</phrase> evolutionary strategies use parameter perturbations but discard all temporal structure in the process and require significantly more samples. combining parameter noise with traditional rl methods allows to combine <phrase>the best</phrase> of both worlds. we demonstrate that both off and on policy methods benefit from <phrase>this approach</phrase> through experimental comparison of dqn ddpg and trpo on <phrase>high dimensional</phrase> discrete action environments <phrase>as well as</phrase> continuous control tasks. our <phrase>results show</phrase> that rl with parameter noise learns more efficiently than traditional rl with action space noise and evolutionary strategies individually.
on <phrase>the robustness of</phrase> <phrase>a neural network</phrase>
with the development of <phrase>neural networks</phrase> based <phrase>machine learning</phrase> and their usage in mission critical applications voices are rising against the textit <phrase>black box</phrase> aspect of <phrase>neural networks</phrase> as it becomes crucial <phrase>to understand</phrase> their limits and capabilities. with the rise of neuromorphic hardware it is even more critical <phrase>to understand</phrase> how <phrase>a neural network</phrase> as a distributed system tolerates the failures of its computing nodes neurons and its communication channels synapses. experimentally assessing <phrase>the robustness of</phrase> <phrase>neural networks</phrase> involves the quixotic venture of testing all the possible failures on all the possible inputs which ultimately hits a <phrase>combinatorial explosion</phrase> for the first and the impossibility to gather all the possible inputs for the second. in <phrase>this paper</phrase> we prove an upper bound on the expected error of the output when <phrase>a subset of</phrase> neurons crashes. this bound involves dependencies on <phrase>the network</phrase> parameters that can be seen as being too pessimistic in the average case. it involves a polynomial dependency on the lipschitz coefficient of the neurons <phrase>activation function</phrase> and an exponential dependency on the depth of the layer where a failure occurs. we back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between <phrase>the network</phrase> parameters and robustness. our <phrase>results show</phrase> that <phrase>the robustness of</phrase> <phrase>neural networks</phrase> to the average crash can be estimated without the <phrase>need to</phrase> neither test <phrase>the network</phrase> on all failure configurations nor access the <phrase>training set</phrase> used <phrase>to train</phrase> <phrase>the network</phrase> both of which are practically impossible requirements.
zhusuan a library for <phrase>bayesian deep learning</phrase>
in <phrase>this paper</phrase> we introduce zhusuan a python probabilistic programming library for <phrase>bayesian deep learning</phrase> which conjoins the complimentary advantages of bayesian methods and <phrase>deep learning</phrase>. zhusuan is built upon tensorflow. unlike existing <phrase>deep learning</phrase> libraries which are mainly designed for deterministic <phrase>neural networks</phrase> and supervised tasks zhusuan is featured for its deep root into <phrase>bayesian inference</phrase> thus supporting various kinds of probabilistic models including both the traditional hierarchical bayesian models and recent deep <phrase>generative models</phrase>. we use running examples to illustrate the probabilistic programming on zhusuan including bayesian <phrase>logistic regression</phrase> variational auto encoders deep sigmoid belief networks and bayesian <phrase>recurrent neural networks</phrase>.
using parameterized <phrase>black box</phrase> priors to scale up <phrase>model based</phrase> policy search for robotics
the most data efficient algorithms for <phrase>reinforcement learning</phrase> in robotics are <phrase>model based</phrase> policy search algorithms which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given <phrase>the model</phrase> and its uncertainties. among the few proposed approaches the recently introduced black drops algorithm exploits a <phrase>black box</phrase> optimization algorithm to achieve both high data efficiency and good computation times when several cores are used nevertheless like all <phrase>model based</phrase> policy search approaches black drops <phrase>does not</phrase> scale to <phrase>high dimensional</phrase> state action spaces. in <phrase>this paper</phrase> we introduce <phrase>a new</phrase> model learning procedure in black drops that leverages parameterized <phrase>black box</phrase> priors to 1 scale up to <phrase>high dimensional</phrase> systems and 2 be robust to large inaccuracies of the prior information. we demonstrate <phrase>the effectiveness of</phrase> our approach with the pendubot swing up task in simulation and with a physical hexapod robot 48d <phrase>state space</phrase> 18d action space that has to walk forward as fast as possible. the <phrase>results show</phrase> that our new algorithm is more data efficient than previous <phrase>model based</phrase> policy search algorithms with and without priors and that it can allow a physical 6 legged robot <phrase>to learn</phrase> new gaits in only 16 to 30 seconds of interaction time.
bayesian optimization with automatic prior selection for data efficient direct policy search
one of the most interesting features of bayesian optimization for direct policy search is that it can leverage priors e.g. from simulation or from previous tasks to accelerate learning on a robot. in <phrase>this paper</phrase> we are interested in situations for which several priors exist but we <phrase>do not</phrase> know in advance which one fits best the current situation. we tackle <phrase>this problem</phrase> <phrase>by introducing</phrase> <phrase>a novel</phrase> acquisition function called most likely expected improvement mlei that combines the likelihood of the priors and the expected improvement. we evaluate this new acquisition function on a <phrase>transfer learning</phrase> task for a 5 dof planar arm and on a possibly damaged 6 legged robot that has <phrase>to learn</phrase> to walk on flat ground and on stairs with priors corresponding to different stairs and different kinds of damages. our <phrase>results show</phrase> that mlei effectively identifies and exploits the priors even when there is no obvious match between the current situations and the priors.
bounding and counting linear regions of <phrase>deep neural networks</phrase>
in <phrase>this paper</phrase> we study the representational power of <phrase>deep neural networks</phrase> dnn that belong to the <phrase>family of</phrase> piecewise linear pwl functions <phrase>based on</phrase> pwl activation units <phrase>such as</phrase> rectifier or maxout. we investigate <phrase>the complexity of</phrase> such networks by studying <phrase>the number of</phrase> linear regions of the pwl function. typically a pwl function from a dnn can be seen as <phrase>a large</phrase> <phrase>family of</phrase> linear functions acting on millions of such regions. we directly build upon the work of montufar <phrase>et al</phrase>. 2014 montufar 2017 and raghu <phrase>et al</phrase>. 2017 by refining the upper and lower bounds on <phrase>the number of</phrase> linear regions for rectified and maxout networks. <phrase>in addition</phrase> to achieving tighter bounds we also develop <phrase>a novel</phrase> method <phrase>to perform</phrase> exact enumeration or counting of <phrase>the number of</phrase> linear regions with a mixed integer linear formulation that maps <phrase>the input</phrase> space to output. we use this new capability to visualize how <phrase>the number of</phrase> linear regions change while training dnns.
deep rewiring training very sparse <phrase>deep networks</phrase>
neuromorphic hardware tends to pose limits on the connectivity of <phrase>deep networks</phrase> that one can run on them. <phrase>but also</phrase> generic hardware and software implementations of <phrase>deep learning</phrase> run more efficiently for sparse networks. several methods exist for pruning connections of <phrase>a neural network</phrase> after it was trained without connectivity constraints. we present an algorithm deep r that enables us <phrase>to train</phrase> directly a sparsely connected <phrase>neural network</phrase>. deep r automatically rewires <phrase>the network</phrase> during supervised training so that connections are there where they are most needed for the task while its total number is all the time strictly bounded. we demonstrate that deep r can be used <phrase>to train</phrase> very sparse feedforward and <phrase>recurrent neural networks</phrase> on standard benchmark tasks with just a minor loss in performance. deep r is <phrase>based on</phrase> a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.
comparing heterogeneous entities using <phrase>artificial neural networks</phrase> of trainable weighted structural components and machine learned <phrase>activation functions</phrase>
to compare entities of differing types and structural components the <phrase>artificial neural network</phrase> paradigm was used to cross compare structural components between heterogeneous documents. trainable weighted structural components were input into machine learned <phrase>activation functions</phrase> of the neurons. <phrase>the model</phrase> was used for matching news articles and videos where the inputs and <phrase>activation functions</phrase> respectively consisted of term vectors and cosine similarity measures between the weighted structural components. <phrase>the model</phrase> was tested with different weights achieving as high as 59.2 accuracy for matching videos to news articles. a mobile application <phrase>user interface</phrase> for recommending related videos for news articles was developed to demonstrate consumer value including its potential usefulness for cross selling products from unrelated categories.
<phrase>active learning</phrase> of inverse models with intrinsically motivated goal exploration in robots
we introduce the self adaptive goal generation robust intelligent adaptive curiosity sagg riac architecture as an intrinsi cally motivated goal exploration mechanism which allows <phrase>active learning</phrase> of inverse models in <phrase>high dimensional</phrase> redundant robots. this allows a robot to efficiently and actively learn distributions of parameterized motor skills policies that solve a corresponding distribution of parameterized tasks goals. the architecture makes the robot sample actively novel parameterized tasks in the task space <phrase>based on</phrase> a measure of competence progress each of which triggers low level goal directed learning of the motor policy pa rameters that allow <phrase>to solve</phrase> it. for both learning and generalization the system leverages regression techniques which allow to infer the motor policy parameters corresponding to a given novel parameterized task and <phrase>based on</phrase> the previously learnt correspondences between policy and task parameters. we present experiments with <phrase>high dimensional</phrase> continuous sensorimotor spaces in <phrase>three different</phrase> robotic setups 1 learning the <phrase>inverse kinematics</phrase> in a highly redundant <phrase>robotic arm</phrase> 2 learning omnidirectional locomotion with motor primitives in a quadruped robot 3 an arm learning to control a <phrase>fishing rod</phrase> with a flexible wire. we show that 1 exploration in the task space can be a lot <phrase>faster than</phrase> exploration in the actuator space for learning inverse models in redundant robots 2 selecting goals maximizing competence progress creates developmental trajectories driving the robot to progressively <phrase>focus on</phrase> tasks of increasing complexity and is statistically significantly <phrase>more efficient</phrase> than selecting tasks randomly <phrase>as well as</phrase> <phrase>more efficient</phrase> than different standard active motor babbling methods 3 this architecture allows the robot to actively discover which <phrase>parts of</phrase> its task space it can learn to reach and which part it cannot.
<phrase>end to end</phrase> tracking and <phrase>semantic segmentation</phrase> using <phrase>recurrent neural networks</phrase>
in <phrase>this work</phrase> we present <phrase>a novel</phrase> <phrase>end to end</phrase> <phrase>framework for</phrase> tracking and classifying a robot s surroundings in complex dynamic and only <phrase>partially observable</phrase> <phrase>real world</phrase> environments. the approach deploys <phrase>a recurrent neural network</phrase> to filter an input stream of raw laser measurements <phrase>in order to</phrase> directly infer object locations <phrase>along with</phrase> their identity in both visible and occluded areas. to achieve this we first train <phrase>the network</phrase> using unsupervised deep tracking a <phrase>recently proposed</phrase> theoretical <phrase>framework for</phrase> <phrase>end to end</phrase> space occupancy prediction. we show that by learning to track on <phrase>a large</phrase> <phrase>amount of</phrase> unsupervised data <phrase>the network</phrase> creates a rich internal representation of its environment which we in turn exploit through the principle of inductive transfer of knowledge <phrase>to perform</phrase> <phrase>the task of</phrase> it s semantic classification. as a result we show that only <phrase>a small</phrase> <phrase>amount of</phrase> labelled data suffices to steer <phrase>the network</phrase> towards mastering this additional task. furthermore we propose <phrase>a novel</phrase> <phrase>recurrent neural network</phrase> architecture specifically tailored to tracking and semantic classification in <phrase>real world</phrase> robotics applications. we demonstrate the tracking and <phrase>classification performance</phrase> of the method on <phrase>real world</phrase> data collected at a busy road junction. our evaluation shows that <phrase>the proposed</phrase> <phrase>end to end</phrase> framework compares favourably to a <phrase>state of</phrase> <phrase>the art</phrase> model free tracking solution and that it outperforms a conventional one shot training scheme for semantic classification.
deep tracking seeing beyond seeing using <phrase>recurrent neural networks</phrase>
<phrase>this paper</phrase> presents to <phrase>the best</phrase> of our knowledge the first <phrase>end to end</phrase> object tracking approach which directly maps <phrase>from raw</phrase> sensor input to object tracks in sensor space <phrase>without requiring</phrase> any feature engineering or system identification in the form of plant or sensor models. specifically our system accepts a stream of raw sensor data at one end and in <phrase>real time</phrase> produces an estimate of the entire environment state at the output including even occluded objects. we achieve this by framing the problem as a <phrase>deep learning</phrase> task and exploit sequence models in the form of <phrase>recurrent neural networks</phrase> <phrase>to learn</phrase> a mapping from sensor measurements to object tracks. <phrase>in particular</phrase> we propose a learning method <phrase>based on</phrase> a form of input dropout which allows learning in an unsupervised manner only <phrase>based on</phrase> raw occluded sensor data without access to ground truth annotations. we demonstrate our approach using a synthetic dataset designed to mimic <phrase>the task of</phrase> tracking objects in 2d laser data as commonly encountered in robotics applications and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.
deep predictive coding networks for video prediction and <phrase>unsupervised learning</phrase>
while great strides have been made in using <phrase>deep learning</phrase> algorithms <phrase>to solve</phrase> <phrase>supervised learning</phrase> tasks <phrase>the problem of</phrase> <phrase>unsupervised learning</phrase> leveraging unlabeled examples <phrase>to learn</phrase> about the structure of a domain remains a difficult unsolved challenge. here we explore prediction of future frames in a video sequence as an <phrase>unsupervised learning</phrase> rule for learning about the structure of the visual world. we describe a predictive <phrase>neural network</phrase> prednet architecture that is <phrase>inspired by</phrase> the concept of predictive coding from the neuroscience literature. these networks learn <phrase>to predict</phrase> future frames in a video sequence with <phrase>each layer</phrase> in <phrase>the network</phrase> making local predictions and only forwarding deviations from those predictions to subsequent network layers. we show that these networks are <phrase>able to</phrase> robustly learn <phrase>to predict</phrase> the movement of synthetic rendered objects and that in doing so the networks learn internal representations that are useful for decoding latent object parameters e.g. pose that support <phrase>object recognition</phrase> with fewer training views. we <phrase>also show</phrase> that these networks can scale to complex natural image streams car mounted camera videos capturing key <phrase>aspects of</phrase> both egocentric movement and the movement of objects in the visual scene and the representation learned in this setting is useful for estimating the steering angle. altogether these <phrase>results suggest</phrase> that prediction represents a powerful <phrase>framework for</phrase> <phrase>unsupervised learning</phrase> allowing for implicit learning of object and scene structure.
vote3deep fast <phrase>object detection</phrase> in 3d point clouds using efficient <phrase>convolutional neural networks</phrase>
<phrase>this paper</phrase> proposes a computationally efficient <phrase>approach to</phrase> detecting objects natively in 3d point clouds using <phrase>convolutional neural networks</phrase> cnns . <phrase>in particular</phrase> this is <phrase>achieved by</phrase> leveraging a feature centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in <phrase>the input</phrase>. to this end we examine the trade off between accuracy and speed for different architectures and additionally propose to use an l1 penalty on the filter activations to further encourage sparsity in the intermediate representations. to <phrase>the best</phrase> of our knowledge this is the first work to propose sparse convolutional layers and l1 regularisation for efficient <phrase>large scale</phrase> processing of 3d data. we demonstrate <phrase>the efficacy of</phrase> our approach on the kitti <phrase>object detection</phrase> benchmark and show that vote3deep models with as few as three layers outperform the <phrase>previous state of</phrase> <phrase>the art</phrase> in both laser and laser vision <phrase>based approaches</phrase> by margins of up to 40 while remaining highly competitive <phrase>in terms of</phrase> processing time.
on convergence and stability of gans
we propose studying gan training dynamics as regret minimization which is <phrase>in contrast to</phrase> the popular view that there is consistent minimization of a divergence between real and generated distributions. we analyze the convergence of gan training from this new point of view <phrase>to understand</phrase> why mode collapse happens. we hypothesize <phrase>the existence of</phrase> undesirable local equilibria in this <phrase>non convex</phrase> game to be responsible for mode collapse. we observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. we demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called dragan. we show that dragan enables faster training achieves improved stability with fewer mode collapses and <phrase>leads to</phrase> generator networks with better modeling performance across <phrase>a variety of</phrase> architectures and objective functions.
imitation from observation learning to imitate behaviors <phrase>from raw</phrase> video via context translation
imitation learning is <phrase>an effective</phrase> approach for autonomous systems to acquire control policies when an explicit reward function is unavailable using supervision provided as demonstrations from an expert typically a human operator. however standard imitation <phrase>learning methods</phrase> assume that the agent receives examples of observation action tuples that could be provided for instance to a <phrase>supervised learning</phrase> algorithm. this stands <phrase>in contrast to</phrase> how humans and animals imitate we observe another person performing some behavior and then figure out which actions will realize that behavior compensating for changes in viewpoint surroundings and embodiment. we term this <phrase>kind of</phrase> imitation learning as imitation from observation and propose an imitation learning method <phrase>based on</phrase> video prediction with context translation and <phrase>deep reinforcement learning</phrase>. this lifts the assumption in imitation learning that the demonstration should consist of observations and actions in <phrase>the same</phrase> environment and enables <phrase>a variety of</phrase> interesting applications including learning robotic skills that involve tool use simply by observing videos of human tool use. our <phrase>experimental results</phrase> show that our approach can perform imitation from observation for <phrase>a variety of</phrase> <phrase>real world</phrase> robotic tasks modeled on common household chores acquiring skills <phrase>such as</phrase> sweeping from videos of a human demonstrator. videos can be found at https sites.google.com site imitationfromobservation
convergence rates for pretraining and dropout guiding learning parameters using <phrase>network structure</phrase>
unsupervised pretraining and dropout have been well studied especially <phrase>with respect to</phrase> regularization and output consistency. however our understanding about the explicit convergence rates of the parameter estimates and their dependence on the learning like denoising and dropout rate and structural like depth and layer lengths <phrase>aspects of</phrase> <phrase>the network</phrase> is less mature. an interesting question in this context is to ask if <phrase>the network</phrase> structure could guide the choices of such learning parameters. in <phrase>this work</phrase> we explore these gaps between <phrase>network structure</phrase> the learning mechanisms and their interaction with parameter convergence rates. we present a way <phrase>to address</phrase> these issues <phrase>based on</phrase> the backpropagation convergence rates for general nonconvex objectives using first order information. we then incorporate two learning mechanisms into this general framework denoising autoencoder and dropout and subsequently derive the convergence rates of <phrase>deep networks</phrase>. building upon these bounds we provide insights into the choices of learning parameters and network sizes that achieve certain levels of convergence accuracy. the results derived here support existing empirical observations and we also conduct <phrase>a set of</phrase> experiments to evaluate them.
learning discriminative features via label consistent <phrase>neural network</phrase>
<phrase>deep convolutional neural networks</phrase> cnn enforces supervised information only at <phrase>the output layer</phrase> and <phrase>hidden layers</phrase> are trained by back propagating the prediction error from <phrase>the output layer</phrase> without explicit supervision. we propose a supervised <phrase>feature learning</phrase> approach label consistent <phrase>neural network</phrase> which enforces direct supervision in late <phrase>hidden layers</phrase>. we associate each neuron in a <phrase>hidden layer</phrase> with a particular class label and encourage it to be activated for input signals from <phrase>the same</phrase> class. more specifically we introduce a label consistency regularization called discriminative representation error loss for late <phrase>hidden layers</phrase> and combine it with classification error loss to build our overall <phrase>objective function</phrase>. this label consistency constraint alleviates the common problem of gradient vanishing and tends to faster convergence it also makes the features <phrase>derived from</phrase> late <phrase>hidden layers</phrase> discriminative enough for classification even using <phrase>a simple</phrase> k nn classifier since input signals from <phrase>the same</phrase> class will have very similar representations. <phrase>experimental results</phrase> demonstrate that our approach <phrase>achieves state of</phrase> <phrase>the art</phrase> performances on several public benchmarks for action and object category recognition.
out of sample extension for <phrase>dimensionality reduction</phrase> of noisy <phrase>time series</phrase>
<phrase>this paper</phrase> proposes an out of sample extension <phrase>framework for</phrase> a global manifold <phrase>learning algorithm</phrase> isomap that uses temporal information in out of sample points <phrase>in order to</phrase> make the embedding <phrase>more robust</phrase> to noise and artifacts. given <phrase>a set of</phrase> noise free <phrase>training data</phrase> and its embedding <phrase>the proposed</phrase> framework extends the embedding for a noisy <phrase>time series</phrase>. this is <phrase>achieved by</phrase> adding a spatio temporal compactness term to the optimization objective of the embedding. to <phrase>the best</phrase> of our knowledge this is the first <phrase>method for</phrase> out of sample extension of manifold embeddings that leverages timing information available for the extension set. <phrase>experimental results</phrase> demonstrate that our out of sample extension algorithm renders a <phrase>more robust</phrase> and accurate embedding of sequentially ordered image data in the presence of various noise and artifacts when <phrase>compared to</phrase> other timing aware embeddings. additionally we show that an out of sample extension framework <phrase>based on</phrase> <phrase>the proposed</phrase> algorithm outperforms the <phrase>state of</phrase> <phrase>the art</phrase> in eye gaze estimation.
<phrase>adversarial examples</phrase> for semantic <phrase>image segmentation</phrase>
<phrase>machine learning</phrase> methods in general and <phrase>deep neural networks</phrase> <phrase>in particular</phrase> have <phrase>shown to</phrase> be vulnerable to <phrase>adversarial perturbations</phrase>. <phrase>so far</phrase> this phenomenon has mainly been studied in <phrase>the context of</phrase> whole <phrase>image classification</phrase>. in this contribution we analyse how <phrase>adversarial perturbations</phrase> can affect <phrase>the task of</phrase> <phrase>semantic segmentation</phrase>. we show how existing adversarial attackers can be transferred to <phrase>this task</phrase> and that it is possible to create imperceptible <phrase>adversarial perturbations</phrase> that lead a <phrase>deep network</phrase> to misclassify almost all pixels of a chosen class while leaving network prediction nearly unchanged outside this class.
decision based adversarial attacks reliable attacks against <phrase>black box</phrase> <phrase>machine learning</phrase> models
many <phrase>machine learning</phrase> algorithms are vulnerable to almost imperceptible perturbations of their inputs. <phrase>so far</phrase> it was unclear how much risk <phrase>adversarial perturbations</phrase> carry for the safety of <phrase>real world</phrase> <phrase>machine learning</phrase> applications because most methods used <phrase>to generate</phrase> such perturbations rely either on detailed model information <phrase>gradient based</phrase> attacks or on confidence scores <phrase>such as</phrase> class probabilities score based attacks neither of which are available in most <phrase>real world</phrase> scenarios. in many such cases one currently <phrase>needs to</phrase> retreat to transfer based attacks which <phrase>rely on</phrase> cumbersome substitute models need access to <phrase>the training data</phrase> and can be defended against. here we emphasise the importance of attacks which solely <phrase>rely on</phrase> <phrase>the final</phrase> model decision. such decision based attacks are 1 <phrase>applicable to</phrase> <phrase>real world</phrase> <phrase>black box</phrase> models <phrase>such as</phrase> autonomous <phrase>cars 2</phrase> need less knowledge and are easier to apply than transfer based attacks and 3 are <phrase>more robust</phrase> to simple defences than gradient or score based attacks. previous attacks in this category were limited to simple models or simple datasets. here we introduce the boundary attack a decision based attack that starts from <phrase>a large</phrase> adversarial perturbation and then seeks <phrase>to reduce</phrase> the perturbation while staying adversarial. the attack is conceptually simple requires <phrase>close to</phrase> no hyperparameter tuning <phrase>does not</phrase> <phrase>rely on</phrase> substitute models and is competitive with <phrase>the best</phrase> <phrase>gradient based</phrase> attacks in standard <phrase>computer vision</phrase> tasks like imagenet. we apply the attack on two <phrase>black box</phrase> algorithms from clarifai.com. the boundary attack <phrase>in particular</phrase> and the class of decision based attacks in general open new avenues to study <phrase>the robustness of</phrase> <phrase>machine learning</phrase> models and raise new questions regarding the safety of deployed <phrase>machine learning</phrase> systems. an implementation of the attack is available as part of foolbox at https github.com bethgelab foolbox .
towards building an intelligent anti malware system a <phrase>deep learning</phrase> approach using <phrase>support vector machine</phrase> svm for malware classification
effective and efficient mitigation of malware is a long time endeavor in the <phrase>information security</phrase> community. the development of an anti malware system that can counteract an unknown malware is a prolific activity that may benefit several sectors. we envision an intelligent anti malware system that utilizes the power of <phrase>deep learning</phrase> dl models. using such models would enable the detection of newly released malware through mathematical generalization. that is finding the relationship between a given malware x and its corresponding malware family y f x mapsto y . to accomplish this feat we used the malimg dataset nataraj <phrase>et al</phrase>. 2011 which <phrase>consists of</phrase> malware images that were processed from malware binaries and then we trained the following dl <phrase>models 1</phrase> to classify each malware family cnn svm tang 2013 gru svm agarap 2017 and mlp svm. <phrase>empirical evidence</phrase> has shown that the gru svm stands out among the dl models with a predictive accuracy of 84.92 . this stands to reason for the mentioned model had the relatively most sophisticated architecture design among the presented models. the exploration of an even more optimal dl svm model is the next stage towards the engineering of an intelligent anti malware system.
<phrase>feature extraction</phrase> using <phrase>latent dirichlet allocation</phrase> and <phrase>neural networks</phrase> a case study on movie synopses
<phrase>feature extraction</phrase> has gained increasing attention in <phrase>the field of</phrase> <phrase>machine learning</phrase> as <phrase>in order to</phrase> detect patterns extract information or predict future observations from <phrase>big data</phrase> the urge of informative features is crucial. the process of extracting features is highly linked to <phrase>dimensionality reduction</phrase> as it implies the transformation of the data from a sparse <phrase>high dimensional</phrase> space to <phrase>higher level</phrase> meaningful abstractions. this dissertation employs <phrase>neural networks</phrase> for distributed paragraph representations and <phrase>latent dirichlet allocation</phrase> <phrase>to capture</phrase> <phrase>higher level</phrase> features of paragraph vectors. although <phrase>neural networks</phrase> for distributed paragraph representations are considered the <phrase>state of</phrase> <phrase>the art</phrase> for extracting paragraph vectors we show that a quick topic analysis model <phrase>such as</phrase> <phrase>latent dirichlet allocation</phrase> can provide meaningful features too. we evaluate the two methods on the cmu movie summary corpus a collection of 25 203 movie plot summaries <phrase>extracted from</phrase> wikipedia. finally for both approaches we use k nearest neighbors <phrase>to discover</phrase> similar movies and plot the projected representations using t distributed stochastic neighbor embedding to depict the context similarities. these similarities expressed as movie distances can be used for movies recommendation. the recommended movies of <phrase>this approach</phrase> are <phrase>compared with</phrase> the recommended movies from imdb which use a <phrase>collaborative filtering</phrase> recommendation <phrase>approach to</phrase> show that our two models could constitute either <phrase>an alternative</phrase> or a supplementary recommendation approach.
a survey of available corpora for building <phrase>data driven</phrase> <phrase>dialogue systems</phrase>
during <phrase>the past</phrase> decade several areas of speech and <phrase>language understanding</phrase> have witnessed substantial breakthroughs from <phrase>the use of</phrase> <phrase>data driven</phrase> models. in the area of <phrase>dialogue systems</phrase> the trend is less obvious and most practical systems are still built through significant engineering and expert knowledge. nevertheless several recent <phrase>results suggest</phrase> that <phrase>data driven</phrase> approaches are feasible and quite promising. to facilitate research in this area we have carried out a wide survey of <phrase>publicly available</phrase> datasets <phrase>suitable for</phrase> <phrase>data driven</phrase> learning of <phrase>dialogue systems</phrase>. we discuss important characteristics of these datasets how they can be used <phrase>to learn</phrase> diverse dialogue strategies and their other potential uses. we also examine methods for <phrase>transfer learning</phrase> between datasets and <phrase>the use of</phrase> external knowledge. finally we discuss appropriate <phrase>choice of</phrase> <phrase>evaluation metrics</phrase> for the learning objective.
generative topic embedding a continuous representation of documents extended version with proofs 
<phrase>word embedding</phrase> maps words into a <phrase>low dimensional</phrase> continuous embedding space by exploiting the local word collocation patterns in <phrase>a small</phrase> context window. on the other hand topic modeling maps documents onto a <phrase>low dimensional</phrase> topic space by utilizing the global word collocation patterns in <phrase>the same</phrase> document. these two <phrase>types of</phrase> patterns are complementary. in <phrase>this paper</phrase> we propose a generative topic embedding model to combine the two <phrase>types of</phrase> patterns. in our model topics are represented by embedding vectors and are shared across documents. the probability of each word is influenced by both its local context and its topic. a <phrase>variational inference</phrase> method yields the topic embeddings <phrase>as well as</phrase> the topic mixing proportions for each document. jointly they represent the document in a <phrase>low dimensional</phrase> continuous space. in two <phrase>document classification</phrase> tasks our method performs <phrase>better than</phrase> eight <phrase>existing methods</phrase> with fewer features. <phrase>in addition</phrase> we illustrate with an example that our method can generate coherent topics even <phrase>based on</phrase> only one document.
<phrase>fine grained</phrase> entity typing with high multiplicity assignments
as entity type systems become richer and more <phrase>fine grained</phrase> we expect <phrase>the number of</phrase> types assigned to a given entity to increase. however most <phrase>fine grained</phrase> typing work has <phrase>focused on</phrase> datasets that exhibit a low degree of type multiplicity. in <phrase>this paper</phrase> we consider the high multiplicity regime inherent in data sources <phrase>such as</phrase> wikipedia that have semi open type systems. we introduce a set prediction <phrase>approach to</phrase> <phrase>this problem</phrase> and show that our <phrase>model outperforms</phrase> unstructured baselines on <phrase>a new</phrase> wikipedia based <phrase>fine grained</phrase> typing corpus.
towards a visual turing challenge
as language and visual understanding by machines progresses rapidly we are observing an increasing interest in holistic architectures that tightly interlink both modalities in a joint learning and inference process. this trend has allowed the community to progress towards more challenging and open tasks and refueled the hope at achieving the old ai dream of building machines that could pass a <phrase>turing test</phrase> in open domains. <phrase>in order to</phrase> steadily make progress towards this goal we realize that quantifying performance becomes increasingly difficult. therefore we ask how we can precisely define such challenges and how we can evaluate different algorithms on this open tasks in <phrase>this paper</phrase> we summarize and discuss such challenges <phrase>as well as</phrase> try to give answers where appropriate options are available in the literature. we exemplify some of the solutions on a recently presented dataset of <phrase>question answering</phrase> task <phrase>based on</phrase> <phrase>real world</phrase> indoor images that establishes a visual turing challenge. finally we argue despite the success of unique ground truth annotation we likely have to step away from carefully curated dataset and rather <phrase>rely on</phrase> social consensus as the main driving force to create suitable benchmarks. providing coverage in this inherently ambiguous output space is an emerging challenge that we face <phrase>in order to</phrase> make quantifiable progress in this area.
interactive robot learning of gestures language and affordances
a growing field in robotics and <phrase>artificial intelligence</phrase> ai research is human robot collaboration whose target is to enable effective teamwork between humans and robots. however in many situations human teams are still superior to human robot teams primarily because human teams can easily agree on a common goal with language and the individual members observe each other effectively leveraging their shared motor repertoire and sensorimotor resources. <phrase>this paper</phrase> shows that for cognitive robots it is possible and indeed fruitful to combine knowledge acquired from interacting with elements of the environment affordance exploration with the probabilistic observation of another agent s actions. we propose a model that unites i learning robot affordances and word descriptions with ii statistical recognition of human gestures with vision sensors. we discuss theoretical motivations possible implementations and we show initial results which highlight that after having acquired knowledge of its surrounding environment a <phrase>humanoid robot</phrase> can generalize this knowledge to the case when it observes another agent human partner performing <phrase>the same</phrase> motor actions previously executed <phrase>during training</phrase>.
visual features for context aware <phrase>speech recognition</phrase>
automatic transcriptions of consumer generated multi media content <phrase>such as</phrase> youtube videos still exhibit high word <phrase>error rates</phrase>. such data typically occupies a very broad domain has been recorded in challenging conditions with cheap hardware and a <phrase>focus on</phrase> the visual modality and may have been post processed or edited. in <phrase>this paper</phrase> we extend our earlier work on adapting the acoustic model of a dnn based <phrase>speech recognition</phrase> system to an rnn <phrase>language model</phrase> and show how both can be adapted to the objects and scenes that can be automatically detected in the video. we are working on a corpus of how to videos from the web and the idea is that an object that can be seen car or a scene that is being detected kitchen can be used to condition both models on <phrase>the context of</phrase> the recording thereby reducing perplexity and improving transcription. we achieve good improvements in both cases and compare and analyze the respective reductions in <phrase>word error rate</phrase>. we expect that our results can be used for any <phrase>type of</phrase> <phrase>speech processing</phrase> in which context information is available for example in robotics man machine interaction or when indexing large audio visual archives and should ultimately help to bring together the video to text and speech to text communities.
examining cooperation in <phrase>visual dialog</phrase> models
in <phrase>this work</phrase> we propose a blackbox intervention <phrase>method for</phrase> <phrase>visual dialog</phrase> models with the aim of assessing the contribution of individual linguistic or visual components. concretely we conduct structured or randomized interventions that aim to impair an individual component of <phrase>the model</phrase> and observe changes in task performance. we reproduce a <phrase>state of</phrase> <phrase>the art</phrase> <phrase>visual dialog</phrase> model and demonstrate that our methodology yields surprising insights namely that both dialog and image information have minimal contributions to task performance. the intervention method presented here can be applied as a sanity check for the strength and robustness of each component in <phrase>visual dialog</phrase> systems.
video highlight prediction using audience chat reactions
sports channel video portals offer an exciting domain for research on multimodal multilingual analysis. we present methods addressing <phrase>the problem of</phrase> automatic video highlight prediction <phrase>based on</phrase> joint visual features and textual analysis of the <phrase>real world</phrase> audience discourse with complex slang in both english and <phrase>traditional chinese</phrase>. we present <phrase>a novel</phrase> dataset <phrase>based on</phrase> league of legends championships recorded from <phrase>north american</phrase> and taiwanese twitch.tv channels will be released for further research and demonstrate strong <phrase>results on</phrase> these using multimodal <phrase>character level</phrase> cnn rnn model architectures.
invariant representations for noisy <phrase>speech recognition</phrase>
modern <phrase>automatic speech recognition</phrase> asr systems <phrase>need to</phrase> be robust under acoustic variability arising from environmental speaker channel and recording conditions. ensuring such robustness to variability is a challenge in modern day <phrase>neural network</phrase> based asr systems especially when all <phrase>types of</phrase> variability are not seen <phrase>during training</phrase>. we <phrase>attempt to</phrase> address <phrase>this problem</phrase> by encouraging the <phrase>neural network</phrase> acoustic model <phrase>to learn</phrase> invariant <phrase>feature representations</phrase>. we use ideas from recent research on image generation using <phrase>generative adversarial networks</phrase> and <phrase>domain adaptation</phrase> ideas extending adversarial <phrase>gradient based</phrase> training. a <phrase>recent work</phrase> from ganin <phrase>et al</phrase>. proposes to use adversarial training for image <phrase>domain adaptation</phrase> <phrase>by using</phrase> an intermediate representation from the main target classification network to deteriorate the domain classifier performance through a separate <phrase>neural network</phrase>. our work <phrase>focuses on</phrase> investigating <phrase>neural architectures</phrase> which produce representations invariant to noise conditions for asr. we evaluate <phrase>the proposed</phrase> architecture on the aurora 4 task a popular benchmark for noise robust asr. we show that our method generalizes <phrase>better than</phrase> the standard multi condition training especially when only a few noise categories are seen <phrase>during training</phrase>.
self supervised vision based detection of the active speaker as a prerequisite for socially aware <phrase>language acquisition</phrase>
<phrase>this paper</phrase> presents a self supervised <phrase>method for</phrase> detecting the active speaker in a multi person spoken interaction scenario. we argue that this capability is a fundamental prerequisite for any artificial cognitive system attempting to acquire language in social settings. our methods are <phrase>able to</phrase> detect an arbitrary <phrase>number of</phrase> possibly overlapping active speakers based exclusively on visual <phrase>information about</phrase> their face. our methods <phrase>do not</phrase> <phrase>rely on</phrase> external annotations thus complying with <phrase>cognitive development</phrase>. instead they use information from the auditory modality to support learning in the visual domain. the methods have been extensively evaluated on <phrase>a large</phrase> multi person face to face interaction dataset. the results reach an accuracy of 80 on a multi speaker setting. we believe this system represents an essential component of any artificial cognitive system or robotic platform engaging in social interaction.
product characterisation towards personalisation learning attributes from <phrase>unstructured data</phrase> to recommend fashion products
in <phrase>this paper</phrase> we describe a solution <phrase>to tackle</phrase> a common <phrase>set of</phrase> challenges in <phrase>e commerce</phrase> which arise from the fact that new products are continually being added to the catalogue. the challenges involve properly personalising the <phrase>customer experience</phrase> forecasting demand and planning the product range. we argue that the foundational piece <phrase>to solve</phrase> all of these problems is having consistent and detailed <phrase>information about</phrase> each product information that is rarely available or consistent given the multitude of suppliers and <phrase>types of</phrase> products. we describe in detail the architecture and methodology implemented at asos one of the world s largest fashion <phrase>e commerce</phrase> retailers <phrase>to tackle</phrase> <phrase>this problem</phrase>. we then show how this quantitative understanding of the products can be leveraged <phrase>to improve</phrase> recommendations in a hybrid recommender system approach.
the <phrase>self organization</phrase> of speech sounds
the speech code is a vehicle of language it defines <phrase>a set of</phrase> forms used by a community to carry information. such a code is necessary to support the linguistic interactions that allow humans to communicate. how then may a speech code be formed prior to <phrase>the existence of</phrase> linguistic interactions moreover the human speech code is discrete and compositional shared by all the individuals of a community but different across communities and phoneme inventories are characterized by statistical regularities. how can a speech code with these properties form we try to approach these questions in the paper using the methodology of the artificial . we build a society of artificial agents and detail a mechanism that shows the formation of a discrete speech code without pre supposing <phrase>the existence of</phrase> linguistic capacities or of coordinated interactions. the mechanism is <phrase>based on</phrase> a low level model of sensory motor interactions. we show that the integration of certain very simple and non language specific neural devices <phrase>leads to</phrase> the formation of a speech code that has properties <phrase>similar to</phrase> the human speech code. this result relies on the self organizing <phrase>properties of</phrase> a generic coupling between perception and production within agents and on the interactions between agents. the artificial system helps us to develop better intuitions on how speech might have appeared by showing how <phrase>self organization</phrase> might have helped <phrase>natural selection</phrase> to find speech.
what the f measure doesn t measure features flaws fallacies and fixes
the f measure or f score is one of the most commonly used single number measures in <phrase>information retrieval</phrase> <phrase>natural language</phrase> processing and <phrase>machine learning</phrase> but it is <phrase>based on</phrase> a mistake and the flawed assumptions render it unsuitable for use in most contexts fortunately there are better alternatives.
a <phrase>machine learning</phrase> perspective on predictive coding with paq
paq8 is an <phrase>open source</phrase> lossless <phrase>data compression</phrase> algorithm that currently achieves <phrase>the best</phrase> compression rates on many benchmarks. this report presents a detailed description of paq8 from a statistical <phrase>machine learning</phrase> perspective. it shows that it is possible <phrase>to understand</phrase> some of the modules of paq8 and use this understanding <phrase>to improve</phrase> the method. however intuitive statistical explanations of the behavior of other modules remain elusive. we hope the description in this report will be a starting point for discussions that will increase our understanding <phrase>lead to</phrase> improvements to paq8 and facilitate a transfer of knowledge from paq8 to other <phrase>machine learning</phrase> methods such <phrase>a recurrent neural</phrase> networks and stochastic memoizers. finally the report presents a broad range of new applications of paq to <phrase>machine learning</phrase> tasks including <phrase>language modeling</phrase> and adaptive text prediction adaptive game playing classification and compression using features from <phrase>the field of</phrase> <phrase>deep learning</phrase>.
<phrase>a novel</phrase> frank wolfe algorithm. analysis and applications to <phrase>large scale</phrase> svm training
recently there has been a renewed interest in the <phrase>machine learning</phrase> community for variants of a sparse greedy approximation procedure for concave optimization <phrase>known as</phrase> the frank wolfe fw method . <phrase>in particular</phrase> this procedure has been successfully <phrase>applied to</phrase> train <phrase>large scale</phrase> instances of <phrase>non linear</phrase> <phrase>support vector machines</phrase> svms . specializing fw to svm training has allowed <phrase>to obtain</phrase> efficient algorithms <phrase>but also</phrase> important theoretical results including convergence analysis of training algorithms and new characterizations of model sparsity. in <phrase>this paper</phrase> we present and analyze <phrase>a novel</phrase> variant of the fw method <phrase>based on</phrase> <phrase>a new</phrase> way <phrase>to perform</phrase> away steps a classic strategy used to accelerate the convergence of the basic fw procedure. our formulation and analysis is <phrase>focused on</phrase> a general concave maximization problem on the simplex. however the specialization of our algorithm to quadratic forms is strongly <phrase>related to</phrase> some classic methods in <phrase>computational geometry</phrase> namely the gilbert and mdm algorithms. on the theoretical side we demonstrate that the method matches the guarantees <phrase>in terms of</phrase> convergence rate and <phrase>number of</phrase> iterations <phrase>obtained by</phrase> using classic away steps. <phrase>in particular</phrase> the method enjoys a linear rate of convergence a result that has been recently proved for mdm on quadratic forms. on the practical side we provide <phrase>experiments on</phrase> several classification datasets and evaluate the results using statistical tests. <phrase>experiments show</phrase> that our method is <phrase>faster than</phrase> the fw method with classic away steps and works well even in the cases in which classic away steps slow down the algorithm. furthermore these improvements are obtained without sacrificing the predictive accuracy of the obtained svm model.
<phrase>semi supervised</phrase> vocabulary informed learning
despite significant progress in object categorization <phrase>in recent years</phrase> <phrase>a number of</phrase> important challenges remain mainly <phrase>ability to</phrase> learn from limited labeled data and <phrase>ability to</phrase> recognize object classes within large potentially <phrase>open set</phrase> of labels. <phrase>zero shot</phrase> learning is one way of addressing these challenges but it has only been <phrase>shown to</phrase> work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes allowing former to inform <phrase>the latter</phrase> but not vice versa. we propose the <phrase>notion of</phrase> <phrase>semi supervised</phrase> vocabulary informed learning to alleviate the above mentioned challenges and address problems of supervised <phrase>zero shot</phrase> and <phrase>open set</phrase> recognition using <phrase>a unified</phrase> framework. specifically we propose a maximum margin <phrase>framework for</phrase> semantic manifold based recognition that incorporates distance constraints from both supervised and unsupervised vocabulary atoms ensuring that labeled samples are projected closest to their correct prototypes in the embedding space than to others. we show that resulting model shows improvements in supervised <phrase>zero shot</phrase> and large <phrase>open set</phrase> recognition with up to 310k class vocabulary on awa and imagenet datasets.
submodular meets structured finding diverse subsets in exponentially large structured item sets
to cope with the <phrase>high level</phrase> of ambiguity faced in <phrase>domains such as</phrase> <phrase>computer vision</phrase> or <phrase>natural language</phrase> processing robust prediction methods often search for a diverse <phrase>set of</phrase> <phrase>high quality</phrase> candidate solutions or proposals. in <phrase>structured prediction</phrase> problems this becomes a daunting task as the solution space image labelings sentence parses etc. is exponentially large. we study greedy algorithms for finding a diverse <phrase>subset of</phrase> solutions in structured output spaces by drawing new connections between submodular functions over combinatorial item sets and high order potentials hops studied for <phrase>graphical models</phrase>. specifically we show via examples that when marginal gains of submodular diversity functions allow structured representations this enables efficient sub linear time approximate maximization by reducing the greedy augmentation step to inference in a factor graph with appropriately constructed hops. we discuss benefits tradeoffs and show that our constructions <phrase>lead to</phrase> significantly better proposals.
zm net <phrase>real time</phrase> <phrase>zero shot</phrase> image manipulation network
many problems in <phrase>image processing</phrase> and <phrase>computer vision</phrase> e.g. colorization style transfer can be posed as manipulating an input image into a corresponding output image given a user specified guiding signal. a <phrase>holy grail</phrase> solution towards generic image manipulation should be <phrase>able to</phrase> efficiently alter an input image with any personalized signals even signals unseen <phrase>during training</phrase> <phrase>such as</phrase> diverse paintings and arbitrary descriptive attributes. however <phrase>existing methods</phrase> are either inefficient to simultaneously process multiple signals let alone generalize to unseen signals or unable to handle signals from other modalities. in <phrase>this paper</phrase> we make the first <phrase>attempt to</phrase> address the <phrase>zero shot</phrase> image manipulation task. we cast <phrase>this problem</phrase> as manipulating an input image <phrase>according to</phrase> a parametric model whose key parameters can be conditionally generated from any guiding signal even unseen ones . to this end we propose the <phrase>zero shot</phrase> manipulation net zm net a fully differentiable architecture that jointly optimizes <phrase>an image</phrase> transformation network tnet and a parameter network pnet . the pnet learns <phrase>to generate</phrase> key transformation parameters for the tnet given any guiding signal while the tnet performs fast <phrase>zero shot</phrase> image manipulation <phrase>according to</phrase> both signal dependent parameters from the pnet and signal invariant parameters from the tnet itself. <phrase>extensive experiments</phrase> show that our zm net can perform <phrase>high quality</phrase> image manipulation <phrase>conditioned on</phrase> different forms of guiding signals e.g. style images and attributes in <phrase>real time</phrase> tens of milliseconds per image even for unseen signals. moreover <phrase>a large</phrase> scale style dataset with over 20 000 style images is also constructed to promote further research.
<phrase>multi agent</phrase> diverse <phrase>generative adversarial networks</phrase>
we propose an intuitive generalization to the <phrase>generative adversarial networks</phrase> gans and its conditional variants <phrase>to address</phrase> the <phrase>well known</phrase> mode collapse problem. firstly we propose a <phrase>multi agent</phrase> gan architecture incorporating multiple generators and one discriminator. secondly to enforce different generators <phrase>to capture</phrase> diverse high probability modes we modify discriminator s <phrase>objective function</phrase> where <phrase>along with</phrase> finding the real and fake samples the discriminator has to identify the generator that generated the fake sample. intuitively to succeed in <phrase>this task</phrase> the discriminator must learn to push different generators towards different identifiable modes. our framework mad gan is generalizable in the sense that it can be easily <phrase>combined with</phrase> other existing variants of gans <phrase>to produce</phrase> diverse samples. we perform <phrase>extensive experiments</phrase> on synthetic and real datasets and compare mad gan with different variants of gan. we show <phrase>high quality</phrase> diverse sample generations for the challenging <phrase>tasks such as</phrase> image to image translation known <phrase>to learn</phrase> delta distribution and face generation. <phrase>in addition</phrase> we show that mad gan is <phrase>able to</phrase> disentangle different modalities even when trained using highly challenging <phrase>multi view</phrase> dataset mixture of forests icebergs bedrooms etc . in the end we <phrase>also show</phrase> its efficacy for the unsupervised feature representation task. in the appendix we introduce a similarity based competing objective which encourages the different generators <phrase>to generate</phrase> varied samples judged by a user defined similarity metric. we show extensive evaluations on a 1 d setting of mixture of gaussians for non parametric <phrase>density estimation</phrase>. the theoretical proofs back <phrase>the efficacy of</phrase> the framework and explains why various generators are pushed towards distinct clusters of modes.
geometric gan
<phrase>generative adversarial</phrase> nets gans represent <phrase>an important</phrase> milestone for effective <phrase>generative models</phrase> which has inspired numerous variants seemingly different from each other. one of the main contributions of <phrase>this paper</phrase> is to reveal <phrase>a unified</phrase> geometric structure in gan and its variants. specifically we show that the adversarial <phrase>generative model</phrase> training can be decomposed into three geometric steps separating hyperplane search discriminator parameter update away from the separating hyperplane and the generator update along the normal vector direction of the separating hyperplane. this geometric intuition reveals the limitations of the <phrase>existing approaches</phrase> and leads us to propose <phrase>a new</phrase> formulation called geometric gan using svm separating hyperplane that maximizes the margin. our theoretical analysis shows that the geometric gan converges to a <phrase>nash equilibrium</phrase> between the discriminator and generator. <phrase>in addition</phrase> extensive numerical <phrase>results show</phrase> that the superior performance of geometric gan.
a data and model parallel distributed and scalable <phrase>framework for</phrase> training of <phrase>deep networks</phrase> in apache spark
training <phrase>deep networks</phrase> is expensive and time consuming with the training period increasing with data size and growth in <phrase>model parameters</phrase>. in <phrase>this paper</phrase> we provide a <phrase>framework for</phrase> distributed training of <phrase>deep networks</phrase> over a cluster of cpus in apache spark. the framework implements both data parallelism and model parallelism making it suitable to use for <phrase>deep networks</phrase> which require huge <phrase>training data</phrase> and <phrase>model parameters</phrase> which are too big to fit into the memory of <phrase>a single</phrase> machine. it can be scaled easily over a cluster of cheap commodity hardware to attain significant speedup and obtain better results making it quite economical as <phrase>compared to</phrase> farm of gpus and supercomputers. we have proposed <phrase>a new</phrase> algorithm for training of <phrase>deep networks</phrase> for the case when <phrase>the network</phrase> is partitioned across the machines model parallelism <phrase>along with</phrase> detailed cost analysis and proof of convergence of <phrase>the same</phrase>. we have developed implementations for fully connected feedforward networks <phrase>convolutional neural networks</phrase> <phrase>recurrent neural networks</phrase> and <phrase>long short term memory</phrase> architectures. we present the results of extensive simulations demonstrating the speedup and accuracy <phrase>obtained by</phrase> our <phrase>framework for</phrase> different sizes of the data and <phrase>model parameters</phrase> with variation in <phrase>the number of</phrase> worker cores partitions thereby showing that our <phrase>proposed framework</phrase> can achieve significant speedup upto 11x for cnn and is also quite scalable.
understanding and comparing <phrase>deep neural networks</phrase> for age and gender classification
recently <phrase>deep neural networks</phrase> have demonstrated excellent performances in recognizing the age and gender on human face images. however <phrase>these models</phrase> were applied in a <phrase>black box</phrase> manner with no information provided about which facial features are actually used for prediction and how these features depend on image preprocessing model initialization and architecture choice. we present a study investigating these different effects. in detail our work compares four popular <phrase>neural network</phrase> architectures studies <phrase>the effect of</phrase> pretraining evaluates <phrase>the robustness of</phrase> the considered alignment preprocessings via cross method <phrase>test set</phrase> swapping and intuitively visualizes <phrase>the model</phrase> s prediction strategies in given preprocessing conditions using the recent <phrase>layer wise</phrase> relevance propagation lrp algorithm. our evaluations on the challenging adience benchmark show that suitable parameter initialization <phrase>leads to</phrase> a holistic perception of <phrase>the input</phrase> compensating artefactual data representations. with a <phrase>combination of</phrase> simple preprocessing steps we reach <phrase>state of</phrase> <phrase>the art</phrase> performance in gender recognition.
when is a convolutional filter <phrase>easy to</phrase> learn 
we analyze the convergence of <phrase>stochastic gradient descent</phrase> algorithm for learning a convolutional filter with <phrase>rectified linear</phrase> unit relu <phrase>activation function</phrase>. our analysis <phrase>does not</phrase> <phrase>rely on</phrase> any specific form of <phrase>the input</phrase> distribution and our proofs only use the definition of relu <phrase>in contrast</phrase> with previous works that are restricted to standard gaussian input. we show that <phrase>stochastic gradient descent</phrase> with random initialization can learn the convolutional filter in polynomial time and the convergence rate <phrase>depends on</phrase> the smoothness of <phrase>the input</phrase> distribution and the closeness of patches. to <phrase>the best</phrase> of our knowledge this is the first recovery guarantee of <phrase>gradient based</phrase> algorithms for convolutional filter on non gaussian input distributions. our theory also justifies the two stage <phrase>learning rate</phrase> strategy in <phrase>deep neural networks</phrase>. while our focus is theoretical we <phrase>also present</phrase> experiments that illustrate our theoretical findings.
learning sparse visual representations with leaky capped norm regularizers
sparsity inducing regularization is <phrase>an important</phrase> part for learning over complete visual representations. despite the popularity of ell 1 regularization in <phrase>this paper</phrase> we investigate the usage of <phrase>non convex</phrase> regularizations in <phrase>this problem</phrase>. our contribution <phrase>consists of</phrase> three parts. first we propose the leaky capped norm regularization lcnr which allows model weights below a certain threshold to be regularized more strongly as opposed to those above therefore imposes strong sparsity and only introduces controllable estimation bias. we propose a majorization minimization algorithm to optimize the joint <phrase>objective function</phrase>. second our study over monocular 3d shape recovery and <phrase>neural networks</phrase> with lcnr outperforms ell 1 and other <phrase>non convex</phrase> regularizations achieving <phrase>state of</phrase> <phrase>the art</phrase> performance and faster convergence. third we prove a theoretical global convergence speed on the 3d recovery problem. to <phrase>the best</phrase> of our knowledge this is the first convergence analysis of the 3d recovery problem.
convnets and imagenet beyond accuracy explanations bias detection <phrase>adversarial examples</phrase> and model criticism
convnets and imagenet have driven the recent success of <phrase>deep learning</phrase> for <phrase>image classification</phrase>. however the marked slowdown in <phrase>performance improvement</phrase> the recent studies on <phrase>the lack of</phrase> robustness of <phrase>neural networks</phrase> to <phrase>adversarial examples</phrase> and their tendency to exhibit undesirable biases e.g racial biases questioned the reliability and the sustained development of these methods. <phrase>this work</phrase> investigates these questions from the perspective of the end user <phrase>by using</phrase> human subject studies and explanations. we experimentally demonstrate that the accuracy and robustness of convnets measured on imagenet are underestimated. we show that explanations can mitigate the impact of misclassified <phrase>adversarial examples</phrase> from the perspective of the end user and we introduce <phrase>a novel</phrase> tool for uncovering the undesirable biases learned by a model. these contributions <phrase>also show</phrase> that explanations are a promising tool for improving our understanding of convnets predictions and for designing more reliable models
<phrase>gradient descent</phrase> learns one <phrase>hidden layer</phrase> cnn don t be afraid of spurious <phrase>local minima</phrase>
we consider <phrase>the problem of</phrase> learning a one <phrase>hidden layer</phrase> <phrase>neural network</phrase> with non overlapping convolutional layer and relu <phrase>activation function</phrase> i.e. f mathbf z mathbf w mathbf a sum j a j sigma mathbf w top mathbf z j in which both the convolutional weights mathbf w and the output weights mathbf a are parameters to be learned. we prove that with gaussian input mathbf z there is a spurious local minimum that is not a global mininum. surprisingly in the presence of local minimum starting from randomly initialized weights <phrase>gradient descent</phrase> with weight normalization can still be proven to recover the true parameters with constant probability which can be boosted to arbitrarily high accuracy with multiple restarts . we <phrase>also show</phrase> that with constant probability <phrase>the same</phrase> procedure could also converge to the spurious local minimum showing that the local minimum plays a non trivial <phrase>role in</phrase> the dynamics of <phrase>gradient descent</phrase>. furthermore a quantitative analysis shows that the <phrase>gradient descent</phrase> dynamics has two phases it starts off slow but converges much faster after several iterations.
curiosity driven exploration by self supervised prediction
in many <phrase>real world</phrase> scenarios rewards extrinsic to the agent are extremely sparse or absent altogether. in such cases curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. we formulate curiosity as the error in <phrase>an agent</phrase> s <phrase>ability to</phrase> predict the consequence of its own actions in a visual <phrase>feature space</phrase> learned by a self supervised inverse dynamics model. our formulation scales to <phrase>high dimensional</phrase> continuous state spaces like images bypasses the difficulties of directly predicting pixels and critically ignores the <phrase>aspects of</phrase> the environment that cannot affect the agent. <phrase>the proposed</phrase> approach is evaluated in two environments vizdoom and <phrase>super mario</phrase> bros. three broad settings are investigated 1 sparse extrinsic reward where curiosity allows for far fewer interactions with the environment to reach the goal 2 exploration with no extrinsic reward where curiosity pushes the agent to explore more efficiently and 3 generalization to unseen scenarios e.g. new levels of <phrase>the same</phrase> game where the knowledge gained from earlier experience helps the agent explore new places much <phrase>faster than</phrase> starting <phrase>from scratch</phrase>. demo video and code <phrase>available at</phrase> https pathak22.github.io noreward rl 
houdini fooling deep <phrase>structured prediction</phrase> models
generating <phrase>adversarial examples</phrase> is a critical step for evaluating and improving <phrase>the robustness of</phrase> <phrase>learning machines</phrase>. <phrase>so far</phrase> most <phrase>existing methods</phrase> only work for classification and are not designed to alter the true performance measure of the problem at hand. we introduce <phrase>a novel</phrase> flexible approach named houdini for generating <phrase>adversarial examples</phrase> specifically tailored for <phrase>the final</phrase> performance measure of the task considered be it combinatorial and non decomposable. we successfully apply houdini to <phrase>a range of</phrase> <phrase>applications such as</phrase> <phrase>speech recognition</phrase> pose estimation and <phrase>semantic segmentation</phrase>. in all cases the attacks <phrase>based on</phrase> houdini achieve higher success rate than those <phrase>based on</phrase> the traditional surrogates used <phrase>to train</phrase> the models while using a less perceptible adversarial perturbation.
<phrase>recent advances in</phrase> <phrase>zero shot</phrase> recognition
with the recent renaissance of deep convolution <phrase>neural networks</phrase> encouraging breakthroughs have been achieved on the supervised <phrase>recognition tasks</phrase> where each class has sufficient <phrase>training data</phrase> and fully annotated <phrase>training data</phrase>. however to scale the recognition to <phrase>a large number of</phrase> classes with few or now <phrase>training samples</phrase> for each class remains an unsolved problem. one <phrase>approach to</phrase> scaling up the recognition is to develop models <phrase>capable of</phrase> recognizing unseen categories without any training instances or <phrase>zero shot</phrase> recognition learning. this article provides a comprehensive review of existing <phrase>zero shot</phrase> recognition techniques covering various aspects ranging from representations of models and from datasets and evaluation settings. we also overview related <phrase>recognition tasks</phrase> including one shot and <phrase>open set</phrase> recognition which can be <phrase>used as</phrase> natural extensions of <phrase>zero shot</phrase> recognition when limited <phrase>number of</phrase> class samples become available or when <phrase>zero shot</phrase> recognition is implemented in a <phrase>real world</phrase> setting. importantly we highlight the limitations of <phrase>existing approaches</phrase> and point out future research directions in this existing new research area.
the loss surface and expressivity of <phrase>deep convolutional neural networks</phrase>
we analyze the expressiveness and loss surface of practical <phrase>deep convolutional neural networks</phrase> cnns with shared weights and max pooling layers. we show that such cnns produce <phrase>linearly independent</phrase> features at a wide layer which has more neurons than <phrase>the number of</phrase> <phrase>training samples</phrase>. this condition holds e.g. for the vgg network. furthermore we provide for such wide cnns necessary and sufficient conditions for global minima with zero training error. for the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. our analysis suggests that both depth and width are very important in <phrase>deep learning</phrase>. while depth brings more representational power and allows <phrase>the network</phrase> <phrase>to learn</phrase> <phrase>high level</phrase> features width smoothes the optimization landscape of the <phrase>loss function</phrase> in the sense that a sufficiently wide network has a well behaved loss surface with potentially no bad <phrase>local minima</phrase>.
physics guided <phrase>neural networks</phrase> pgnn an application in lake temperature modeling
<phrase>this paper</phrase> introduces <phrase>a novel</phrase> <phrase>framework for</phrase> combining <phrase>scientific knowledge</phrase> of physics based models with <phrase>neural networks</phrase> to advance scientific discovery. this framework termed as physics guided <phrase>neural network</phrase> pgnn leverages the output of physics based model simulations <phrase>along with</phrase> observational features <phrase>to generate</phrase> predictions using <phrase>a neural network</phrase> architecture. further <phrase>this paper</phrase> presents <phrase>a novel</phrase> <phrase>framework for</phrase> using physics based loss functions in the learning objective of <phrase>neural networks</phrase> to ensure that <phrase>the model</phrase> predictions <phrase>not only</phrase> show lower errors on the <phrase>training set</phrase> but are also scientifically consistent with the known physics on the unlabeled set. we illustrate <phrase>the effectiveness of</phrase> pgnn for <phrase>the problem of</phrase> lake temperature modeling where physical relationships between the temperature density and depth of water are used to design a physics based <phrase>loss function</phrase>. <phrase>by using</phrase> <phrase>scientific knowledge</phrase> to guide the construction and learning of <phrase>neural networks</phrase> we are <phrase>able to</phrase> show that <phrase>the proposed</phrase> framework ensures better generalizability <phrase>as well as</phrase> scientific consistency of results.
unified <phrase>spectral clustering</phrase> with optimal graph
<phrase>spectral clustering</phrase> has found extensive use in many areas. most traditional <phrase>spectral clustering</phrase> algorithms work in three separate steps similarity graph construction continuous labels learning discretizing the learned labels by <phrase>k means clustering</phrase>. such common practice has two potential flaws which may <phrase>lead to</phrase> severe information loss and performance degradation. first predefined similarity graph might not be optimal for subsequent clustering. it is well accepted that similarity graph highly affects the clustering results. to this end we propose to automatically learn similarity information from data and simultaneously consider the constraint that the similarity matrix has exact c connected components if there are c clusters. second the discrete solution may deviate from the spectral solution since k means method is <phrase>well known</phrase> as sensitive to the initialization of cluster centers. in <phrase>this work</phrase> we transform the candidate solution into <phrase>a new</phrase> one that better approximates the discrete one. finally those three subtasks are integrated into <phrase>a unified</phrase> framework with each subtask iteratively boosted <phrase>by using</phrase> the results of the others towards an overall optimal solution. it is known that <phrase>the performance of</phrase> a kernel method is largely determined by the <phrase>choice of</phrase> kernels. <phrase>to tackle</phrase> this practical problem of how <phrase>to select</phrase> the most suitable kernel for a particular <phrase>data set</phrase> we further extend our model to incorporate multiple kernel learning ability. <phrase>extensive experiments</phrase> demonstrate the superiority of our <phrase>proposed method</phrase> as <phrase>compared to</phrase> existing clustering approaches.
on the inductive bias of dropout
dropout is <phrase>a simple</phrase> but effective technique for learning in <phrase>neural networks</phrase> and other settings. a sound theoretical understanding of dropout is needed to determine when dropout should be applied and how to use it most effectively. in <phrase>this paper</phrase> we continue the exploration of dropout as a regularizer pioneered by wager et.al. we <phrase>focus on</phrase> linear classification where a convex proxy to the misclassification loss i.e. the logistic loss used in <phrase>logistic regression</phrase> is minimized. we show a when the dropout regularized criterion has a unique minimizer b when the dropout regularization penalty goes to infinity with the weights and when it remains bounded c that the dropout regularization can be non monotonic as individual weights increase from 0 and d that the dropout regularization penalty may not be convex. this last point is particularly surprising because the <phrase>combination of</phrase> dropout regularization with any convex loss proxy is always a <phrase>convex function</phrase>. <phrase>in order to</phrase> contrast dropout regularization with l 2 regularization we formalize the <phrase>notion of</phrase> when different sources are more compatible with different regularizers. we then exhibit distributions that are provably more compatible with dropout regularization than l 2 regularization and vice versa. these sources provide additional insight into how the inductive biases of dropout and l 2 regularization differ. we provide some similar results for l 1 regularization.
surprising <phrase>properties of</phrase> dropout in <phrase>deep networks</phrase>
we analyze dropout in <phrase>deep networks</phrase> with <phrase>rectified linear</phrase> units and the quadratic loss. our results expose surprising differences between the behavior of dropout and more traditional regularizers like weight decay. for example on some simple <phrase>data sets</phrase> dropout training produces negative weights even though the output is the sum of the inputs. this provides a counterpoint to the suggestion that dropout discourages co adaptation of weights. we <phrase>also show</phrase> that the dropout penalty can grow exponentially in the depth of <phrase>the network</phrase> while the weight decay penalty remains essentially linear and that dropout is insensitive to various re scalings of <phrase>the input</phrase> features outputs and network weights. this last insensitivity implies that there are no isolated <phrase>local minima</phrase> of the dropout training criterion. our work uncovers new <phrase>properties of</phrase> dropout extends our understanding of why dropout succeeds and lays the foundation for further progress.
training probabilistic <phrase>spiking neural networks</phrase> with first to spike decoding
third generation <phrase>neural networks</phrase> or <phrase>spiking neural networks</phrase> snns aim at harnessing the energy efficiency of spike domain processing by building on computing elements that operate on and exchange spikes. in <phrase>this paper</phrase> <phrase>the problem of</phrase> training a two layer snn is studied for the purpose of classification under a <phrase>generalized linear model</phrase> glm probabilistic neural model that was previously considered within the <phrase>computational neuroscience</phrase> literature. conventional classification rules for snns operate offline <phrase>based on</phrase> <phrase>the number of</phrase> output spikes at each output neuron. <phrase>in contrast</phrase> <phrase>a novel</phrase> training method is proposed here for a first to spike decoding rule whereby the snn can perform an early classification decision once spike firing is detected at an output neuron. numerical results bring insights into the optimal parameter selection for the glm neuron and on the accuracy complexity trade off performance of conventional and first to spike decoding.
<phrase>a novel</phrase> clustering algorithm <phrase>based on</phrase> quantum games
enormous successes have been made by quantum algorithms during the last decade. in <phrase>this paper</phrase> we combine the quantum game with <phrase>the problem of</phrase> data clustering and then develop a quantum game based clustering algorithm in which data points in a dataset are considered as players who can make decisions and implement quantum strategies in quantum games. after each round of a quantum game each player s expected payoff is calculated. later he uses a link removing and rewiring lrr function to change his neighbors and adjust the strength of links connecting to them <phrase>in order to</phrase> maximize his payoff. further algorithms are discussed and analyzed in two cases of strategies two payoff matrixes and two lrr functions. consequently the simulation results have demonstrated that data points in datasets are clustered reasonably and efficiently and the clustering algorithms have fast rates of convergence. moreover the comparison with other algorithms also provides an indication of <phrase>the effectiveness of</phrase> <phrase>the proposed</phrase> approach.
exact solutions to the nonlinear dynamics of learning in deep linear <phrase>neural networks</phrase>
despite the widespread practical success of <phrase>deep learning</phrase> methods our theoretical understanding of the dynamics of learning in <phrase>deep neural networks</phrase> remains quite sparse. we <phrase>attempt to</phrase> bridge the gap between the theory and practice of <phrase>deep learning</phrase> by systematically analyzing learning dynamics for the restricted case of deep linear <phrase>neural networks</phrase>. despite the linearity of their <phrase>input output</phrase> map such networks have nonlinear <phrase>gradient descent</phrase> dynamics on weights that change with the addition of each new <phrase>hidden layer</phrase>. we show that deep linear networks exhibit nonlinear learning phenomena <phrase>similar to</phrase> those seen in simulations of nonlinear networks including long plateaus followed by rapid transitions to lower error solutions and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. we provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of <phrase>deep learning</phrase>. our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity learning speed can nevertheless remain finite for <phrase>a special</phrase> class of initial conditions on the weights very <phrase>deep networks</phrase> incur only a finite depth independent delay in learning speed relative to shallow networks. we show that under certain conditions on <phrase>the training data</phrase> unsupervised pretraining can find this special class of initial conditions while scaled random gaussian initializations cannot. we further exhibit <phrase>a new</phrase> class of random orthogonal initial conditions on weights that like unsupervised <phrase>pre training</phrase> enjoys depth independent learning times. we further show that these initial conditions also <phrase>lead to</phrase> faithful propagation of gradients even in deep nonlinear networks as long as they operate in <phrase>a special</phrase> regime <phrase>known as</phrase> the edge of chaos.
entropy of overcomplete kernel dictionaries
in signal analysis and synthesis <phrase>linear approximation</phrase> theory considers a linear decomposition of any given signal in <phrase>a set of</phrase> atoms collected into a so called dictionary. relevant sparse representations are <phrase>obtained by</phrase> relaxing the orthogonality condition of the atoms yielding overcomplete dictionaries with an extended <phrase>number of</phrase> atoms. more generally than the linear decomposition overcomplete kernel dictionaries provide an elegant nonlinear extension by defining the atoms through a mapping kernel function e.g. the gaussian kernel . models <phrase>based on</phrase> such kernel dictionaries are used in <phrase>neural networks</phrase> gaussian processes and online learning with kernels. the quality of an overcomplete dictionary is evaluated with a diversity measure the distance the approximation the coherence and the babel measures. in <phrase>this paper</phrase> we develop a framework to examine overcomplete kernel dictionaries with the entropy from <phrase>information theory</phrase>. indeed a higher value of the entropy is associated to a further uniform spread of the atoms over the space. for each of the aforementioned diversity measures we derive lower bounds on the entropy. several definitions of the entropy are examined with an extensive analysis in both <phrase>the input</phrase> space and the mapped <phrase>feature space</phrase>.
rotation invariant <phrase>convolutional neural networks</phrase> for galaxy morphology prediction
measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. surveys <phrase>such as</phrase> the <phrase>sloan digital sky survey</phrase> sdss have resulted in the availability of very large collections of images which have permitted population wide analyses of galaxy morphology. morphological analysis has traditionally been carried out mostly via visual inspection by trained experts which is time consuming and <phrase>does not</phrase> scale to large gtrsim10 4 numbers of images. although attempts have been made to build automated classification systems these have not been <phrase>able to</phrase> achieve the desired level of accuracy. the galaxy zoo project successfully applied a crowdsourcing strategy inviting online users to classify images by answering <phrase>a series of</phrase> questions. unfortunately even <phrase>this approach</phrase> <phrase>does not</phrase> scale well enough to keep up with the increasing availability of galaxy images. we present <phrase>a deep neural network</phrase> model for galaxy morphology classification which exploits translational and <phrase>rotational symmetry</phrase>. it was developed in <phrase>the context of</phrase> the galaxy challenge an international competition to build <phrase>the best</phrase> model for morphology classification <phrase>based on</phrase> annotated images from the galaxy zoo project. for images with high agreement among the galaxy zoo participants our model is <phrase>able to</phrase> reproduce their consensus with near perfect accuracy 99 for most questions. confident model predictions are highly accurate which makes <phrase>the model</phrase> <phrase>suitable for</phrase> filtering large collections of images and forwarding challenging images to experts for manual annotation. <phrase>this approach</phrase> greatly reduces the experts workload without affecting accuracy. the <phrase>application of</phrase> these algorithms to larger sets of <phrase>training data</phrase> will be critical for analysing results from future surveys <phrase>such as</phrase> the lsst.
kernel nonnegative matrix factorization without the curse of the pre image <phrase>application to</phrase> unmixing hyperspectral images
the nonnegative matrix factorization nmf is <phrase>widely used</phrase> in signal and <phrase>image processing</phrase> including bio informatics blind source separation and hyperspectral <phrase>image analysis</phrase> in <phrase>remote sensing</phrase>. a great challenge arises when dealing with a nonlinear formulation of the nmf. within the framework of kernel machines the models suggested in the literature <phrase>do not</phrase> allow the representation of the factorization matrices which is a fallout of the curse of the pre image. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> kernel based model for the nmf that <phrase>does not</phrase> <phrase>suffer from</phrase> the pre image problem by investigating the estimation of the factorization matrices directly in <phrase>the input</phrase> space. for different kernel functions we describe two schemes for iterative algorithms an additive update rule <phrase>based on</phrase> a <phrase>gradient descent</phrase> scheme and a multiplicative update rule in <phrase>the same</phrase> spirit as in the lee and seung algorithm. within <phrase>the proposed</phrase> framework we develop several extensions to incorporate constraints including sparseness smoothness and spatial regularization with a <phrase>total variation</phrase> like penalty. <phrase>the effectiveness of</phrase> <phrase>the proposed</phrase> method is demonstrated with <phrase>the problem of</phrase> unmixing hyperspectral images using <phrase>well known</phrase> real images and results with <phrase>state of</phrase> <phrase>the art</phrase> techniques.
approximation errors of online sparsification criteria
many <phrase>machine learning</phrase> frameworks <phrase>such as</phrase> resource allocating networks kernel <phrase>based methods</phrase> gaussian processes and <phrase>radial basis function</phrase> networks require a sparsification scheme <phrase>in order to</phrase> address the online learning paradigm. for this purpose several online sparsification criteria have been proposed to restrict <phrase>the model</phrase> definition on <phrase>a subset of</phrase> samples. the most known criterion is the <phrase>linear approximation</phrase> criterion which discards any sample that can be well represented by the already contributing samples an operation with excessive <phrase>computational complexity</phrase>. several computationally efficient sparsification criteria have been introduced in the literature <phrase>such as</phrase> the distance the coherence and the babel criteria. in <phrase>this paper</phrase> we provide a framework that connects these sparsification criteria to the issue of approximating samples by deriving theoretical bounds on the approximation errors. moreover we investigate the error of approximating any feature by proposing upper bounds on the approximation error for each of the aforementioned sparsification criteria. two classes of features are described in detail the empirical mean and the principal axes in the kernel <phrase>principal component analysis</phrase>.
discrete deep <phrase>feature extraction</phrase> a theory and new architectures
first steps towards a mathematical theory of <phrase>deep convolutional neural networks</phrase> for <phrase>feature extraction</phrase> were made for the continuous time case in mallat 2012 and wiatowski and b olcskei 2015. <phrase>this paper</phrase> considers the discrete case introduces new <phrase>convolutional neural network</phrase> architectures and proposes a mathematical <phrase>framework for</phrase> their analysis. specifically we establish deformation and translation sensitivity results of local and global nature and we investigate how certain structural <phrase>properties of</phrase> <phrase>the input</phrase> signal are reflected in the corresponding feature vectors. our theory applies to general filters and general lipschitz continuous non linearities and pooling operators. <phrase>experiments on</phrase> handwritten digit classification and facial landmark detection including feature importance evaluation complement the theoretical findings.
neural responding machine for short text conversation
we propose neural responding machine nrm <phrase>a neural network</phrase> based response generator for short text conversation. nrm takes the general <phrase>encoder decoder</phrase> framework it formalizes <phrase>the generation of</phrase> response as a decoding process <phrase>based on</phrase> the latent representation of <phrase>the input</phrase> text while both encoding and decoding are realized with <phrase>recurrent neural networks</phrase> rnn . the nrm is trained with <phrase>a large</phrase> <phrase>amount of</phrase> one round conversation data collected from a microblogging service. empirical study shows that nrm can generate grammatically correct and content wise appropriate responses to over 75 of <phrase>the input</phrase> text outperforming <phrase>state of</phrase> the arts in <phrase>the same</phrase> setting including retrieval based and smt based models.
deep <phrase>active learning</phrase> for dialogue generation
we propose an online <phrase>end to end</phrase> neural generative conversational model for <phrase>open domain</phrase> dialogue. it is trained using a unique <phrase>combination of</phrase> offline two phase <phrase>supervised learning</phrase> and online human in the loop <phrase>active learning</phrase>. while most existing research proposes offline supervision or <phrase>hand crafted</phrase> reward functions for online reinforcement we devise <phrase>a novel</phrase> interactive learning mechanism <phrase>based on</phrase> hamming diverse <phrase>beam search</phrase> for <phrase>response generation</phrase> and one character user feedback at each step. <phrase>experiments show</phrase> that our model inherently promotes <phrase>the generation of</phrase> semantically relevant and interesting responses and can be used <phrase>to train</phrase> agents with customized personas moods and conversational styles.
teaching machines to read and comprehend
teaching machines to read <phrase>natural language</phrase> documents remains an elusive challenge. machine reading systems can be <phrase>tested on</phrase> their <phrase>ability to</phrase> answer questions posed on the contents of documents that they have seen but until now <phrase>large scale</phrase> training and test datasets have been missing for this <phrase>type of</phrase> evaluation. in <phrase>this work</phrase> we define <phrase>a new</phrase> methodology that resolves this bottleneck and provides <phrase>large scale</phrase> supervised <phrase>reading comprehension</phrase> data. this allows us to develop a class of <phrase>attention based</phrase> <phrase>deep neural networks</phrase> that learn to read real documents and answer complex questions <phrase>with minimal</phrase> <phrase>prior knowledge</phrase> of language structure.
syntax aware multi sense <phrase>word embeddings</phrase> for deep compositional models of meaning
deep compositional models of meaning acting on distributional representations of words <phrase>in order to</phrase> produce vectors of larger text constituents are evolving to a popular area of nlp research. we detail a compositional distributional framework <phrase>based on</phrase> a rich form of <phrase>word embeddings</phrase> that aims at facilitating the interactions between words in <phrase>the context of</phrase> a sentence. embeddings and composition layers are jointly learned against a generic objective that enhances the vectors with syntactic information from the surrounding context. furthermore each word is <phrase>associated with</phrase> <phrase>a number of</phrase> senses the most plausible of which is selected dynamically during the composition process. we evaluate the produced vectors qualitatively and quantitatively with positive results. at the <phrase>sentence level</phrase> <phrase>the effectiveness of</phrase> the framework is demonstrated on the msrpar task for which we report results within the <phrase>state of</phrase> <phrase>the art</phrase> range.
a deep architecture for semantic matching with multiple positional sentence representations
matching <phrase>natural language</phrase> sentences is central for <phrase>many applications</phrase> <phrase>such as</phrase> <phrase>information retrieval</phrase> and <phrase>question answering</phrase>. existing deep models <phrase>rely on</phrase> <phrase>a single</phrase> sentence representation or multiple granularity representations for matching. however such methods cannot well capture the contextualized local information in the matching process. <phrase>to tackle</phrase> <phrase>this problem</phrase> we present <phrase>a new</phrase> deep architecture to match two sentences with multiple positional sentence representations. specifically each positional sentence representation is a sentence representation at this position generated by a bidirectional <phrase>long short term memory</phrase> bi lstm . the matching score is finally <phrase>produced by</phrase> aggregating interactions between these different positional sentence representations through k max pooling and a <phrase>multi layer</phrase> perceptron. our model has several advantages 1 <phrase>by using</phrase> bi lstm rich context of the whole sentence is leveraged <phrase>to capture</phrase> the contextualized local information in each positional sentence representation 2 by matching with multiple positional sentence representations it is flexible to aggregate different important contextualized local information in a sentence to support the matching 3 <phrase>experiments on</phrase> different <phrase>tasks such as</phrase> <phrase>question answering</phrase> and sentence completion demonstrate the superiority of our model.
lstm neural reordering feature for <phrase>statistical machine translation</phrase>
<phrase>artificial neural networks</phrase> are powerful models which have been widely applied into many <phrase>aspects of</phrase> <phrase>machine translation</phrase> <phrase>such as</phrase> <phrase>language modeling</phrase> and translation modeling. though notable improvements have been made in these areas the reordering problem still remains a challenge in statistical machine translations. in <phrase>this paper</phrase> we present <phrase>a novel</phrase> neural reordering model that directly models word pairs and alignment. by utilizing lstm <phrase>recurrent neural networks</phrase> much longer context could be learned for reordering prediction. <phrase>experimental results</phrase> on nist openmt12 arabic english and chinese english 1000 best rescoring task show that our lstm neural reordering feature is robust and achieves <phrase>significant improvements</phrase> over various baseline systems.
learning <phrase>natural language</phrase> inference with lstm
<phrase>natural language</phrase> inference nli is a fundamentally important task in <phrase>natural language</phrase> processing that has <phrase>many applications</phrase>. the recently released stanford <phrase>natural language</phrase> inference snli corpus has made it possible to develop and evaluate learning centered methods <phrase>such as</phrase> <phrase>deep neural networks</phrase> for <phrase>natural language</phrase> inference nli . in <phrase>this paper</phrase> we propose <phrase>a special</phrase> <phrase>long short term memory lstm</phrase> architecture for nli. our model builds on top of a <phrase>recently proposed</phrase> neural <phrase>attention model</phrase> for nli but is <phrase>based on</phrase> a significantly different idea. <phrase>instead of</phrase> deriving sentence embeddings for the premise and the hypothesis to be used for classification our solution uses a match lstm <phrase>to perform</phrase> word by word matching of the hypothesis with the premise. this lstm is <phrase>able to</phrase> place more emphasis on important <phrase>word level</phrase> matching results. <phrase>in particular</phrase> we observe that this lstm remembers important mismatches that are critical for predicting the contradiction or the neutral relationship label. on the snli corpus our <phrase>model achieves</phrase> an accuracy of 86.1 outperforming the <phrase>state of</phrase> <phrase>the art</phrase>.
quantifying the vanishing gradient and long distance dependency problem in <phrase>recursive neural</phrase> networks and recursive lstms
<phrase>recursive neural</phrase> networks rnn and their <phrase>recently proposed</phrase> extension recursive <phrase>long short term memory</phrase> networks rlstm are models that compute representations for sentences by recursively combining <phrase>word embeddings</phrase> <phrase>according to</phrase> an externally provided <phrase>parse tree</phrase>. both models thus unlike recurrent networks explicitly make use of the hierarchical structure of a sentence. in <phrase>this paper</phrase> we demonstrate that rnns nevertheless <phrase>suffer from</phrase> the vanishing gradient and long distance dependency problem and that rlstms greatly improve over rnn s on these problems. we present an artificial learning task that allows us to quantify the severity of these problems for both models. we further show that a ratio of gradients at the root node and a focal leaf node is highly indicative of the success of backpropagation at optimizing the relevant weights low in the tree. <phrase>this paper</phrase> thus provides an explanation for existing superior results of rlstms on <phrase>tasks such as</phrase> <phrase>sentiment analysis</phrase> and suggests that the benefits of including hierarchical structure and of including lstm style gating are complementary.
implicit discourse <phrase>relation classification</phrase> via <phrase>multi task</phrase> <phrase>neural networks</phrase>
without discourse connectives classifying implicit discourse relations is a <phrase>challenging task</phrase> and a bottleneck for building a practical discourse parser. previous research usually makes use of one <phrase>kind of</phrase> discourse framework <phrase>such as</phrase> pdtb or rst <phrase>to improve</phrase> the <phrase>classification performance</phrase> on discourse relations. actually under different discourse annotation frameworks there exist multiple corpora which have internal connections. to exploit the <phrase>combination of</phrase> different discourse corpora we design related discourse <phrase>classification tasks</phrase> specific to a corpus and propose <phrase>a novel</phrase> <phrase>convolutional neural network</phrase> embedded <phrase>multi task learning</phrase> system to synthesize these tasks by learning both unique and shared representations for each task. the <phrase>experimental results</phrase> on the pdtb implicit discourse <phrase>relation classification</phrase> task demonstrate that our <phrase>model achieves</phrase> significant gains over baseline systems.
enhancing sentence relation modeling with auxiliary <phrase>character level</phrase> embedding
<phrase>neural network based</phrase> approaches for sentence relation modeling automatically generate hidden matching features <phrase>from raw</phrase> sentence pairs. however the quality of matching feature representation may not be satisfied <phrase>due to</phrase> complex semantic relations <phrase>such as</phrase> entailment or contradiction. <phrase>to address</phrase> this challenge we propose <phrase>a new</phrase> <phrase>deep neural network</phrase> architecture that jointly leverage <phrase>pre trained</phrase> <phrase>word embedding</phrase> and auxiliary character embedding <phrase>to learn</phrase> sentence meanings. the two kinds of word sequence representations as inputs into <phrase>multi layer</phrase> bidirectional lstm <phrase>to learn</phrase> enhanced sentence representation. after that we construct matching features followed by another temporal cnn <phrase>to learn</phrase> <phrase>high level</phrase> hidden matching <phrase>feature representations</phrase>. <phrase>experimental results</phrase> demonstrate that our approach consistently outperforms the <phrase>existing methods</phrase> on standard evaluation datasets.
automatic open knowledge acquisition via <phrase>long short term memory</phrase> networks with feedback negative sampling
previous studies in open <phrase>information extraction</phrase> open ie are mainly <phrase>based on</phrase> extraction patterns. they manually define patterns or automatically learn them from <phrase>a large</phrase> corpus. however <phrase>these approaches</phrase> are limited when grasping <phrase>the context of</phrase> a sentence and they fail <phrase>to capture</phrase> implicit relations. in <phrase>this paper</phrase> we address <phrase>this problem</phrase> with the following methods. first we exploit <phrase>long short term memory lstm</phrase> networks <phrase>to extract</phrase> <phrase>higher level</phrase> features along the shortest dependency paths connecting headwords of relations and arguments. the path level features from <phrase>lstm networks</phrase> provide useful clues regarding contextual information and the validity of arguments. second we constructed samples <phrase>to train</phrase> <phrase>lstm networks</phrase> without <phrase>the need for</phrase> manual labeling. <phrase>in particular</phrase> feedback negative sampling picks highly negative samples among non positive samples through a model trained with positive samples. the <phrase>experimental results</phrase> show that our approach produces more precise and abundant extractions than <phrase>state of</phrase> <phrase>the art</phrase> open ie systems. to <phrase>the best</phrase> of our knowledge this is the first work to apply <phrase>deep learning</phrase> to open ie.
<phrase>question answering</phrase> over <phrase>knowledge base</phrase> with neural attention combining global knowledge information
with the rapid growth of knowledge bases kbs on the web how to take full <phrase>advantage of</phrase> them becomes increasingly important. <phrase>knowledge base</phrase> based <phrase>question answering</phrase> kb qa is one of the most promising approaches to access the substantial knowledge. meantime as the <phrase>neural network</phrase> based nn <phrase>based methods</phrase> develop nn based kb qa has already achieved impressive results. however <phrase>previous work</phrase> did not put emphasis on question representation and the question is converted into <phrase>a fixed</phrase> vector regardless of its candidate answers. this simple representation strategy is unable to express the proper information of the question. hence we present a neural <phrase>attention based</phrase> model <phrase>to represent</phrase> the questions dynamically <phrase>according to</phrase> the different focuses of various candidate answer aspects. <phrase>in addition</phrase> we leverage the global knowledge inside the underlying kb aiming at integrating the rich kb information into the representation of the answers. and it also alleviates the out of vocabulary oov problem which helps the <phrase>attention model</phrase> <phrase>to represent</phrase> the question more precisely. the <phrase>experimental results</phrase> on webquestions demonstrate <phrase>the effectiveness of</phrase> <phrase>the proposed</phrase> approach.
generating <phrase>natural language</phrase> inference chains
the <phrase>ability to</phrase> reason with <phrase>natural language</phrase> is a fundamental prerequisite for many nlp <phrase>tasks such as</phrase> <phrase>information extraction</phrase> <phrase>machine translation</phrase> and <phrase>question answering</phrase>. to quantify this ability systems are commonly tested whether they can recognize <phrase>textual entailment</phrase> i.e. whether one sentence can be inferred from another one. however in most nlp applications only single source sentences <phrase>instead of</phrase> sentence pairs are available. hence we propose <phrase>a new</phrase> task that measures how well a model can generate an entailed sentence from a <phrase>source sentence</phrase>. we take entailment pairs of the stanford <phrase>natural language</phrase> inference corpus and train an lstm with attention. on a manually annotated <phrase>test set</phrase> we found that 82 of generated sentences are correct an improvement of 10.3 over an lstm baseline. a qualitative analysis shows that this model is <phrase>not only</phrase> <phrase>capable of</phrase> shortening input sentences <phrase>but also</phrase> inferring new statements via paraphrasing and phrase entailment. we then apply this model recursively to <phrase>input output</phrase> pairs thereby generating <phrase>natural language</phrase> inference chains that can be used to automatically construct an entailment graph from source sentences. finally by swapping source and target sentences we can also train a model that given an input sentence invents additional information <phrase>to generate</phrase> <phrase>a new</phrase> sentence.
mufuru the multi function recurrent unit
<phrase>recurrent neural networks</phrase> <phrase>such as</phrase> the gru and lstm found wide adoption in <phrase>natural language</phrase> processing and <phrase>achieve state of</phrase> <phrase>the art</phrase> results for many tasks. <phrase>these models</phrase> are characterized by a memory state that can be written to and read from by applying gated composition operations to the current input and the <phrase>previous state</phrase>. however they only cover <phrase>a small</phrase> <phrase>subset of</phrase> potentially useful compositions. we propose multi function recurrent units mufurus that allow for arbitrary differentiable functions as composition operations. furthermore mufurus allow for an input and state dependent <phrase>choice of</phrase> these composition operations that is learned. our <phrase>experiments demonstrate</phrase> that the additional functionality helps in different <phrase>sequence modeling</phrase> tasks including the evaluation of <phrase>propositional logic</phrase> formulae <phrase>language modeling</phrase> and <phrase>sentiment analysis</phrase>.
lstmvis a tool for visual analysis of hidden state dynamics in <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> and <phrase>in particular</phrase> <phrase>long short term memory lstm</phrase> networks are a remarkably effective tool for <phrase>sequence modeling</phrase> that learn a dense <phrase>black box</phrase> hidden representation of their sequential input. researchers interested in better understanding <phrase>these models</phrase> have studied the changes in hidden state representations over time and noticed some interpretable patterns <phrase>but also</phrase> significant noise. in <phrase>this work</phrase> we present lstmvis a visual analysis tool for <phrase>recurrent neural networks</phrase> with a <phrase>focus on</phrase> understanding these hidden state dynamics. the tool allows users <phrase>to select</phrase> a hypothesis input range to <phrase>focus on</phrase> local state changes to match these states changes to similar patterns in <phrase>a large</phrase> <phrase>data set</phrase> and to align these results with structural annotations from their domain. we show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting phrase structure and chord progressions and demonstrate how the tool can be used to isolate patterns for further <phrase>statistical analysis</phrase>. we characterize the domain the different stakeholders and their goals and tasks.
compression of <phrase>neural machine translation</phrase> models via pruning
<phrase>neural machine translation</phrase> nmt like many other <phrase>deep learning</phrase> domains typically suffers from over parameterization resulting in large storage sizes. <phrase>this paper</phrase> examines three simple magnitude based pruning schemes to compress nmt models namely class blind class uniform and class distribution which differ <phrase>in terms of</phrase> how pruning thresholds are computed for the different classes of weights in the nmt architecture. we demonstrate <phrase>the efficacy of</phrase> weight pruning as a compression technique for a <phrase>state of</phrase> <phrase>the art</phrase> nmt system. we show that an nmt model with over 200 million parameters can be pruned by 40 with very little performance loss as measured on the wmt 14 english german translation task. this sheds light on the distribution of redundancy in the nmt architecture. our main result is that with retraining we can recover and even surpass <phrase>the original</phrase> performance with an 80 pruned model.
constructing a <phrase>natural language</phrase> inference dataset using generative <phrase>neural networks</phrase>
<phrase>natural language</phrase> inference is <phrase>an important</phrase> task for <phrase>natural language</phrase> understanding. it is concerned with classifying the logical relation between two sentences. in <phrase>this paper</phrase> we propose several text generative <phrase>neural networks</phrase> for generating text hypothesis which allows construction of new <phrase>natural language</phrase> inference datasets. to evaluate the models we propose <phrase>a new</phrase> metric the accuracy of the classifier <phrase>trained on</phrase> the generated dataset. the accuracy <phrase>obtained by</phrase> our best <phrase>generative model</phrase> is only 2.7 lower than the accuracy of the classifier <phrase>trained on</phrase> <phrase>the original</phrase> human crafted dataset. furthermore <phrase>the best</phrase> generated dataset <phrase>combined with</phrase> <phrase>the original</phrase> dataset achieves the highest accuracy. <phrase>the best</phrase> model learns a mapping embedding for each training example. by comparing various metrics we show that datasets that obtain higher rouge or meteor scores <phrase>do not</phrase> necessarily yield higher classification accuracies. we also provide analysis of what are the characteristics of a good dataset including the distinguishability of the generated datasets from <phrase>the original</phrase> one.
dataset and neural recurrent <phrase>sequence labeling</phrase> model for <phrase>open domain</phrase> factoid <phrase>question answering</phrase>
while <phrase>question answering</phrase> qa with <phrase>neural network</phrase> i.e. neural qa has achieved <phrase>promising results</phrase> <phrase>in recent years</phrase> lacking of <phrase>large scale</phrase> real word qa dataset is still a challenge for developing and evaluating neural qa system. to alleviate <phrase>this problem</phrase> we propose <phrase>a large</phrase> scale human annotated <phrase>real world</phrase> qa dataset webqa with <phrase>more than</phrase> 42k questions and 556k evidences. as existing neural qa methods resolve qa either as sequence generation or classification ranking problem they face challenges of expensive softmax computation unseen answers handling or separate candidate answer generation component. in <phrase>this work</phrase> we cast neural qa as a <phrase>sequence labeling</phrase> problem and propose <phrase>an end to end</phrase> <phrase>sequence labeling</phrase> model which overcomes all the above challenges. <phrase>experimental results</phrase> on webqa show that our <phrase>model outperforms</phrase> the baselines significantly with an f1 score of 74.69 with word based input and the performance drops only 3.72 f1 points with more challenging character based input.
tweet2vec learning tweet embeddings using <phrase>character level</phrase> cnn lstm <phrase>encoder decoder</phrase>
we present tweet2vec <phrase>a novel method</phrase> for generating <phrase>general purpose</phrase> vector representation of tweets. <phrase>the model</phrase> learns tweet embeddings using <phrase>character level</phrase> cnn lstm <phrase>encoder decoder</phrase>. we trained our model on 3 million randomly selected <phrase>english language</phrase> tweets. <phrase>the model</phrase> was evaluated using two methods tweet semantic similarity and tweet sentiment categorization outperforming the <phrase>previous state of</phrase> <phrase>the art</phrase> in both tasks. the evaluations demonstrate the power of the tweet embeddings generated by our model for various tweet categorization tasks. the <phrase>vector representations</phrase> generated by our model are generic and hence can be <phrase>applied to</phrase> <phrase>a variety of</phrase> tasks. though <phrase>the model</phrase> presented in <phrase>this paper</phrase> is <phrase>trained on</phrase> <phrase>english language</phrase> tweets the method presented can be used <phrase>to learn</phrase> tweet embeddings for different languages.
online segment to segment neural transduction
we introduce an online neural <phrase>sequence to sequence</phrase> model that learns to alternate between encoding and decoding segments of <phrase>the input</phrase> as it is read. by independently tracking the encoding and decoding representations our algorithm permits exact polynomial marginalization of the latent segmentation <phrase>during training</phrase> and during decoding <phrase>beam search</phrase> is employed to find <phrase>the best</phrase> alignment path together with the predicted output sequence. our model tackles the bottleneck of vanilla encoder decoders that have to read and memorize the entire <phrase>input sequence</phrase> in their fixed length hidden states before producing any output. it is different from previous attentive models in that <phrase>instead of</phrase> treating the attention weights as output of a deterministic function our model assigns attention weights to a sequential <phrase>latent variable</phrase> which can be marginalized out and permits online generation. <phrase>experiments on</phrase> abstractive sentence summarization and morphological inflection show significant performance gains over the baseline encoder decoders.
semantic parsing with <phrase>semi supervised</phrase> sequential autoencoders
we present <phrase>a novel</phrase> <phrase>semi supervised</phrase> approach for sequence transduction and apply it to semantic parsing. the unsupervised component is <phrase>based on</phrase> a <phrase>generative model</phrase> in which latent sentences generate the unpaired logical forms. we apply this method to <phrase>a number of</phrase> semantic parsing tasks focusing on domains with limited access to labelled <phrase>training data</phrase> and extend those datasets with synthetically generated logical forms.
exploiting sentence and context representations in <phrase>deep neural</phrase> models for spoken <phrase>language understanding</phrase>
<phrase>this paper</phrase> presents a <phrase>deep learning</phrase> architecture for the semantic decoder component of a statistical spoken dialogue system. in a slot filling dialogue the semantic decoder predicts the dialogue act and <phrase>a set of</phrase> slot value pairs from <phrase>a set of</phrase> n best hypotheses returned by the <phrase>automatic speech recognition</phrase>. most current models for spoken <phrase>language understanding</phrase> assume i word aligned semantic annotations as in sequence taggers and ii delexicalisation or a mapping of input words to <phrase>domain specific</phrase> concepts using heuristics that try <phrase>to capture</phrase> morphological variation but that <phrase>do not</phrase> scale to other domains nor to language variation e.g. morphology synonyms paraphrasing . in <phrase>this work</phrase> the semantic decoder is trained using unaligned semantic annotations and it uses distributed semantic <phrase>representation learning</phrase> <phrase>to overcome</phrase> the limitations of explicit delexicalisation. <phrase>the proposed</phrase> architecture uses <phrase>a convolutional neural network</phrase> for the sentence representation and a <phrase>long short term memory</phrase> network for the context representation. results are presented for the <phrase>publicly available</phrase> dstc2 corpus and an in car corpus which is <phrase>similar to</phrase> dstc2 but has a significantly higher <phrase>word error rate</phrase> wer .
the neural noisy channel
we formulate <phrase>sequence to sequence</phrase> transduction as a noisy channel decoding problem and use <phrase>recurrent neural networks</phrase> to parameterise the source and channel models. unlike direct models which can <phrase>suffer from</phrase> explaining away effects <phrase>during training</phrase> noisy channel models must produce outputs that explain their inputs and their component models can be trained with <phrase>not only</phrase> paired <phrase>training samples</phrase> <phrase>but also</phrase> unpaired samples from the marginal output distribution. using a <phrase>latent variable</phrase> to control how much of the conditioning sequence the channel model <phrase>needs to</phrase> read <phrase>in order to</phrase> generate a subsequent symbol we obtain a tractable and effective <phrase>beam search</phrase> decoder. <phrase>experimental results</phrase> on abstractive sentence summarisation morphological inflection and <phrase>machine translation</phrase> show that noisy channel models outperform direct models and that they significantly benefit from increased <phrase>amounts of</phrase> unpaired output data that direct models cannot easily use.
generative <phrase>deep neural networks</phrase> for dialogue a short review
researchers have recently started investigating <phrase>deep neural networks</phrase> for dialogue applications. <phrase>in particular</phrase> generative <phrase>sequence to sequence</phrase> seq2seq models have shown <phrase>promising results</phrase> for unstructured <phrase>tasks such as</phrase> <phrase>word level</phrase> dialogue <phrase>response generation</phrase>. the hope is that such models will be <phrase>able to</phrase> leverage massive <phrase>amounts of</phrase> data <phrase>to learn</phrase> meaningful <phrase>natural language</phrase> representations and <phrase>response generation</phrase> strategies while requiring a minimum <phrase>amount of</phrase> <phrase>domain knowledge</phrase> and hand crafting. <phrase>an important</phrase> challenge is to develop models that can effectively incorporate dialogue context and generate meaningful and diverse responses. in support of this goal we review <phrase>recently proposed</phrase> models <phrase>based on</phrase> generative <phrase>encoder decoder</phrase> <phrase>neural network</phrase> architectures and show that <phrase>these models</phrase> have better <phrase>ability to</phrase> incorporate <phrase>long term</phrase> dialogue history to model uncertainty and ambiguity in dialogue and <phrase>to generate</phrase> responses with <phrase>high level</phrase> compositional structure.
learning python code suggestion with a sparse pointer network
to enhance developer productivity all modern integrated development environments ides include code suggestion functionality that proposes likely next tokens at the cursor. while current ides work well for statically typed languages their reliance on type annotations means that they <phrase>do not</phrase> provide <phrase>the same</phrase> level of support for <phrase>dynamic programming</phrase> languages as for statically typed languages. moreover suggestion engines in modern ides <phrase>do not</phrase> propose expressions or multi statement idiomatic code. <phrase>recent work</phrase> has shown that <phrase>language models</phrase> can improve code suggestion systems by learning from software repositories. <phrase>this paper</phrase> introduces a neural <phrase>language model</phrase> with a sparse pointer network aimed at capturing very <phrase>long range</phrase> dependencies. we release <phrase>a large</phrase> scale code suggestion corpus of 41m lines of python code crawled from github. on this corpus we found standard <phrase>neural language models</phrase> <phrase>to perform</phrase> well at suggesting local phenomena but struggle to refer to identifiers that are introduced many tokens in <phrase>the past</phrase>. by augmenting a neural <phrase>language model</phrase> with a pointer network specialized in referring to predefined classes of identifiers we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion <phrase>compared to</phrase> an lstm baseline. in fact this increase in code suggestion accuracy is <phrase>due to</phrase> a 13 times <phrase>more accurate</phrase> prediction of identifiers. furthermore a qualitative analysis shows this model indeed captures interesting <phrase>long range</phrase> dependencies like referring to a class member defined over 60 tokens in <phrase>the past</phrase>.
opennmt <phrase>open source</phrase> toolkit for <phrase>neural machine translation</phrase>
we describe an <phrase>open source</phrase> toolkit for <phrase>neural machine translation</phrase> nmt . the toolkit prioritizes efficiency modularity and extensibility with <phrase>the goal of</phrase> supporting nmt research into model architectures <phrase>feature representations</phrase> and source modalities while maintaining competitive performance and reasonable training requirements. the toolkit <phrase>consists of</phrase> modeling and translation support <phrase>as well as</phrase> detailed pedagogical documentation about the underlying techniques.
making neural qa as simple as possible but not simpler
recent development of <phrase>large scale</phrase> <phrase>question answering</phrase> qa datasets triggered a substantial <phrase>amount of</phrase> research into <phrase>end to end</phrase> <phrase>neural architectures</phrase> for qa. increasingly <phrase>complex systems</phrase> have been conceived without comparison to simpler neural baseline systems that would justify their complexity. in <phrase>this work</phrase> we propose <phrase>a simple</phrase> heuristic that guides the development of neural baseline systems for the extractive qa task. we find that there are two ingredients necessary for building a high performing neural qa system first the awareness of question words while processing the context and second a composition function that goes beyond simple bag of words modeling <phrase>such as</phrase> <phrase>recurrent neural networks</phrase>. our <phrase>results show</phrase> that fastqa a system that meets these two requirements can achieve very competitive performance <phrase>compared with</phrase> existing models. we argue that this surprising finding puts results of previous systems and <phrase>the complexity of</phrase> recent qa datasets into perspective.
survey of the <phrase>state of</phrase> <phrase>the art</phrase> in <phrase>natural language</phrase> generation core tasks applications and evaluation
<phrase>this paper</phrase> surveys <phrase>the current state of</phrase> <phrase>the art</phrase> in <phrase>natural language</phrase> generation nlg defined as <phrase>the task of</phrase> generating text or speech from non linguistic input. a survey of nlg is timely in view of the changes that the field has undergone over <phrase>the past</phrase> decade or so especially in relation to new usually <phrase>data driven</phrase> methods <phrase>as well as</phrase> new applications of nlg technology. this survey therefore aims to a give an up <phrase>to date</phrase> synthesis of research on the core tasks in nlg and the architectures adopted in which such tasks are organised b highlight <phrase>a number of</phrase> relatively recent research topics that have arisen partly as a result of growing synergies between nlg and other areas of <phrase>artificial intelligence</phrase> c draw attention to the challenges in nlg evaluation relating them to similar challenges faced in other areas of <phrase>natural language</phrase> processing with an emphasis on different evaluation methods and the relationships between them.
a constrained <phrase>sequence to sequence</phrase> neural model for sentence simplification
sentence simplification reduces semantic complexity to benefit people with language impairments. previous simplification studies on the <phrase>sentence level</phrase> and <phrase>word level</phrase> have achieved <phrase>promising results</phrase> <phrase>but also</phrase> meet great challenges. for <phrase>sentence level</phrase> studies sentences after simplification are fluent but sometimes are not really simplified. for <phrase>word level</phrase> studies words are simplified <phrase>but also</phrase> have potential grammar errors <phrase>due to</phrase> different usages of words before and after simplification. in <phrase>this paper</phrase> we propose a two step simplification framework by combining both the <phrase>word level</phrase> and the <phrase>sentence level</phrase> simplifications making use of their corresponding advantages. <phrase>based on</phrase> the two step framework we implement <phrase>a novel</phrase> constrained neural generation model to simplify sentences given simplified words. <phrase>the final</phrase> <phrase>results on</phrase> wikipedia and simple wikipedia aligned datasets indicate that our method yields <phrase>better performance</phrase> than various baselines.
improved neural relation detection for <phrase>knowledge base</phrase> <phrase>question answering</phrase>
relation detection is a core component for many nlp applications including <phrase>knowledge base</phrase> <phrase>question answering</phrase> kbqa . in <phrase>this paper</phrase> we propose a hierarchical <phrase>recurrent neural network</phrase> enhanced by residual learning that detects kb relations given an input question. our method uses deep residual bidirectional lstms to compare questions and relation names via different hierarchies of abstraction. additionally we propose <phrase>a simple</phrase> kbqa system that integrates entity linking and our proposed relation detector to enable one enhance another. <phrase>experimental results</phrase> evidence that our approach achieves <phrase>not only</phrase> outstanding relation detection performance but more importantly it helps our kbqa system to <phrase>achieve state of</phrase> <phrase>the art</phrase> accuracy for both single relation simplequestions and multi relation webqsp qa benchmarks.
asr error management for improving spoken <phrase>language understanding</phrase>
<phrase>this paper</phrase> addresses <phrase>the problem of</phrase> <phrase>automatic speech recognition</phrase> asr <phrase>error detection</phrase> and their use for improving spoken <phrase>language understanding</phrase> slu systems. in <phrase>this study</phrase> the slu task consists in automatically extracting from asr transcriptions semantic concepts and concept values pairs in a e.g touristic information system. an approach is proposed for enriching the <phrase>set of</phrase> semantic labels with error specific labels and <phrase>by using</phrase> a <phrase>recently proposed</phrase> neural <phrase>approach based on</phrase> <phrase>word embeddings</phrase> to compute well calibrated asr confidence measures. <phrase>experimental results</phrase> are reported showing that it is possible to decrease significantly the concept value <phrase>error rate</phrase> with a <phrase>state of</phrase> <phrase>the art</phrase> system outperforming previously published results <phrase>performance on</phrase> <phrase>the same</phrase> experimental data. it also shown that combining an slu <phrase>approach based on</phrase> conditional random fields with a neural <phrase>encoder decoder</phrase> <phrase>attention based</phrase> architecture it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy .
dynamic integration of background knowledge in neural nlu systems
common sense or background knowledge is required <phrase>to understand</phrase> <phrase>natural language</phrase> but in most neural <phrase>natural language</phrase> understanding nlu systems the requisite background knowledge is indirectly acquired from static corpora. we develop <phrase>a new</phrase> reading architecture for the dynamic integration of explicit background knowledge in nlu models. <phrase>a new</phrase> task agnostic reading module provides refined word representations to a <phrase>task specific</phrase> nlu architecture by processing background knowledge in the form of free text statements together with the <phrase>task specific</phrase> inputs. strong <phrase>performance on</phrase> the tasks of document <phrase>question answering</phrase> dqa and recognizing <phrase>textual entailment</phrase> rte demonstrate the effectiveness and flexibility of our approach. analysis shows that our models learn to exploit knowledge selectively and in a semantically appropriate way.
rethinking <phrase>skip thought</phrase> a neighborhood <phrase>based approach</phrase>
we study the <phrase>skip thought</phrase> model with neighborhood information as weak supervision. more specifically we propose a <phrase>skip thought</phrase> neighbor model to consider the adjacent sentences as a neighborhood. we train our <phrase>skip thought</phrase> neighbor model on <phrase>a large</phrase> corpus with continuous sentences and then evaluate the trained model on 7 tasks which include semantic relatedness paraphrase detection and classification benchmarks. both quantitative comparison and qualitative investigation are conducted. we empirically show that our <phrase>skip thought</phrase> neighbor model performs <phrase>as well as</phrase> the <phrase>skip thought</phrase> model on evaluation tasks. <phrase>in addition</phrase> we found that incorporating an autoencoder path in our model didn t aid our model <phrase>to perform</phrase> better while it hurts <phrase>the performance of</phrase> the <phrase>skip thought</phrase> model.
neural <phrase>domain adaptation</phrase> for biomedical <phrase>question answering</phrase>
factoid <phrase>question answering</phrase> qa has recently benefited from the development of <phrase>deep learning</phrase> dl systems. <phrase>neural network</phrase> models outperform traditional approaches in domains where large datasets exist <phrase>such as</phrase> squad ca. 100 000 questions for wikipedia articles. however these systems have not yet been <phrase>applied to</phrase> qa in more specific <phrase>domains such as</phrase> biomedicine because datasets are generally too small <phrase>to train</phrase> a dl system <phrase>from scratch</phrase>. for example the bioasq dataset for biomedical qa comprises less then 900 factoid single answer and list multiple answers qa instances. in <phrase>this work</phrase> we adapt a neural qa system <phrase>trained on</phrase> <phrase>a large</phrase> <phrase>open domain</phrase> dataset squad source to a biomedical dataset bioasq target by employing various <phrase>transfer learning</phrase> techniques. our <phrase>network architecture</phrase> is <phrase>based on</phrase> a <phrase>state of</phrase> <phrase>the art</phrase> qa system extended with biomedical <phrase>word embeddings</phrase> and <phrase>a novel</phrase> mechanism to answer list questions. <phrase>in contrast to</phrase> existing biomedical qa systems our system <phrase>does not</phrase> <phrase>rely on</phrase> <phrase>domain specific</phrase> ontologies parsers or entity taggers which are expensive to create. despite this fact our systems <phrase>achieve state of</phrase> <phrase>the art results</phrase> on factoid questions and <phrase>competitive results</phrase> on list questions.
<phrase>neural models</phrase> for key phrase detection and question generation
we propose a two stage neural model <phrase>to tackle</phrase> question generation from documents. our model first estimates the probability that word sequences in a document compose interesting answers using a neural model <phrase>trained on</phrase> a <phrase>question answering</phrase> corpus. we thus take a <phrase>data driven</phrase> <phrase>approach to</phrase> interestingness. predicted key phrases then act as target answers that condition a <phrase>sequence to sequence</phrase> question generation model with a copy mechanism. empirically our neural key phrase detection model <phrase>significantly outperforms</phrase> an entity tagging baseline system and existing rule <phrase>based approaches</phrase>. we demonstrate that the question generator formulates good quality <phrase>natural language</phrase> questions from extracted key phrases and a human study indicates that our system s generated <phrase>question answer</phrase> pairs are competitive with those of an earlier approach. we foresee our system being used in an educational setting to assess <phrase>reading comprehension</phrase> and also as a <phrase>data augmentation</phrase> technique for <phrase>semi supervised</phrase> learning.
neural <phrase>question answering</phrase> at bioasq 5b
<phrase>this paper</phrase> describes our submission to the 2017 bioasq challenge. we participated in task b phase b which is concerned with biomedical <phrase>question answering</phrase> qa . we <phrase>focus on</phrase> factoid and list question using an extractive qa model that is we restrict our system to output substrings of the provided text snippets. at the core of our system we use fastqa a <phrase>state of</phrase> <phrase>the art</phrase> neural qa system. we extended it with biomedical <phrase>word embeddings</phrase> and changed its answer layer to be <phrase>able to</phrase> answer list questions <phrase>in addition</phrase> to factoid questions. we <phrase>pre trained</phrase> <phrase>the model</phrase> on <phrase>a large</phrase> scale <phrase>open domain</phrase> qa dataset squad and then fine tuned the parameters on the bioasq <phrase>training set</phrase>. with our approach we <phrase>achieve state of</phrase> <phrase>the art results</phrase> on factoid questions and <phrase>competitive results</phrase> on list questions.
a <phrase>deep network</phrase> with visual text composition behavior
while natural languages are compositional how <phrase>state of</phrase> <phrase>the art</phrase> <phrase>neural models</phrase> achieve compositionality is still unclear. we propose a <phrase>deep network</phrase> which <phrase>not only</phrase> achieves competitive accuracy for <phrase>text classification</phrase> <phrase>but also</phrase> exhibits compositional behavior. that is while creating hierarchical representations of a piece of text <phrase>such as</phrase> a sentence the lower layers of <phrase>the network</phrase> distribute their layer specific attention weights to individual words. <phrase>in contrast</phrase> the higher layers compose meaningful phrases and clauses whose lengths increase as the networks get deeper until fully composing the sentence.
<phrase>semi supervised</phrase> emotion lexicon expansion with label propagation and specialized <phrase>word embeddings</phrase>
there exist two main approaches to automatically extract affective orientation lexicon based and corpus based. in <phrase>this work</phrase> we argue that these two methods are compatible and show that combining them can improve the accuracy of emotion classifiers. <phrase>in particular</phrase> we introduce <phrase>a novel</phrase> variant of the label propagation algorithm that is tailored to distributed word representations we apply batch <phrase>gradient descent</phrase> to accelerate the optimization of label propagation and to make the optimization feasible for large graphs and we propose a reproducible <phrase>method for</phrase> emotion lexicon expansion. we conclude that label propagation can expand an emotion lexicon in a meaningful way and that the expanded emotion lexicon can be leveraged <phrase>to improve</phrase> the accuracy of an emotion classifier.
modelling protagonist goals and desires in <phrase>first person narrative</phrase>
many genres of <phrase>natural language</phrase> text are narratively structured a testament to our predilection for organizing our experiences as narratives. there is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. however <phrase>to date</phrase> there has been limited work on computational models for <phrase>this problem</phrase>. we introduce <phrase>a new</phrase> dataset desiredb which includes <phrase>gold standard</phrase> labels for identifying statements of desire textual evidence for desire fulfillment and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. we report <phrase>experiments on</phrase> tracking desire fulfillment using different methods and show that lstm <phrase>skip thought</phrase> <phrase>model achieves</phrase> f measure of 0.7 on our corpus.
understanding grounded language learning agents
<phrase>neural network</phrase> based systems can now learn to locate the referents of words and phrases in images answer <phrase>questions about</phrase> visual scenes and even execute symbolic instructions as first person actors in <phrase>partially observable</phrase> worlds. to achieve this so called grounded language <phrase>learning models</phrase> must overcome certain well studied learning challenges that are also fundamental to infants learning their first words. while it is notable that models with no meaningful <phrase>prior knowledge</phrase> overcome these learning obstacles ai researchers and practitioners currently lack a clear understanding of exactly how they do so. here we address this question as a way of achieving a clearer general understanding of grounded language learning both to inform future research and <phrase>to improve</phrase> confidence in model predictions. for maximum control and generality we <phrase>focus on</phrase> <phrase>a simple</phrase> <phrase>neural network</phrase> based language learning agent trained via policy gradient methods to interpret synthetic linguistic instructions in a simulated 3d world. we apply experimental paradigms from <phrase>developmental psychology</phrase> to this agent exploring the conditions under which established human biases and learning effects emerge. we further propose <phrase>a novel</phrase> way to visualise and analyse semantic representation in grounded language learning agents that yields a plausible computational account of the observed effects.
just ask building an architecture for extensible self service spoken <phrase>language understanding</phrase>
<phrase>this paper</phrase> presents the design of the <phrase>machine learning</phrase> architecture that underlies the alexa skills kit ask <phrase>a large</phrase> scale spoken <phrase>language understanding</phrase> slu <phrase>software development</phrase> kit sdk that enables developers to extend the capabilities of amazon s virtual assistant alexa. at amazon the infrastructure powers over 25 000 skills deployed through the ask <phrase>as well as</phrase> aws s amazon lex slu service. the ask emphasizes flexibility predictability and a rapid iteration cycle for third party developers. it imposes inductive biases that allow it <phrase>to learn</phrase> robust slu models from extremely small and sparse datasets and in doing so removes significant barriers to entry for software developers and <phrase>dialogue systems</phrase> researchers.
the narrativeqa <phrase>reading comprehension</phrase> challenge
<phrase>reading comprehension</phrase> rc <phrase>in contrast to</phrase> <phrase>information retrieval</phrase> requires integrating information and reasoning about events entities and their relations across a full document. <phrase>question answering</phrase> is conventionally used to assess rc ability in both artificial agents and children learning to read. however existing rc datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information e.g. local context similarity or global term frequency they thus fail to test for the essential integrative aspect of rc. to encourage progress on deeper comprehension of language we present <phrase>a new</phrase> dataset and <phrase>set of</phrase> tasks in which the reader must answer <phrase>questions about</phrase> stories by reading entire books or movie scripts. these tasks are designed so that successfully answering their questions requires understanding the underlying narrative <phrase>rather than</phrase> relying on shallow <phrase>pattern matching</phrase> or salience. we show that although humans solve the tasks easily standard rc models struggle on the tasks presented here. we provide an analysis of the dataset and the challenges it presents.
cognitive database a <phrase>step towards</phrase> endowing <phrase>relational databases</phrase> with <phrase>artificial intelligence</phrase> capabilities
we propose cognitive databases an approach for transparently enabling <phrase>artificial intelligence</phrase> ai capabilities in <phrase>relational databases</phrase>. <phrase>a novel</phrase> aspect of our design is to first view the structured data source as meaningful unstructured text and then use the text to build an unsupervised <phrase>neural network</phrase> model using a <phrase>natural language</phrase> processing nlp technique called <phrase>word embedding</phrase>. this model captures the hidden inter intra column relationships between database tokens of different types. for each database token <phrase>the model</phrase> includes a vector that encodes contextual semantic relationships. we seamlessly integrate the <phrase>word embedding</phrase> model into existing sql query infrastructure and use it to enable <phrase>a new</phrase> class of sql based analytics queries called cognitive intelligence ci queries. ci queries use <phrase>the model</phrase> vectors to enable complex queries <phrase>such as</phrase> semantic matching <phrase>inductive reasoning</phrase> queries <phrase>such as</phrase> analogies predictive queries using entities not present in a database and more generally using knowledge from external sources. we demonstrate unique capabilities of cognitive databases using an apache spark based prototype to execute <phrase>inductive reasoning</phrase> ci queries over a multi modal database containing text and images. we believe our first of a kind system exemplifies using ai functionality to endow <phrase>relational databases</phrase> with capabilities that were previously very hard to realize <phrase>in practice</phrase>.
feudal <phrase>reinforcement learning</phrase> for dialogue management in large domains
<phrase>reinforcement learning</phrase> rl is a promising <phrase>approach to</phrase> solve dialogue policy optimisation. traditional rl algorithms however fail to scale to large domains <phrase>due to</phrase> the curse of dimensionality. we propose <phrase>a novel</phrase> dialogue management architecture <phrase>based on</phrase> feudal rl which decomposes the decision into two steps a first step where a master policy selects <phrase>a subset of</phrase> primitive actions and a second step where a primitive action is chosen from the selected subset. the structural information included in the domain ontology is used to abstract the dialogue <phrase>state space</phrase> taking the decisions at each step using different <phrase>parts of</phrase> the abstracted state. this <phrase>combined with</phrase> an information sharing mechanism between slots increases the scalability to large domains. we show that an implementation of <phrase>this approach</phrase> <phrase>based on</phrase> <phrase>deep q</phrase> networks <phrase>significantly outperforms</phrase> <phrase>previous state of</phrase> <phrase>the art</phrase> in several dialogue domains and environments without the need of any additional reward signal.
an analysis of neural <phrase>language modeling</phrase> at multiple scales
many of the leading approaches in <phrase>language modeling</phrase> introduce novel complex and specialized architectures. we take existing <phrase>state of</phrase> <phrase>the art</phrase> <phrase>word level</phrase> <phrase>language models</phrase> <phrase>based on</phrase> lstms and qrnns and extend them to both larger vocabularies <phrase>as well as</phrase> <phrase>character level</phrase> granularity. when properly tuned lstms and qrnns <phrase>achieve state of</phrase> <phrase>the art results</phrase> on <phrase>character level</phrase> <phrase>penn treebank</phrase> enwik8 and <phrase>word level</phrase> wikitext 103 datasets respectively. results are obtained in only 12 hours wikitext 103 to 2 days enwik8 using <phrase>a single</phrase> modern gpu.
spatial diffuseness features for dnn based <phrase>speech recognition</phrase> in noisy and reverberant environments
we propose a spatial diffuseness feature for <phrase>deep neural network</phrase> dnn based <phrase>automatic speech recognition</phrase> <phrase>to improve</phrase> recognition accuracy in reverberant and noisy environments. the feature is computed in <phrase>real time</phrase> from multiple microphone signals <phrase>without requiring</phrase> knowledge or estimation of the direction of arrival and represents the relative <phrase>amount of</phrase> diffuse noise in each time and frequency bin. it is shown that using the diffuseness feature as an additional input to a dnn based acoustic model <phrase>leads to</phrase> a reduced <phrase>word error rate</phrase> for the reverb challenge corpus both <phrase>compared to</phrase> logmelspec features <phrase>extracted from</phrase> noisy signals and features enhanced by spectral subtraction.
character aware <phrase>neural language models</phrase>
we describe <phrase>a simple</phrase> neural <phrase>language model</phrase> that relies only on <phrase>character level</phrase> inputs. predictions are still made at the <phrase>word level</phrase>. our model employs <phrase>a convolutional neural network</phrase> cnn and a highway network over characters whose output is given to a <phrase>long short term memory lstm</phrase> <phrase>recurrent neural network</phrase> <phrase>language model</phrase> rnn lm . on the english <phrase>penn treebank</phrase> <phrase>the model</phrase> is on par with the existing <phrase>state of</phrase> <phrase>the art</phrase> despite having 60 <phrase>fewer parameters</phrase>. on languages with rich morphology arabic czech french german spanish russian <phrase>the model</phrase> outperforms <phrase>word level</phrase> morpheme level lstm baselines again with <phrase>fewer parameters</phrase>. the <phrase>results suggest</phrase> that on many languages character inputs are sufficient for <phrase>language modeling</phrase>. analysis of word representations obtained from the character composition part of <phrase>the model</phrase> reveals that <phrase>the model</phrase> is <phrase>able to</phrase> encode from characters only both semantic and orthographic information.
neural based <phrase>machine translation</phrase> for medical text domain. <phrase>based on</phrase> <phrase>european medicines agency</phrase> leaflet texts
the quality of <phrase>machine translation</phrase> is rapidly evolving. today one can find several <phrase>machine translation</phrase> systems on the web that provide reasonable translations although the systems are not perfect. in some specific domains the quality may decrease. a <phrase>recently proposed</phrase> <phrase>approach to</phrase> this domain is <phrase>neural machine translation</phrase>. it aims at building a jointly tuned single <phrase>neural network</phrase> that maximizes translation performance a very different approach from traditional <phrase>statistical machine translation</phrase>. <phrase>recently proposed</phrase> <phrase>neural machine translation</phrase> models often belong to the <phrase>encoder decoder</phrase> family in which a <phrase>source sentence</phrase> is encoded into <phrase>a fixed</phrase> length vector that is in turn decoded <phrase>to generate</phrase> a translation. the present research examines the effects of different training methods on a polish english <phrase>machine translation</phrase> system used for medical data. the <phrase>european medicines agency</phrase> parallel <phrase>text corpus</phrase> was <phrase>used as</phrase> the basis for training of neural and statistical network based translation systems. the main <phrase>machine translation</phrase> <phrase>evaluation metrics</phrase> have also been used in analysis of the systems. a comparison and implementation of a <phrase>real time</phrase> medical translator is the main focus of our experiments.
conditional generation and snapshot learning in neural <phrase>dialogue systems</phrase>
recently <phrase>a variety of</phrase> lstm based conditional <phrase>language models</phrase> lm have been applied across <phrase>a range of</phrase> language generation tasks. in <phrase>this work</phrase> we study various model architectures and different ways <phrase>to represent</phrase> and aggregate the source information in <phrase>an end to end</phrase> neural dialogue system framework. a method called snapshot learning is also proposed to facilitate learning from supervised sequential signals by applying a companion <phrase>cross entropy</phrase> <phrase>objective function</phrase> to the conditioning vector. the experimental and analytical <phrase>results demonstrate</phrase> firstly that competition occurs between the conditioning vector and the lm and the differing architectures provide different trade offs between the two. secondly the discriminative power and transparency of the conditioning vector is key to providing both model interpretability and <phrase>better performance</phrase>. thirdly snapshot learning <phrase>leads to</phrase> consistent performance improvements independent of which architecture is used.
dialog state tracking a machine reading approach using <phrase>memory network</phrase>
in <phrase>an end to end</phrase> dialog system the aim of dialog state tracking is to accurately estimate a compact representation of the current dialog status from a sequence of noisy observations <phrase>produced by</phrase> the <phrase>speech recognition</phrase> and the <phrase>natural language</phrase> understanding modules. <phrase>this paper</phrase> introduces <phrase>a novel</phrase> method of dialog state tracking <phrase>based on</phrase> the general paradigm of machine reading and proposes <phrase>to solve</phrase> it using <phrase>an end to end</phrase> <phrase>memory network</phrase> memn2n a memory enhanced <phrase>neural network</phrase> architecture. we evaluate <phrase>the proposed</phrase> approach on the second dialog state tracking challenge dstc 2 dataset. the corpus has been converted for the occasion <phrase>in order to</phrase> frame the hidden state variable inference as a <phrase>question answering</phrase> task <phrase>based on</phrase> a sequence of utterances <phrase>extracted from</phrase> a dialog. we show that <phrase>the proposed</phrase> tracker gives encouraging results. then we propose to extend the dstc 2 dataset with specific reasoning capabilities requirement like counting list maintenance yes no <phrase>question answering</phrase> and indefinite <phrase>knowledge management</phrase>. finally we present encouraging results using our proposed memn2n based tracking model.
a physical metaphor to study semantic drift
in accessibility tests for <phrase>digital preservation</phrase> over time we experience drifts of localized and labelled content in statistical models of evolving semantics represented as a <phrase>vector field</phrase>. this articulates the <phrase>need to</phrase> detect measure interpret and model outcomes of knowledge dynamics. to this end we employ a high performance <phrase>machine learning</phrase> algorithm for the training of extremely large emergent self organizing maps for <phrase>exploratory data analysis</phrase>. the working hypothesis we present here is that the dynamics of semantic drifts can be modeled on a relaxed <phrase>version of</phrase> <phrase>newtonian mechanics</phrase> called social mechanics. <phrase>by using</phrase> term distances as a measure of semantic relatedness vs. their pagerank values indicating social importance and applied as variable term mass gravitation as a metaphor to express changes in the semantic content of a <phrase>vector field</phrase> lends <phrase>a new</phrase> perspective for experimentation. from term gravitation over time one can compute its generating potential whose fluctuations manifest modifications in pairwise term similarity vs. social importance thereby updating osgood s semantic differential. the dataset examined is the public catalog metadata of tate galleries london.
optimizing <phrase>neural network</phrase> hyperparameters with gaussian processes for dialog act classification
systems <phrase>based on</phrase> <phrase>artificial neural networks</phrase> anns have achieved <phrase>state of</phrase> <phrase>the art</phrase> results in many <phrase>natural language</phrase> processing tasks. although anns <phrase>do not</phrase> require manually engineered features anns have many hyperparameters to be optimized. the <phrase>choice of</phrase> hyperparameters significantly impacts models performances. however the ann hyperparameters are typically chosen by manual grid or random search which either requires expert experiences or is computationally expensive. recent approaches <phrase>based on</phrase> bayesian optimization using gaussian processes gps is a more systematic way to automatically pinpoint optimal or near optimal <phrase>machine learning</phrase> hyperparameters. using a previously published ann model yielding <phrase>state of</phrase> <phrase>the art</phrase> results for dialog act classification we demonstrate that optimizing hyperparameters using gp further improves the results and reduces the computational time by a factor of 4 <phrase>compared to</phrase> a random search. therefore it is a useful technique for tuning ann models to yield <phrase>the best</phrase> performances for <phrase>natural language</phrase> processing tasks.
a survey of voice translation methodologies acoustic dialect decoder
speech translation has always been about giving source text or audio input and waiting for system to give translated output in desired form. in <phrase>this paper</phrase> we present the acoustic dialect decoder add a voice to voice ear piece translation device. we introduce and survey the <phrase>recent advances</phrase> made in <phrase>the field of</phrase> speech engineering to employ in the add particularly focusing on the three major processing steps of recognition translation and synthesis. we tackle <phrase>the problem of</phrase> machine understanding of <phrase>natural language</phrase> by designing a recognition unit for source audio to text a translation unit for source language text to <phrase>target language</phrase> text and a synthesis unit for <phrase>target language</phrase> text to <phrase>target language</phrase> speech. speech from the surroundings will be recorded by the recognition unit present on the ear piece and translation will start as soon as one sentence is successfully read. this way we hope to give translated output as and when input is being read. the recognition unit will use <phrase>hidden markov models</phrase> hmms based tool kit htk hybrid rnn systems with gated memory cells and the synthesis unit hmm based <phrase>speech synthesis</phrase> system hts. this system will initially be built as an english to tamil translation device.
learning to reason with adaptive computation
multi hop inference is necessary for <phrase>machine learning</phrase> systems to successfully solve <phrase>tasks such as</phrase> recognising <phrase>textual entailment</phrase> and machine reading. in <phrase>this work</phrase> we demonstrate <phrase>the effectiveness of</phrase> adaptive computation for learning <phrase>the number of</phrase> inference steps required for examples of different complexity and that learning the correct <phrase>number of</phrase> inference steps is difficult. we introduce the first model involving adaptive computation time which provides <phrase>a small</phrase> performance benefit on top of a similar model without an adaptive component <phrase>as well as</phrase> enabling considerable insight into the reasoning process of <phrase>the model</phrase>.
feature augmented <phrase>neural networks</phrase> for patient note <phrase>de identification</phrase>
patient notes contain a wealth of information of potentially great interest to medical investigators. however to protect patients privacy protected health information phi must be removed from the patient notes before they can be legally released a process <phrase>known as</phrase> patient note <phrase>de identification</phrase>. the main objective for a <phrase>de identification</phrase> system is to have the highest possible recall. recently the first <phrase>neural network</phrase> based <phrase>de identification</phrase> system has been proposed yielding <phrase>state of</phrase> <phrase>the art</phrase> results. unlike other systems it <phrase>does not</phrase> <phrase>rely on</phrase> human engineered features which allows it to be quickly deployed but <phrase>does not</phrase> leverage knowledge from human experts or from <phrase>electronic health records</phrase> ehrs . in <phrase>this work</phrase> we explore a method to incorporate human engineered features <phrase>as well as</phrase> features <phrase>derived from</phrase> ehrs to <phrase>a neural network</phrase> based <phrase>de identification</phrase> system. our <phrase>results show</phrase> that the addition of features especially the ehr derived features further improves the <phrase>state of</phrase> <phrase>the art</phrase> in patient note <phrase>de identification</phrase> including for some of the most sensitive phi types <phrase>such as</phrase> patient names. since in a real life setting patient notes typically come with ehrs we recommend developers of <phrase>de identification</phrase> systems to leverage the information ehrs contain.
direct acoustics to word models for english conversational <phrase>speech recognition</phrase>
<phrase>recent work</phrase> on <phrase>end to end</phrase> <phrase>automatic speech recognition</phrase> asr has shown that the connectionist temporal classification ctc loss can be used to convert acoustics to phone or character sequences. such systems are used with a dictionary and separately trained <phrase>language model</phrase> lm <phrase>to produce</phrase> word sequences. however they are not truly <phrase>end to end</phrase> in the sense of mapping acoustics directly to words without an intermediate phone representation. in <phrase>this paper</phrase> we present the first results employing direct acoustics to word ctc models on two <phrase>well known</phrase> public benchmark tasks switchboard and callhome. <phrase>these models</phrase> <phrase>do not</phrase> require an lm or even a decoder at run time and hence recognize speech <phrase>with minimal</phrase> complexity. however <phrase>due to</phrase> the <phrase>large number of</phrase> word output units ctc word models require orders <phrase>of magnitude</phrase> more data <phrase>to train</phrase> reliably <phrase>compared to</phrase> traditional systems. we present some techniques to mitigate <phrase>this issue</phrase>. our ctc word <phrase>model achieves</phrase> a <phrase>word error rate</phrase> of 13.0 18.8 on the hub5 2000 switchboard callhome test sets without any lm or decoder <phrase>compared with</phrase> 9.6 16.0 for phone based ctc with <phrase>a 4</phrase> gram lm. we <phrase>also present</phrase> rescoring <phrase>results on</phrase> ctc word model lattices to quantify the performance benefits of a lm and contrast <phrase>the performance of</phrase> word and phone ctc models.
factorization tricks for <phrase>lstm networks</phrase>
we present two simple ways of reducing <phrase>the number of</phrase> parameters and accelerating the training of large <phrase>long short term memory lstm</phrase> networks the first one is matrix factorization by design of lstm matrix into the product of two smaller matrices and the second one is partitioning of lstm matrix its inputs and states into the independent groups. both approaches allow us <phrase>to train</phrase> large <phrase>lstm networks</phrase> significantly faster to the near <phrase>state of</phrase> <phrase>the art</phrase> perplexity while using significantly less rnn parameters.
neuroner an <phrase>easy to</phrase> use program for <phrase>named entity recognition</phrase> <phrase>based on</phrase> <phrase>neural networks</phrase>
<phrase>named entity recognition</phrase> ner aims at identifying entities of interest in a text. <phrase>artificial neural networks</phrase> anns have recently been <phrase>shown to</phrase> outperform existing ner systems. however anns remain challenging to use for non expert users. in <phrase>this paper</phrase> we present neuroner an <phrase>easy to</phrase> use <phrase>named entity recognition</phrase> tool <phrase>based on</phrase> anns. users can annotate entities using a graphical web based <phrase>user interface</phrase> brat the annotations are then used <phrase>to train</phrase> an ann which in turn predict entities locations and categories in new texts. neuroner makes this annotation training prediction flow smooth and accessible to anyone.
syllable aware <phrase>neural language models</phrase> a failure to beat character aware ones
syllabification <phrase>does not</phrase> seem <phrase>to improve</phrase> <phrase>word level</phrase> rnn <phrase>language modeling</phrase> quality when <phrase>compared to</phrase> character based segmentation. however our best syllable aware <phrase>language model</phrase> achieving performance <phrase>comparable to</phrase> the competitive character aware model has 18 33 <phrase>fewer parameters</phrase> and is trained 1.2 2.2 times faster.
a benchmarking environment for <phrase>reinforcement learning</phrase> based task oriented dialogue management
dialogue assistants are rapidly becoming an indispensable daily aid. to avoid the significant effort needed to hand craft the required dialogue flow the dialogue management dm module can be cast as a continuous <phrase>markov decision process</phrase> mdp and trained through <phrase>reinforcement learning</phrase> rl . several rl models have been investigated over <phrase>recent years</phrase>. however <phrase>the lack of</phrase> a common benchmarking framework makes it difficult <phrase>to perform</phrase> a fair comparison between different models and their capability to generalise to different environments. therefore <phrase>this paper</phrase> proposes <phrase>a set of</phrase> challenging simulated environments for dialogue model development and evaluation. to provide some baselines we investigate <phrase>a number of</phrase> representative parametric algorithms namely <phrase>deep reinforcement learning</phrase> algorithms dqn a2c and natural <phrase>actor critic</phrase> and compare them to a non parametric model gp sarsa. both the environments and policy models are implemented using the <phrase>publicly available</phrase> pydial toolkit and released <phrase>on line</phrase> <phrase>in order to</phrase> establish a testbed <phrase>framework for</phrase> further experiments and to facilitate experimental reproducibility.
reusing weights in subword aware <phrase>neural language models</phrase>
we propose several ways of reusing subword embeddings and other weights in subword aware <phrase>neural language models</phrase>. <phrase>the proposed</phrase> techniques <phrase>do not</phrase> benefit a competitive character aware model but some of them improve <phrase>the performance of</phrase> syllable and morpheme aware models while showing significant reductions in model sizes. we discover <phrase>a simple</phrase> hands on principle in a <phrase>multi layer</phrase> input embedding model layers should be tied consecutively bottom up if reused at output. our best morpheme aware model with properly reused weights beats the competitive <phrase>word level</phrase> model by <phrase>a large</phrase> margin across multiple languages and has 20 87 <phrase>fewer parameters</phrase>.
<phrase>multi task learning</phrase> of pairwise sequence <phrase>classification tasks</phrase> over disparate label spaces
we combine <phrase>multi task learning</phrase> and <phrase>semi supervised</phrase> learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings enabling us to jointly leverage unlabelled data and auxiliary annotated datasets. we evaluate our approach on <phrase>a variety of</phrase> sequence <phrase>classification tasks</phrase> with disparate label spaces. we outperform strong single and <phrase>multi task</phrase> baselines and achieve <phrase>a new</phrase> <phrase>state of</phrase> <phrase>the art</phrase> for aspect and topic based <phrase>sentiment analysis</phrase>.
dynamic <phrase>memory networks</phrase> for visual and textual <phrase>question answering</phrase>
<phrase>neural network</phrase> architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for <phrase>question answering</phrase>. one such architecture the dynamic <phrase>memory network</phrase> dmn obtained high accuracy on <phrase>a variety of</phrase> language tasks. however it was not shown whether the architecture achieves strong results for <phrase>question answering</phrase> when supporting facts are not marked <phrase>during training</phrase> or whether it could be <phrase>applied to</phrase> other modalities <phrase>such as</phrase> images. <phrase>based on</phrase> an analysis of the dmn we propose several improvements to its memory and input modules. together with these changes we introduce <phrase>a novel</phrase> input module for images <phrase>in order to</phrase> be <phrase>able to</phrase> answer visual questions. our new dmn model improves the <phrase>state of</phrase> <phrase>the art</phrase> on both the <phrase>visual question answering</phrase> dataset and the babi 10k text <phrase>question answering</phrase> dataset without supporting fact supervision.
picture it in your mind generating <phrase>high level</phrase> visual representations from textual descriptions
in <phrase>this paper</phrase> we tackle <phrase>the problem of</phrase> image search when the query is a short textual description of the image the user is looking for. we choose to implement the actual search process as a similarity search in a visual <phrase>feature space</phrase> by learning to translate a textual query into a visual representation. searching in the visual <phrase>feature space</phrase> has the advantage that any update to the translation model <phrase>does not</phrase> require to reprocess the typically huge image collection on which the search is performed. we propose text2vis <phrase>a neural network</phrase> that generates a visual representation in the visual <phrase>feature space</phrase> of the fc6 fc7 layers of imagenet from a short descriptive text. text2vis optimizes two loss functions using a stochastic loss selection method. a visual focused loss is aimed at learning the actual text to visual feature mapping while a text focused loss is aimed at modeling the <phrase>higher level</phrase> semantic concepts expressed in language and countering the overfit on non relevant visual components of the visual loss. we report preliminary <phrase>results on</phrase> the ms coco dataset.
where to put the image in <phrase>an image</phrase> caption generator
when <phrase>a recurrent neural network</phrase> <phrase>language model</phrase> is used for caption generation the image information can be fed to the <phrase>neural network</phrase> either by directly incorporating it in the rnn conditioning the <phrase>language model</phrase> by injecting image features or in a layer following the rnn conditioning the <phrase>language model</phrase> by merging image features. while both options are attested in the literature there is as yet no systematic comparison between the two. in <phrase>this paper</phrase> we empirically show that it is not especially detrimental to performance whether one architecture is used or another. the merge architecture does have practical advantages as conditioning by merging allows the rnn s hidden state vector to shrink in size by up to four times. our <phrase>results suggest</phrase> that the visual and linguistic modalities for caption generation need not be jointly encoded by the rnn as that yields large memory intensive models with few tangible advantages in performance rather the multimodal integration should be delayed to a subsequent stage.
a focused dynamic <phrase>attention model</phrase> for <phrase>visual question answering</phrase>
<phrase>visual question</phrase> and answering vqa problems are attracting increasing interest from multiple research disciplines. solving vqa problems requires techniques from both <phrase>computer vision</phrase> for understanding the visual contents of a presented image or video <phrase>as well as</phrase> the ones from <phrase>natural language</phrase> processing for understanding semantics of the question and generating the answers. regarding visual content modeling most of existing vqa methods adopt the strategy of extracting global features from the image or video which inevitably fails in capturing <phrase>fine grained</phrase> information <phrase>such as</phrase> spatial configuration of multiple objects. extracting features from auto generated regions as some region based image recognition methods do cannot essentially address <phrase>this problem</phrase> and may introduce some overwhelming irrelevant features with the question. in <phrase>this work</phrase> we propose <phrase>a novel</phrase> focused dynamic attention fda model to provide better aligned image content representation with proposed questions. being aware of the key words in the question fda employs off the shelf object detector to identify important regions and fuse the information from the regions and global features via an lstm unit. such question driven representations are then <phrase>combined with</phrase> question representation and fed into a reasoning unit for generating the answers. extensive evaluation on <phrase>a large</phrase> scale benchmark dataset vqa clearly demonstrate the superior performance of fda over well established baselines.
simple image description generator via a linear phrase <phrase>based approach</phrase>
generating <phrase>a novel</phrase> textual description of <phrase>an image</phrase> is an interesting problem that connects <phrase>computer vision</phrase> and <phrase>natural language</phrase> processing. in <phrase>this paper</phrase> we present <phrase>a simple</phrase> model that is <phrase>able to</phrase> generate descriptive sentences given a sample image. this model has a strong <phrase>focus on</phrase> the syntax of the descriptions. we train a purely bilinear model that learns a metric between <phrase>an image</phrase> representation generated from a previously trained <phrase>convolutional neural network</phrase> and phrases that are used to described them. the system is then <phrase>able to</phrase> infer phrases from a given image sample. <phrase>based on</phrase> caption syntax statistics we propose <phrase>a simple</phrase> <phrase>language model</phrase> that can produce relevant descriptions for a given test image using the phrases inferred. our approach which is considerably simpler than <phrase>state of</phrase> <phrase>the art</phrase> models achieves comparable <phrase>results on</phrase> the recently release microsoft coco dataset.
multimodal <phrase>convolutional neural networks</phrase> for matching image and sentence
in <phrase>this paper</phrase> we propose multimodal <phrase>convolutional neural networks</phrase> m cnns for matching image and sentence. our m cnn provides <phrase>an end to end</phrase> framework with convolutional architectures to exploit image representation word composition and the matching <phrase>relations between</phrase> the two modalities. more specifically it <phrase>consists of</phrase> one image cnn encoding the image content and one matching cnn learning the joint representation of image and sentence. the matching cnn composes words to different semantic fragments and learns the inter modal <phrase>relations between</phrase> image and the composed fragments at different levels thus fully exploit the matching <phrase>relations between</phrase> image and sentence. <phrase>experimental results</phrase> on benchmark databases of bidirectional image and sentence retrieval demonstrate that <phrase>the proposed</phrase> m cnns can effectively capture the information necessary for image and sentence matching. specifically our proposed m cnns for bidirectional image and sentence retrieval on flickr30k and microsoft coco databases achieve the <phrase>state of</phrase> <phrase>the art</phrase> performances.
learning to compose <phrase>neural networks</phrase> for <phrase>question answering</phrase>
we describe a <phrase>question answering</phrase> model that applies to both images and structured knowledge bases. <phrase>the model</phrase> uses <phrase>natural language</phrase> strings to automatically assemble <phrase>neural networks</phrase> from a collection of composable modules. parameters for these modules are learned jointly with network assembly parameters via <phrase>reinforcement learning</phrase> with only world <phrase>question answer</phrase> triples as supervision. our approach which we term a dynamic neural model network <phrase>achieves state of</phrase> <phrase>the art results</phrase> on <phrase>benchmark datasets</phrase> in both visual and structured domains.
signer independent fingerspelling recognition with <phrase>deep neural network</phrase> adaptation
we study <phrase>the problem of</phrase> recognition of fingerspelled letter sequences in <phrase>american sign language</phrase> in a signer independent setting. fingerspelled sequences are both challenging and important to recognize as they are used for many content words <phrase>such as</phrase> <phrase>proper nouns</phrase> and technical terms. <phrase>previous work</phrase> has shown that it is possible to achieve almost 90 accuracies on fingerspelling recognition in a signer dependent setting. however the more realistic signer independent setting presents challenges <phrase>due to</phrase> significant variations among signers coupled with the dearth of available <phrase>training data</phrase>. we investigate <phrase>this problem</phrase> with approaches <phrase>inspired by</phrase> <phrase>automatic speech recognition</phrase>. we start with <phrase>the best</phrase> performing approaches from prior work <phrase>based on</phrase> tandem models and segmental conditional random fields scrfs with features <phrase>based on</phrase> <phrase>deep neural network dnn</phrase> classifiers of letters and phonological features. using dnn adaptation we find that it is possible to bridge <phrase>a large</phrase> part of the gap between signer dependent and signer independent performance. using only about 115 transcribed words for adaptation from the target signer we obtain letter accuracies of up to 82.7 with frame level adaptation labels and 69.7 with only word labels.
full network embedding in a multimodal embedding pipeline
<phrase>the current state of</phrase> <phrase>the art</phrase> for image annotation and image retrieval tasks is obtained through <phrase>deep neural networks</phrase> which combine <phrase>an image</phrase> representation and a text representation into a shared embedding space. in <phrase>this paper</phrase> we evaluate the impact of using the full network embedding in this setting replacing <phrase>the original</phrase> image representation in a competitive multimodal embedding generation scheme. unlike the one layer image embeddings typically used by most approaches the full network embedding provides a multi scale representation of images which results in richer characterizations. to measure the influence of the full network embedding we evaluate its <phrase>performance on</phrase> <phrase>three different</phrase> datasets and compare the results with <phrase>the original</phrase> multimodal embedding generation scheme when using a one layer image embedding and with the rest of the <phrase>state of</phrase> <phrase>the art</phrase>. results for image annotation and image retrieval tasks indicate that the full network embedding is consistently superior to the one layer embedding. these results motivate the integration of the full network embedding on any multimodal embedding generation scheme something feasible thanks to the flexibility of the approach.
what is <phrase>the role of</phrase> <phrase>recurrent neural networks</phrase> rnns in <phrase>an image</phrase> caption generator 
in neural image captioning systems <phrase>a recurrent neural network</phrase> rnn is typically viewed as the primary generation component. this view suggests that the image features should be injected into the rnn. this is in fact the dominant view in the literature. alternatively the rnn can instead be viewed as only encoding the previously generated words. this view suggests that the rnn should only be used to encode linguistic features and that only <phrase>the final</phrase> representation should be merged with the image features at a later stage. <phrase>this paper</phrase> compares these two architectures. we find that in general late merging outperforms injection suggesting that rnns are better viewed as encoders <phrase>rather than</phrase> generators.
<phrase>a fixed</phrase> size encoding <phrase>method for</phrase> variable length sequences with its <phrase>application to</phrase> <phrase>neural network</phrase> <phrase>language models</phrase>
in <phrase>this paper</phrase> we propose the new fixed size ordinally forgetting encoding fofe method which can almost uniquely encode any variable length sequence of words into <phrase>a fixed</phrase> size representation. fofe can model the <phrase>word order</phrase> in a sequence using <phrase>a simple</phrase> ordinally forgetting mechanism <phrase>according to</phrase> the positions of words. in <phrase>this work</phrase> we have applied fofe to feedforward <phrase>neural network</phrase> <phrase>language models</phrase> fnn lms . <phrase>experimental results</phrase> have shown that without using any recurrent feedbacks fofe based fnn lms can <phrase>significantly outperform</phrase> <phrase>not only</phrase> the standard fixed input fnn lms <phrase>but also</phrase> the popular rnn lms.
transition based dependency parsing with stack <phrase>long short term memory</phrase>
we propose a technique for learning representations of parser states in transition based dependency parsers. our primary innovation is <phrase>a new</phrase> control structure for <phrase>sequence to sequence</phrase> <phrase>neural networks</phrase> the stack lstm. like the conventional stack <phrase>data structures</phrase> used in transition based parsing elements can be pushed to or popped from the top of the stack in constant time but <phrase>in addition</phrase> an lstm maintains a continuous space embedding of the stack contents. this lets us formulate an efficient parsing model that captures three facets of a parser s state i unbounded look ahead into the buffer of incoming words ii the complete history of actions taken by the parser and iii the complete contents of the stack of partially built tree fragments including their internal structures. standard backpropagation techniques are used for training and yield <phrase>state of</phrase> <phrase>the art</phrase> parsing performance.
a semisupervised approach for language identification <phrase>based on</phrase> ladder networks
in <phrase>this study</phrase> we address <phrase>the problem of</phrase> training a neuralnetwork for language identification using both labeled and unlabeled speech samples in the form of i vectors. we propose <phrase>a neural network</phrase> architecture that can also handle out of set languages. we utilize a modified <phrase>version of</phrase> the <phrase>recently proposed</phrase> ladder network semisupervised training procedure that optimizes the reconstruction costs of a stack of denoising autoencoders. we show that <phrase>this approach</phrase> can be successfully <phrase>applied to</phrase> the case where the training dataset is <phrase>composed of</phrase> both labeled and unlabeled acoustic data. the <phrase>results show</phrase> enhanced language identification on the nist 2015 language identification dataset.
first pass <phrase>large vocabulary</phrase> <phrase>continuous speech</phrase> recognition using bi directional recurrent dnns
we present a method <phrase>to perform</phrase> first pass <phrase>large vocabulary</phrase> <phrase>continuous speech</phrase> recognition using only <phrase>a neural network</phrase> and <phrase>language model</phrase>. <phrase>deep neural network</phrase> <phrase>acoustic models</phrase> are now commonplace in hmm based <phrase>speech recognition</phrase> systems but building such systems is a complex <phrase>domain specific</phrase> task. <phrase>recent work</phrase> demonstrated the feasibility of discarding the hmm <phrase>sequence modeling</phrase> framework by directly predicting transcript text from audio. <phrase>this paper</phrase> extends <phrase>this approach</phrase> in two ways. first we demonstrate that a straightforward <phrase>recurrent neural network</phrase> architecture can achieve a <phrase>high level</phrase> of accuracy. second we propose and evaluate a modified prefix search decoding algorithm. <phrase>this approach</phrase> to decoding enables first pass <phrase>speech recognition</phrase> with a <phrase>language model</phrase> completely unaided by the cumbersome infrastructure of hmm based systems. <phrase>experiments on</phrase> the <phrase>wall street</phrase> journal corpus demonstrate fairly competitive word <phrase>error rates</phrase> and the importance of bi directional network recurrence.
applying <phrase>deep learning</phrase> techniques on medical corpora from the <phrase>world wide web</phrase> a prototypical system and evaluation
background the <phrase>amount of</phrase> biomedical literature is rapidly growing and it is becoming increasingly difficult to keep manually curated knowledge bases and ontologies up <phrase>to date</phrase>. in <phrase>this study</phrase> we applied the word2vec <phrase>deep learning</phrase> toolkit to medical corpora to test its potential for identifying relationships from unstructured text. we evaluated the efficiency of word2vec in identifying <phrase>properties of</phrase> pharmaceuticals <phrase>based on</phrase> mid sized unstructured medical text corpora available on the web. properties included relationships to diseases may treat or physiological processes has physiological effect . we compared the relationships identified by word2vec with manually curated information from the national drug file reference terminology ndf rt ontology as a <phrase>gold standard</phrase>. results our results revealed a maximum accuracy of 49.28 which suggests a limited ability of word2vec <phrase>to capture</phrase> linguistic regularities on the collected medical corpora <phrase>compared with</phrase> other published results. we were <phrase>able to</phrase> document the influence of different parameter settings on result accuracy and found and unexpected trade off between ranking quality and accuracy. pre processing corpora <phrase>to reduce</phrase> syntactic variability proved to be a good strategy for increasing the utility of the trained vector models. conclusions word2vec is a very efficient implementation for computing <phrase>vector representations</phrase> and for its <phrase>ability to</phrase> identify relationships in textual data without any prior <phrase>domain knowledge</phrase>. we found that the ranking and retrieved results generated by word2vec were not of sufficient quality for automatic population of knowledge bases and ontologies but could serve as a starting point for further manual curation.
syntax based deep matching of short texts
many tasks in <phrase>natural language</phrase> processing ranging from <phrase>machine translation</phrase> to <phrase>question answering</phrase> can be reduced to <phrase>the problem of</phrase> matching two sentences or more generally two short texts. we propose <phrase>a new approach</phrase> to the problem called deep match tree deepmatch tree under a general setting. the approach <phrase>consists of</phrase> two components 1 a mining algorithm <phrase>to discover</phrase> patterns for matching two short texts defined in the product space of dependency trees and 2 <phrase>a deep neural network</phrase> for matching short texts using the mined patterns <phrase>as well as</phrase> a <phrase>learning algorithm</phrase> to build <phrase>the network</phrase> having a sparse structure. we test our algorithm on <phrase>the problem of</phrase> matching a tweet and a response in <phrase>social media</phrase> a hard matching problem proposed in wang <phrase>et al</phrase>. 2013 and show that deepmatch tree can outperform <phrase>a number of</phrase> competitor models including one without using dependency trees and one <phrase>based on</phrase> <phrase>word embedding</phrase> all with large margins
ensemble of generative and discriminative techniques for <phrase>sentiment analysis</phrase> of movie reviews
<phrase>sentiment analysis</phrase> is a common task in <phrase>natural language</phrase> processing that aims to detect polarity of a text document typically a consumer review . in the simplest settings we discriminate only between positive and negative sentiment turning the task into a standard <phrase>binary classification</phrase> problem. we compare several ma chine <phrase>learning approaches</phrase> to <phrase>this problem</phrase> and combine them to achieve <phrase>the best</phrase> possible results. we show how to use for <phrase>this task</phrase> the standard generative lan guage models which are slightly complementary to the <phrase>state of</phrase> <phrase>the art</phrase> techniques. we achieve strong <phrase>results on</phrase> a <phrase>well known</phrase> dataset of imdb movie reviews. our results are easily reproducible as we publish also the code needed to repeat the experiments. this should simplify further advance of the <phrase>state of</phrase> <phrase>the art</phrase> as other researchers can combine their techniques with ours with little effort.
diverse embedding <phrase>neural network</phrase> <phrase>language models</phrase>
we propose diverse embedding <phrase>neural network</phrase> denn <phrase>a novel</phrase> architecture for <phrase>language models</phrase> lms . a dennlm projects <phrase>the input</phrase> word history vector onto multiple diverse <phrase>low dimensional</phrase> sub spaces <phrase>instead of</phrase> <phrase>a single</phrase> higher dimensional sub space as in conventional <phrase>feed forward</phrase> <phrase>neural network</phrase> lms. we encourage these sub spaces to be diverse during <phrase>network training</phrase> through an augmented <phrase>loss function</phrase>. our <phrase>language modeling</phrase> <phrase>experiments on</phrase> the <phrase>penn treebank</phrase> <phrase>data set</phrase> show the performance benefit of using a dennlm.
learning linearly separable features <phrase>for speech recognition</phrase> using <phrase>convolutional neural networks</phrase>
<phrase>automatic speech recognition</phrase> systems usually <phrase>rely on</phrase> spectral based features <phrase>such as</phrase> mfcc of plp. these features are extracted <phrase>based on</phrase> <phrase>prior knowledge</phrase> <phrase>such as</phrase> <phrase>speech perception</phrase> or and <phrase>speech production</phrase>. recently <phrase>convolutional neural networks</phrase> have been <phrase>shown to</phrase> be <phrase>able to</phrase> estimate phoneme conditional probabilities in a completely <phrase>data driven</phrase> manner i.e. using directly temporal raw speech signal as input. this system was <phrase>shown to</phrase> yield similar or <phrase>better performance</phrase> than hmm ann based system on <phrase>phoneme recognition</phrase> task and on <phrase>large scale</phrase> <phrase>continuous speech</phrase> <phrase>recognition task</phrase> using less parameters. <phrase>motivated by</phrase> these studies we investigate <phrase>the use of</phrase> simple linear classifier in the cnn based framework. thus <phrase>the network</phrase> learns linearly separable features <phrase>from raw</phrase> speech. we show that such system yields similar or <phrase>better performance</phrase> than mlp based system using cepstral based features as input.
learning to transduce with unbounded memory
recently strong results have been demonstrated by deep <phrase>recurrent neural networks</phrase> on <phrase>natural language</phrase> transduction problems. in <phrase>this paper</phrase> we explore the representational power of <phrase>these models</phrase> using synthetic grammars designed to exhibit phenomena <phrase>similar to</phrase> those found in real transduction problems <phrase>such as</phrase> <phrase>machine translation</phrase>. these experiments lead us to propose new memory based recurrent networks that implement continuously differentiable analogues of traditional <phrase>data structures</phrase> <phrase>such as</phrase> stacks queues and deques. we show that these architectures exhibit superior generalisation performance to deep rnns and are often <phrase>able to</phrase> learn the underlying generating algorithms in our transduction experiments.
feedforward sequential memory <phrase>neural networks</phrase> without recurrent feedback
we introduce <phrase>a new</phrase> structure for memory <phrase>neural networks</phrase> called feedforward sequential <phrase>memory networks</phrase> fsmn which can learn <phrase>long term</phrase> dependency without using recurrent feedback. <phrase>the proposed</phrase> fsmn is a standard feedforward <phrase>neural networks</phrase> equipped with learnable sequential memory blocks in the <phrase>hidden layers</phrase>. in <phrase>this work</phrase> we have applied fsmn to several <phrase>language modeling</phrase> lm tasks. <phrase>experimental results</phrase> have shown that the memory blocks in fsmn can learn effective representations of long history. experiments have shown that fsmn based <phrase>language models</phrase> can <phrase>significantly outperform</phrase> <phrase>not only</phrase> feedforward <phrase>neural network</phrase> fnn based lms <phrase>but also</phrase> the popular <phrase>recurrent neural network rnn</phrase> lms.
towards structured <phrase>deep neural network</phrase> for <phrase>automatic speech recognition</phrase>
in <phrase>this paper</phrase> we propose the structured <phrase>deep neural network</phrase> structured dnn as a structured and <phrase>deep learning</phrase> framework. <phrase>this approach</phrase> can learn to find <phrase>the best</phrase> structured object <phrase>such as</phrase> a label sequence given a structured input <phrase>such as</phrase> a vector sequence by globally considering the mapping relationships between the structures <phrase>rather than</phrase> item by item. when <phrase>automatic speech recognition</phrase> is viewed as <phrase>a special</phrase> case of such a structured learning problem where we have the acoustic vector sequence as <phrase>the input</phrase> and the phoneme label sequence as the output it becomes possible to comprehensively learn utterance by utterance as a whole <phrase>rather than</phrase> frame by frame. structured <phrase>support vector machine</phrase> structured svm was proposed <phrase>to perform</phrase> asr with structured learning previously but limited by the linear nature of svm. here we propose structured dnn to use nonlinear transformations in multi layers as a structured and <phrase>deep learning</phrase> approach. <phrase>this approach</phrase> was <phrase>shown to</phrase> beat structured svm in preliminary <phrase>experiments on</phrase> timit.
<phrase>character level</phrase> incremental <phrase>speech recognition</phrase> with <phrase>recurrent neural networks</phrase>
in <phrase>real time</phrase> <phrase>speech recognition</phrase> applications the latency is <phrase>an important</phrase> issue. we have developed a <phrase>character level</phrase> incremental <phrase>speech recognition</phrase> isr system that responds quickly even during the speech where the hypotheses are gradually improved while the speaking proceeds. the algorithm employs a speech to character unidirectional <phrase>recurrent neural network rnn</phrase> which is <phrase>end to end</phrase> trained with connectionist temporal classification ctc and an <phrase>rnn based</phrase> <phrase>character level</phrase> <phrase>language model</phrase> lm . the output values of the ctc trained rnn are <phrase>character level</phrase> probabilities which are processed by <phrase>beam search</phrase> decoding. the rnn lm augments the decoding by providing <phrase>long term</phrase> dependency information. we propose tree based online <phrase>beam search</phrase> with additional depth pruning which enables the system to process infinitely long input speech with low latency. this system <phrase>not only</phrase> responds quickly on speech <phrase>but also</phrase> can dictate out of vocabulary oov words <phrase>according to</phrase> pronunciation. <phrase>the proposed model</phrase> achieves the <phrase>word error rate</phrase> wer of 8.90 on the <phrase>wall street</phrase> journal wsj nov 92 20k evaluation set when <phrase>trained on</phrase> the wsj si 284 <phrase>training set</phrase>.
globally normalized transition based <phrase>neural networks</phrase>
we introduce a globally normalized transition based <phrase>neural network</phrase> model that <phrase>achieves state of</phrase> <phrase>the art</phrase> <phrase>part of speech tagging</phrase> dependency parsing and sentence compression results. our model is <phrase>a simple</phrase> <phrase>feed forward</phrase> <phrase>neural network</phrase> that operates on a <phrase>task specific</phrase> transition system yet achieves comparable or better accuracies than recurrent models. we discuss the importance of global as opposed to local normalization a key insight is that the label bias problem implies that globally normalized models can be strictly more expressive than locally normalized models.
clinical <phrase>information extraction</phrase> via <phrase>convolutional neural network</phrase>
we report an implementation of a clinical <phrase>information extraction</phrase> tool that leverages <phrase>deep neural network</phrase> to annotate event spans and their attributes <phrase>from raw</phrase> clinical notes and pathology reports. our approach uses context words and their part of speech tags and shape information as features. then we hire temporal 1d <phrase>convolutional neural network</phrase> <phrase>to learn</phrase> hidden <phrase>feature representations</phrase>. finally we use <phrase>multilayer perceptron</phrase> mlp <phrase>to predict</phrase> event spans. the empirical evaluation demonstrates that our approach <phrase>significantly outperforms</phrase> baselines.
zoneout regularizing rnns by randomly preserving hidden activations
we propose zoneout <phrase>a novel method</phrase> for regularizing rnns. at each timestep zoneout stochastically forces some hidden units to maintain their previous values. like dropout zoneout uses random noise <phrase>to train</phrase> a pseudo ensemble improving generalization. but by preserving <phrase>instead of</phrase> dropping hidden units gradient information and state information are more readily propagated through time as in feedforward stochastic depth networks. we perform an empirical investigation of various rnn regularizers and find that zoneout gives significant performance improvements across tasks. we achieve <phrase>competitive results</phrase> with relatively simple models in character and <phrase>word level</phrase> language modelling on the <phrase>penn treebank</phrase> and text8 datasets and combining with recurrent <phrase>batch normalization</phrase> yields <phrase>state of</phrase> <phrase>the art results</phrase> on permuted sequential mnist.
stance detection with bidirectional conditional encoding
stance detection is <phrase>the task of</phrase> classifying the attitude expressed in a text towards a target <phrase>such as</phrase> <phrase>hillary clinton</phrase> to be positive negative or neutral . <phrase>previous work</phrase> has assumed that either the target is mentioned in the text or that <phrase>training data</phrase> for every target is given. <phrase>this paper</phrase> considers the more challenging <phrase>version of</phrase> <phrase>this task</phrase> where targets are not always mentioned and no <phrase>training data</phrase> is available for the test targets. we experiment with conditional lstm encoding which builds a representation of the tweet that is dependent on the target and demonstrate that it outperforms encoding the tweet and the target independently. performance is improved further when the conditional model is augmented with bidirectional encoding. we evaluate our approach on the semeval 2016 task 6 twitter stance detection corpus achieving performance second best only to a system <phrase>trained on</phrase> semi automatically labelled tweets for the test target. when such weak supervision is added our approach <phrase>achieves state of</phrase> <phrase>the art</phrase> results.
sms spam filtering using probabilistic topic modelling and stacked denoising autoencoder
in <phrase>this paper</phrase> we present <phrase>a novel</phrase> <phrase>approach to</phrase> spam filtering and demonstrate its applicability <phrase>with respect to</phrase> sms messages. our approach requires minimum features engineering and <phrase>a small</phrase> <phrase>set of</phrase> la belled data samples. features are extracted using topic modelling <phrase>based on</phrase> <phrase>latent dirichlet allocation</phrase> and then a comprehensive <phrase>data model</phrase> is created using a stacked denoising autoencoder sda . topic modelling summarises the data providing ease of use and high interpretability by visualising the topics using word clouds. given that the sms messages can be regarded as either spam unwanted or ham wanted the sda is <phrase>able to</phrase> model the messages and accurately discriminate between the two classes without <phrase>the need for</phrase> a pre labelled <phrase>training set</phrase>. the results are compared against the <phrase>state of</phrase> <phrase>the art</phrase> spam detection algorithms with our <phrase>proposed approach</phrase> achieving over 97 accuracy which compares favourably to <phrase>the best</phrase> reported algorithms presented in the literature.
bidirectional <phrase>recurrent neural networks</phrase> for medical event detection in <phrase>electronic health records</phrase>
<phrase>sequence labeling</phrase> for extraction of medical events and their attributes from unstructured text in <phrase>electronic health record</phrase> ehr notes is a key <phrase>step towards</phrase> semantic understanding of ehrs. it has important applications in <phrase>health informatics</phrase> including pharmacovigilance and drug surveillance. the <phrase>state of</phrase> <phrase>the art</phrase> supervised <phrase>machine learning</phrase> models in this domain are <phrase>based on</phrase> conditional random fields crfs with features calculated from fixed context windows. in this application we explored various <phrase>recurrent neural network</phrase> frameworks and show that they significantly outperformed the crf models.
sequence training and adaptation of highway <phrase>deep neural networks</phrase>
highway <phrase>deep neural network</phrase> hdnn is a <phrase>type of</phrase> depth gated feedforward <phrase>neural network</phrase> which has <phrase>shown to</phrase> be easier <phrase>to train</phrase> with more <phrase>hidden layers</phrase> and also generalise better <phrase>compared to</phrase> conventional plain <phrase>deep neural networks</phrase> dnns . previously we investigated a structured hdnn architecture <phrase>for speech recognition</phrase> in which the two gate functions were tied across all the <phrase>hidden layers</phrase> and we were <phrase>able to</phrase> train a much smaller model without sacrificing the recognition accuracy. in <phrase>this paper</phrase> we carry on the study of this architecture with sequence discriminative training criterion and speaker adaptation techniques on the ami meeting <phrase>speech recognition</phrase> corpus. we show that these two techniques improve <phrase>speech recognition</phrase> accuracy on top of <phrase>the model</phrase> trained with the <phrase>cross entropy</phrase> criterion. furthermore we demonstrate that the two gate functions that are tied across all the <phrase>hidden layers</phrase> are <phrase>able to</phrase> control the information flow over the whole network and we can achieve considerable improvements by only updating these gate functions in both sequence training and adaptation experiments.
recurrent highway networks
many sequential processing tasks require complex nonlinear transition functions from one step to the next. however <phrase>recurrent neural networks</phrase> with deep transition functions remain difficult <phrase>to train</phrase> even when using <phrase>long short term memory lstm</phrase> networks. we introduce <phrase>a novel</phrase> theoretical analysis of recurrent networks <phrase>based on</phrase> gersgorin s circle theorem that illuminates several modeling and optimization issues and improves our understanding of the lstm cell. <phrase>based on</phrase> this analysis we propose recurrent highway networks which extend the lstm architecture to allow step to step transition depths larger than one. several <phrase>language modeling</phrase> <phrase>experiments demonstrate</phrase> that <phrase>the proposed</phrase> architecture results in powerful and efficient models. on the <phrase>penn treebank</phrase> corpus solely increasing the transition depth from 1 to 10 improves <phrase>word level</phrase> perplexity from 90.6 to 65.4 using <phrase>the same</phrase> <phrase>number of</phrase> parameters. on the larger wikipedia datasets for character prediction text8 and enwik8 rhns outperform all previous results and achieve an entropy of 1.27 bits per character.
towards cross lingual distributed representations without parallel text trained with adversarial autoencoders
current approaches to learning <phrase>vector representations</phrase> of text that are compatible between different languages usually require some <phrase>amount of</phrase> parallel text aligned at word sentence or at least document level. we hypothesize however that different natural languages share enough semantic structure that it should be possible in principle <phrase>to learn</phrase> compatible <phrase>vector representations</phrase> just by analyzing the monolingual distribution of words. <phrase>in order to</phrase> evaluate this hypothesis we propose a scheme to map word vectors <phrase>trained on</phrase> a source language to vectors semantically compatible with word vectors <phrase>trained on</phrase> a <phrase>target language</phrase> using an adversarial autoencoder. we present preliminary qualitative results and discuss possible future developments of this technique <phrase>such as</phrase> applications to cross lingual sentence representations.
memory visualization for <phrase>gated recurrent</phrase> <phrase>neural networks</phrase> in <phrase>speech recognition</phrase>
<phrase>recurrent neural networks</phrase> rnns have shown clear superiority in <phrase>sequence modeling</phrase> particularly the ones with gated units <phrase>such as</phrase> <phrase>long short term memory lstm</phrase> and <phrase>gated recurrent</phrase> unit gru . however the dynamic properties behind the remarkable performance remain unclear in <phrase>many applications</phrase> e.g. <phrase>automatic speech recognition</phrase> asr . <phrase>this paper</phrase> employs visualization techniques to study the behavior of lstm and gru when performing <phrase>speech recognition</phrase> tasks. our <phrase>experiments show</phrase> some interesting patterns in the gated memory and some of them have inspired simple yet effective modifications on <phrase>the network</phrase> structure. we report two of such modifications 1 lazy cell update in lstm and 2 shortcut connections for residual learning. both modifications <phrase>lead to</phrase> more comprehensible and powerful networks.
neural speech recognizer acoustic to word lstm model for <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase>
we present results that show it is possible to build a competitive greatly simplified <phrase>large vocabulary</phrase> <phrase>continuous speech</phrase> recognition system with whole words as acoustic units. we model the output vocabulary of about 100 000 words directly using deep bi directional lstm rnns with ctc loss. <phrase>the model</phrase> is <phrase>trained on</phrase> 125 000 hours of <phrase>semi supervised</phrase> acoustic <phrase>training data</phrase> which enables us to alleviate the data sparsity problem for word models. we show that the ctc word models work very well as <phrase>an end to end</phrase> all neural <phrase>speech recognition</phrase> model without <phrase>the use of</phrase> traditional context dependent sub word phone units that require a pronunciation lexicon and without any <phrase>language model</phrase> removing the <phrase>need to</phrase> decode. we demonstrate that the ctc word models perform <phrase>better than</phrase> a strong more complex <phrase>state of</phrase> <phrase>the art</phrase> baseline with sub word units.
unsupervised pretraining for <phrase>sequence to sequence</phrase> learning
<phrase>this work</phrase> presents a general <phrase>unsupervised learning</phrase> method <phrase>to improve</phrase> the accuracy of <phrase>sequence to sequence</phrase> seq2seq models. in our method the weights of the encoder and decoder of a seq2seq model are initialized with the pretrained weights of two <phrase>language models</phrase> and then fine tuned with labeled data. we apply this method to challenging benchmarks in <phrase>machine translation</phrase> and abstractive summarization and find that it significantly improves the subsequent supervised models. our main result is that pretraining improves the generalization of seq2seq models. we <phrase>achieve state of</phrase> <phrase>the art results</phrase> on the wmt english rightarrow german task surpassing <phrase>a range of</phrase> methods using both phrase based <phrase>machine translation</phrase> and <phrase>neural machine translation</phrase>. our method achieves a <phrase>significant improvement</phrase> of 1.3 bleu from the previous best models on both wmt 14 and wmt 15 english rightarrow german. we also conduct human evaluations on abstractive summarization and find that our method outperforms a purely <phrase>supervised learning</phrase> baseline in a statistically significant manner.
structured attention networks
attention networks have proven to be <phrase>an effective</phrase> approach for embedding categorical inference within <phrase>a deep neural network</phrase>. however for many tasks we may want to model richer structural dependencies without abandoning <phrase>end to end</phrase> training. in <phrase>this work</phrase> we experiment with incorporating richer structural distributions encoded using <phrase>graphical models</phrase> within <phrase>deep networks</phrase>. we show that these structured attention networks are simple extensions of the basic attention procedure and that they allow for extending attention beyond the standard soft selection approach <phrase>such as</phrase> attending to partial segmentations or to subtrees. we experiment with two different classes of structured attention networks a linear chain <phrase>conditional random field</phrase> and a graph based parsing model and describe how <phrase>these models</phrase> can be practically implemented as <phrase>neural network</phrase> layers. <phrase>experiments show</phrase> that <phrase>this approach</phrase> is effective for incorporating structural biases and structured attention networks outperform baseline attention models on <phrase>a variety of</phrase> synthetic and real tasks tree transduction <phrase>neural machine translation</phrase> <phrase>question answering</phrase> and <phrase>natural language</phrase> inference. we further find that models trained in this way learn interesting unsupervised hidden representations that generalize simple attention.
<phrase>end to end</phrase> <phrase>multi view</phrase> networks for <phrase>text classification</phrase>
we propose a <phrase>multi view</phrase> network for <phrase>text classification</phrase>. our method automatically creates various views of its input text each taking the form of soft attention weights that distribute the classifier s focus among <phrase>a set of</phrase> base features. for a bag of words representation each view <phrase>focuses on</phrase> a different <phrase>subset of</phrase> the text s words. aggregating many such views results in a more discriminative and robust representation. through <phrase>a novel</phrase> architecture that both stacks and concatenates views we produce a network that emphasizes both depth and width allowing training to converge quickly. using our <phrase>multi view</phrase> architecture we establish new <phrase>state of</phrase> <phrase>the art</phrase> accuracies on two benchmark tasks.
differentiable scheduled sampling for credit assignment
we demonstrate that a continuous relaxation of the argmax operation can be used to create a differentiable approximation to greedy decoding for <phrase>sequence to sequence</phrase> seq2seq models. by incorporating this approximation into the scheduled sampling training procedure bengio <phrase>et al</phrase>. 2015 a <phrase>well known</phrase> technique for correcting exposure bias we introduce <phrase>a new</phrase> training objective that is continuous and differentiable everywhere and that can provide informative gradients near points where previous decoding decisions change their value. <phrase>in addition</phrase> <phrase>by using</phrase> a related approximation we demonstrate a similar <phrase>approach to</phrase> sampled based training. finally we show that our approach outperforms <phrase>cross entropy</phrase> training and scheduled sampling procedures in two sequence prediction tasks <phrase>named entity recognition</phrase> and <phrase>machine translation</phrase>.
phone aware neural language identification
pure acoustic <phrase>neural models</phrase> particularly the <phrase>lstm rnn</phrase> model have shown great potential in language identification lid . however the phonetic information has been largely overlooked by most of existing neural lid models although this information has been used in the conventional phonetic lid systems with a great success. we present a phone aware neural lid architecture which is a deep <phrase>lstm rnn</phrase> lid system but accepts output from an <phrase>rnn based</phrase> asr system. by utilizing the phonetic knowledge the lid performance can be significantly improved. interestingly even if the test language is not involved in the asr training the phonetic knowledge still presents <phrase>a large</phrase> contribution. our experiments conducted on four languages within the babel corpus demonstrated that the phone aware approach is highly effective.
detecting off topic responses to visual prompts
automated methods for essay scoring have made great progress <phrase>in recent years</phrase> achieving accuracies very <phrase>close to</phrase> human annotators. however a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text. while there is existing work on detecting answer relevance given a textual prompt very little previous research has been done to incorporate visual writing prompts. we propose a neural architecture and several extensions for detecting off topic responses to visual prompts and evaluate it on a dataset of texts written by language learners.
dual <phrase>rectified linear</phrase> units drelus a replacement for tanh <phrase>activation functions</phrase> in quasi <phrase>recurrent neural networks</phrase>
in <phrase>this paper</phrase> we introduce <phrase>a novel</phrase> <phrase>type of</phrase> <phrase>rectified linear</phrase> unit relu called a dual <phrase>rectified linear</phrase> unit drelu . a drelu which comes with an unbounded positive and negative image can be <phrase>used as</phrase> a drop in replacement for a tanh <phrase>activation function</phrase> in the recurrent step of quasi <phrase>recurrent neural networks</phrase> qrnns bradbury <phrase>et al</phrase>. 2017 . <phrase>similar to</phrase> relus drelus are less prone to the vanishing gradient problem they are noise robust and they induce sparse activations. we independently reproduce the qrnn experiments of bradbury <phrase>et al</phrase>. 2017 and compare our drelu based qrnns with <phrase>the original</phrase> tanh based qrnns and <phrase>long short term memory</phrase> networks lstms on sentiment classification and <phrase>word level</phrase> <phrase>language modeling</phrase>. additionally we evaluate on <phrase>character level</phrase> <phrase>language modeling</phrase> showing that we are <phrase>able to</phrase> stack up to eight qrnn layers with drelus thus making it possible <phrase>to improve</phrase> <phrase>the current state of</phrase> <phrase>the art</phrase> in <phrase>character level</phrase> <phrase>language modeling</phrase> over shallow architectures <phrase>based on</phrase> lstms.
fidelity weighted learning
<phrase>training deep neural networks</phrase> requires many <phrase>training samples</phrase> but <phrase>in practice</phrase> training labels are expensive <phrase>to obtain</phrase> and may be of varying quality as some may be from trusted expert labelers while others might be from heuristics or other sources of weak supervision <phrase>such as</phrase> crowd sourcing. this creates a fundamental quality versus quantity trade off in the learning process. do we learn from the small <phrase>amount of</phrase> <phrase>high quality</phrase> data or the potentially large <phrase>amount of</phrase> weakly labeled data we argue that if the learner could somehow know and take the label quality into account when learning the data representation we could get <phrase>the best</phrase> of both worlds. to this end we propose fidelity weighted learning fwl a <phrase>semi supervised</phrase> student teacher approach for <phrase>training deep neural networks</phrase> using weakly labeled data. fwl modulates the parameter updates to a student network <phrase>trained on</phrase> the task we care about on a per sample basis <phrase>according to</phrase> the posterior confidence of its label quality estimated by a teacher who has access to the <phrase>high quality</phrase> labels . both student and teacher are learned from the data. we evaluate fwl on two tasks in <phrase>information retrieval</phrase> and <phrase>natural language</phrase> processing where we outperform <phrase>state of</phrase> <phrase>the art</phrase> alternative <phrase>semi supervised</phrase> methods indicating that our approach makes better use of strong and weak labels and <phrase>leads to</phrase> better task dependent data representations.
<phrase>feature learning</phrase> in <phrase>deep neural networks</phrase> studies on <phrase>speech recognition</phrase> tasks
recent studies have shown that <phrase>deep neural networks</phrase> dnns perform significantly <phrase>better than</phrase> shallow networks and gaussian mixture models gmms on <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase> tasks. in <phrase>this paper</phrase> we argue that the improved accuracy <phrase>achieved by</phrase> the dnns is the result of their <phrase>ability to</phrase> extract discriminative internal representations that are robust to the many sources of variability in speech signals. we show that these representations become increasingly insensitive to small perturbations in <phrase>the input</phrase> with increasing network depth which <phrase>leads to</phrase> better <phrase>speech recognition</phrase> performance with deeper networks. we <phrase>also show</phrase> that dnns cannot extrapolate to test samples that are substantially different from the training examples. if <phrase>the training data</phrase> are sufficiently representative however internal features learned by the dnn are relatively stable <phrase>with respect to</phrase> speaker differences bandwidth differences and environment distortion. this enables dnn based recognizers <phrase>to perform</phrase> as well or <phrase>better than</phrase> <phrase>state of</phrase> <phrase>the art</phrase> systems <phrase>based on</phrase> gmms or shallow networks without <phrase>the need for</phrase> explicit model adaptation or feature normalization.
estimating phoneme class conditional probabilities <phrase>from raw</phrase> speech signal using <phrase>convolutional neural networks</phrase>
in hybrid <phrase>hidden markov model</phrase> <phrase>artificial neural networks</phrase> hmm ann <phrase>automatic speech recognition</phrase> asr system the phoneme class conditional probabilities are estimated by first extracting acoustic features from the speech signal <phrase>based on</phrase> <phrase>prior knowledge</phrase> <phrase>such as</phrase> <phrase>speech perception</phrase> or and <phrase>speech production</phrase> knowledge and then modeling the acoustic features with an ann. <phrase>recent advances in</phrase> <phrase>machine learning</phrase> techniques more specifically in <phrase>the field of</phrase> <phrase>image processing</phrase> and text processing have shown that such divide and conquer strategy i.e. separating <phrase>feature extraction</phrase> and modeling steps may not be necessary. motivated from these studies in the framework of <phrase>convolutional neural networks</phrase> cnns <phrase>this paper</phrase> investigates <phrase>a novel</phrase> approach where <phrase>the input</phrase> to the ann is raw speech signal and the output is phoneme class <phrase>conditional probability</phrase> estimates. on timit <phrase>phoneme recognition</phrase> task we study different ann architectures to show the benefit of cnns and compare <phrase>the proposed</phrase> approach against conventional approach where spectral based feature mfcc is extracted and modeled by a <phrase>multilayer perceptron</phrase>. our studies show that <phrase>the proposed</phrase> approach can yield comparable or better <phrase>phoneme recognition</phrase> performance when <phrase>compared to</phrase> the conventional approach. it indicates that cnns can learn features relevant for phoneme classification automatically from the raw speech signal.
<phrase>recursive neural</phrase> networks can learn logical semantics
tree structured <phrase>recursive neural</phrase> networks treernns for sentence meaning have been successful for <phrase>many applications</phrase> but it remains an open question whether the fixed length representations that they learn can support tasks as demanding as logical deduction. we pursue this question by evaluating whether two such models plain treernns and tree structured neural tensor networks treerntns can correctly learn to identify logical relationships <phrase>such as</phrase> entailment and contradiction using these representations. in our first <phrase>set of</phrase> experiments we generate artificial data from a logical grammar and use it to evaluate the models <phrase>ability to</phrase> learn to handle basic relational reasoning recursive structures and quantification. we then evaluate the models on the more natural sick challenge data. both models perform competitively on the sick data and generalize well in all three <phrase>experiments on</phrase> simulated data suggesting that they can learn suitable representations for logical inference in <phrase>natural language</phrase>.
a re ranking model for dependency parser with recursive <phrase>convolutional neural network</phrase>
in <phrase>this work</phrase> we address the problem to model all the nodes words or phrases in a dependency tree with the dense representations. we propose a recursive <phrase>convolutional neural network</phrase> rcnn architecture <phrase>to capture</phrase> syntactic and compositional semantic representations of phrases and words in a dependency tree. different with <phrase>the original</phrase> <phrase>recursive neural</phrase> network we introduce the convolution and pooling layers which can model <phrase>a variety of</phrase> compositions by the feature maps and choose the most informative compositions by the pooling layers. <phrase>based on</phrase> rcnn we use a discriminative model to re rank a k best list of candidate dependency parsing trees. the <phrase>experiments show</phrase> that rcnn is very effective <phrase>to improve</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> dependency parsing on both english and chinese datasets.
deep speaker vectors for semi text independent speaker verification
recent research shows that <phrase>deep neural networks</phrase> dnns can be used <phrase>to extract</phrase> deep speaker vectors d vectors that preserve speaker characteristics and can be used in speaker verification. this new method has been <phrase>tested on</phrase> text dependent speaker verification tasks and improvement was reported when <phrase>combined with</phrase> the conventional i vector method. <phrase>this paper</phrase> extends the d vector <phrase>approach to</phrase> semi text independent speaker verification tasks i.e. the text of the speech is in a limited <phrase>set of</phrase> short phrases. we explore various settings of the dnn structure used for d vector extraction and present a phone dependent training which employs the posterior features obtained from an asr system. the <phrase>experimental results</phrase> show that it is possible to apply d vectors on semi text independent <phrase>speaker recognition</phrase> and the phone dependent training improves system performance.
<phrase>advances in</phrase> very <phrase>deep convolutional neural networks</phrase> for lvcsr
very deep cnns with small 3x3 kernels have recently been <phrase>shown to</phrase> achieve very strong performance as <phrase>acoustic models</phrase> in hybrid nn hmm <phrase>speech recognition</phrase> systems. in <phrase>this paper</phrase> we investigate how to efficiently scale <phrase>these models</phrase> to larger datasets. specifically we address the design <phrase>choice of</phrase> pooling and padding along the time dimension which renders convolutional evaluation of sequences highly inefficient. we propose <phrase>a new</phrase> cnn design without timepadding and without timepooling which is slightly suboptimal for accuracy but has two significant advantages it enables sequence training and deployment by allowing efficient convolutional evaluation of full utterances and it allows for <phrase>batch normalization</phrase> to be straightforwardly adopted to cnns on sequence data. through <phrase>batch normalization</phrase> we recover the lost peformance from removing the time pooling while keeping the benefit of efficient convolutional evaluation. we demonstrate <phrase>the performance of</phrase> our models both on larger scale data than before and after sequence training. our very deep cnn model sequence <phrase>trained on</phrase> the 2000h switchboard dataset obtains 9.4 <phrase>word error rate</phrase> on the hub5 <phrase>test set</phrase> matching with <phrase>a single</phrase> model <phrase>the performance of</phrase> the 2015 ibm system combination which was the previous best published result.
learning compact <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> rnns including <phrase>long short term memory lstm</phrase> rnns have produced <phrase>state of</phrase> <phrase>the art results</phrase> on <phrase>a variety of</phrase> <phrase>speech recognition</phrase> tasks. however <phrase>these models</phrase> are often too large in size for deployment on mobile devices with memory and latency constraints. in <phrase>this work</phrase> we study mechanisms for learning compact rnns and lstms via low rank factorizations and parameter sharing schemes. our goal is to investigate redundancies in recurrent architectures where compression can be admitted without losing performance. a hybrid strategy of using structured matrices in the bottom layers and shared low rank factors on the top layers is found to be particularly effective reducing <phrase>the parameters of</phrase> a standard lstm by 75 at <phrase>a small</phrase> cost of 0.3 increase in wer on a 2 000 hr english voice search task.
dependency parsing with lstms an empirical evaluation
we propose a transition based dependency parser using <phrase>recurrent neural networks</phrase> with <phrase>long short term memory lstm</phrase> units. this extends the feedforward <phrase>neural network</phrase> parser of chen and manning 2014 and enables modelling of entire sequences of shift reduce transition decisions. on the google web treebank our lstm parser is competitive with <phrase>the best</phrase> feedforward parser on overall accuracy and notably achieves <phrase>more than</phrase> 3 improvement for <phrase>long range</phrase> dependencies which has proved difficult for previous transition based parsers <phrase>due to</phrase> error propagation and limited context information. our findings additionally suggest that dropout regularisation on the embedding layer is crucial <phrase>to improve</phrase> the lstm s generalisation.
deep sentence embedding using <phrase>long short term memory</phrase> networks analysis and <phrase>application to</phrase> <phrase>information retrieval</phrase>
<phrase>this paper</phrase> develops a model that addresses sentence embedding a <phrase>hot topic</phrase> in current <phrase>natural language</phrase> processing research using <phrase>recurrent neural networks</phrase> with <phrase>long short term memory lstm</phrase> cells. <phrase>due to</phrase> its <phrase>ability to</phrase> capture <phrase>long term memory</phrase> the <phrase>lstm rnn</phrase> accumulates increasingly richer information as it goes through the sentence and when it reaches the last word the <phrase>hidden layer</phrase> of <phrase>the network</phrase> provides a semantic representation of the whole sentence. in <phrase>this paper</phrase> the <phrase>lstm rnn</phrase> is trained in a <phrase>weakly supervised</phrase> manner on user click through data logged by a commercial <phrase>web search</phrase> engine. visualization and analysis are performed <phrase>to understand</phrase> how the embedding process works. <phrase>the model</phrase> is found to automatically attenuate the unimportant words and detects the salient keywords in the sentence. furthermore these detected keywords are found to automatically activate different cells of the <phrase>lstm rnn</phrase> where words belonging to a similar topic activate <phrase>the same</phrase> cell. as a semantic representation of the sentence the embedding vector can be used in many different applications. these automatic keyword detection and topic allocation abilities enabled by the <phrase>lstm rnn</phrase> allow <phrase>the network</phrase> <phrase>to perform</phrase> document retrieval a difficult <phrase>language processing</phrase> task where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the <phrase>lstm rnn</phrase>. on a <phrase>web search</phrase> task the <phrase>lstm rnn</phrase> embedding is <phrase>shown to</phrase> <phrase>significantly outperform</phrase> several existing <phrase>state of</phrase> <phrase>the art</phrase> methods. we emphasize that <phrase>the proposed</phrase> model generates sentence embedding vectors that are specially useful for web document retrieval tasks. a comparison with a <phrase>well known</phrase> general sentence embedding method the paragraph vector is performed. the <phrase>results show</phrase> that <phrase>the proposed</phrase> method in <phrase>this paper</phrase> <phrase>significantly outperforms</phrase> it for web document retrieval task.
encoding source language with <phrase>convolutional neural network</phrase> for <phrase>machine translation</phrase>
the <phrase>recently proposed</phrase> <phrase>neural network</phrase> joint model nnjm devlin <phrase>et al</phrase>. 2014 augments the <phrase>n gram</phrase> <phrase>target language</phrase> model with a heuristically chosen source context window achieving <phrase>state of</phrase> <phrase>the art</phrase> performance in smt. in <phrase>this paper</phrase> we give a more systematic treatment by summarizing the relevant source information through a convolutional architecture guided by the target information. with different guiding signals during decoding our specifically designed convolution gating architectures can pinpoint the <phrase>parts of</phrase> a <phrase>source sentence</phrase> that are relevant to predicting a target word and fuse them with <phrase>the context of</phrase> entire <phrase>source sentence</phrase> to form <phrase>a unified</phrase> representation. this representation together with <phrase>target language</phrase> words are fed to <phrase>a deep neural network</phrase> dnn to form a stronger nnjm. <phrase>experiments on</phrase> two nist chinese english translation tasks show that <phrase>the proposed</phrase> model can achieve <phrase>significant improvements</phrase> over the previous nnjm by up to 1.08 bleu points on average
maximum a posteriori adaptation of network parameters in deep models
we present a bayesian <phrase>approach to</phrase> adapting parameters of a well trained context dependent <phrase>deep neural network</phrase> <phrase>hidden markov model</phrase> cd dnn hmm <phrase>to improve</phrase> <phrase>automatic speech recognition</phrase> performance. given an abundance of dnn parameters but with only a limited <phrase>amount of</phrase> data <phrase>the effectiveness of</phrase> the adapted dnn model can often be compromised. we formulate maximum a posteriori map adaptation of parameters of a specially designed cd dnn hmm with an augmented linear hidden networks connected to the output tied states or senones and compare it to <phrase>feature space</phrase> map <phrase>linear regression</phrase> previously proposed. experimental evidences on the 20 000 word open vocabulary <phrase>wall street</phrase> journal task demonstrate the feasibility of <phrase>the proposed</phrase> framework. in supervised adaptation <phrase>the proposed</phrase> map adaptation approach provides <phrase>more than</phrase> 10 relative error reduction and consistently outperforms the conventional transformation <phrase>based methods</phrase>. furthermore we present an initial <phrase>attempt to</phrase> generate hierarchical priors <phrase>to improve</phrase> adaptation efficiency and effectiveness with limited adaptation data by exploiting similarities among senones.
context dependent translation selection using <phrase>convolutional neural network</phrase>
we propose <phrase>a novel method</phrase> for translation selection in <phrase>statistical machine translation</phrase> in which <phrase>a convolutional neural network</phrase> is employed to judge the similarity between a phrase pair in two languages. the specifically designed convolutional architecture encodes <phrase>not only</phrase> the semantic similarity of the translation pair <phrase>but also</phrase> the context containing the phrase in the source language. therefore our approach is <phrase>able to</phrase> capture context dependent semantic similarities of translation pairs. we adopt a <phrase>curriculum learning</phrase> strategy <phrase>to train</phrase> <phrase>the model</phrase> we classify the training examples into easy medium and difficult categories and gradually build the ability of representing phrase and <phrase>sentence level</phrase> context <phrase>by using</phrase> training examples from <phrase>easy to</phrase> difficult. <phrase>experimental results</phrase> show that our approach <phrase>significantly outperforms</phrase> the baseline system by up to 1.4 bleu points.
<phrase>convolutional neural network</phrase> architectures for matching <phrase>natural language</phrase> sentences
semantic matching is of central importance to many <phrase>natural language</phrase> tasks cite bordes2014semantic retrievalqa . a successful matching algorithm <phrase>needs to</phrase> adequately model the internal structures of language objects and the interaction between them. as a step toward this goal we propose <phrase>convolutional neural network</phrase> models for matching two sentences by adapting the convolutional strategy in vision and speech. <phrase>the proposed</phrase> models <phrase>not only</phrase> nicely represent the hierarchical structures of sentences with their layer by layer composition and pooling <phrase>but also</phrase> capture the rich matching patterns at different levels. our models are rather generic requiring no <phrase>prior knowledge</phrase> on language and can hence be <phrase>applied to</phrase> matching tasks of different nature and in different languages. the empirical study on <phrase>a variety of</phrase> matching tasks demonstrates <phrase>the efficacy of</phrase> <phrase>the proposed</phrase> model on <phrase>a variety of</phrase> matching tasks and its superiority to competitor models.
<phrase>long short term memory</phrase> over tree structures
the chain structured <phrase>long short term memory lstm</phrase> has showed to be effective in <phrase>a wide range of</phrase> problems <phrase>such as</phrase> <phrase>speech recognition</phrase> and <phrase>machine translation</phrase>. in <phrase>this paper</phrase> we propose to extend it to tree structures in which a memory cell can reflect the history memories of multiple child cells or multiple descendant cells in a recursive process. we call <phrase>the model</phrase> s lstm which provides a principled way of considering long distance interaction over hierarchies e.g. language or image parse structures. we leverage the models for semantic composition <phrase>to understand</phrase> the meaning of text a fundamental problem in <phrase>natural language</phrase> understanding and show that it outperforms a <phrase>state of</phrase> <phrase>the art</phrase> recursive model by replacing its composition layers with the s lstm memory blocks. we <phrase>also show</phrase> that utilizing the given structures is helpful in achieving a performance <phrase>better than</phrase> that without considering the structures.
improving <phrase>the performance of</phrase> <phrase>neural machine translation</phrase> involving morphologically rich languages
the advent of the <phrase>attention mechanism</phrase> in <phrase>neural machine translation</phrase> models has improved <phrase>the performance of</phrase> <phrase>machine translation</phrase> systems by enabling selective lookup into the <phrase>source sentence</phrase>. in <phrase>this paper</phrase> the efficiencies of translation using bidirectional encoder attention decoder models were studied <phrase>with respect to</phrase> translation involving morphologically rich languages. the english <phrase>tamil language</phrase> pair was selected for this analysis. first <phrase>the use of</phrase> word2vec embedding for both the english and tamil words improved the translation results by 0.73 bleu points over the baseline rnnsearch model with 4.84 bleu score. <phrase>the use of</phrase> morphological segmentation before word vectorization to split the morphologically rich tamil words into their respective morphemes before the translation caused a <phrase>reduction in</phrase> the target vocabulary size by a factor of 8. also this model rnnmorph improved <phrase>the performance of</phrase> <phrase>neural machine translation</phrase> by 7.05 bleu points over the rnnsearch model used over <phrase>the same</phrase> corpus. since the bleu evaluation of the rnnmorph model might be unreliable <phrase>due to</phrase> an increase in <phrase>the number of</phrase> matching tokens per sentence the performances of the translations were also compared by means of human <phrase>evaluation metrics</phrase> of adequacy fluency and relative ranking. further <phrase>the use of</phrase> morphological segmentation also improved <phrase>the efficacy of</phrase> the <phrase>attention mechanism</phrase>.
<phrase>a recurrent neural network</phrase> without chaos
we introduce an exceptionally simple <phrase>gated recurrent</phrase> <phrase>neural network</phrase> rnn that achieves performance <phrase>comparable to</phrase> <phrase>well known</phrase> gated architectures <phrase>such as</phrase> lstms and grus on the <phrase>word level</phrase> <phrase>language modeling</phrase> task. we prove that our model has simple predicable and non chaotic dynamics. this stands in stark contrast to more standard gated architectures whose underlying <phrase>dynamical systems</phrase> exhibit chaotic behavior.
<phrase>end to end</phrase> phoneme sequence recognition using <phrase>convolutional neural networks</phrase>
most <phrase>phoneme recognition</phrase> <phrase>state of</phrase> <phrase>the art</phrase> systems <phrase>rely on</phrase> a classical <phrase>neural network</phrase> classifiers fed with highly tuned features <phrase>such as</phrase> mfcc or plp features. <phrase>recent advances in</phrase> <phrase>deep learning</phrase> approaches questioned such systems but while some attempts were made with simpler features <phrase>such as</phrase> spectrograms <phrase>state of</phrase> <phrase>the art</phrase> systems still <phrase>rely on</phrase> mfccs. this might be viewed as a <phrase>kind of</phrase> failure from <phrase>deep learning</phrase> approaches which are often claimed to have the <phrase>ability to</phrase> train with raw signals alleviating the need of <phrase>hand crafted</phrase> features. in <phrase>this paper</phrase> we investigate <phrase>a convolutional neural network</phrase> approach for raw speech signals. while convolutional architectures got tremendous success <phrase>in computer vision</phrase> or text processing they seem to have been let down in <phrase>the past</phrase> <phrase>recent years</phrase> in the <phrase>speech processing</phrase> field. we show that it is possible <phrase>to learn</phrase> <phrase>an end to end</phrase> phoneme sequence classifier system directly <phrase>from raw</phrase> signal with similar <phrase>performance on</phrase> the timit and wsj datasets than existing systems <phrase>based on</phrase> mfcc questioning the need of complex <phrase>hand crafted</phrase> features on large datasets.
a <phrase>deep learning</phrase> <phrase>approach to</phrase> <phrase>data driven</phrase> parameterizations for statistical parametric <phrase>speech synthesis</phrase>
nearly all statistical parametric speech synthesizers today use mel cepstral coefficients as the <phrase>vocal tract</phrase> parameterization of the speech signal. mel cepstral coefficients were never intended to work in a parametric <phrase>speech synthesis</phrase> framework but as yet there has been little success in creating a better parameterization that is more suited to synthesis. in <phrase>this paper</phrase> we use <phrase>deep learning</phrase> algorithms to investigate a <phrase>data driven</phrase> parameterization technique that is designed for the specific requirements of synthesis. we create an invertible <phrase>low dimensional</phrase> noise robust encoding of the mel log spectrum by training a tapered stacked denoising autoencoder sda . this sda is then unwrapped and <phrase>used as</phrase> the initialization for a <phrase>multi layer</phrase> perceptron mlp . the mlp is fine tuned by training it to reconstruct <phrase>the input</phrase> at <phrase>the output layer</phrase>. this mlp is then split down the middle to form encoding and decoding networks. these networks produce a parameterization of the mel log spectrum that is intended to better fulfill the requirements of synthesis. results are reported for experiments conducted using this resulting parameterization with the clustergen speech synthesizer.
addressing the rare word problem in <phrase>neural machine translation</phrase>
<phrase>neural machine translation</phrase> nmt is <phrase>a new approach</phrase> to <phrase>machine translation</phrase> that has shown <phrase>promising results</phrase> that are <phrase>comparable to</phrase> traditional approaches. a significant weakness in conventional nmt systems is their inability to correctly translate very rare words <phrase>end to end</phrase> nmts <phrase>tend to</phrase> have relatively small vocabularies with <phrase>a single</phrase> unk symbol that represents every possible out of vocabulary oov word. in <phrase>this paper</phrase> we propose and implement <phrase>an effective</phrase> technique <phrase>to address</phrase> <phrase>this problem</phrase>. we train an nmt system on data that is augmented by the output of a word alignment algorithm allowing the nmt system to emit for each oov word in the target sentence the position of its corresponding word in the <phrase>source sentence</phrase>. this information is later utilized in a post processing step that translates every oov word using a dictionary. our <phrase>experiments on</phrase> the wmt14 english to french translation task show that this method provides a substantial improvement of up to 2.8 bleu points over an equivalent nmt system that <phrase>does not</phrase> use this technique. with 37.5 bleu points our nmt system is the first to surpass <phrase>the best</phrase> result achieved on a wmt14 contest task.
investigating <phrase>the role of</phrase> prior disambiguation in <phrase>deep learning</phrase> compositional models of meaning
<phrase>this paper</phrase> aims to explore <phrase>the effect of</phrase> prior disambiguation on <phrase>neural network</phrase> based compositional models with the hope that better semantic representations for text compounds can be produced. we disambiguate <phrase>the input</phrase> word vectors before they are fed into a compositional deep net. <phrase>a series of</phrase> evaluations shows the positive effect of prior disambiguation for such deep models.
deep speech scaling up <phrase>end to end</phrase> <phrase>speech recognition</phrase>
we present a <phrase>state of</phrase> <phrase>the art</phrase> <phrase>speech recognition</phrase> system developed using <phrase>end to end</phrase> <phrase>deep learning</phrase>. our architecture is significantly simpler than traditional speech systems which <phrase>rely on</phrase> laboriously engineered processing pipelines these traditional systems also <phrase>tend to</phrase> perform poorly when used in noisy environments. <phrase>in contrast</phrase> our system <phrase>does not</phrase> need hand designed components to model background noise reverberation or speaker variation but instead directly learns a function that is robust to such effects. we <phrase>do not</phrase> need a phoneme dictionary nor even the concept of a phoneme. key to our approach is a well optimized rnn training system that uses multiple gpus <phrase>as well as</phrase> <phrase>a set of</phrase> novel data synthesis techniques that allow us to efficiently obtain <phrase>a large</phrase> <phrase>amount of</phrase> varied data for training. our system called deep speech outperforms previously published <phrase>results on</phrase> the widely studied switchboard hub5 00 achieving 16.0 error on the full <phrase>test set</phrase>. deep speech also handles challenging noisy environments <phrase>better than</phrase> <phrase>widely used</phrase> <phrase>state of</phrase> <phrase>the art</phrase> commercial speech systems.
incremental adaptation strategies for <phrase>neural network</phrase> <phrase>language models</phrase>
it is today acknowledged that <phrase>neural network</phrase> <phrase>language models</phrase> outperform backoff <phrase>language models</phrase> in applications like <phrase>speech recognition</phrase> or <phrase>statistical machine translation</phrase>. however training <phrase>these models</phrase> on large <phrase>amounts of</phrase> data can take several days. we present efficient techniques to adapt <phrase>a neural network</phrase> <phrase>language model</phrase> to new data. <phrase>instead of</phrase> training a completely new model or relying on mixture approaches we propose two new methods continued training on resampled data or insertion of adaptation layers. we present <phrase>experimental results</phrase> in an cat environment where the post edits of professional translators are used <phrase>to improve</phrase> an smt system. both methods are very fast and achieve <phrase>significant improvements</phrase> without overfitting the small adaptation data.
joint <phrase>rnn based</phrase> greedy parsing and word composition
<phrase>this paper</phrase> introduces a greedy parser <phrase>based on</phrase> <phrase>neural networks</phrase> which leverages <phrase>a new</phrase> compositional sub tree representation. the greedy parser and the compositional procedure are jointly trained and tightly <phrase>depends on</phrase> each other. the composition procedure outputs a vector representation which summarizes syntactically parsing tags and semantically words sub trees. composition and tagging is achieved over continuous word or tag representations and <phrase>recurrent neural networks</phrase>. we reach f1 <phrase>performance on</phrase> par with <phrase>well known</phrase> existing parsers while having the <phrase>advantage of</phrase> speed thanks to the greedy nature of the parser. we provide a fully functional implementation of the method described in <phrase>this paper</phrase>.
efficient exact gradient update for training <phrase>deep networks</phrase> with very large sparse targets
<phrase>an important</phrase> class of problems involves <phrase>training deep neural networks</phrase> with sparse prediction targets of very high dimension d. these occur naturally in e.g. <phrase>neural language models</phrase> or the learning of <phrase>word embeddings</phrase> often posed as predicting the probability of next words among a vocabulary of size d e.g. 200 000 . computing the equally large but typically non sparse d dimensional output vector from a last <phrase>hidden layer</phrase> of reasonable dimension d e.g. 500 incurs a prohibitive o dd <phrase>computational cost</phrase> for each example as does updating the d x d output weight matrix and computing the gradient needed for backpropagation to previous layers. while efficient handling of large sparse network inputs is trivial the case of large sparse targets is not and has thus <phrase>so far</phrase> been sidestepped with approximate alternatives <phrase>such as</phrase> hierarchical softmax or sampling based approximations <phrase>during training</phrase>. in <phrase>this work</phrase> we develop an original algorithmic approach which for a <phrase>family of</phrase> loss functions that includes squared error and spherical softmax can compute the exact loss gradient update for the output weights and gradient for backpropagation all in o d 2 per example <phrase>instead of</phrase> o dd remarkably without ever computing the d dimensional output. <phrase>the proposed</phrase> algorithm yields a speedup of d 4d i.e. two orders <phrase>of magnitude</phrase> for typical sizes for that critical part of the computations that often dominates the training time in this <phrase>kind of</phrase> <phrase>network architecture</phrase>.
discriminative neural sentence modeling by tree based convolution
<phrase>this paper</phrase> proposes a tree based <phrase>convolutional neural network</phrase> tbcnn for discriminative sentence modeling. our models leverage either constituency trees or dependency trees of sentences. the tree based convolution process extracts sentences structural features and these features are aggregated by max pooling. such architecture allows short propagation paths between <phrase>the output layer</phrase> and underlying feature detectors which enables effective structural <phrase>feature learning</phrase> and extraction. we evaluate our models on two tasks <phrase>sentiment analysis</phrase> and question classification. in both experiments tbcnn outperforms <phrase>previous state of</phrase> <phrase>the art</phrase> results including existing <phrase>neural networks</phrase> and dedicated feature rule engineering. we also make efforts to visualize the tree based convolution process shedding light on how our models work.
self adaptive hierarchical sentence model
the <phrase>ability to</phrase> accurately model a sentence at varying stages e.g. word phrase sentence plays a central <phrase>role in</phrase> <phrase>natural language</phrase> processing. as an effort towards this goal we propose a self adaptive hierarchical sentence model adasent . adasent effectively forms a hierarchy of representations from words to phrases and then to sentences through recursive gated local composition of adjacent segments. we design a competitive mechanism through gating networks to allow the representations of <phrase>the same</phrase> sentence to be engaged in a particular learning task e.g. classification therefore effectively mitigating the gradient vanishing problem persistent in other recursive models. both qualitative and quantitative analysis shows that adasent can automatically form and select the representations <phrase>suitable for</phrase> the task at hand <phrase>during training</phrase> yielding superior <phrase>classification performance</phrase> over competitor models on 5 benchmark <phrase>data sets</phrase>.
classifying relations by ranking with <phrase>convolutional neural networks</phrase>
<phrase>relation classification</phrase> is <phrase>an important</phrase> semantic processing task for which state ofthe art systems still <phrase>rely on</phrase> costly handcrafted features. in <phrase>this work</phrase> we tackle the <phrase>relation classification</phrase> task using <phrase>a convolutional neural network</phrase> that performs classification by ranking cr cnn . we propose <phrase>a new</phrase> pairwise ranking <phrase>loss function</phrase> that makes it <phrase>easy to</phrase> reduce the impact of artificial classes. we perform experiments using the the semeval 2010 task 8 dataset which is designed for <phrase>the task of</phrase> classifying the relationship between two nominals marked in a sentence. using crcnn we outperform the <phrase>state of</phrase> <phrase>the art</phrase> for this dataset and achieve a f1 of 84.1 without using any costly handcrafted features. additionally our <phrase>experimental results</phrase> show that 1 our approach is <phrase>more effective</phrase> than cnn followed by a softmax classifier 2 omitting the representation of the artificial class other improves both precision and recall and 3 using only <phrase>word embeddings</phrase> as <phrase>input features</phrase> is enough to <phrase>achieve state of</phrase> <phrase>the art</phrase> results if we consider only the text between the two target nominals.
lexical translation model using <phrase>a deep neural network</phrase> architecture
in <phrase>this paper</phrase> we combine the advantages of a model using global <phrase>source sentence</phrase> contexts the discriminative word lexicon and <phrase>neural networks</phrase>. <phrase>by using</phrase> <phrase>deep neural networks</phrase> <phrase>instead of</phrase> the linear maximum entropy model in the discriminative word lexicon models we are <phrase>able to</phrase> leverage dependencies between different source words <phrase>due to</phrase> the non linearity. furthermore the models for different target words can share parameters and therefore data sparsity problems are effectively reduced. <phrase>by using</phrase> <phrase>this approach</phrase> in a <phrase>state of</phrase> <phrase>the art</phrase> translation system we can improve the performance by up to 0.5 bleu points for <phrase>three different</phrase> language pairs on the ted translation task.
visualizing and understanding recurrent networks
<phrase>recurrent neural networks</phrase> rnns and specifically a variant with <phrase>long short term memory lstm</phrase> are enjoying renewed interest as a result of successful applications in <phrase>a wide range of</phrase> <phrase>machine learning</phrase> problems that involve sequential data. however while lstms provide exceptional results <phrase>in practice</phrase> the source of their performance and their limitations remain rather poorly understood. using <phrase>character level</phrase> <phrase>language models</phrase> as an interpretable testbed we aim to bridge this gap by providing an analysis of their representations predictions and error types. <phrase>in particular</phrase> our experiments reveal <phrase>the existence of</phrase> interpretable cells that keep track of <phrase>long range</phrase> dependencies <phrase>such as</phrase> line lengths quotes and brackets. moreover our comparative analysis with finite horizon <phrase>n gram</phrase> models traces the source of the lstm improvements to <phrase>long range</phrase> structural dependencies. finally we provide analysis of the remaining errors and suggests areas for further study.
a multi layered acoustic tokenizing <phrase>deep neural network</phrase> mat dnn for unsupervised discovery of linguistic units and generation of <phrase>high quality</phrase> features
<phrase>this paper</phrase> summarizes the work done by the authors for the zero resource speech challenge organized in the technical program of interspeech 2015. <phrase>the goal of</phrase> the challenge is <phrase>to discover</phrase> linguistic units directly from unlabeled speech data. the multi layered acoustic tokenizer mat proposed in <phrase>this work</phrase> automatically discovers multiple sets of acoustic tokens from the given corpus. each acoustic token set is specified by <phrase>a set of</phrase> hyperparameters that describe <phrase>the model</phrase> configuration. these sets of acoustic tokens carry different characteristics of the given corpus and the language behind thus can be mutually reinforced. the multiple sets of token labels are then <phrase>used as</phrase> the targets of a multi target dnn mdnn <phrase>trained on</phrase> low level acoustic features. bottleneck features <phrase>extracted from</phrase> the mdnn are <phrase>used as</phrase> feedback for the mat and the mdnn itself. we call this iterative system the multi layered acoustic tokenizing <phrase>deep neural network</phrase> mat dnn which generates <phrase>high quality</phrase> features for track 1 of the challenge and acoustic tokens for track 2 of the challenge.
author identification using multi headed <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> rnns are very good at modelling the flow of text but typically <phrase>need to</phrase> be <phrase>trained on</phrase> a far larger corpus than is available for the pan 2015 author identification task. <phrase>this paper</phrase> describes <phrase>a novel</phrase> approach where <phrase>the output layer</phrase> of a <phrase>character level</phrase> rnn <phrase>language model</phrase> is split into several independent predictive sub models each representing an author while the recurrent layer is shared by all. this allows the recurrent layer to model the language as a whole without over fitting while the outputs select <phrase>aspects of</phrase> the underlying model that reflect their author s style. the method proves competitive ranking first in two of the four languages.
a deep memory based architecture for <phrase>sequence to sequence</phrase> learning
we propose deepmemory <phrase>a novel</phrase> deep architecture for <phrase>sequence to sequence</phrase> learning which performs the task through <phrase>a series of</phrase> nonlinear transformations from the representation of <phrase>the input</phrase> sequence e.g. a chinese sentence to <phrase>the final</phrase> output sequence e.g. translation to english . <phrase>inspired by</phrase> the <phrase>recently proposed</phrase> neural <phrase>turing machine</phrase> graves <phrase>et al</phrase>. 2014 we store the intermediate representations in stacked layers of memories and use read write operations on the memories to realize the nonlinear transformations between the representations. the <phrase>types of</phrase> transformations are designed in advance but the parameters are learned from data. through layer by layer transformations deepmemory can model complicated <phrase>relations between</phrase> sequences necessary for <phrase>applications such as</phrase> <phrase>machine translation</phrase> between distant languages. the architecture can be trained with normal <phrase>back propagation</phrase> on sequenceto sequence data and the learning can be easily scaled up to <phrase>a large</phrase> corpus. deepmemory is broad enough to subsume the <phrase>state of</phrase> <phrase>the art</phrase> neural translation model in bahdanau <phrase>et al</phrase>. 2015 as its special case while significantly improving upon <phrase>the model</phrase> with its deeper architecture. remarkably deepmemory being purely <phrase>neural network</phrase> based can achieve performance <phrase>comparable to</phrase> the traditional phrase based <phrase>machine translation</phrase> system moses with <phrase>a small</phrase> vocabulary and a modest parameter size.
ask me anything dynamic <phrase>memory networks</phrase> for <phrase>natural language</phrase> processing
most tasks in <phrase>natural language</phrase> processing can be cast into <phrase>question answering</phrase> qa problems over language input. we introduce the dynamic <phrase>memory network</phrase> dmn <phrase>a neural network</phrase> architecture which processes input sequences and questions forms episodic memories and generates relevant answers. questions trigger an iterative attention process which allows <phrase>the model</phrase> to condition its attention on the inputs and the result of previous iterations. these results are then reasoned over in a hierarchical recurrent sequence model <phrase>to generate</phrase> answers. the dmn can be <phrase>trained end to end</phrase> and obtains <phrase>state of</phrase> <phrase>the art results</phrase> on several <phrase>types of</phrase> tasks and datasets <phrase>question answering</phrase> facebook s babi dataset <phrase>text classification</phrase> for <phrase>sentiment analysis</phrase> stanford sentiment treebank and <phrase>sequence modeling</phrase> for <phrase>part of speech tagging</phrase> wsj ptb . the training for these different tasks relies exclusively on trained word <phrase>vector representations</phrase> and input <phrase>question answer</phrase> triplets.
improved deep speaker <phrase>feature learning</phrase> for text dependent <phrase>speaker recognition</phrase>
a <phrase>deep learning</phrase> approach has been proposed recently to derive speaker identifies d vector by <phrase>a deep neural network</phrase> dnn . <phrase>this approach</phrase> has been <phrase>applied to</phrase> text dependent <phrase>speaker recognition</phrase> tasks and shows reasonable performance gains when <phrase>combined with</phrase> the conventional i vector approach. although promising the existing d vector implementation still can not compete with the i vector baseline. <phrase>this paper</phrase> presents two improvements for the <phrase>deep learning</phrase> approach a phonedependent dnn structure to normalize phone variation and <phrase>a new</phrase> scoring <phrase>approach based on</phrase> dynamic time warping dtw . <phrase>experiments on</phrase> a text dependent <phrase>speaker recognition</phrase> task demonstrated that <phrase>the proposed</phrase> methods can provide considerable <phrase>performance improvement</phrase> over the existing d vector implementation.
grid <phrase>long short term memory</phrase>
<phrase>this paper</phrase> introduces grid <phrase>long short term memory</phrase> a network of lstm cells arranged in a multidimensional grid that can be <phrase>applied to</phrase> vectors sequences or higher dimensional data <phrase>such as</phrase> images. <phrase>the network</phrase> differs from existing deep lstm architectures in that the cells are connected between network layers <phrase>as well as</phrase> along the spatiotemporal dimensions of the data. <phrase>the network</phrase> provides <phrase>a unified</phrase> way of using lstm for both deep and sequential computation. we apply <phrase>the model</phrase> to algorithmic <phrase>tasks such as</phrase> 15 digit integer addition and sequence memorization where it is <phrase>able to</phrase> <phrase>significantly outperform</phrase> the standard lstm. we then give results for two empirical tasks. we find that 2d grid lstm achieves 1.47 bits per character on the wikipedia character prediction benchmark which is <phrase>state of</phrase> <phrase>the art</phrase> among neural approaches. <phrase>in addition</phrase> we use the grid lstm to define <phrase>a novel</phrase> two dimensional translation model the reencoder and show that it outperforms a phrase based reference system on a chinese to english translation task.
a dependency based <phrase>neural network</phrase> for <phrase>relation classification</phrase>
previous research on <phrase>relation classification</phrase> has verified <phrase>the effectiveness of</phrase> using dependency shortest paths or subtrees. in <phrase>this paper</phrase> we further explore how to make full use of the <phrase>combination of</phrase> these dependency information. we first propose <phrase>a new</phrase> structure termed augmented dependency path adp which is <phrase>composed of</phrase> the shortest dependency path between two entities and the subtrees attached to the <phrase>shortest path</phrase>. to exploit the semantic representation behind the adp structure we develop dependency based <phrase>neural networks</phrase> depnn a <phrase>recursive neural</phrase> network designed to model the subtrees and <phrase>a convolutional neural network</phrase> <phrase>to capture</phrase> the most important features on the <phrase>shortest path</phrase>. <phrase>experiments on</phrase> the semeval 2010 dataset show that our <phrase>proposed method</phrase> <phrase>achieves state of</phrase> <phrase>art results</phrase>.
pte <phrase>predictive text</phrase> embedding through <phrase>large scale</phrase> heterogeneous text networks
unsupervised text embedding methods <phrase>such as</phrase> skip gram and paragraph vector have been attracting increasing attention <phrase>due to</phrase> their simplicity scalability and effectiveness. however comparing to sophisticated <phrase>deep learning</phrase> architectures <phrase>such as</phrase> <phrase>convolutional neural networks</phrase> these methods usually yield inferior results when <phrase>applied to</phrase> particular <phrase>machine learning</phrase> tasks. one possible reason is that these text embedding methods learn the representation of text in a fully unsupervised way without leveraging the labeled information available for the task. although the <phrase>low dimensional</phrase> representations learned are <phrase>applicable to</phrase> many different tasks they are not particularly tuned for any task. in <phrase>this paper</phrase> we fill this gap by proposing a <phrase>semi supervised</phrase> <phrase>representation learning</phrase> <phrase>method for</phrase> text data which we call the textit <phrase>predictive text</phrase> embedding pte . <phrase>predictive text</phrase> embedding utilizes both labeled and unlabeled data <phrase>to learn</phrase> the embedding of text. the labeled information and different levels of word co occurrence information are first represented as <phrase>a large</phrase> scale heterogeneous text network which is then embedded into a <phrase>low dimensional</phrase> space through a principled and efficient algorithm. this <phrase>low dimensional</phrase> embedding <phrase>not only</phrase> preserves the semantic closeness of words and documents <phrase>but also</phrase> has a strong predictive power for the particular task. <phrase>compared to</phrase> recent supervised approaches <phrase>based on</phrase> <phrase>convolutional neural networks</phrase> <phrase>predictive text</phrase> embedding is comparable or <phrase>more effective</phrase> much <phrase>more efficient</phrase> and has <phrase>fewer parameters</phrase> to tune.
<phrase>relation classification</phrase> via <phrase>recurrent neural network</phrase>
<phrase>deep learning</phrase> has gained much success in <phrase>sentence level</phrase> <phrase>relation classification</phrase>. for example <phrase>convolutional neural networks</phrase> cnn have delivered competitive performance without much effort on feature engineering as the conventional pattern <phrase>based methods</phrase>. thus a lot of works have been produced <phrase>based on</phrase> cnn structures. however a key issue that has not been well addressed by the cnn based method is <phrase>the lack of</phrase> capability <phrase>to learn</phrase> temporal features especially long distance dependency between nominal pairs. in <phrase>this paper</phrase> we propose <phrase>a simple</phrase> framework <phrase>based on</phrase> <phrase>recurrent neural networks</phrase> rnn and compare it with cnn based model. to show the limitation of popular used semeval 2010 task 8 dataset we introduce another dataset refined from mimlre angeli <phrase>et al</phrase>. 2014 . <phrase>experiments on</phrase> two different datasets strongly indicates that the <phrase>rnn based</phrase> model can deliver <phrase>better performance</phrase> on <phrase>relation classification</phrase> and it is particularly <phrase>capable of</phrase> learning long distance relation patterns. this makes it <phrase>suitable for</phrase> <phrase>real world</phrase> applications where complicated expressions are often involved.
learning from lda using <phrase>deep neural networks</phrase>
<phrase>latent dirichlet allocation</phrase> lda is a three level hierarchical bayesian model for topic inference. in spite of its great success inferring the latent topic distribution with lda is time consuming. <phrase>motivated by</phrase> the <phrase>transfer learning</phrase> approach proposed by newcite hinton2015distilling we present <phrase>a novel</phrase> method that uses lda to supervise the training of <phrase>a deep neural network</phrase> dnn so that the dnn can approximate the costly lda inference with less computation. our <phrase>experiments on</phrase> a <phrase>document classification</phrase> task show that <phrase>a simple</phrase> dnn can learn the lda behavior pretty well while the inference is speeded up tens or hundreds of times.
online <phrase>representation learning</phrase> in <phrase>recurrent neural</phrase> <phrase>language models</phrase>
we investigate an extension of continuous online learning in <phrase>recurrent neural network</phrase> <phrase>language models</phrase>. <phrase>the model</phrase> keeps a separate vector representation of the current unit of text being processed and adaptively adjusts it after each prediction. the initial experiments give <phrase>promising results</phrase> indicating that the method is <phrase>able to</phrase> increase language modelling accuracy while also decreasing the parameters needed to store <phrase>the model</phrase> <phrase>along with</phrase> the computation required at each step.
a <phrase>sensitivity analysis</phrase> of and practitioners guide to <phrase>convolutional neural networks</phrase> for <phrase>sentence classification</phrase>
<phrase>convolutional neural networks</phrase> cnns have recently achieved remarkably strong <phrase>performance on</phrase> the practically important task of <phrase>sentence classification</phrase> kim 2014 kalchbrenner 2014 johnson 2014 . however <phrase>these models</phrase> require practitioners to specify an exact model architecture and set accompanying hyperparameters including the filter region size regularization parameters and so on. it is currently unknown how sensitive model performance is to changes in these configurations for <phrase>the task of</phrase> <phrase>sentence classification</phrase>. we thus conduct a <phrase>sensitivity analysis</phrase> of one layer cnns to explore <phrase>the effect of</phrase> architecture components on model performance our aim is to distinguish between important and comparatively inconsequential design decisions for <phrase>sentence classification</phrase>. we <phrase>focus on</phrase> one layer cnns to the exclusion of more complex models <phrase>due to</phrase> their comparative simplicity and strong empirical performance which makes it a modern standard baseline method akin to <phrase>support vector machine</phrase> svms and <phrase>logistic regression</phrase>. we derive practical advice from our extensive empirical results for those interested in getting the most out of cnns for <phrase>sentence classification</phrase> in <phrase>real world</phrase> settings.
prediction adaptation correction <phrase>recurrent neural networks</phrase> for low resource language <phrase>speech recognition</phrase>
in <phrase>this paper</phrase> we investigate <phrase>the use of</phrase> prediction adaptation correction <phrase>recurrent neural networks</phrase> pac rnns for low resource <phrase>speech recognition</phrase>. a pac rnn is comprised of a pair of <phrase>neural networks</phrase> in which a it correction network uses auxiliary information given by a it prediction network to help estimate the state probability. the information from the correction network is also used by the prediction network in a recurrent loop. our <phrase>model outperforms</phrase> other <phrase>state of</phrase> <phrase>the art</phrase> <phrase>neural networks</phrase> dnns lstms on iarpa babel tasks. moreover <phrase>transfer learning</phrase> from a language that is <phrase>similar to</phrase> the <phrase>target language</phrase> can help <phrase>improve performance</phrase> further.
generating text with <phrase>deep reinforcement learning</phrase>
we introduce <phrase>a novel</phrase> schema for <phrase>sequence to sequence</phrase> learning with a <phrase>deep q</phrase> network dqn which decodes the output sequence iteratively. the aim here is to enable the decoder to first tackle easier portions of the sequences and then turn to cope with difficult parts. specifically in each iteration an <phrase>encoder decoder</phrase> <phrase>long short term memory lstm</phrase> network is employed to from <phrase>the input</phrase> sequence automatically create features <phrase>to represent</phrase> the internal states of and formulate a list of potential actions for the dqn. take rephrasing a natural sentence as an example. this list can contain ranked potential words. next the dqn learns to make decision on which action e.g. word will be selected from the list to modify the current decoded sequence. the newly modified output sequence is subsequently <phrase>used as</phrase> <phrase>the input</phrase> to the dqn for the next decoding iteration. in each iteration we also bias the <phrase>reinforcement learning</phrase> s attention to explore sequence portions which are previously difficult to be decoded. for evaluation <phrase>the proposed</phrase> strategy was trained to decode ten thousands natural sentences. our experiments indicate that when <phrase>compared to</phrase> a left to right greedy <phrase>beam search</phrase> lstm decoder <phrase>the proposed</phrase> method performed competitively well when decoding sentences from the <phrase>training set</phrase> but significantly outperformed the baseline when decoding unseen sentences <phrase>in terms of</phrase> bleu score obtained.
detecting interrogative utterances with <phrase>recurrent neural networks</phrase>
in <phrase>this paper</phrase> we explore different <phrase>neural network</phrase> architectures that can predict if a speaker of a given utterance is asking a question or making a statement. we com pare the outcomes of regularization methods that are popularly used <phrase>to train</phrase> <phrase>deep neural networks</phrase> and study how different context functions can affect the <phrase>classification performance</phrase>. we also compare <phrase>the efficacy of</phrase> gated <phrase>activation functions</phrase> that are favorably used in <phrase>recurrent neural networks</phrase> and study how to combine multimodal inputs. we evaluate our models on two multimodal datasets msr skype and callhome.
a neural transducer
<phrase>sequence to sequence</phrase> models have achieved impressive <phrase>results on</phrase> various tasks. however they are unsuitable for tasks that require incremental predictions to be made as more data arrives or tasks that have long input sequences and output sequences. this is because they generate an output sequence <phrase>conditioned on</phrase> an entire <phrase>input sequence</phrase>. in <phrase>this paper</phrase> we present a neural transducer that can make incremental predictions as more input arrives without redoing the entire computation. unlike <phrase>sequence to sequence</phrase> models the neural transducer computes the next step distribution <phrase>conditioned on</phrase> the partially observed <phrase>input sequence</phrase> and the partially generated sequence. at each time step the transducer can decide to emit zero to many output symbols. the data can be processed using an encoder and presented as input to the transducer. the discrete decision to emit a symbol at every time step makes it difficult <phrase>to learn</phrase> with conventional backpropagation. it is however possible <phrase>to train</phrase> the transducer <phrase>by using</phrase> a <phrase>dynamic programming</phrase> algorithm <phrase>to generate</phrase> target discrete decisions. our <phrase>experiments show</phrase> that the neural transducer works well in settings where it is required <phrase>to produce</phrase> output predictions as data come in. we also find that the neural transducer performs well for long sequences even when attention mechanisms are not used.
<phrase>skip thought</phrase> <phrase>memory networks</phrase>
<phrase>question answering</phrase> qa is fundamental to <phrase>natural language</phrase> processing in that most nlp problems can be phrased as qa kumar <phrase>et al</phrase>. 2015 . current <phrase>weakly supervised</phrase> <phrase>memory network</phrase> models that have been proposed <phrase>so far</phrase> struggle at answering questions that involve relations among multiple entities <phrase>such as</phrase> facebook s babi qa5 three arg relations in weston <phrase>et al</phrase>. 2015 . <phrase>to address</phrase> <phrase>this problem</phrase> of learning multi argument multi hop semantic relations for the purpose of qa we propose a method that combines the jointly learned <phrase>long term</phrase> read write memory and attentive inference components of <phrase>end to end</phrase> <phrase>memory networks</phrase> memn2n sukhbaatar <phrase>et al</phrase>. 2015 with distributed sentence <phrase>vector representations</phrase> encoded by a <phrase>skip thought</phrase> model kiros <phrase>et al</phrase>. 2015 . this choice to append <phrase>skip thought</phrase> vectors to the existing memn2n framework is <phrase>motivated by</phrase> the fact that <phrase>skip thought</phrase> vectors have been <phrase>shown to</phrase> accurately model multi argument semantic relations kiros <phrase>et al</phrase>. 2015 .
<phrase>named entity recognition</phrase> with bidirectional lstm cnns
<phrase>named entity recognition</phrase> is a <phrase>challenging task</phrase> that has traditionally required large <phrase>amounts of</phrase> knowledge in the form of feature engineering and lexicons to achieve high performance. in <phrase>this paper</phrase> we present <phrase>a novel</phrase> <phrase>neural network</phrase> architecture that automatically detects word and <phrase>character level</phrase> features using a hybrid bidirectional lstm and cnn architecture eliminating <phrase>the need for</phrase> most feature engineering. we also propose <phrase>a novel</phrase> method of encoding partial lexicon matches in <phrase>neural networks</phrase> and compare it to <phrase>existing approaches</phrase>. extensive evaluation shows that given only tokenized text and <phrase>publicly available</phrase> <phrase>word embeddings</phrase> our system is competitive on the conll 2003 dataset and surpasses the previously reported <phrase>state of</phrase> <phrase>the art performance on</phrase> the ontonotes 5.0 dataset by 2.13 f1 points. <phrase>by using</phrase> two lexicons constructed from <phrase>publicly available</phrase> sources we establish new <phrase>state of</phrase> <phrase>the art</phrase> performance with an f1 score of 91.62 on conll 2003 and 86.28 on ontonotes surpassing systems that employ heavy feature engineering proprietary lexicons and rich entity linking information.
generating news headlines with <phrase>recurrent neural networks</phrase>
we describe an <phrase>application of</phrase> an <phrase>encoder decoder</phrase> <phrase>recurrent neural network</phrase> with lstm units and attention to generating headlines from the text of news articles. we find that <phrase>the model</phrase> is quite effective at concisely paraphrasing news articles. furthermore we study how the <phrase>neural network</phrase> decides which input words to pay attention to and specifically we identify the function of the different neurons in a simplified <phrase>attention mechanism</phrase>. interestingly our simplified <phrase>attention mechanism</phrase> performs better that the more complex <phrase>attention mechanism</phrase> on a held out <phrase>set of</phrase> articles.
words are not equal graded weighting model for building composite document vectors
despite the success of distributional semantics composing phrases from word vectors remains <phrase>an important</phrase> challenge. several methods have been tried for benchmark <phrase>tasks such as</phrase> sentiment classification including word vector averaging matrix vector approaches <phrase>based on</phrase> parsing and on the fly learning of paragraph vectors. most models usually omit stop words from the composition. <phrase>instead of</phrase> such an yes no decision we consider several graded schemes where words are weighted <phrase>according to</phrase> their discriminatory relevance <phrase>with respect to</phrase> its use in the document e.g. idf . some of these methods particularly tf idf are seen to result in a <phrase>significant improvement</phrase> in performance over prior <phrase>state of</phrase> <phrase>the art</phrase>. further combining such approaches into an ensemble <phrase>based on</phrase> alternate classifiers <phrase>such as</phrase> the rnn model results in an 1.6 <phrase>performance improvement</phrase> on the standard imdb movie review dataset and a 7.01 improvement on amazon product reviews. since these are language free models and can be obtained in an unsupervised manner they are of interest also for under resourced languages <phrase>such as</phrase> hindi as well and many more languages. we demonstrate the language free aspects by showing a gain of 12 for two review datasets over earlier results and also release <phrase>a new</phrase> larger dataset for future testing singh 2015 .
small footprint <phrase>deep neural networks</phrase> with highway connections <phrase>for speech recognition</phrase>
<phrase>for speech recognition</phrase> <phrase>deep neural networks</phrase> dnns have significantly improved the recognition accuracy in most of <phrase>benchmark datasets</phrase> and application domains. however <phrase>compared to</phrase> the conventional gaussian mixture models dnn based <phrase>acoustic models</phrase> usually have much larger <phrase>number of</phrase> <phrase>model parameters</phrase> making it challenging for their applications in resource constrained platforms e.g. mobile devices. in <phrase>this paper</phrase> we study the <phrase>application of</phrase> the <phrase>recently proposed</phrase> highway network <phrase>to train</phrase> small footprint dnns which are it thinner and it deeper and have significantly smaller <phrase>number of</phrase> <phrase>model parameters</phrase> <phrase>compared to</phrase> conventional dnns. we investigated <phrase>this approach</phrase> on the ami meeting speech transcription corpus which has around 70 hours of audio data. the highway <phrase>neural networks</phrase> constantly outperformed their plain dnn counterparts and <phrase>the number of</phrase> <phrase>model parameters</phrase> can be reduced significantly without sacrificing the recognition accuracy.
backward and forward <phrase>language modeling</phrase> for constrained sentence generation
recent <phrase>language models</phrase> especially those <phrase>based on</phrase> <phrase>recurrent neural networks</phrase> rnns make it possible <phrase>to generate</phrase> <phrase>natural language</phrase> from a learned probability. language generation has wide applications including <phrase>machine translation</phrase> summarization <phrase>question answering</phrase> conversation systems etc. <phrase>existing methods</phrase> typically learn a joint probability of words <phrase>conditioned on</phrase> additional information which is either statically or dynamically fed to rnn s <phrase>hidden layer</phrase>. in <phrase>many applications</phrase> we are likely to impose hard constraints on the generated texts i.e. a particular word must appear in the sentence. unfortunately <phrase>existing approaches</phrase> could not solve <phrase>this problem</phrase>. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> backward and forward <phrase>language model</phrase>. provided a specific word we use rnns <phrase>to generate</phrase> previous words and future words either simultaneously or asynchronously resulting in two model variants. in this way the given word could appear at any position in the sentence. <phrase>experimental results</phrase> show that the generated texts are <phrase>comparable to</phrase> sequential lms in quality.
online keyword spotting with a <phrase>character level</phrase> <phrase>recurrent neural network</phrase>
in <phrase>this paper</phrase> we propose a context aware keyword spotting model employing a <phrase>character level</phrase> <phrase>recurrent neural network</phrase> rnn for spoken term detection in <phrase>continuous speech</phrase>. the rnn is <phrase>end to end</phrase> trained with connectionist temporal classification ctc <phrase>to generate</phrase> the probabilities of character and word boundary labels. there is no need for the <phrase>phonetic transcription</phrase> senone modeling or system dictionary in training and testing. also keywords can easily be added and modified by editing the text based keyword list without retraining the rnn. moreover the unidirectional rnn processes an infinitely long input audio streams without pre segmentation and keywords are detected with low latency before the utterance is finished. <phrase>experimental results</phrase> show that <phrase>the proposed</phrase> keyword spotter <phrase>significantly outperforms</phrase> the <phrase>deep neural network</phrase> dnn and <phrase>hidden markov model</phrase> hmm based keyword filler model even with less computations.
<phrase>domain specific</phrase> author attribution <phrase>based on</phrase> feedforward <phrase>neural network</phrase> <phrase>language models</phrase>
authorship attribution refers to <phrase>the task of</phrase> automatically determining the author <phrase>based on</phrase> a given sample of text. it is a problem with a long history and has <phrase>a wide range of</phrase> application. building author profiles using <phrase>language models</phrase> is one of the most successful methods to automate <phrase>this task</phrase>. new <phrase>language modeling</phrase> methods <phrase>based on</phrase> <phrase>neural networks</phrase> alleviate the curse of dimensionality and usually outperform conventional <phrase>n gram</phrase> methods. however there have not been much research applying them to authorship attribution. in <phrase>this paper</phrase> we present <phrase>a novel</phrase> setup of <phrase>a neural network</phrase> <phrase>language model</phrase> nnlm and apply it to a database of text samples from different authors. we investigate how the nnlm performs on a task with moderate author set size and relatively limited training and test data and how the topics of the text samples affect the accuracy. nnlm achieves nearly 2.5 <phrase>reduction in</phrase> perplexity a measurement of fitness of a trained <phrase>language model</phrase> to the test data. given 5 random test sentences it also increases the author <phrase>classification accuracy</phrase> by 3.43 on average <phrase>compared with</phrase> the <phrase>n gram</phrase> methods using srilm tools. an <phrase>open source</phrase> implementation of our methodology is freely <phrase>available at</phrase> https github.com zge authorship attribution .
segmental <phrase>recurrent neural networks</phrase> for <phrase>end to end</phrase> <phrase>speech recognition</phrase>
we study the segmental <phrase>recurrent neural network</phrase> for <phrase>end to end</phrase> acoustic modelling. this model connects the segmental <phrase>conditional random field</phrase> crf with <phrase>a recurrent neural network</phrase> rnn used for <phrase>feature extraction</phrase>. <phrase>compared to</phrase> most previous crf based <phrase>acoustic models</phrase> it <phrase>does not</phrase> <phrase>rely on</phrase> an external system to provide features or segmentation boundaries. instead this model marginalises out all the possible segmentations and features are <phrase>extracted from</phrase> the rnn trained together with the segmental crf. in essence this model is self contained and can be <phrase>trained end to end</phrase>. in <phrase>this paper</phrase> we discuss practical training and decoding issues <phrase>as well as</phrase> the method to speed up the training in <phrase>the context of</phrase> <phrase>speech recognition</phrase>. we performed <phrase>experiments on</phrase> the timit dataset. we achieved 17.3 phone <phrase>error rate</phrase> per from the first pass decoding <phrase>the best</phrase> reported result using crfs despite the fact that we only used a zeroth order crf and without using any <phrase>language model</phrase>.
how transferable are <phrase>neural networks</phrase> in nlp applications 
<phrase>transfer learning</phrase> is aimed to make use of valuable knowledge in a source domain to help model performance in a target domain. it is particularly important to <phrase>neural networks</phrase> which are very likely to be overfitting. in some fields like <phrase>image processing</phrase> many studies have shown <phrase>the effectiveness of</phrase> <phrase>neural network</phrase> based <phrase>transfer learning</phrase>. for neural nlp however existing studies have only casually applied <phrase>transfer learning</phrase> and conclusions are inconsistent. in <phrase>this paper</phrase> we conduct systematic case studies and provide an illuminating picture on the transferability of <phrase>neural networks</phrase> in nlp.
<phrase>recurrent neural network</phrase> encoder with attention for community <phrase>question answering</phrase>
we apply a general <phrase>recurrent neural network</phrase> rnn encoder framework to community <phrase>question answering</phrase> cqa tasks. our approach <phrase>does not</phrase> <phrase>rely on</phrase> any linguistic processing and can be <phrase>applied to</phrase> different languages or domains. further improvements are observed when we extend the rnn encoders with a neural <phrase>attention mechanism</phrase> that encourages reasoning over entire sequences. to deal with practical issues <phrase>such as</phrase> data sparsity and imbalanced labels we apply various techniques <phrase>such as</phrase> <phrase>transfer learning</phrase> and multitask learning. our <phrase>experiments on</phrase> the semeval 2016 cqa task show 10 improvement on a map score <phrase>compared to</phrase> an <phrase>information retrieval</phrase> <phrase>based approach</phrase> and achieve comparable performance to a strong handcrafted feature based method.
<phrase>recursive neural</phrase> language architecture for tag prediction
we consider <phrase>the problem of</phrase> learning distributed representations for tags from their associated content for <phrase>the task of</phrase> tag recommendation. considering tagging information is usually very sparse effective learning from content and tag association is very crucial and <phrase>challenging task</phrase>. recently various neural <phrase>representation learning</phrase> models <phrase>such as</phrase> wsabie and its variants show promising performance mainly <phrase>due to</phrase> compact <phrase>feature representations</phrase> learned in a semantic space. however their capacity is limited by a linear compositional approach for representing tags as sum of equal parts and hurt their performance. in <phrase>this work</phrase> we propose a neural feedback relevance model for learning tag representations with weighted <phrase>feature representations</phrase>. our <phrase>experiments on</phrase> two <phrase>widely used</phrase> datasets show <phrase>significant improvement</phrase> for quality of recommendations over various baselines.
on the compression of <phrase>recurrent neural networks</phrase> with an <phrase>application to</phrase> lvcsr acoustic modeling for embedded <phrase>speech recognition</phrase>
we study <phrase>the problem of</phrase> compressing <phrase>recurrent neural networks</phrase> rnns . <phrase>in particular</phrase> we <phrase>focus on</phrase> the compression of rnn <phrase>acoustic models</phrase> which are <phrase>motivated by</phrase> <phrase>the goal of</phrase> building compact and accurate <phrase>speech recognition</phrase> systems which can be run efficiently on mobile devices. in <phrase>this work</phrase> we present a technique for general recurrent model compression that jointly compresses both recurrent and non recurrent inter layer weight matrices. we find that <phrase>the proposed</phrase> technique allows us <phrase>to reduce</phrase> the size of our <phrase>long short term memory lstm</phrase> acoustic model to a third of its original size with negligible loss in accuracy.
pointing the unknown words
<phrase>the problem of</phrase> rare and unknown words is <phrase>an important</phrase> issue that can potentially influence <phrase>the performance of</phrase> many nlp systems including both the traditional count based and the <phrase>deep learning</phrase> models. we propose <phrase>a novel</phrase> way to deal with the rare and unseen words for the <phrase>neural network</phrase> models using attention. our model uses two softmax layers <phrase>in order to</phrase> predict the next word in conditional <phrase>language models</phrase> one predicts the location of a word in the <phrase>source sentence</phrase> and the other predicts a word in the shortlist vocabulary. at each time step the decision of which softmax layer to use choose adaptively made by an mlp which is <phrase>conditioned on</phrase> the context. we motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known. we observe improvements on two tasks <phrase>neural machine translation</phrase> on the europarl english to french parallel corpora and text summarization on the gigaword dataset using our <phrase>proposed model</phrase>.
learning multiscale features directly from waveforms
<phrase>deep learning</phrase> has dramatically improved <phrase>the performance of</phrase> <phrase>speech recognition</phrase> systems through learning hierarchies of features optimized for the task at hand. however true <phrase>end to end</phrase> learning where features are learned directly from waveforms has only recently reached <phrase>the performance of</phrase> hand tailored representations <phrase>based on</phrase> the <phrase>fourier transform</phrase>. in <phrase>this paper</phrase> we detail an <phrase>approach to</phrase> use convolutional filters to push past the inherent tradeoff of temporal and frequency resolution that exists for spectral representations. at increased <phrase>computational cost</phrase> we show that increasing <phrase>temporal resolution</phrase> via reduced stride and increasing frequency resolution via additional filters delivers significant performance improvements. further we find <phrase>more efficient</phrase> representations by simultaneously learning at multiple scales <phrase>leading to</phrase> an overall <phrase>decrease in</phrase> <phrase>word error rate</phrase> on a difficult internal speech <phrase>test set</phrase> by 20.7 relative to networks with <phrase>the same</phrase> <phrase>number of</phrase> parameters <phrase>trained on</phrase> spectrograms.
joint learning of sentence embeddings for relevance and entailment
we consider <phrase>the problem of</phrase> recognizing <phrase>textual entailment</phrase> within an <phrase>information retrieval</phrase> context where we must simultaneously determine the relevancy <phrase>as well as</phrase> degree of entailment for individual pieces of evidence to determine a yes no answer to a binary <phrase>natural language</phrase> question. we compare several variants of <phrase>neural networks</phrase> for sentence embeddings in a setting of <phrase>decision making</phrase> <phrase>based on</phrase> evidence of varying relevance. we propose a basic model to integrate evidence for entailment show that joint training of the sentence embeddings to model relevance and entailment is feasible even with no explicit per evidence supervision and show the importance of evaluating strong baselines. we also demonstrate the benefit of carrying over text comprehension model <phrase>trained on</phrase> an unrelated task for our small datasets. our research is motivated primarily by <phrase>a new</phrase> open dataset we introduce <phrase>consisting of</phrase> binary questions and news based evidence snippets. we also apply <phrase>the proposed</phrase> relevance entailment model on a similar task of ranking <phrase>multiple choice</phrase> test answers evaluating it on a preliminary dataset of school test questions <phrase>as well as</phrase> the standard mctest dataset where we improve the neural model <phrase>state of</phrase> art.
deep api learning
developers often wonder how to implement a certain functionality e.g. how to parse xml files using apis. obtaining an api usage sequence <phrase>based on</phrase> an api related <phrase>natural language</phrase> query is very helpful in this regard. given a query <phrase>existing approaches</phrase> utilize <phrase>information retrieval</phrase> models to search for matching api sequences. <phrase>these approaches</phrase> treat queries and apis as bag of words i.e. keyword matching or word to word alignment and lack a deep understanding of the semantics of the query. we propose deepapi a <phrase>deep learning</phrase> <phrase>based approach</phrase> <phrase>to generate</phrase> api usage sequences for a given <phrase>natural language</phrase> query. <phrase>instead of</phrase> a bags of words assumption it learns the sequence of words in a query and the sequence of associated apis. deepapi adapts a neural <phrase>language model</phrase> named rnn <phrase>encoder decoder</phrase>. it encodes a word sequence user query into <phrase>a fixed</phrase> length context vector and generates an api sequence <phrase>based on</phrase> the context vector. we also augment the rnn <phrase>encoder decoder</phrase> by considering the importance of individual apis. we empirically evaluate our approach with <phrase>more than</phrase> 7 million annotated code snippets collected from github. the <phrase>results show</phrase> that our approach generates largely accurate api sequences and outperforms the related approaches.
does multimodality help human and machine for translation and image captioning 
<phrase>this paper</phrase> presents the systems developed by lium and cvc for the wmt16 multimodal <phrase>machine translation</phrase> challenge. we explored various comparative methods namely phrase based systems and attentional <phrase>recurrent neural networks</phrase> models trained using monomodal or multimodal data. we also performed a human evaluation <phrase>in order to</phrase> estimate the usefulness of multimodal data for human <phrase>machine translation</phrase> and image description generation. our systems obtained <phrase>the best</phrase> results for both tasks <phrase>according to</phrase> the automatic <phrase>evaluation metrics</phrase> bleu and meteor.
very <phrase>deep convolutional</phrase> networks for <phrase>text classification</phrase>
the dominant approach for many nlp tasks are <phrase>recurrent neural networks</phrase> <phrase>in particular</phrase> lstms and <phrase>convolutional neural networks</phrase>. however these architectures are rather shallow in comparison to the <phrase>deep convolutional</phrase> networks which have pushed the <phrase>state of</phrase> <phrase>the art</phrase> <phrase>in computer vision</phrase>. we present <phrase>a new</phrase> architecture vdcnn for text processing which operates directly at the <phrase>character level</phrase> and uses only small convolutions and pooling operations. we are <phrase>able to</phrase> show that <phrase>the performance of</phrase> this model increases with depth using up to 29 convolutional layers we report improvements over the <phrase>state of</phrase> <phrase>the art</phrase> on several public <phrase>text classification</phrase> tasks. to <phrase>the best</phrase> of our knowledge this is the first time that very <phrase>deep convolutional</phrase> nets have been <phrase>applied to</phrase> text processing.
improving <phrase>recurrent neural networks</phrase> for sequence labelling
in <phrase>this paper</phrase> we study different <phrase>types of</phrase> <phrase>recurrent neural networks</phrase> rnn for <phrase>sequence labeling</phrase> tasks. we propose two new variants of rnns integrating improvements for <phrase>sequence labeling</phrase> and we compare them to the more traditional elman and jordan rnns. we compare all models either traditional or new on four distinct tasks of <phrase>sequence labeling</phrase> two on spoken <phrase>language understanding</phrase> atis and media and two of pos tagging for the french treebank ftb and the <phrase>penn treebank</phrase> ptb corpora. the <phrase>results show</phrase> that our new variants of rnns are always <phrase>more effective</phrase> than the others.
sentence similarity measures for <phrase>fine grained</phrase> estimation of topical relevance in learner essays
we investigate <phrase>the task of</phrase> assessing <phrase>sentence level</phrase> prompt relevance in learner essays. various systems using word overlap neural embeddings and neural compositional models are evaluated on two datasets of learner writing. we propose <phrase>a new</phrase> <phrase>method for</phrase> <phrase>sentence level</phrase> similarity calculation which learns to adjust the weights of <phrase>pre trained</phrase> <phrase>word embeddings</phrase> for a specific task achieving substantially higher accuracy <phrase>compared to</phrase> other relevant baselines.
deep cnns along the time axis with intermap pooling for robustness to spectral variations
<phrase>convolutional neural networks</phrase> cnns with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features. however this is inappropriate with regard to the fact that acoustic features vary in frequency. in <phrase>this paper</phrase> we contend that convolution along the time axis is <phrase>more effective</phrase>. we also propose the addition of an intermap pooling imp layer to deep cnns. in this layer filters in each group extract common but spectrally variant features then the layer pools the feature maps of each group. as a result <phrase>the proposed</phrase> imp cnn can achieve insensitivity to spectral variations characteristic of different speakers and utterances. <phrase>the effectiveness of</phrase> the imp cnn architecture is demonstrated on several lvcsr tasks. even without speaker adaptation techniques the architecture achieved a wer of 12.7 on the swb part of the hub5 2000 evaluation <phrase>test set</phrase> which is competitive with other <phrase>state of</phrase> <phrase>the art</phrase> methods.
automatic text scoring using <phrase>neural networks</phrase>
automated text scoring ats provides a cost effective and consistent alternative to human marking. however <phrase>in order to</phrase> achieve good performance the predictive features of the system <phrase>need to</phrase> be manually engineered by human experts. we introduce a model that forms word representations by learning the extent to which specific words contribute to the text s score. using <phrase>long short term memory</phrase> networks <phrase>to represent</phrase> the meaning of texts we demonstrate that a fully automated framework is <phrase>able to</phrase> achieve excellent results over similar approaches. in an <phrase>attempt to</phrase> make our results more interpretable and <phrase>inspired by</phrase> <phrase>recent advances in</phrase> visualizing <phrase>neural networks</phrase> we introduce <phrase>a novel method</phrase> for identifying the regions of the text that <phrase>the model</phrase> has found more discriminative.
a comprehensive study of deep bidirectional lstm rnns for acoustic modeling in <phrase>speech recognition</phrase>
we present a comprehensive study of deep bidirectional <phrase>long short term memory lstm</phrase> <phrase>recurrent neural network rnn</phrase> based <phrase>acoustic models</phrase> for <phrase>automatic speech recognition</phrase> asr . we study <phrase>the effect of</phrase> size and depth and train models of up to 8 layers. we investigate the training aspect and study different variants of optimization methods batching truncated backpropagation different regularization techniques <phrase>such as</phrase> dropout and l 2 regularization and different gradient clipping variants. the major part of the experimental analysis was performed on the quaero corpus. additional experiments also were performed on the switchboard corpus. our best lstm model has a relative improvement in <phrase>word error rate</phrase> of over 14 <phrase>compared to</phrase> our best <phrase>feed forward</phrase> <phrase>neural network</phrase> ffnn baseline on the quaero task. on <phrase>this task</phrase> we get our best result with an 8 layer bidirectional lstm and we show that a pretraining scheme with <phrase>layer wise</phrase> construction helps for deep lstms. finally we compare the training calculation time of many of the presented experiments in relation with recognition performance. all the experiments were done with returnn the rwth extensible training <phrase>framework for</phrase> universal <phrase>recurrent neural networks</phrase> in combination with rasr the rwth asr toolkit.
sequence level knowledge distillation
<phrase>neural machine translation</phrase> nmt offers <phrase>a novel</phrase> alternative formulation of translation that is potentially simpler than statistical approaches. however to reach competitive performance nmt models <phrase>need to</phrase> be exceedingly large. in <phrase>this paper</phrase> we consider applying knowledge distillation approaches bucila <phrase>et al</phrase>. 2006 hinton <phrase>et al</phrase>. 2015 that have proven successful for reducing the size of <phrase>neural models</phrase> in other domains to <phrase>the problem of</phrase> nmt. we demonstrate that standard knowledge distillation <phrase>applied to</phrase> <phrase>word level</phrase> prediction can be effective for nmt and also introduce two novel sequence level versions of knowledge distillation that further <phrase>improve performance</phrase> and somewhat surprisingly seem to eliminate <phrase>the need for</phrase> <phrase>beam search</phrase> even when applied on <phrase>the original</phrase> teacher model . our best student model runs 10 times <phrase>faster than</phrase> its <phrase>state of</phrase> <phrase>the art</phrase> teacher with little loss in performance. it is also significantly <phrase>better than</phrase> a baseline model trained without knowledge distillation by 4.2 1.7 bleu with greedy decoding <phrase>beam search</phrase>. applying weight pruning on top of knowledge distillation results in a student model that has 13 times <phrase>fewer parameters</phrase> than <phrase>the original</phrase> teacher model with a decrease of 0.4 bleu.
learning semantically coherent and reusable kernels in convolution neural nets for <phrase>sentence classification</phrase>
the <phrase>state of</phrase> <phrase>the art</phrase> cnn models give good <phrase>performance on</phrase> <phrase>sentence classification</phrase> tasks. the purpose of <phrase>this work</phrase> is to empirically study desirable properties <phrase>such as</phrase> semantic coherence <phrase>attention mechanism</phrase> and reusability of cnns in these tasks. semantically coherent kernels are preferable as they are a lot more interpretable for explaining the decision of the learned cnn model. we observe that the learned kernels <phrase>do not</phrase> have semantic coherence. <phrase>motivated by</phrase> this observation we propose <phrase>to learn</phrase> kernels with semantic coherence using clustering scheme <phrase>combined with</phrase> word2vec representation and <phrase>domain knowledge</phrase> <phrase>such as</phrase> sentiwordnet. we suggest a technique to visualize <phrase>attention mechanism</phrase> of cnns for decision explanation purpose. reusable property enables kernels learned on one problem to be used in another problem. this helps in efficient learning as only a few additional <phrase>domain specific</phrase> filters may have to be learned. we demonstrate <phrase>the efficacy of</phrase> our core ideas of learning semantically coherent kernels and leveraging reusable kernels for efficient learning on several <phrase>benchmark datasets</phrase>. <phrase>experimental results</phrase> show the usefulness of our approach by achieving performance <phrase>close to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> methods but with semantic and reusable properties.
returnn the rwth extensible training <phrase>framework for</phrase> universal <phrase>recurrent neural networks</phrase>
in <phrase>this work</phrase> we release our extensible and easily configurable <phrase>neural network</phrase> training software. it provides a rich <phrase>set of</phrase> functional layers with a particular <phrase>focus on</phrase> efficient training of <phrase>recurrent neural network</phrase> topologies on multiple gpus. the source of the software package is public and freely available for academic research purposes and can be <phrase>used as</phrase> a framework or as a standalone tool which supports a flexible configuration. the software allows <phrase>to train</phrase> <phrase>state of</phrase> <phrase>the art</phrase> deep bidirectional <phrase>long short term memory lstm</phrase> models on both one dimensional data like speech or two dimensional data like handwritten text and was used to develop successful submission systems in several evaluation campaigns.
<phrase>character level</phrase> <phrase>language modeling</phrase> with hierarchical <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural network rnn</phrase> based <phrase>character level</phrase> <phrase>language models</phrase> clms are extremely useful for modeling out of vocabulary words by nature. however their performance is generally much worse than the <phrase>word level</phrase> <phrase>language models</phrase> wlms since clms <phrase>need to</phrase> consider longer history of tokens to properly predict the next one. we address <phrase>this problem</phrase> by proposing hierarchical rnn architectures which consist of multiple modules with different timescales. despite the multi timescale structures <phrase>the input</phrase> and output layers operate with the <phrase>character level</phrase> clock which allows the existing rnn clm training approaches to be directly applicable without any modifications. our clm models show better perplexity than kneser ney kn 5 gram wlms on the one billion word benchmark with only 2 of parameters. also we present <phrase>real time</phrase> <phrase>character level</phrase> <phrase>end to end</phrase> <phrase>speech recognition</phrase> examples on the <phrase>wall street</phrase> journal wsj corpus where replacing traditional mono clock rnn clms with <phrase>the proposed</phrase> models results in better recognition accuracies even though <phrase>the number of</phrase> parameters are reduced to 30 .
<phrase>multi task</phrase> recurrent model for true multilingual <phrase>speech recognition</phrase>
research on multilingual <phrase>speech recognition</phrase> remains attractive yet challenging. recent studies <phrase>focus on</phrase> learning shared structures under the <phrase>multi task</phrase> paradigm <phrase>in particular</phrase> a feature sharing structure. <phrase>this approach</phrase> has been found effective <phrase>to improve</phrase> <phrase>performance on</phrase> each individual language. however <phrase>this approach</phrase> is only useful when the deployed system supports just one language. in a true multilingual scenario where multiple languages are allowed performance will be significantly reduced <phrase>due to</phrase> the competition among languages in the decoding space. <phrase>this paper</phrase> presents a <phrase>multi task</phrase> recurrent model that involves a multilingual <phrase>speech recognition</phrase> asr component and a language recognition lr component and the asr component is informed of the language information by the lr component <phrase>leading to</phrase> a language aware recognition. we tested the approach on an english chinese bilingual <phrase>recognition task</phrase>. the <phrase>results show</phrase> that <phrase>the proposed</phrase> <phrase>multi task</phrase> recurrent model can <phrase>improve performance</phrase> of multilingual <phrase>recognition systems</phrase>.
<phrase>sentiment analysis</phrase> on bangla and romanized bangla text brbt using deep recurrent models
<phrase>sentiment analysis</phrase> sa is an <phrase>action research</phrase> area in the digital age. with rapid and constant growth of online <phrase>social media</phrase> sites and services and the increasing <phrase>amount of</phrase> textual data <phrase>such as</phrase> statuses comments reviews etc. available in them <phrase>application of</phrase> automatic sa is on the rise. however most of the research works on sa in <phrase>natural language</phrase> processing nlp are <phrase>based on</phrase> <phrase>english language</phrase>. despite being the sixth most widely spoken language in the world bangla still <phrase>does not</phrase> have <phrase>a large</phrase> and standard dataset. because of this recent research works in bangla have failed <phrase>to produce</phrase> results that can be both <phrase>comparable to</phrase> works done by others and reusable as stepping stones for future researchers to progress in this field. therefore we first tried to provide a textual dataset that includes not just bangla but romanized bangla texts as well is substantial post processed and multiple validated ready to be used in sa experiments. we tested this dataset in deep recurrent model specifically <phrase>long short term memory lstm</phrase> using two <phrase>types of</phrase> loss functions binary crossentropy and categorical crossentropy and also did some experimental <phrase>pre training</phrase> <phrase>by using</phrase> data from one validation to pre train the other and vice versa. lastly we documented the results <phrase>along with</phrase> some analysis on them which were promising.
attending to characters in neural <phrase>sequence labeling</phrase> models
<phrase>sequence labeling</phrase> architectures use <phrase>word embeddings</phrase> for capturing similarity but suffer when handling previously unseen or rare words. we investigate <phrase>character level</phrase> extensions to such models and propose <phrase>a novel</phrase> architecture for combining alternative word representations. <phrase>by using</phrase> an <phrase>attention mechanism</phrase> <phrase>the model</phrase> is <phrase>able to</phrase> dynamically decide how much information to use from a word or <phrase>character level</phrase> component. we evaluated different architectures on <phrase>a range of</phrase> <phrase>sequence labeling</phrase> datasets and <phrase>character level</phrase> extensions were found <phrase>to improve</phrase> <phrase>performance on</phrase> every benchmark. <phrase>in addition</phrase> <phrase>the proposed</phrase> <phrase>attention based</phrase> architecture delivered <phrase>the best</phrase> results even with a smaller <phrase>number of</phrase> trainable parameters.
visualizing and understanding <phrase>curriculum learning</phrase> for <phrase>long short term memory</phrase> networks
<phrase>curriculum learning</phrase> emphasizes the order of training instances in a computational learning setup. the core hypothesis is that simpler instances should be learned early as <phrase>building blocks</phrase> <phrase>to learn</phrase> more complex ones. despite its usefulness it is still unknown how exactly the internal representation of models are affected by <phrase>curriculum learning</phrase>. in <phrase>this paper</phrase> we study <phrase>the effect of</phrase> <phrase>curriculum learning</phrase> on <phrase>long short term memory lstm</phrase> networks which have shown strong competency in many <phrase>natural language</phrase> processing nlp problems. our <phrase>experiments on</phrase> <phrase>sentiment analysis</phrase> task and a synthetic task <phrase>similar to</phrase> sequence prediction tasks in nlp show that <phrase>curriculum learning</phrase> has a positive effect on the lstm s internal states by biasing <phrase>the model</phrase> towards building constructive representations i.e. the internal representation at the previous timesteps are <phrase>used as</phrase> <phrase>building blocks</phrase> for <phrase>the final</phrase> prediction. we also find that smaller models significantly improves when they are trained with <phrase>curriculum learning</phrase>. lastly we show that <phrase>curriculum learning</phrase> helps more when the <phrase>amount of</phrase> <phrase>training data</phrase> is limited.
dense prediction on sequences with time dilated convolutions <phrase>for speech recognition</phrase>
<phrase>in computer vision</phrase> pixelwise dense prediction is <phrase>the task of</phrase> predicting a label for each pixel in the image. <phrase>convolutional neural networks</phrase> achieve good <phrase>performance on</phrase> <phrase>this task</phrase> while being computationally efficient. in <phrase>this paper</phrase> we carry these ideas over to <phrase>the problem of</phrase> assigning a sequence of labels to <phrase>a set of</phrase> speech frames a task commonly <phrase>known as</phrase> framewise classification. we show that dense prediction view of framewise classification offers several advantages and insights including computational efficiency and the <phrase>ability to</phrase> apply <phrase>batch normalization</phrase>. when doing dense prediction we pay specific attention to strided pooling in time and introduce an asymmetric dilated convolution called time dilated convolution that allows for efficient and elegant implementation of pooling in time. we show results using time dilated convolutions in a very deep vgg style cnn with <phrase>batch normalization</phrase> on the hub5 switchboard 2000 benchmark task. with a big <phrase>n gram</phrase> <phrase>language model</phrase> we achieve 7.7 wer which is <phrase>the best</phrase> single model single pass performance reported <phrase>so far</phrase>.
<phrase>end to end</phrase> asr free keyword search from speech
<phrase>end to end</phrase> e2e systems have achieved <phrase>competitive results</phrase> <phrase>compared to</phrase> conventional hybrid <phrase>hidden markov model</phrase> hmm <phrase>deep neural network</phrase> based <phrase>automatic speech recognition</phrase> asr systems. such e2e systems are attractive <phrase>due to</phrase> <phrase>the lack of</phrase> dependence on alignments between input acoustic and output grapheme or hmm state sequence <phrase>during training</phrase>. <phrase>this paper</phrase> explores the design of an asr free <phrase>end to end</phrase> system for text query based keyword search kws from speech trained <phrase>with minimal</phrase> supervision. our e2e kws system <phrase>consists of</phrase> three sub systems. the first sub system is <phrase>a recurrent neural network</phrase> <phrase>rnn based</phrase> acoustic auto encoder trained to reconstruct the audio through a finite dimensional representation. the second sub system is a <phrase>character level</phrase> rnn <phrase>language model</phrase> using embeddings learned from <phrase>a convolutional neural network</phrase>. since the acoustic and text query embeddings occupy different representation spaces they are input to a third <phrase>feed forward</phrase> <phrase>neural network</phrase> that predicts whether the query occurs in the acoustic utterance or not. this e2e asr free kws system performs respectably despite lacking a conventional asr system and trains much faster.
training <phrase>language models</phrase> using target propagation
while truncated <phrase>back propagation</phrase> through time bptt is the most popular <phrase>approach to</phrase> training <phrase>recurrent neural networks</phrase> rnns it suffers from being inherently sequential making parallelization difficult and from truncating gradient flow between distant time steps. we investigate whether target propagation tprop style approaches can address these shortcomings. unfortunately <phrase>extensive experiments</phrase> suggest that tprop generally underperforms bptt and we end with an analysis of this phenomenon and suggestions for future work.
deep voice <phrase>real time</phrase> neural text to speech
we present deep voice a production quality text to speech system constructed entirely from <phrase>deep neural networks</phrase>. deep voice lays the groundwork for truly <phrase>end to end</phrase> neural <phrase>speech synthesis</phrase>. the system comprises five major <phrase>building blocks</phrase> a segmentation model for locating phoneme boundaries a grapheme to phoneme conversion model a phoneme duration prediction model a <phrase>fundamental frequency</phrase> prediction model and an audio synthesis model. for the segmentation model we propose <phrase>a novel</phrase> way of performing phoneme boundary detection with <phrase>deep neural networks</phrase> using connectionist temporal classification ctc loss. for the audio synthesis model we implement a variant of wavenet that requires <phrase>fewer parameters</phrase> and trains <phrase>faster than</phrase> <phrase>the original</phrase>. <phrase>by using</phrase> <phrase>a neural network</phrase> for each component our system is simpler and more flexible than traditional text to speech systems where each component requires laborious feature engineering and extensive domain expertise. finally we show that inference with our system can be performed <phrase>faster than</phrase> <phrase>real time</phrase> and describe optimized wavenet inference kernels on both cpu and gpu that achieve up to 400x speedups over existing implementations.
improved variational autoencoders for text modeling using dilated convolutions
<phrase>recent work</phrase> on generative modeling of text has found that variational auto encoders vae incorporating lstm decoders perform worse than simpler lstm <phrase>language models</phrase> bowman <phrase>et al</phrase>. 2015 . this negative result is <phrase>so far</phrase> poorly understood but has been attributed to the propensity of lstm decoders to ignore conditioning information from the encoder. in <phrase>this paper</phrase> we experiment with <phrase>a new</phrase> <phrase>type of</phrase> decoder for vae a dilated cnn. by changing the decoder s dilation architecture we control the effective context from previously generated words. in experiments we find that there is a trade off between the contextual capacity of the decoder and the <phrase>amount of</phrase> encoding information used. we show that with the right decoder vae can outperform lstm <phrase>language models</phrase>. we demonstrate perplexity gains on two datasets representing the first positive experimental result on the use vae for generative modeling of text. further we conduct an in depth investigation of <phrase>the use of</phrase> vae with our new decoding architecture for <phrase>semi supervised</phrase> and unsupervised labeling tasks demonstrating gains over several strong baselines.
gram ctc automatic unit selection and target decomposition for sequence labelling
most existing sequence labelling models <phrase>rely on</phrase> <phrase>a fixed</phrase> decomposition of a target sequence into a sequence of basic units. these methods <phrase>suffer from</phrase> two major drawbacks 1 the <phrase>set of</phrase> basic units is fixed <phrase>such as</phrase> the <phrase>set of</phrase> words characters or phonemes in <phrase>speech recognition</phrase> and 2 the decomposition of target sequences is fixed. these drawbacks usually result in sub optimal performance of modeling sequences. in this pa per we extend the popular ctc loss criterion to alleviate these limitations and propose <phrase>a new</phrase> <phrase>loss function</phrase> called gram ctc. while preserving the advantages of ctc gram ctc automatically learns <phrase>the best</phrase> <phrase>set of</phrase> basic units grams <phrase>as well as</phrase> the most suitable decomposition of tar get sequences. unlike ctc gram ctc allows <phrase>the model</phrase> to output variable <phrase>number of</phrase> characters at each time step which enables <phrase>the model</phrase> <phrase>to capture</phrase> longer term dependency and improves the computational efficiency. we demonstrate that <phrase>the proposed</phrase> gram ctc improves ctc <phrase>in terms of</phrase> both performance and efficiency on the <phrase>large vocabulary</phrase> <phrase>speech recognition</phrase> task at multiple scales of data and that with gram ctc we can outperform the <phrase>state of</phrase> <phrase>the art</phrase> on a standard speech benchmark.
ask me even more dynamic memory tensor networks extended model 
we examine <phrase>memory networks</phrase> for <phrase>the task of</phrase> <phrase>question answering</phrase> qa under common <phrase>real world</phrase> scenario where training examples are scarce and under <phrase>weakly supervised</phrase> scenario that is only extrinsic labels are available for training. we propose extensions for the dynamic <phrase>memory network</phrase> dmn specifically within the <phrase>attention mechanism</phrase> we call the resulting neural architecture as dynamic memory tensor network dmtn . ultimately we see that our proposed extensions results in over 80 improvement in <phrase>the number of</phrase> task passed against the baselined standard dmn and 20 more task passed <phrase>compared to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> <phrase>end to end</phrase> <phrase>memory network</phrase> for facebook s single task weakly trained 1k babi dataset.
simplified <phrase>end to end</phrase> mmi training and voting for asr
a simplified <phrase>speech recognition</phrase> system that uses the maximum <phrase>mutual information</phrase> mmi criterion is considered. <phrase>end to end</phrase> training using <phrase>gradient descent</phrase> is suggested similarly to the training of connectionist temporal classification ctc . we use an mmi criterion with <phrase>a simple</phrase> <phrase>language model</phrase> in the training stage and a standard hmm decoder. our method compares favorably to ctc <phrase>in terms of</phrase> performance robustness decoding time disk footprint and quality of alignments. the good alignments enable <phrase>the use of</phrase> a straightforward ensemble method <phrase>obtained by</phrase> simply averaging the predictions of several <phrase>neural network</phrase> models that were trained separately <phrase>end to end</phrase>. the ensemble method yields a considerable <phrase>reduction in</phrase> the <phrase>word error rate</phrase>.
learning <phrase>to generate</phrase> reviews and discovering sentiment
we explore the <phrase>properties of</phrase> byte level recurrent <phrase>language models</phrase>. when given sufficient <phrase>amounts of</phrase> capacity <phrase>training data</phrase> and compute time the representations learned by <phrase>these models</phrase> include disentangled features corresponding to <phrase>high level</phrase> concepts. specifically we find <phrase>a single</phrase> unit which performs <phrase>sentiment analysis</phrase>. these representations learned in an unsupervised manner <phrase>achieve state of</phrase> <phrase>the art</phrase> on the binary <phrase>subset of</phrase> the stanford sentiment treebank. they are also very data efficient. when using only a handful of labeled examples our approach matches <phrase>the performance of</phrase> strong baselines <phrase>trained on</phrase> full datasets. we also demonstrate the sentiment unit has a direct influence on the generative process of <phrase>the model</phrase>. simply fixing its value to be positive or negative generates samples with the corresponding positive or negative sentiment.
<phrase>semi supervised</phrase> multitask learning for <phrase>sequence labeling</phrase>
we propose a <phrase>sequence labeling</phrase> framework with a secondary training objective learning <phrase>to predict</phrase> surrounding words for every word in the dataset. this <phrase>language modeling</phrase> objective incentivises the system <phrase>to learn</phrase> <phrase>general purpose</phrase> patterns of semantic and syntactic composition which are also useful for improving accuracy on different <phrase>sequence labeling</phrase> tasks. the architecture was evaluated on <phrase>a range of</phrase> datasets covering the tasks of <phrase>error detection</phrase> in learner texts <phrase>named entity recognition</phrase> chunking and pos tagging. the novel <phrase>language modeling</phrase> objective provided consistent performance improvements on every benchmark <phrase>without requiring</phrase> any additional annotated or unannotated data.
going wider <phrase>recurrent neural network</phrase> with parallel cells
<phrase>recurrent neural network</phrase> rnn has been widely applied for <phrase>sequence modeling</phrase>. in rnn the hidden states at current step are full connected to those at previous step thus the influence from less related features at previous step may potentially decrease model s learning ability. we propose <phrase>a simple</phrase> technique called parallel cells pcs to enhance the learning ability of <phrase>recurrent neural network</phrase> rnn . in <phrase>each layer</phrase> we run multiple small rnn cells <phrase>rather than</phrase> one single large cell. in <phrase>this paper</phrase> we evaluate pcs on 2 tasks. on <phrase>language modeling</phrase> task on ptb penn tree bank our <phrase>model outperforms</phrase> <phrase>state of</phrase> art models by decreasing perplexity from 78.6 to 75.3. on chinese english translation task our model increases bleu score for 0.39 points than baseline model.
phonetic temporal neural model for language identification
<phrase>deep neural</phrase> models particularly the <phrase>lstm rnn</phrase> model have shown great potential for language identification lid . however <phrase>the use of</phrase> phonetic information has been largely overlooked by most existing neural lid methods although this information has been used very successfully in conventional phonetic lid systems. we present a phonetic temporal neural model for lid which is an <phrase>lstm rnn</phrase> lid system that accepts phonetic features <phrase>produced by</phrase> a phone discriminative dnn as <phrase>the input</phrase> <phrase>rather than</phrase> raw acoustic features. this new model is <phrase>similar to</phrase> traditional phonetic lid methods but the phonetic knowledge here is much richer it is at the frame level and involves compacted information of all phones. our experiments conducted on the babel database and the ap16 olr database demonstrate that the temporal phonetic neural approach is very effective and <phrase>significantly outperforms</phrase> existing acoustic <phrase>neural models</phrase>. it also outperforms the conventional i vector approach on short utterances and in noisy conditions.
relevance based <phrase>word embedding</phrase>
learning a <phrase>high dimensional</phrase> dense representation for vocabulary terms also <phrase>known as</phrase> a <phrase>word embedding</phrase> has recently attracted much attention in <phrase>natural language</phrase> processing and <phrase>information retrieval</phrase> tasks. the embedding vectors are typically learned <phrase>based on</phrase> term proximity in <phrase>a large</phrase> corpus. this means that the objective in <phrase>well known</phrase> <phrase>word embedding</phrase> algorithms e.g. word2vec is to accurately predict adjacent word s for a given word or context. however this objective is not necessarily equivalent to <phrase>the goal of</phrase> many <phrase>information retrieval</phrase> ir tasks. the primary objective in various ir tasks is <phrase>to capture</phrase> relevance <phrase>instead of</phrase> term proximity syntactic or even semantic similarity. this is the motivation for developing unsupervised relevance based <phrase>word embedding</phrase> models that learn word representations <phrase>based on</phrase> query document relevance information. in <phrase>this paper</phrase> we propose two <phrase>learning models</phrase> with different objective functions one learns a relevance distribution over the vocabulary set for each query and the other classifies each term as belonging to the relevant or non relevant class for each query. <phrase>to train</phrase> our models we used over six million unique queries and the top ranked documents retrieved in response to each query which are assumed to be relevant to the query. we extrinsically evaluate our learned word representation models using two ir tasks query expansion and query classification. both query expansion <phrase>experiments on</phrase> four trec collections and query classification <phrase>experiments on</phrase> the kdd cup 2005 dataset suggest that the relevance based <phrase>word embedding</phrase> models <phrase>significantly outperform</phrase> <phrase>state of</phrase> <phrase>the art</phrase> proximity based embedding models <phrase>such as</phrase> word2vec and glove.
deriving <phrase>neural architectures</phrase> from sequence and graph kernels
the design of <phrase>neural architectures</phrase> for structured objects is typically guided by experimental insights <phrase>rather than</phrase> a formal process. in <phrase>this work</phrase> we appeal to kernels over combinatorial structures <phrase>such as</phrase> sequences and graphs to derive appropriate neural operations. we introduce a class of deep <phrase>recurrent neural</phrase> operations and formally characterize their associated kernel spaces. our recurrent modules compare <phrase>the input</phrase> to virtual reference objects cf. filters in cnn via the kernels. <phrase>similar to</phrase> traditional neural operations these reference objects are parameterized and directly optimized in <phrase>end to end</phrase> training. we empirically evaluate <phrase>the proposed</phrase> class of <phrase>neural architectures</phrase> on standard <phrase>applications such as</phrase> <phrase>language modeling</phrase> and molecular graph regression achieving <phrase>state of</phrase> <phrase>the art</phrase> results across these applications.
on multilingual training of neural dependency parsers
we show that a <phrase>recently proposed</phrase> neural dependency parser can be improved by joint training on multiple languages from <phrase>the same</phrase> family. the parser is implemented as <phrase>a deep neural network</phrase> whose only input is orthographic representations of words. <phrase>in order to</phrase> successfully parse <phrase>the network</phrase> has <phrase>to discover</phrase> how linguistically relevant concepts can be inferred from word spellings. we analyze the representations of characters and words that are learned by <phrase>the network</phrase> to establish which <phrase>properties of</phrase> languages were accounted for. <phrase>in particular</phrase> we show that the parser has approximately learned to associate latin characters with their cyrillic counterparts and that it can group polish and russian words that have a similar grammatical function. finally we evaluate the parser on selected languages from the universal dependencies dataset and show that it is competitive with other <phrase>recently proposed</phrase> <phrase>state of</phrase> <phrase>the art</phrase> methods while having <phrase>a simple</phrase> structure.
<phrase>semi supervised</phrase> <phrase>phoneme recognition</phrase> with recurrent ladder networks
ladder networks are a notable new concept in <phrase>the field of</phrase> <phrase>semi supervised</phrase> learning by showing <phrase>state of</phrase> <phrase>the art</phrase> results in image <phrase>recognition tasks</phrase> while being compatible with many existing <phrase>neural architectures</phrase>. we present the recurrent ladder network <phrase>a novel</phrase> modification of the ladder network for <phrase>semi supervised</phrase> learning of <phrase>recurrent neural networks</phrase> which we evaluate with a <phrase>phoneme recognition</phrase> task on the timit corpus. our <phrase>results show</phrase> that <phrase>the model</phrase> is <phrase>able to</phrase> consistently outperform the baseline and achieve fully supervised baseline performance with only 75 of all labels which demonstrates that <phrase>the model</phrase> is <phrase>capable of</phrase> using unsupervised data as <phrase>an effective</phrase> regulariser.
adversarially regularized autoencoders
while autoencoders are a key technique in <phrase>representation learning</phrase> for continuous structures <phrase>such as</phrase> images or wave forms developing <phrase>general purpose</phrase> autoencoders for discrete structures <phrase>such as</phrase> text sequence or discretized images has proven to be more challenging. <phrase>in particular</phrase> discrete inputs make it more difficult <phrase>to learn</phrase> a smooth encoder that preserves the complex local relationships in <phrase>the input</phrase> space. in <phrase>this work</phrase> we propose an adversarially regularized autoencoder arae with <phrase>the goal of</phrase> learning <phrase>more robust</phrase> <phrase>discrete space</phrase> representations. arae jointly trains both a rich <phrase>discrete space</phrase> encoder <phrase>such as</phrase> an rnn and a simpler continuous space generator function while using <phrase>generative adversarial</phrase> network gan training to constrain the distributions to be similar. this method yields a smoother contracted code space that maps similar inputs to nearby codes and also an implicit <phrase>latent variable</phrase> gan model for generation. <phrase>experiments on</phrase> text and discretized images demonstrate that the gan model produces clean interpolations and captures the multimodality of <phrase>the original</phrase> space and that the autoencoder produces improve ments in <phrase>semi supervised</phrase> learning <phrase>as well as</phrase> <phrase>state of</phrase> <phrase>the art</phrase> results in unaligned text style transfer task using only a shared continuous space representation.
auxiliary objectives for neural <phrase>error detection</phrase> models
we investigate the utility of different auxiliary objectives and training strategies within a neural <phrase>sequence labeling</phrase> <phrase>approach to</phrase> <phrase>error detection</phrase> in learner writing. auxiliary costs provide <phrase>the model</phrase> with additional linguistic information allowing it <phrase>to learn</phrase> <phrase>general purpose</phrase> compositional features that can then be exploited for other objectives. our <phrase>experiments show</phrase> that a joint <phrase>learning approach</phrase> trained with parallel labels on in domain data improves performance over the previous best <phrase>error detection</phrase> system. while the resulting model has <phrase>the same</phrase> <phrase>number of</phrase> parameters the additional objectives allow it to be optimised more efficiently and achieve <phrase>better performance</phrase>.
an error oriented <phrase>approach to</phrase> <phrase>word embedding</phrase> <phrase>pre training</phrase>
we propose <phrase>a novel</phrase> <phrase>word embedding</phrase> <phrase>pre training</phrase> approach that exploits writing errors in learners scripts. we compare our method to previous models that tune the embeddings <phrase>based on</phrase> script scores and the discrimination between correct and corrupt word contexts <phrase>in addition</phrase> to the generic commonly used embeddings <phrase>pre trained</phrase> on large corpora. the comparison is <phrase>achieved by</phrase> using the aforementioned models to bootstrap <phrase>a neural network</phrase> that learns <phrase>to predict</phrase> a holistic score for scripts. furthermore we investigate augmenting our model with error corrections and monitor the impact on performance. our <phrase>results show</phrase> that our error oriented approach outperforms other comparable ones which is further demonstrated when training on more data. additionally extending <phrase>the model</phrase> with corrections provides further performance gains when data sparsity is an issue.
a continuous relaxation of <phrase>beam search</phrase> for <phrase>end to end</phrase> training of neural sequence models
<phrase>beam search</phrase> is a desirable <phrase>choice of</phrase> <phrase>test time</phrase> decoding algorithm for neural sequence models because it potentially avoids search errors made by simpler greedy methods. however typical <phrase>cross entropy</phrase> training procedures for <phrase>these models</phrase> <phrase>do not</phrase> directly consider the behaviour of <phrase>the final</phrase> decoding method. as a result for <phrase>cross entropy</phrase> trained models beam decoding can sometimes yield reduced test performance when <phrase>compared with</phrase> greedy decoding. <phrase>in order to</phrase> train models that can more effectively make use of <phrase>beam search</phrase> we propose <phrase>a new</phrase> training procedure that <phrase>focuses on</phrase> <phrase>the final</phrase> loss metric e.g. hamming loss evaluated on the output of <phrase>beam search</phrase>. while well defined this direct loss objective is itself discontinuous and thus difficult to optimize. hence in our approach we form a sub differentiable surrogate objective <phrase>by introducing</phrase> <phrase>a novel</phrase> continuous approximation of the <phrase>beam search</phrase> decoding procedure. in experiments we show that optimizing this new training objective yields substantially better <phrase>results on</phrase> two sequence tasks <phrase>named entity recognition</phrase> and ccg supertagging when <phrase>compared with</phrase> both <phrase>cross entropy</phrase> trained greedy decoding and <phrase>cross entropy</phrase> trained beam decoding baselines.
regularizing and optimizing lstm <phrase>language models</phrase>
<phrase>recurrent neural networks</phrase> rnns <phrase>such as</phrase> <phrase>long short term memory</phrase> networks lstms serve as a fundamental building block for many <phrase>sequence learning</phrase> tasks including <phrase>machine translation</phrase> <phrase>language modeling</phrase> and <phrase>question answering</phrase>. in <phrase>this paper</phrase> we consider the specific problem of <phrase>word level</phrase> <phrase>language modeling</phrase> and investigate strategies for regularizing and optimizing lstm based models. we propose the weight dropped lstm which uses dropconnect on hidden to hidden weights as a form of recurrent regularization. further we introduce nt asgd a variant of the averaged <phrase>stochastic gradient</phrase> method wherein the averaging trigger is determined using a non monotonic condition as opposed to being tuned by the user. using these and other regularization strategies we <phrase>achieve state of</phrase> <phrase>the art</phrase> <phrase>word level</phrase> perplexities on two <phrase>data sets</phrase> 57.3 on <phrase>penn treebank</phrase> and 65.8 on wikitext 2. in exploring <phrase>the effectiveness of</phrase> a neural cache in conjunction with our <phrase>proposed model</phrase> we achieve an even lower <phrase>state of</phrase> <phrase>the art</phrase> perplexity of 52.8 on <phrase>penn treebank</phrase> and 52.0 on wikitext 2.
supervised speech separation <phrase>based on</phrase> <phrase>deep learning</phrase> an overview
speech separation is <phrase>the task of</phrase> separating target speech from background interference. traditionally speech separation is studied as a <phrase>signal processing</phrase> problem. a more recent approach formulates speech separation as a <phrase>supervised learning</phrase> problem where the discriminative patterns of speech speakers and background noise are learned from <phrase>training data</phrase>. over <phrase>the past</phrase> decade many supervised separation algorithms have been put forward. <phrase>in particular</phrase> the recent introduction of <phrase>deep learning</phrase> to supervised speech separation has dramatically accelerated progress and boosted separation performance. this article provides a comprehensive overview of the research on <phrase>deep learning</phrase> based supervised speech separation in the last several years. we first introduce the background of speech separation and the formulation of supervised separation. then we discuss three main components of supervised separation <phrase>learning machines</phrase> training targets and acoustic features. much of the overview is on separation algorithms where we review monaural methods including speech enhancement speech nonspeech separation speaker separation multi talker separation and speech dereverberation <phrase>as well as</phrase> multi microphone techniques. the important issue of generalization unique to <phrase>supervised learning</phrase> is discussed. this overview provides a historical perspective on how advances are made. <phrase>in addition</phrase> we discuss <phrase>a number of</phrase> conceptual issues including what constitutes the target source.
grasping the finer point a supervised similarity network for metaphor detection
the ubiquity of metaphor in our everyday communication makes it <phrase>an important</phrase> problem for <phrase>natural language</phrase> understanding. yet the majority of metaphor processing systems <phrase>to date</phrase> <phrase>rely on</phrase> hand engineered features and there is still no consensus in the field as to which features are optimal for <phrase>this task</phrase>. in <phrase>this paper</phrase> we present the first <phrase>deep learning</phrase> architecture designed <phrase>to capture</phrase> metaphorical composition. our <phrase>results demonstrate</phrase> that it outperforms the <phrase>existing approaches</phrase> in the metaphor identification task.
think globally embed locally locally linear meta embedding of words
distributed <phrase>word embeddings</phrase> have shown superior performances in numerous <phrase>natural language</phrase> processing nlp tasks. however their performances vary significantly across different tasks implying that the <phrase>word embeddings</phrase> learnt by those methods capture complementary <phrase>aspects of</phrase> <phrase>lexical semantics</phrase>. therefore we believe that it is important to combine the existing <phrase>word embeddings</phrase> <phrase>to produce</phrase> <phrase>more accurate</phrase> and complete emph meta embeddings of words. for this purpose we propose an unsupervised locally linear meta embedding learning method that takes <phrase>pre trained</phrase> <phrase>word embeddings</phrase> as <phrase>the input</phrase> and produces <phrase>more accurate</phrase> meta embeddings. unlike previously proposed meta embedding <phrase>learning methods</phrase> that learn a global projection over all words in a vocabulary our <phrase>proposed method</phrase> is sensitive to the differences in local neighbourhoods of the individual source <phrase>word embeddings</phrase>. moreover we show that vector concatenation a previously proposed highly competitive baseline approach for integrating <phrase>word embeddings</phrase> can be derived as <phrase>a special</phrase> case of <phrase>the proposed</phrase> method. <phrase>experimental results</phrase> on semantic similarity word analogy <phrase>relation classification</phrase> and short <phrase>text classification</phrase> tasks show that our meta embeddings to <phrase>significantly outperform</phrase> prior methods in several <phrase>benchmark datasets</phrase> establishing <phrase>a new</phrase> <phrase>state of</phrase> <phrase>the art</phrase> for meta embeddings.
keyvec key semantics preserving document representations
previous studies have demonstrated the empirical success of <phrase>word embeddings</phrase> in various applications. in <phrase>this paper</phrase> we investigate <phrase>the problem of</phrase> learning distributed representations for text documents which many <phrase>machine learning</phrase> algorithms take as input for <phrase>a number of</phrase> nlp tasks. we propose <phrase>a neural network</phrase> model keyvec which learns document representations with <phrase>the goal of</phrase> preserving key semantics of <phrase>the input</phrase> text. it enables the learned <phrase>low dimensional</phrase> vectors to retain the topics and important information from the documents that will flow to downstream tasks. our empirical evaluations show the superior quality of keyvec representations in two different document understanding tasks.
exploring asymmetric <phrase>encoder decoder</phrase> structure for context based sentence <phrase>representation learning</phrase>
context information plays <phrase>an important</phrase> <phrase>role in</phrase> human <phrase>language understanding</phrase> and it is also useful for machines <phrase>to learn</phrase> <phrase>vector representations</phrase> of language. in <phrase>this paper</phrase> we explore an asymmetric <phrase>encoder decoder</phrase> structure for unsupervised context based sentence <phrase>representation learning</phrase>. as a result we build an <phrase>encoder decoder</phrase> architecture with an rnn encoder and a cnn decoder. we further combine a suite of effective designs to significantly improve model efficiency while also achieving <phrase>better performance</phrase>. our model is <phrase>trained on</phrase> two different large unlabeled corpora and in both cases transferability is evaluated on <phrase>a set of</phrase> downstream <phrase>language understanding</phrase> tasks. we empirically show that our model is simple and fast while producing rich sentence representations that excel in downstream tasks.
cnn is all you need
the convolution <phrase>neural network</phrase> cnn has demonstrated the unique advantage in audio image and text learning recently it has also challenged <phrase>recurrent neural networks</phrase> rnns with <phrase>long short term memory</phrase> cells lstm in <phrase>sequence to sequence</phrase> learning since the computations involved in cnn are easily parallelizable whereas those involved in rnn are mostly sequential <phrase>leading to</phrase> a performance bottleneck. however unlike rnn the native cnn lacks the history sensitivity required for sequence transformation therefore enhancing the sequential order awareness or position sensitivity becomes the key to make cnn the general <phrase>deep learning</phrase> model. in <phrase>this work</phrase> we introduce an extended cnn model with strengthen position sensitivity called posenet. a notable feature of posenet is the asymmetric treatment of position information in the encoder and the decoder. experiments shows that posenet allows us <phrase>to improve</phrase> the accuracy of cnn based <phrase>sequence to sequence</phrase> learning significantly achieving around 33 36 bleu scores on the wmt 2014 english to german translation task and around 44 46 bleu scores on the english to french translation task.
combining <phrase>representation learning</phrase> with logic for <phrase>language processing</phrase>
<phrase>the current state of</phrase> <phrase>the art</phrase> in many <phrase>natural language</phrase> processing and automated <phrase>knowledge base</phrase> completion tasks is held by <phrase>representation learning</phrase> methods which learn distributed <phrase>vector representations</phrase> of symbols via <phrase>gradient based</phrase> optimization. they require little or no <phrase>hand crafted</phrase> features thus avoiding <phrase>the need for</phrase> most preprocessing steps and <phrase>task specific</phrase> assumptions. however in many cases <phrase>representation learning</phrase> requires <phrase>a large</phrase> <phrase>amount of</phrase> annotated <phrase>training data</phrase> to generalize well to unseen data. such labeled <phrase>training data</phrase> is provided by human annotators who often use <phrase>formal logic</phrase> as the language for specifying annotations. this thesis investigates different combinations of <phrase>representation learning</phrase> methods with logic for reducing <phrase>the need for</phrase> annotated <phrase>training data</phrase> and for improving generalization.
a note on topology preservation in classification and the construction of a universal neuron grid
it will be shown that <phrase>according to</phrase> theorems of k. menger every neuron grid if identified with a curve is <phrase>able to</phrase> preserve the adopted qualitative structure of a data space. furthermore if this identification is made the neuron grid structure can always be mapped to <phrase>a subset of</phrase> a universal neuron grid which is constructable in three space dimensions. conclusions will be drawn for established neuron grid types <phrase>as well as</phrase> neural fields.
linear nonlinear poisson neuron networks perform <phrase>bayesian inference</phrase> on <phrase>boltzmann machines</phrase>
one conjecture in both <phrase>deep learning</phrase> and classical connectionist viewpoint is that the biological brain implements certain kinds of <phrase>deep networks</phrase> as its back end. however to our knowledge a detailed correspondence has not yet been set up which is important if we want to bridge between neuroscience and <phrase>machine learning</phrase>. recent researches emphasized the biological plausibility of linear nonlinear poisson lnp neuron model. we show that with neurally plausible settings the whole network is <phrase>capable of</phrase> representing any boltzmann machine and performing a semi stochastic <phrase>bayesian inference</phrase> algorithm lying between <phrase>gibbs sampling</phrase> and <phrase>variational inference</phrase>.
mapping temporal variables into the neucube for improved <phrase>pattern recognition</phrase> predictive modelling and understanding of stream data
<phrase>this paper</phrase> proposes <phrase>a new</phrase> <phrase>method for</phrase> an optimized mapping of temporal variables describing a temporal stream data into the <phrase>recently proposed</phrase> neucube spiking <phrase>neural network</phrase> architecture. this optimized mapping extends <phrase>the use of</phrase> the neucube which was initially designed for spatiotemporal brain data to work on arbitrary stream data and to achieve a better accuracy of temporal <phrase>pattern recognition</phrase> a better and earlier event prediction and a better understanding of complex temporal stream data through visualization of the neucube connectivity. <phrase>the effect of</phrase> the new mapping is demonstrated on three bench mark problems. the first one is early prediction of patient sleep stage event from temporal physiological data. the second one is <phrase>pattern recognition</phrase> of dynamic temporal patterns of traffic in the <phrase>bay area</phrase> of california and the last one is the challenge 2012 contest <phrase>data set</phrase>. in all cases <phrase>the use of</phrase> <phrase>the proposed</phrase> mapping <phrase>leads to</phrase> an improved accuracy of <phrase>pattern recognition</phrase> and event prediction and a better understanding of the data when <phrase>compared to</phrase> traditional <phrase>machine learning</phrase> techniques or spiking <phrase>neural network</phrase> reservoirs with arbitrary mapping of the variables.
an <phrase>evolutionary algorithm</phrase> <phrase>to learn</phrase> sparql queries for source target pairs finding patterns for human associations in dbpedia
efficient usage of the knowledge provided by the <phrase>linked data</phrase> community is often hindered by <phrase>the need for</phrase> domain experts to formulate the right sparql queries to answer questions. for new questions they have to decide which datasets are suitable and in which terminology and modelling style to phrase the sparql query. in <phrase>this work</phrase> we present an <phrase>evolutionary algorithm</phrase> to help with this <phrase>challenging task</phrase>. given a training list of source target node pair examples our algorithm can learn patterns sparql queries from a sparql endpoint. the learned patterns can be visualised to form the basis for further investigation or they can be used <phrase>to predict</phrase> target nodes for new source nodes. amongst others we apply our algorithm to a dataset of several hundred human associations <phrase>such as</phrase> circle square to find patterns for them in dbpedia. we show the scalability of the algorithm by running it against a sparql endpoint loaded with 7.9 billion triples. further we use the resulting sparql queries to mimic human associations with a mean average precision map of 39.9 and a recall 10 of 63.9 .
a geometric <phrase>framework for</phrase> <phrase>convolutional neural networks</phrase>
in <phrase>this paper</phrase> a geometric <phrase>framework for</phrase> <phrase>neural networks</phrase> is proposed. this framework uses the inner product space structure underlying the parameter set <phrase>to perform</phrase> <phrase>gradient descent</phrase> not in a component based form but in a coordinate free manner. <phrase>convolutional neural networks</phrase> are described in this framework in a compact form with the gradients of standard and higher order loss functions calculated for <phrase>each layer</phrase> of <phrase>the network</phrase>. <phrase>this approach</phrase> can be <phrase>applied to</phrase> other network structures and provides a basis on which to create new networks.
<phrase>a novel</phrase> representation of <phrase>neural networks</phrase>
<phrase>deep neural networks</phrase> dnns have become very popular for prediction in many areas. their strength is in representation with a high <phrase>number of</phrase> parameters that are commonly learned via <phrase>gradient descent</phrase> or similar optimization methods. however the representation is non standardized and the gradient calculation methods are often performed using component <phrase>based approaches</phrase> that break parameters down into scalar units <phrase>instead of</phrase> considering the parameters as whole entities. in <phrase>this work</phrase> these problems are addressed. standard notation is used <phrase>to represent</phrase> dnns in a compact framework. gradients of dnn loss functions are calculated directly over the inner product space on which the parameters are defined. this framework is general and is <phrase>applied to</phrase> two common network types the <phrase>multilayer perceptron</phrase> and the deep autoencoder.
converting cascade correlation neural nets into probabilistic <phrase>generative models</phrase>
humans are <phrase>not only</phrase> adept in recognizing what class an input instance belongs to i.e. <phrase>classification task</phrase> but perhaps more remarkably they can imagine i.e. generate plausible instances of a desired class with ease when prompted. <phrase>inspired by</phrase> this we propose a framework which allows transforming cascade correlation <phrase>neural networks</phrase> ccnns into probabilistic <phrase>generative models</phrase> thereby enabling ccnns <phrase>to generate</phrase> samples from a category of interest. ccnns are a <phrase>well known</phrase> class of deterministic discriminative nns which autonomously construct their topology and have been successful in giving accounts for <phrase>a variety of</phrase> psychological phenomena. our <phrase>proposed framework</phrase> is <phrase>based on</phrase> a <phrase>markov chain</phrase> <phrase>monte carlo</phrase> mcmc method called the metropolis adjusted langevin algorithm which capitalizes on the gradient information of the target distribution to direct its explorations towards regions of high probability thereby achieving good mixing properties. through extensive simulations we demonstrate <phrase>the efficacy of</phrase> our <phrase>proposed framework</phrase>.
on <phrase>the performance of</phrase> network parallel training in <phrase>artificial neural networks</phrase>
<phrase>artificial neural networks</phrase> anns have received increasing attention <phrase>in recent years</phrase> with applications that span <phrase>a wide range of</phrase> disciplines including vital <phrase>domains such as</phrase> medicine network security and autonomous transportation. however <phrase>neural network</phrase> architectures are becoming increasingly complex and with an increasing <phrase>need to</phrase> obtain <phrase>real time</phrase> results from such models it has become pivotal to use parallelization as a mechanism for speeding up <phrase>network training</phrase> and deployment. in <phrase>this work</phrase> we propose an implementation of network parallel training through cannon s algorithm for <phrase>matrix multiplication</phrase>. we show that increasing <phrase>the number of</phrase> processes speeds up training until the point where process communication costs become prohibitive this point varies by network complexity. we <phrase>also show</phrase> through empirical efficiency calculations that the speedup obtained is superlinear.
programmable agents
we build deep rl agents that execute declarative programs expressed in <phrase>formal language</phrase>. the agents learn to ground the terms in this language in their environment and can generalize their behavior at <phrase>test time</phrase> to execute new programs that refer to objects that were not referenced <phrase>during training</phrase>. the agents develop disentangled interpretable representations that allow them to generalize to a wide <phrase>variety of</phrase> <phrase>zero shot</phrase> semantic tasks.
explainable <phrase>artificial intelligence</phrase> understanding visualizing and interpreting <phrase>deep learning</phrase> models
with the availability of large databases and recent improvements in <phrase>deep learning</phrase> methodology <phrase>the performance of</phrase> ai systems is reaching or even exceeding the human level on an increasing <phrase>number of</phrase> complex tasks. impressive examples of this development can be found in <phrase>domains such as</phrase> <phrase>image classification</phrase> <phrase>sentiment analysis</phrase> speech understanding or strategic game playing. however because of their nested <phrase>non linear</phrase> structure these highly successful <phrase>machine learning</phrase> and <phrase>artificial intelligence</phrase> models are usually applied in a <phrase>black box</phrase> manner i.e. no information is provided about what exactly makes them arrive at their predictions. since this lack of transparency can be a major drawback e.g. in medical applications the development of methods for visualizing explaining and interpreting <phrase>deep learning</phrase> models has recently attracted increasing attention. <phrase>this paper</phrase> summarizes recent developments in this field and makes a plea for more interpretability in <phrase>artificial intelligence</phrase>. furthermore it presents two approaches to explaining predictions of <phrase>deep learning</phrase> models one method which computes the sensitivity of the prediction <phrase>with respect to</phrase> changes in <phrase>the input</phrase> and one approach which meaningfully decomposes the decision <phrase>in terms of</phrase> <phrase>the input</phrase> variables. these methods are evaluated on three <phrase>classification tasks</phrase>.
can <phrase>deep reinforcement learning</phrase> solve erdos selfridge spencer games 
<phrase>deep reinforcement learning</phrase> has achieved many recent successes but our understanding of its strengths and limitations is hampered by <phrase>the lack of</phrase> rich environments in which we can fully characterize optimal behavior and correspondingly diagnose individual actions against such a characterization. here we consider a <phrase>family of</phrase> combinatorial games arising from work of erdos selfridge and spencer and we propose their use as environments for evaluating and comparing different approaches to <phrase>reinforcement learning</phrase>. these games have <phrase>a number of</phrase> appealing features they are challenging for current <phrase>learning approaches</phrase> but they form i a <phrase>low dimensional</phrase> simply parametrized environment where ii there is a linear <phrase>closed form</phrase> solution for optimal behavior from any state and iii the difficulty of the game can be tuned by changing environment parameters in an interpretable way. we use these erdos selfridge spencer games <phrase>not only</phrase> to compare different algorithms but test for generalization make comparisons to <phrase>supervised learning</phrase> analyse multiagent play and even develop a self play algorithm.
emergence of grid like representations by training <phrase>recurrent neural networks</phrase> <phrase>to perform</phrase> spatial localization
decades of research on the neural code underlying spatial navigation have revealed a diverse <phrase>set of</phrase> neural response properties. the <phrase>entorhinal cortex</phrase> ec of the mammalian brain contains a rich <phrase>set of</phrase> spatial correlates including grid cells which encode space using tessellating patterns. however the mechanisms and functional significance of these spatial representations remain largely mysterious. as <phrase>a new</phrase> way <phrase>to understand</phrase> these neural representations we trained <phrase>recurrent neural networks</phrase> rnns <phrase>to perform</phrase> navigation tasks in 2d arenas <phrase>based on</phrase> velocity inputs. surprisingly we find that grid like spatial response patterns emerge in trained networks <phrase>along with</phrase> units that exhibit other spatial correlates including border cells and band like cells. all these different functional <phrase>types of</phrase> neurons have been observed experimentally. the order of the emergence of grid like and border cells is also consistent with observations from developmental studies. together our <phrase>results suggest</phrase> that grid cells border cells and others as observed in ec may be a natural solution for representing space efficiently given the predominant recurrent connections in the neural circuits.
<phrase>dimensionality reduction</phrase> and reconstruction using mirroring <phrase>neural networks</phrase> and <phrase>object recognition</phrase> <phrase>based on</phrase> reduced dimension characteristic vector
in <phrase>this paper</phrase> we present a mirroring <phrase>neural network</phrase> architecture <phrase>to perform</phrase> <phrase>non linear</phrase> <phrase>dimensionality reduction</phrase> and <phrase>object recognition</phrase> using a reduced lowdimensional characteristic vector. <phrase>in addition</phrase> to <phrase>dimensionality reduction</phrase> <phrase>the network</phrase> also reconstructs mirrors <phrase>the original</phrase> <phrase>high dimensional</phrase> input vector from the reduced <phrase>low dimensional</phrase> data. the mirroring <phrase>neural network</phrase> architecture has more <phrase>number of</phrase> processing elements adalines in the outer layers and the least <phrase>number of</phrase> elements in the central layer to form a converging diverging shape in its configuration. since this network is <phrase>able to</phrase> reconstruct <phrase>the original</phrase> image from the output of the innermost layer which contains all the <phrase>information about</phrase> <phrase>the input</phrase> pattern these outputs can be <phrase>used as</phrase> object signature to classify patterns. <phrase>the network</phrase> is trained to minimize the discrepancy between actual output and <phrase>the input</phrase> by back propagating the mean squared error from <phrase>the output layer</phrase> to <phrase>the input</phrase> layer. after successfully training <phrase>the network</phrase> it can reduce the dimension of input vectors and mirror the patterns fed to it. the mirroring <phrase>neural network</phrase> architecture gave very good <phrase>results on</phrase> various test patterns.
parcellation of fmri datasets with ica and pls a <phrase>data driven</phrase> approach
inter subject parcellation of <phrase>functional magnetic resonance imaging</phrase> fmri data <phrase>based on</phrase> a standard <phrase>general linear model</phrase> glm and <phrase>spectral clustering</phrase> was <phrase>recently proposed</phrase> as a means to alleviate the issues <phrase>associated with</phrase> spatial normalization in fmri. however for all its appeal a glm based parcellation approach introduces its own biases in the form of a priori knowledge about the shape of hemodynamic response function hrf and task related signal changes or about the subject behaviour during the task. in <phrase>this paper</phrase> we introduce a <phrase>data driven</phrase> <phrase>version of</phrase> the <phrase>spectral clustering</phrase> parcellation <phrase>based on</phrase> <phrase>independent component analysis</phrase> ica and partial least squares pls <phrase>instead of</phrase> the glm. first <phrase>a number of</phrase> independent components are automatically selected. seed voxels are then obtained from the associated ica maps and we compute the pls <phrase>latent variables</phrase> between the fmri signal of the seed voxels which covers regional variations of the hrf and the principal components of the signal across all voxels. finally we parcellate all subjects data with a <phrase>spectral clustering</phrase> of the pls <phrase>latent variables</phrase>. we present results of the <phrase>application of</phrase> <phrase>the proposed</phrase> method on both single subject and multi subject fmri datasets. preliminary <phrase>experimental results</phrase> evaluated with intra parcel variance of glm t values and pls derived t values indicate that this <phrase>data driven</phrase> approach offers improvement <phrase>in terms of</phrase> parcellation accuracy over glm based techniques.
iris codes classification using discriminant and witness directions
the main topic discussed in <phrase>this paper</phrase> is how to use intelligence for biometric decision defuzzification. a neural training model is proposed and tested here as a possible solution for dealing with natural fuzzification that appears between the intra and inter class distribution of scores computed during <phrase>iris recognition</phrase> tests. it is shown here that <phrase>the use of</phrase> proposed <phrase>neural network</phrase> support <phrase>leads to</phrase> an improvement in the artificial perception of the separation between the intra and inter class score distributions by moving them away from each other.
algorithms for <phrase>image analysis</phrase> and <phrase>combination of</phrase> pattern classifiers with <phrase>application to</phrase> <phrase>medical diagnosis</phrase>
<phrase>medical informatics</phrase> and the <phrase>application of</phrase> modern <phrase>signal processing</phrase> in the assistance of the diagnostic process in <phrase>medical imaging</phrase> is one of the more recent and active research areas today. this thesis addresses <phrase>a variety of</phrase> issues <phrase>related to</phrase> the general problem of medical <phrase>image analysis</phrase> specifically in mammography and presents <phrase>a series of</phrase> algorithms and design approaches for all the intermediate levels of a modern system for computer aided diagnosis cad . the diagnostic problem is analyzed with a systematic approach first defining the imaging characteristics and features that are relevant to probable pathology in mammo grams. next these features are quantified and fused into new integrated radio logical systems that exhibit embedded <phrase>digital signal processing</phrase> <phrase>in order to</phrase> improve <phrase>the final</phrase> result and minimize the radiological dose for the patient. in a <phrase>higher level</phrase> special algorithms are designed for detecting and encoding these clinically interest ing imaging features <phrase>in order to</phrase> be <phrase>used as</phrase> input to advanced pattern classifiers and <phrase>machine learning</phrase> models. finally <phrase>these approaches</phrase> are extended in multi classifier models under the scope of <phrase>game theory</phrase> and optimum collective deci sion <phrase>in order to</phrase> produce efficient solutions for combining classifiers with minimum computational costs for advanced diagnostic systems. the material covered in this thesis is <phrase>related to</phrase> a total of 18 published papers 6 in <phrase>scientific journals</phrase> and 12 in international conferences.
<phrase>deep neural networks</phrase> are easily fooled high confidence predictions for unrecognizable images
<phrase>deep neural networks</phrase> dnns have recently been achieving <phrase>state of</phrase> <phrase>the art performance on</phrase> <phrase>a variety of</phrase> <phrase>pattern recognition</phrase> tasks most notably visual <phrase>classification problems</phrase>. given that dnns are now <phrase>able to</phrase> classify objects in images with near human level performance questions naturally arise as to what differences remain between computer and human vision. a recent study revealed that changing <phrase>an image</phrase> e.g. of a lion in a way imperceptible to humans can cause a dnn to label the image as something else entirely e.g. mislabeling a lion a library . here we show a related result it is <phrase>easy to</phrase> produce images that are completely unrecognizable to humans but that <phrase>state of</phrase> <phrase>the art</phrase> dnns believe to be recognizable objects with 99.99 confidence e.g. labeling with certainty that <phrase>white noise</phrase> static is a lion . specifically we take <phrase>convolutional neural networks</phrase> trained <phrase>to perform</phrase> well on either the imagenet or mnist datasets and then find images with <phrase>evolutionary algorithms</phrase> or gradient ascent that dnns label with high confidence as belonging to each dataset class. it is possible <phrase>to produce</phrase> images totally unrecognizable to human eyes that dnns believe with near certainty are familiar objects which we call fooling images more generally fooling examples . our results shed light on interesting differences between human vision and current dnns and raise <phrase>questions about</phrase> the generality of dnn <phrase>computer vision</phrase>.
homogeneous spiking neuromorphic system for <phrase>real world</phrase> <phrase>pattern recognition</phrase>
a neuromorphic chip that combines cmos analog spiking neurons and memristive synapses offers a promising solution to brain inspired computing as it can provide massive <phrase>neural network</phrase> parallelism and density. previous hybrid analog cmos memristor approaches required extensive cmos circuitry for training and thus eliminated most of the density advantages gained by the adoption of memristor synapses. further they used different waveforms for pre and post synaptic spikes that added undesirable circuit overhead. here we describe a hardware architecture that can feature <phrase>a large number of</phrase> memristor synapses <phrase>to learn</phrase> <phrase>real world</phrase> patterns. we present a versatile cmos neuron that combines integrate and fire behavior drives passive memristors and implements competitive learning in a compact circuit module and enables in situ plasticity in the memristor synapses. we demonstrate handwritten digits recognition using <phrase>the proposed</phrase> architecture using transistor level circuit simulations. as the described neuromorphic architecture is homogeneous it realizes a fundamental building block for <phrase>large scale</phrase> energy efficient brain inspired silicon chips that could <phrase>lead to</phrase> next generation cognitive computing.
crowd <phrase>behavior analysis</phrase> a review where physics meets biology
although the traits emerged in a mass gathering are often non deliberative the act of mass impulse may <phrase>lead to</phrase> irre vocable crowd disasters. the two fold increase of carnage in crowd since <phrase>the past</phrase> two decades has spurred significant <phrase>advances in</phrase> <phrase>the field of</phrase> <phrase>computer vision</phrase> towards effective and proactive crowd surveillance. <phrase>computer vision</phrase> stud ies <phrase>related to</phrase> crowd are observed to resonate with the understanding of the emergent behavior in physics <phrase>complex systems</phrase> and biology animal swarm . these studies which are <phrase>inspired by</phrase> biology and physics share surprisingly common insights and interesting contradictions. however this aspect of discussion has not been fully explored. therefore this survey provides the readers with a review of the <phrase>state of</phrase> <phrase>the art</phrase> methods in crowd <phrase>behavior analysis</phrase> from the physics and biologically inspired perspectives. we provide insights and comprehensive discussions for a broader understanding of the underlying prospect of blending physics and biology studies <phrase>in computer vision</phrase>.
can pretrained <phrase>neural networks</phrase> detect anatomy 
<phrase>convolutional neural networks</phrase> demonstrated outstanding empirical results <phrase>in computer vision</phrase> and <phrase>speech recognition</phrase> tasks where labeled <phrase>training data</phrase> is abundant. in <phrase>medical imaging</phrase> there is a huge <phrase>variety of</phrase> possible imaging modalities and contrasts where annotated data is usually very scarce. we present two approaches to deal with this challenge. a network pretrained in a different domain with abundant data is <phrase>used as</phrase> a feature extractor while a subsequent classifier is <phrase>trained on</phrase> <phrase>a small</phrase> target dataset and a deep architecture trained with heavy augmentation and equipped with sophisticated regularization methods. we test the approaches on a corpus of <phrase>x ray</phrase> images to design an anatomy detection system.
metaheuristic algorithms for convolution <phrase>neural network</phrase>
a typical modern optimization technique is usually either heuristic or metaheuristic. this technique has managed <phrase>to solve</phrase> some optimization problems in the research area of science engineering and industry. however implementation strategy of metaheuristic for accuracy improvement on convolution <phrase>neural networks</phrase> cnn a famous <phrase>deep learning</phrase> method is still rarely investigated. <phrase>deep learning</phrase> relates to a <phrase>type of</phrase> <phrase>machine learning</phrase> technique where its aim is to move closer to <phrase>the goal of</phrase> <phrase>artificial intelligence</phrase> of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human. in <phrase>this paper</phrase> we propose the implementation strategy of three popular metaheuristic approaches that is <phrase>simulated annealing</phrase> differential evolution and harmony search to optimize cnn. the performances of these metaheuristic methods in optimizing cnn on classifying mnist and cifar dataset were evaluated and compared. furthermore <phrase>the proposed</phrase> methods are also <phrase>compared with</phrase> <phrase>the original</phrase> cnn. although <phrase>the proposed</phrase> methods show an increase in the computation time their accuracy has also been improved up to 7.14 percent .
hadamard product for low rank bilinear pooling
bilinear models provide rich representations <phrase>compared with</phrase> linear models. they have been applied in various visual <phrase>tasks such as</phrase> <phrase>object recognition</phrase> segmentation and <phrase>visual question answering</phrase> to get <phrase>state of</phrase> <phrase>the art</phrase> performances taking <phrase>advantage of</phrase> the expanded representations. however bilinear representations <phrase>tend to</phrase> be <phrase>high dimensional</phrase> limiting the applicability to computationally complex tasks. we propose low rank bilinear pooling using hadamard product for an efficient <phrase>attention mechanism</phrase> of multimodal learning. we show that our <phrase>model outperforms</phrase> compact bilinear pooling in <phrase>visual question answering</phrase> tasks with the <phrase>state of</phrase> <phrase>the art results</phrase> on the vqa dataset having a better parsimonious property.
incremental network quantization towards lossless cnns with low precision weights
<phrase>this paper</phrase> presents incremental network quantization inq <phrase>a novel</phrase> method targeting to efficiently convert any <phrase>pre trained</phrase> full precision <phrase>convolutional neural network</phrase> cnn model into a low precision version whose weights are constrained to be either powers of two or zero. unlike <phrase>existing methods</phrase> which are struggled in noticeable accuracy loss our inq has the potential to resolve <phrase>this issue</phrase> as benefiting from two innovations. on one hand we introduce three interdependent operations namely weight partition group wise quantization and re training. a well proven measure is employed to divide the weights in <phrase>each layer</phrase> of a <phrase>pre trained</phrase> cnn model into two disjoint groups. the weights in the first group are responsible to form a low precision base thus they are quantized by a variable length encoding method. the weights in the other group are responsible to compensate for the accuracy loss from the quantization thus they are the ones to be re trained. on the other hand these three operations are repeated on the latest re trained group in an iterative manner until all the weights are converted into low precision ones acting as an incremental network quantization and accuracy enhancement procedure. <phrase>extensive experiments</phrase> on the imagenet <phrase>classification task</phrase> using almost all known deep cnn architectures including alexnet vgg 16 googlenet and resnets well testify <phrase>the efficacy of</phrase> <phrase>the proposed</phrase> method. specifically at 5 bit quantization our models have improved accuracy than the 32 bit <phrase>floating point</phrase> references. taking resnet 18 as an example we further show that our quantized models with 4 bit 3 bit and 2 bit ternary weights have improved or very similar accuracy against its 32 bit <phrase>floating point</phrase> baseline. besides impressive results with the <phrase>combination of</phrase> network pruning and inq are also reported. the code is <phrase>available at</phrase> https github.com zhouaojun incremental network quantization.
lesionseg <phrase>semantic segmentation</phrase> of skin lesions using <phrase>deep convolutional</phrase> <phrase>neural network</phrase>
we present a <phrase>method for</phrase> skin lesion segmentation for the isic 2017 skin lesion segmentation challenge. our approach is <phrase>based on</phrase> a fully convolutional <phrase>network architecture</phrase> which is <phrase>trained end to end</phrase> <phrase>from scratch</phrase> on a limited dataset. our <phrase>semantic segmentation</phrase> architecture utilizes several recent innovations in particularly in the combined use of i use of atrous convolutions to increase the effective field of view of <phrase>the network</phrase> s <phrase>receptive field</phrase> without increasing <phrase>the number of</phrase> parameters ii <phrase>the use of</phrase> network in network 1 times1 convolution layers to add capacity to <phrase>the network</phrase> and iii <phrase>state of</phrase> art super resolution upsampling of predictions using subpixel cnn layers. we reported a mean iou score of 0.642 on the validation set provided by the organisers.
convolutional spike timing dependent plasticity based <phrase>feature learning</phrase> in <phrase>spiking neural networks</phrase>
brain inspired <phrase>learning models</phrase> <phrase>attempt to</phrase> mimic the cortical architecture and computations performed in the neurons and synapses constituting the <phrase>human brain</phrase> to achieve its efficiency in cognitive tasks. in <phrase>this work</phrase> we present convolutional spike timing dependent plasticity based <phrase>feature learning</phrase> with biologically plausible leaky integrate and fire neurons in <phrase>spiking neural networks</phrase> snns . we use shared weight kernels that are trained to encode representative features underlying <phrase>the input</phrase> patterns thereby improving the sparsity <phrase>as well as</phrase> <phrase>the robustness of</phrase> the learning model. we demonstrate that <phrase>the proposed</phrase> <phrase>unsupervised learning</phrase> methodology learns several visual categories for <phrase>object recognition</phrase> with fewer <phrase>number of</phrase> examples and outperforms traditional fully connected snn architectures while yielding competitive accuracy. additionally we observe that the learning model performs out of set generalization further making <phrase>the proposed</phrase> biologically plausible framework a viable and efficient architecture for future neuromorphic applications.
adversarial transformation networks learning <phrase>to generate</phrase> <phrase>adversarial examples</phrase>
multiple different approaches of generating <phrase>adversarial examples</phrase> have been proposed to attack <phrase>deep neural networks</phrase>. <phrase>these approaches</phrase> involve either directly computing gradients <phrase>with respect to</phrase> the image pixels or directly solving an optimization on the image pixels. in <phrase>this work</phrase> we present a fundamentally new <phrase>method for</phrase> generating <phrase>adversarial examples</phrase> that is fast to execute and provides exceptional diversity of output. we efficiently train <phrase>feed forward</phrase> <phrase>neural networks</phrase> in a self supervised manner <phrase>to generate</phrase> <phrase>adversarial examples</phrase> against a target network or <phrase>set of</phrase> networks. we call such a network an adversarial transformation network atn . atns are trained <phrase>to generate</phrase> <phrase>adversarial examples</phrase> that minimally modify the classifier s outputs given <phrase>the original</phrase> input while constraining the new classification to match an adversarial target class. we present methods <phrase>to train</phrase> atns and analyze their effectiveness targeting <phrase>a variety of</phrase> mnist classifiers <phrase>as well as</phrase> the latest <phrase>state of</phrase> <phrase>the art</phrase> imagenet classifier inception resnet v2.
opening the <phrase>black box</phrase> of financial ai with clear trade a class enhanced attentive response approach for explaining and visualizing <phrase>deep learning</phrase> driven <phrase>stock market</phrase> prediction
<phrase>deep learning</phrase> has been <phrase>shown to</phrase> outperform traditional <phrase>machine learning</phrase> algorithms across <phrase>a wide range of</phrase> problem domains. however current <phrase>deep learning</phrase> algorithms have been criticized as uninterpretable black boxes which cannot explain their <phrase>decision making</phrase> processes. this is a major shortcoming that prevents the widespread <phrase>application of</phrase> <phrase>deep learning</phrase> to domains with regulatory processes <phrase>such as</phrase> finance. as such industries <phrase>such as</phrase> finance have to <phrase>rely on</phrase> traditional models like decision trees that are much more interpretable but less effective than <phrase>deep learning</phrase> for complex problems. in <phrase>this paper</phrase> we propose clear trade <phrase>a novel</phrase> financial ai visualization <phrase>framework for</phrase> <phrase>deep learning</phrase> driven <phrase>stock market</phrase> prediction that mitigates the interpretability issue of <phrase>deep learning</phrase> methods. <phrase>in particular</phrase> clear trade provides a effective way to visualize and explain decisions made by deep <phrase>stock market</phrase> prediction models. we show <phrase>the efficacy of</phrase> clear trade in enhancing the interpretability of <phrase>stock market</phrase> prediction by conducting experiments <phrase>based on</phrase> s p 500 <phrase>stock index</phrase> prediction. the <phrase>results demonstrate</phrase> that clear trade can provide significant insight into the <phrase>decision making</phrase> process of <phrase>deep learning</phrase> driven financial models particularly for regulatory processes thus improving their potential uptake in the financial industry.
fast yolo a fast you only look once system for <phrase>real time</phrase> embedded <phrase>object detection</phrase> in video
<phrase>object detection</phrase> is considered one of the most challenging problems in this field of <phrase>computer vision</phrase> as it involves the <phrase>combination of</phrase> object classification and object localization within a scene. recently <phrase>deep neural networks</phrase> dnns have been demonstrated to achieve superior <phrase>object detection</phrase> performance <phrase>compared to</phrase> other approaches with yolov2 an improved you only look once model being one of the <phrase>state of</phrase> <phrase>the art</phrase> in dnn based <phrase>object detection</phrase> methods <phrase>in terms of</phrase> both speed and accuracy. although yolov2 can achieve <phrase>real time</phrase> <phrase>performance on</phrase> a powerful gpu it still remains very challenging for leveraging <phrase>this approach</phrase> for <phrase>real time</phrase> <phrase>object detection</phrase> in video on embedded computing devices with limited computational power and limited memory. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> framework called fast yolo a fast you only look once framework which accelerates yolov2 to be <phrase>able to</phrase> perform <phrase>object detection</phrase> in video on <phrase>embedded devices</phrase> in a <phrase>real time</phrase> manner. first we leverage the evolutionary deep intelligence framework to evolve the yolov2 <phrase>network architecture</phrase> and produce an optimized architecture referred to as o yolov2 here that has 2.8x <phrase>fewer parameters</phrase> with just a 2 iou drop. to further reduce power consumption on <phrase>embedded devices</phrase> while maintaining performance a motion adaptive inference method is introduced into <phrase>the proposed</phrase> fast yolo framework <phrase>to reduce</phrase> the frequency of deep inference with o yolov2 <phrase>based on</phrase> temporal motion characteristics. <phrase>experimental results</phrase> show that <phrase>the proposed</phrase> fast yolo framework can reduce <phrase>the number of</phrase> deep inferences by an average of 38.13 and an average speedup of 3.3x for objection detection in video <phrase>compared to</phrase> <phrase>the original</phrase> yolov2 leading fast yolo to run an average of 18fps on a nvidia jetson tx1 embedded system.
nest <phrase>a neural network</phrase> synthesis tool <phrase>based on</phrase> a grow and prune paradigm
<phrase>neural networks</phrase> nns have begun to have a pervasive impact on various applications of <phrase>machine learning</phrase>. however <phrase>the problem of</phrase> finding an optimal nn architecture for large applications has remained open for several decades. conventional approaches search for the optimal nn architecture through extensive trial and error. such a procedure is quite inefficient. <phrase>in addition</phrase> the generated nn architectures incur substantial redundancy. <phrase>to address</phrase> these problems we propose an nn synthesis tool nest that automatically generates very compact architectures for a given dataset. nest starts with a seed nn architecture. it iteratively tunes the architecture with <phrase>gradient based</phrase> growth and magnitude based pruning of neurons and connections. our <phrase>experimental results</phrase> show that nest yields accurate yet very compact nns with <phrase>a wide range of</phrase> seed architecture selection. for example for the lenet 300 100 lenet 5 nn architecture <phrase>derived from</phrase> the mnist dataset we reduce network parameters by 34.1x 74.3x and <phrase>floating point</phrase> operations flops by 35.8x 43.7x . for the alexnet nn architecture <phrase>derived from</phrase> the imagenet dataset we reduce network parameters by 15.7x and flops by 4.6x. all these results are <phrase>the current state of</phrase> <phrase>the art</phrase> for these architectures.
analysis of supervised and <phrase>semi supervised</phrase> growcut <phrase>applied to</phrase> segmentation of masses in mammography images
<phrase>breast cancer</phrase> is already one of the most common form of cancer worldwide. mammography <phrase>image analysis</phrase> is still the most effective diagnostic method to promote the early detection of <phrase>breast cancer</phrase>. accurately segmenting tumors in digital mammography images is important <phrase>to improve</phrase> diagnosis capabilities of health specialists and avoid misdiagnosis. in <phrase>this work</phrase> we evaluate the feasibility of applying growcut to segment regions of tumor and we propose two growcut <phrase>semi supervised</phrase> versions. all the analysis was performed by evaluating the <phrase>application of</phrase> segmentation techniques to <phrase>a set of</phrase> images obtained from the mini mias mammography image database. growcut segmentation was <phrase>compared to</phrase> region growing active contours random walks and graph cut techniques. experiments showed that growcut when <phrase>compared to</phrase> the other techniques was <phrase>able to</phrase> acquire better results for the metrics analyzed. moreover <phrase>the proposed</phrase> <phrase>semi supervised</phrase> versions of growcut was proved to have a clinically satisfactory quality of segmentation.
empirical explorations in training networks with discrete activations
we present <phrase>extensive experiments</phrase> training and testing hidden units in <phrase>deep networks</phrase> that emit only a predefined static <phrase>number of</phrase> discretized values. these units provide benefits in <phrase>real world</phrase> deployment in systems in which memory and or computation may be limited. additionally they are particularly well suited for use in large <phrase>recurrent network</phrase> models that require the maintenance of large <phrase>amounts of</phrase> internal state in memory. surprisingly we find that despite reducing <phrase>the number of</phrase> values that can be represented in the output activations from 2 32 2 64 to between 64 and 256 there is little to no degradation in network performance across <phrase>a variety of</phrase> different settings. we investigate simple classification and regression tasks <phrase>as well as</phrase> memorization and compression problems. we compare the results with more standard activations <phrase>such as</phrase> tanh and relu. unlike previous discretization studies which often concentrate only on binary units we examine the effects of varying <phrase>the number of</phrase> allowed activation levels. <phrase>compared to</phrase> <phrase>existing approaches</phrase> for discretization the approach presented here is both conceptually and programatically simple has no stochastic component and allows the training testing and usage phases to be treated in exactly <phrase>the same</phrase> manner.
regularized evolution for image classifier architecture search
the effort devoted to hand crafting image classifiers has motivated <phrase>the use of</phrase> architecture search <phrase>to discover</phrase> them automatically. <phrase>reinforcement learning</phrase> and evolution have both shown promise for this purpose. <phrase>this study</phrase> employs a regularized <phrase>version of</phrase> a popular asynchronous <phrase>evolutionary algorithm</phrase>. we rigorously compare it to the non regularized form and to a highly successful <phrase>reinforcement learning</phrase> baseline. using <phrase>the same</phrase> hardware compute effort and <phrase>neural network</phrase> training code we conduct repeated experiments side by side exploring different datasets search spaces and scales. we show regularized evolution consistently produces models with similar or higher accuracy across <phrase>a variety of</phrase> contexts without need for re tuning parameters. <phrase>in addition</phrase> evolution exhibits considerably <phrase>better performance</phrase> than <phrase>reinforcement learning</phrase> at early search stages suggesting it may be the better choice when fewer compute resources are available. this constitutes the first controlled comparison of the two search algorithms in this context. finally we present new architectures discovered with evolution that we nickname amoebanets. <phrase>these models</phrase> <phrase>achieve state of</phrase> <phrase>the art</phrase> results for <phrase>cifar 10</phrase> mean test error 2.13 mobile size imagenet top 1 accuracy 75.1 with 5.1 m parameters and imagenet top 1 accuracy 83.1 . this is the first time <phrase>evolutionary algorithms</phrase> produce <phrase>state of</phrase> <phrase>the art</phrase> image classifiers.
tiny ssd a tiny single shot detection <phrase>deep convolutional</phrase> <phrase>neural network</phrase> for <phrase>real time</phrase> embedded <phrase>object detection</phrase>
<phrase>object detection</phrase> is a major challenge <phrase>in computer vision</phrase> involving both object classification and object localization within a scene. while <phrase>deep neural networks</phrase> have been shown <phrase>in recent years</phrase> to yield very powerful techniques for tackling the challenge of <phrase>object detection</phrase> one of the biggest challenges with enabling such <phrase>object detection</phrase> networks for widespread deployment on <phrase>embedded devices</phrase> is high computational and memory requirements. recently there has been an increasing focus in exploring small <phrase>deep neural network</phrase> architectures for <phrase>object detection</phrase> that are more <phrase>suitable for</phrase> <phrase>embedded devices</phrase> <phrase>such as</phrase> tiny yolo and squeezedet. <phrase>inspired by</phrase> the efficiency of the fire microarchitecture introduced in squeezenet and the <phrase>object detection</phrase> performance of the single shot detection macroarchitecture introduced in ssd <phrase>this paper</phrase> introduces tiny ssd <phrase>a single</phrase> shot detection <phrase>deep convolutional</phrase> <phrase>neural network</phrase> for <phrase>real time</phrase> embedded <phrase>object detection</phrase> that is <phrase>composed of</phrase> a highly optimized non uniform fire sub network stack and a non uniform sub network stack of highly optimized ssd based auxiliary convolutional feature layers designed specifically to minimize model size while maintaining <phrase>object detection</phrase> performance. the resulting tiny ssd possess a model size of 2.3mb 26x smaller than tiny yolo while still achieving an map of 61.3 on voc 2007 4.2 higher than tiny yolo . these <phrase>experimental results</phrase> show that very small <phrase>deep neural network</phrase> architectures can be designed for <phrase>real time</phrase> <phrase>object detection</phrase> that are well suited for embedded scenarios.
inferencing <phrase>based on</phrase> <phrase>unsupervised learning</phrase> of disentangled representations
combining <phrase>generative adversarial networks</phrase> gans with encoders that learn to encode data points has shown <phrase>promising results</phrase> in learning data representations in an unsupervised way. we propose a framework that combines an encoder and a generator <phrase>to learn</phrase> disentangled representations which encode meaningful <phrase>information about</phrase> the data distribution without <phrase>the need for</phrase> any labels. while current approaches focus mostly on the generative <phrase>aspects of</phrase> gans our framework can be used <phrase>to perform</phrase> inference on both real and generated data points. <phrase>experiments on</phrase> several <phrase>data sets</phrase> show that the encoder learns interpretable disentangled representations which encode descriptive properties and can be used to sample images that exhibit specific characteristics.
the parameter less <phrase>self organizing map</phrase> algorithm
the parameter less <phrase>self organizing map</phrase> plsom is <phrase>a new</phrase> <phrase>neural network</phrase> algorithm <phrase>based on</phrase> the <phrase>self organizing map</phrase> som . it eliminates <phrase>the need for</phrase> a <phrase>learning rate</phrase> and annealing schemes for <phrase>learning rate</phrase> and neighbourhood size. we discuss the relative performance of the plsom and the som and demonstrate some tasks in which the som fails but the plsom performs satisfactory. finally we discuss some example applications of the plsom and present a proof of ordering under certain limited conditions.
simplified firefly algorithm for 2d image key points search
<phrase>in order to</phrase> identify an object human eyes firstly search <phrase>the field of</phrase> view for points or areas which have particular properties. these properties are used to recognise <phrase>an image</phrase> or an object. then this process could be taken as a model to develop computer algorithms for images identification. <phrase>this paper</phrase> proposes the idea of applying the simplified firefly algorithm to search for key areas in 2d images. for <phrase>a set of</phrase> input test images <phrase>the proposed</phrase> <phrase>version of</phrase> firefly algorithm has been examined. research results are presented and discussed to show the efficiency of this <phrase>evolutionary computation</phrase> method.
deep plant plant identification with <phrase>convolutional neural networks</phrase>
<phrase>this paper</phrase> studies <phrase>convolutional neural networks</phrase> cnn <phrase>to learn</phrase> unsupervised <phrase>feature representations</phrase> for 44 different plant species collected at the <phrase>royal botanic gardens</phrase> kew england. to gain intuition on the chosen features from the cnn model opposed to a <phrase>black box</phrase> solution a visualisation technique <phrase>based on</phrase> the deconvolutional networks dn is utilized. it is found that venations of different order have been chosen to uniquely represent each of the plant species. <phrase>experimental results</phrase> using these cnn features with different classifiers show consistency and superiority <phrase>compared to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> solutions which <phrase>rely on</phrase> <phrase>hand crafted</phrase> features.
adapting <phrase>deep network</phrase> features <phrase>to capture</phrase> psychological representations
<phrase>deep neural networks</phrase> have become increasingly successful at solving classic perception problems <phrase>such as</phrase> <phrase>object recognition</phrase> <phrase>semantic segmentation</phrase> and scene understanding often reaching or surpassing human level accuracy. this success is due in part to the ability of dnns <phrase>to learn</phrase> useful representations of <phrase>high dimensional</phrase> inputs a problem that humans must also solve. we examine the relationship between the representations learned by these networks and human psychological representations recovered from similarity judgments. we find that deep features learned in service of object classification account for a significant <phrase>amount of</phrase> the variance in human similarity judgments for <phrase>a set of</phrase> animal images. however these features <phrase>do not</phrase> capture some qualitative distinctions that are a key part of human representations. to remedy this we develop a <phrase>method for</phrase> adapting deep features to align with human similarity judgments resulting in image representations that can potentially be used to extend the scope of psychological experiments.
<phrase>large scale</phrase> evolution of image classifiers
<phrase>neural networks</phrase> have proven effective at solving difficult problems but designing their architectures can be challenging even for <phrase>image classification</phrase> problems alone. our goal is to minimize human participation so we employ <phrase>evolutionary algorithms</phrase> <phrase>to discover</phrase> such networks automatically. despite significant computational requirements we show that it is now possible to evolve models with accuracies within the range of those published in the last year. specifically we employ simple evolutionary techniques at unprecedented scales <phrase>to discover</phrase> models for the <phrase>cifar 10</phrase> and cifar 100 datasets starting from trivial initial conditions and reaching accuracies of 94.6 95.6 for ensemble and 77.0 respectively. to do this we use novel and intuitive mutation operators that navigate large search spaces we stress that no human participation is required once evolution starts and that the output is a fully trained model. throughout <phrase>this work</phrase> we place special emphasis on the repeatability of results the variability in the outcomes and the computational requirements.
a compact dnn approaching googlenet level accuracy of classification and <phrase>domain adaptation</phrase>
recently dnn model compression <phrase>based on</phrase> <phrase>network architecture</phrase> design e.g. squeezenet attracted a lot attention. no accuracy drop on <phrase>image classification</phrase> is observed on these extremely compact networks <phrase>compared to</phrase> <phrase>well known</phrase> models. an emerging question however is whether these model compression techniques hurt dnn s learning ability other than classifying images on <phrase>a single</phrase> dataset. our preliminary experiment shows that these compression methods could degrade <phrase>domain adaptation</phrase> da ability though the <phrase>classification performance</phrase> is preserved. therefore we propose <phrase>a new</phrase> compact <phrase>network architecture</phrase> and unsupervised da method in <phrase>this paper</phrase>. the dnn is built on <phrase>a new</phrase> basic module conv m which provides more diverse feature extractors without significantly increasing parameters. the unified framework of our da method will simultaneously learn invariance across domains reduce divergence of <phrase>feature representations</phrase> and adapt label prediction. our dnn has 4.1m parameters which is only 6.7 of alexnet or 59 of googlenet. <phrase>experiments show</phrase> that our dnn obtains googlenet level accuracy both on classification and da and our da method slightly outperforms previous competitive ones. put all together our da strategy <phrase>based on</phrase> our dnn <phrase>achieves state of</phrase> <phrase>the art</phrase> on sixteen of total eighteen da tasks on popular office 31 and office caltech datasets.
identifying spatial relations in images using <phrase>convolutional neural networks</phrase>
traditional approaches to building <phrase>a large</phrase> scale <phrase>knowledge graph</phrase> have usually relied on extracting information entities their properties and <phrase>relations between</phrase> them from unstructured text e.g. dbpedia . <phrase>recent advances in</phrase> <phrase>convolutional neural networks</phrase> cnn allow us to shift our focus to learning entities and relations from images as they build robust models that require little or no pre processing of the images. in <phrase>this paper</phrase> we present an <phrase>approach to</phrase> identify and extract spatial relations e.g. the girl is standing behind the table from images using cnns. our research addresses two specific challenges providing insight into how spatial relations are learned by <phrase>the network</phrase> and which <phrase>parts of</phrase> the image are used <phrase>to predict</phrase> these relations. we use the <phrase>pre trained</phrase> network vggnet <phrase>to extract</phrase> features from <phrase>an image</phrase> and train a <phrase>multi layer</phrase> perceptron mlp on <phrase>a set of</phrase> synthetic images and the sun09 dataset <phrase>to extract</phrase> spatial relations. the mlp predicts spatial relations without a bounding box around the objects or the space in the image depicting the relation. <phrase>to understand</phrase> how the spatial relations are represented in <phrase>the network</phrase> a heatmap is overlayed on the image to show the regions that are deemed important by <phrase>the network</phrase>. also we analyze the mlp to show the relationship between the activation of consistent groups of nodes and the prediction of a spatial relation. we show how the loss of these groups affects the networks <phrase>ability to</phrase> identify relations.
hierarchical attentive recurrent tracking
class agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. <phrase>inspired by</phrase> how the human <phrase>visual cortex</phrase> employs spatial attention and separate where and what processing pathways to actively suppress irrelevant visual features <phrase>this work</phrase> develops a hierarchical attentive recurrent model for single object tracking in videos. the first layer of attention discards the majority of background by selecting a region containing the object of interest while the subsequent layers tune in on visual features particular to the tracked object. this framework is fully differentiable and can be trained in a purely <phrase>data driven</phrase> fashion by gradient methods. <phrase>to improve</phrase> training convergence we augment the <phrase>loss function</phrase> with terms for <phrase>a number of</phrase> auxiliary tasks relevant for tracking. evaluation of <phrase>the proposed</phrase> model is performed on two datasets pedestrian tracking on the kth activity recognition dataset and the more difficult kitti object tracking dataset.
psique next sequence prediction of satellite images using a convolutional <phrase>sequence to sequence</phrase> network
predicting unseen weather phenomena is <phrase>an important</phrase> issue for disaster management. in <phrase>this paper</phrase> we suggest a model for a convolutional <phrase>sequence to sequence</phrase> autoencoder for predicting undiscovered weather situations from previous satellite images. we also propose a symmetric skip connection between encoder and decoder modules <phrase>to produce</phrase> more comprehensive image predictions. to examine our model performance we conducted experiments for each suggested model <phrase>to predict</phrase> future satellite images from historical satellite images. a specific <phrase>combination of</phrase> skip connection and <phrase>sequence to sequence</phrase> autoencoder was <phrase>able to</phrase> generate closest prediction from the ground truth image.
evaluation of alzheimer s disease by analysis of mr images using multilayer perceptrons and kohonen som classifiers as <phrase>an alternative</phrase> to the adc maps
alzheimer s disease is the most common cause of dementia yet hard to diagnose precisely without invasive techniques particularly at the onset of the disease. <phrase>this work</phrase> approaches <phrase>image analysis</phrase> and classification of synthetic multispectral images composed by diffusion weighted <phrase>magnetic resonance</phrase> mr cerebral images for the evaluation of <phrase>cerebrospinal fluid</phrase> area and measuring the advance of alzheimer s disease. a clinical 1.5 t mr imaging system was used to acquire all images presented. the classification methods are <phrase>based on</phrase> multilayer perceptrons and kohonen self organized map classifiers. we assume the classes of interest can be separated by hyperquadrics. therefore a 2 degree polynomial network is used to classify <phrase>the original</phrase> image generating the ground truth image. the classification results are used <phrase>to improve</phrase> the usual analysis of the apparent diffusion coefficient map.
neural tuning size is a key factor underlying holistic face processing
faces are a class of visual stimuli with unique significance for <phrase>a variety of</phrase> reasons. they are ubiquitous throughout the course of a person s life and face recognition is crucial for daily social interaction. faces are also unlike any other stimulus class <phrase>in terms of</phrase> certain physical stimulus characteristics. furthermore faces have been empirically found to elicit certain characteristic behavioral phenomena which are widely held to be evidence of holistic processing of faces. however little is known about the neural mechanisms underlying such holistic face processing. in other words for the processing of faces by the primate visual system <phrase>the input</phrase> and output characteristics are relatively <phrase>well known</phrase> but the internal neural computations are not. the main aim of <phrase>this work</phrase> is to further the fundamental understanding of what causes the <phrase>visual processing</phrase> of faces to be different from that of objects. in this computational modeling work we show that <phrase>a single</phrase> factor neural tuning size is <phrase>able to</phrase> account for three key phenomena that are characteristic of face processing namely the composite face effect cfe face inversion effect fie and whole part effect wpe . our computational proof of principle provides specific neural tuning properties that correspond to the poorly understood <phrase>notion of</phrase> holistic face processing and connects these neural properties to psychophysical behavior. overall our work provides <phrase>a unified</phrase> and parsimonious theoretical account for the disparate empirical data on face specific processing deepening the fundamental understanding of face processing.
distribution of the search of evolutionary product unit <phrase>neural networks</phrase> for classification
<phrase>this paper</phrase> deals with the distributed processing in the search for an optimum classification model using evolutionary product unit <phrase>neural networks</phrase>. for this distributed search we used a cluster of computers. our objective is <phrase>to obtain</phrase> a <phrase>more efficient</phrase> design than those net architectures which <phrase>do not</phrase> use a distributed process and which thus result in simpler designs. <phrase>in order to</phrase> get <phrase>the best</phrase> classification models we use <phrase>evolutionary algorithms</phrase> <phrase>to train</phrase> and design <phrase>neural networks</phrase> which require a very time consuming computation. the reasons behind <phrase>the need for</phrase> this distribution are various. it is complicated <phrase>to train</phrase> this <phrase>type of</phrase> nets because of the difficulty entailed in determining their architecture <phrase>due to</phrase> the complex error surface. on the other hand <phrase>the use of</phrase> <phrase>evolutionary algorithms</phrase> involves running a great <phrase>number of</phrase> tests with different seeds and parameters thus resulting in a high <phrase>computational cost</phrase>
correlation alignment for unsupervised <phrase>domain adaptation</phrase>
in this chapter we present correlation alignment coral <phrase>a simple</phrase> yet effective <phrase>method for</phrase> unsupervised <phrase>domain adaptation</phrase>. coral minimizes domain shift by aligning the second order statistics of source and target distributions <phrase>without requiring</phrase> any target labels. <phrase>in contrast to</phrase> subspace manifold methods it aligns <phrase>the original</phrase> feature distributions of the source and target domains <phrase>rather than</phrase> the bases of lower dimensional subspaces. it is also much simpler than other distribution matching methods. coral performs remarkably well in extensive evaluations on standard <phrase>benchmark datasets</phrase>. we first describe a solution that applies a <phrase>linear transformation</phrase> to source features to align them with target features before classifier training. for linear classifiers we propose to equivalently apply coral to the classifier weights <phrase>leading to</phrase> added efficiency when <phrase>the number of</phrase> classifiers is small but the number and dimensionality of target examples are very high. the resulting coral <phrase>linear discriminant analysis</phrase> coral lda outperforms lda by <phrase>a large</phrase> margin on standard <phrase>domain adaptation</phrase> benchmarks. finally we extend coral <phrase>to learn</phrase> a nonlinear transformation that aligns correlations of layer activations in <phrase>deep neural networks</phrase> dnns . the resulting deep coral approach works seamlessly with dnns and <phrase>achieves state of</phrase> <phrase>the art performance on</phrase> standard <phrase>benchmark datasets</phrase>. our code is <phrase>available at</phrase> url https github.com visionlearninggroup coral 
citlab argus for historical handwritten documents
we describe citlab s recognition system for the htrts competition attached to the 13. international conference on document analysis and recognition icdar 2015. the task comprises the recognition of historical handwritten documents. the core algorithms of our system are <phrase>based on</phrase> multi dimensional <phrase>recurrent neural networks</phrase> mdrnn and connectionist temporal classification ctc . the software modules behind that <phrase>as well as</phrase> the basic utility technologies are essentially powered by planet s argus <phrase>framework for</phrase> intelligent text recognition and <phrase>image processing</phrase>.
generalized haar filter based <phrase>deep networks</phrase> for <phrase>real time</phrase> <phrase>object detection</phrase> in traffic scene
vision based <phrase>object detection</phrase> is one of the fundamental functions in numerous traffic scene <phrase>applications such as</phrase> self driving vehicle systems and advance driver assistance systems adas . however it is also a <phrase>challenging task</phrase> <phrase>due to</phrase> the diversity of traffic scene and the storage power and computing source limitations of the platforms for traffic scene applications. <phrase>this paper</phrase> presents a generalized haar filter based <phrase>deep network</phrase> which is <phrase>suitable for</phrase> the <phrase>object detection</phrase> tasks in traffic scene. in <phrase>this approach</phrase> we first decompose a <phrase>object detection</phrase> task into several easier local regression tasks. then we handle the local regression tasks <phrase>by using</phrase> several tiny <phrase>deep networks</phrase> which simultaneously output the bounding boxes categories and confidence scores of detected objects. <phrase>to reduce</phrase> the consumption of storage and computing resources the weights of the <phrase>deep networks</phrase> are constrained to the form of generalized haar filter in training phase. additionally we introduce the strategy of sparse windows generation <phrase>to improve</phrase> the efficiency of the algorithm. finally we perform several experiments to validate <phrase>the performance of</phrase> our <phrase>proposed approach</phrase>. <phrase>experimental results</phrase> demonstrate that <phrase>the proposed</phrase> approach is both efficient and effective in traffic scene <phrase>compared with</phrase> the <phrase>state of</phrase> <phrase>the art</phrase>.
autoencoder regularized network for driving style <phrase>representation learning</phrase>
in <phrase>this paper</phrase> we study learning generalized driving style representations from automobile gps trip data. we propose <phrase>a novel</phrase> autoencoder regularized <phrase>deep neural network</phrase> arnet and a trip encoding framework trip2vec <phrase>to learn</phrase> drivers driving styles directly from gps records by combining supervised and unsupervised <phrase>feature learning</phrase> in <phrase>a unified</phrase> architecture. <phrase>experiments on</phrase> a challenging driver number estimation problem and the driver identification problem show that arnet can learn a good generalized driving style representation it <phrase>significantly outperforms</phrase> <phrase>existing methods</phrase> and alternative architectures by reaching the least estimation error on average 0.68 less than one driver and the highest identification accuracy by at least 3 improvement <phrase>compared with</phrase> traditional <phrase>supervised learning</phrase> methods.
fashioning with networks neural style transfer to design clothes
<phrase>convolutional neural networks</phrase> have been highly successful in performing a host of <phrase>computer vision</phrase> <phrase>tasks such as</phrase> <phrase>object recognition</phrase> <phrase>object detection</phrase> <phrase>image segmentation</phrase> and texture synthesis. in 2015 gatys et. al 7 show how the style of a painter can be <phrase>extracted from</phrase> <phrase>an image</phrase> of the painting and <phrase>applied to</phrase> another normal photograph thus recreating the photo in the style of the painter. the method has been successfully <phrase>applied to</phrase> <phrase>a wide range of</phrase> images and has since spawned multiple applications and <phrase>mobile apps</phrase>. in <phrase>this paper</phrase> the neural style transfer algorithm is <phrase>applied to</phrase> fashion so as to synthesize new custom clothes. we construct an <phrase>approach to</phrase> personalize and generate new custom clothes <phrase>based on</phrase> a users preference and by learning the users fashion choices from a limited <phrase>set of</phrase> clothes from their closet. the approach is evaluated by analyzing the generated images of clothes and how well they align with the users fashion style.
globenet <phrase>convolutional neural networks</phrase> for typhoon <phrase>eye tracking</phrase> from <phrase>remote sensing</phrase> imagery
<phrase>advances in</phrase> <phrase>remote sensing</phrase> technologies have made it possible to use high resolution visual data for weather observation and forecasting tasks. we propose <phrase>the use of</phrase> <phrase>multi layer</phrase> <phrase>neural networks</phrase> for understanding complex atmospheric dynamics <phrase>based on</phrase> multichannel satellite images. the capability of our model was evaluated <phrase>by using</phrase> a <phrase>linear regression</phrase> task for single typhoon coordinates prediction. a specific <phrase>combination of</phrase> models and different activation policies enabled us <phrase>to obtain</phrase> an interesting prediction result in the northeastern hemisphere enh .
improving efficiency in <phrase>convolutional neural network</phrase> with multilinear filters
the excellent performance of <phrase>deep neural networks</phrase> has enabled us <phrase>to solve</phrase> several automatization problems opening an era of autonomous devices. however current deep net architectures are heavy with millions of parameters and require billions of <phrase>floating point</phrase> operations. several works have been developed to compress a <phrase>pre trained</phrase> <phrase>deep network</phrase> <phrase>to reduce</phrase> <phrase>memory footprint</phrase> and possibly computation. <phrase>instead of</phrase> compressing a <phrase>pre trained</phrase> network in <phrase>this work</phrase> we propose a generic <phrase>neural network</phrase> layer structure employing multilinear projection as the primary feature extractor. <phrase>the proposed</phrase> architecture requires several times less memory as <phrase>compared to</phrase> the traditional <phrase>convolutional neural networks</phrase> cnn while inherits the similar design principles of a cnn. <phrase>in addition</phrase> <phrase>the proposed</phrase> architecture is equipped with two computation schemes that enable computation reduction or scalability. <phrase>experimental results</phrase> show <phrase>the effectiveness of</phrase> our compact projection that outperforms traditional cnn while requiring far <phrase>fewer parameters</phrase>.
discovery radiomics with clear dr interpretable computer aided diagnosis of <phrase>diabetic retinopathy</phrase>
objective radiomics driven computer aided diagnosis cad has shown considerable promise <phrase>in recent years</phrase> as a potential tool for improving clinical decision support in <phrase>medical oncology</phrase> particularly those based around the concept of discovery radiomics where radiomic sequencers are discovered through the analysis of <phrase>medical imaging</phrase> data. one of the main limitations with current cad approaches is that it is very difficult to gain insight or rationale as to how decisions are made thus limiting their utility to clinicians. methods in <phrase>this study</phrase> we propose clear dr <phrase>a novel</phrase> interpretable cad system <phrase>based on</phrase> the <phrase>notion of</phrase> class enhanced attentive response discovery radiomics for the purpose of clinical decision support for <phrase>diabetic retinopathy</phrase>. results <phrase>in addition</phrase> to disease grading via the discovered deep radiomic sequencer the clear dr system also produces a visual interpretation of the <phrase>decision making</phrase> process to provide better insight and understanding into the <phrase>decision making</phrase> process of the system. conclusion we demonstrate the effectiveness and utility of <phrase>the proposed</phrase> clear dr system of enhancing the interpretability of diagnostic grading results for the <phrase>application of</phrase> <phrase>diabetic retinopathy</phrase> grading. significance clear dr can act as a potential powerful tool <phrase>to address</phrase> the uninterpretability issue of current cad systems thus improving their utility to clinicians.
hp gan probabilistic 3d human motion prediction via gan
predicting and understanding human motion dynamics has <phrase>many applications</phrase> <phrase>such as</phrase> motion synthesis <phrase>augmented reality</phrase> security and autonomous vehicles. <phrase>due to</phrase> the recent success of <phrase>generative adversarial networks</phrase> gan there has been much interest in probabilistic estimation and synthetic data generation using <phrase>deep neural network</phrase> architectures and <phrase>learning algorithms</phrase>. we propose <phrase>a novel</phrase> <phrase>sequence to sequence</phrase> model for probabilistic human motion prediction trained with a modified <phrase>version of</phrase> improved wasserstein <phrase>generative adversarial networks</phrase> wgan gp in which we use a custom <phrase>loss function</phrase> designed for human motion prediction. our model which we call hp gan learns a <phrase>probability density</phrase> function of future human poses <phrase>conditioned on</phrase> previous poses. it predicts multiple sequences of possible future human poses each from <phrase>the same</phrase> <phrase>input sequence</phrase> but a different vector z drawn from a random distribution. furthermore to quantify the quality of the non deterministic predictions we simultaneously train a motion quality assessment model that learns the probability that a given skeleton sequence is a real human motion. we test our algorithm on two of the largest skeleton datasets nturgb d and human3.6m. we train our model on both single and multiple action types. its predictive power for <phrase>long term</phrase> motion estimation is demonstrated by generating multiple plausible futures of <phrase>more than</phrase> 30 frames from just 10 frames of input. we show that most sequences generated from <phrase>the same</phrase> input have <phrase>more than</phrase> 50 probabilities of being judged as a real human sequence. we will release all the code used in <phrase>this paper</phrase> to github.
report dynamic eye movement matching and visualization tool in neuro gesture
in the research of the impact of gestures using by a lecturer one <phrase>challenging task</phrase> is to infer the attention of a group of audiences. two important measurements that can help infer the level of attention are eye movement data and electroencephalography eeg data. under the fundamental assumption that a group of people would look at <phrase>the same</phrase> place if they all pay attention at <phrase>the same</phrase> time we apply a method time warp edit distance to calculate the similarity of their eye movement trajectories. moreover we also cluster eye movement pattern of audiences <phrase>based on</phrase> these pair wised similarity metrics. besides since we don t have a direct metric for the attention ground truth a visual assessment would be beneficial to evaluate the gesture attention relationship. thus we also implement a visualization tool.
nature vs. nurture <phrase>the role of</phrase> environmental resources in evolutionary deep intelligence
evolutionary deep intelligence synthesizes highly efficient <phrase>deep neural networks</phrase> architectures over successive generations. <phrase>inspired by</phrase> the <phrase>nature versus nurture</phrase> debate we propose a study to examine <phrase>the role of</phrase> external factors on <phrase>the network</phrase> synthesis process by varying the availability of simulated environmental resources. <phrase>experimental results</phrase> were obtained for networks synthesized via asexual evolutionary synthesis 1 parent and sexual evolutionary synthesis 2 parent 3 parent and 5 parent using <phrase>a 10</phrase> <phrase>subset of</phrase> the mnist dataset. <phrase>results show</phrase> that a lower environmental factor model resulted in a more gradual loss in performance accuracy and <phrase>decrease in</phrase> storage size. this potentially allows significantly reduced storage size <phrase>with minimal</phrase> to no drop in performance accuracy and <phrase>the best</phrase> networks were synthesized using the lowest environmental factor models.
a stochastic model of human visual attention with a dynamic <phrase>bayesian network</phrase>
recent studies in <phrase>the field of</phrase> human <phrase>vision science</phrase> suggest that the human responses to the stimuli on a visual display are non deterministic. people may attend to different locations on <phrase>the same</phrase> visual input at <phrase>the same</phrase> time. <phrase>based on</phrase> this knowledge we propose <phrase>a new</phrase> stochastic model of visual attention <phrase>by introducing</phrase> a dynamic <phrase>bayesian network</phrase> <phrase>to predict</phrase> the likelihood of where humans typically <phrase>focus on</phrase> a video scene. <phrase>the proposed</phrase> model is <phrase>composed of</phrase> a dynamic <phrase>bayesian network</phrase> with 4 layers. our model provides a framework that simulates and combines the visual saliency response and the cognitive <phrase>state of</phrase> a person to estimate the most probable attended regions. sample based inference with <phrase>markov chain</phrase> <phrase>monte carlo</phrase> based <phrase>particle filter</phrase> and <phrase>stream processing</phrase> with <phrase>multi core</phrase> processors enable us to estimate human visual attention in near <phrase>real time</phrase>. <phrase>experimental results</phrase> have demonstrated that our model performs significantly better in predicting human visual attention <phrase>compared to</phrase> the previous deterministic models.
smart content recognition from images using a mixture of <phrase>convolutional neural networks</phrase>
with rapid development of the internet web contents become huge. most of the websites are <phrase>publicly available</phrase> and anyone can access the contents from anywhere <phrase>such as</phrase> workplace home and even schools. nevertheless not all the web contents are appropriate for all users especially children. an example of these contents is pornography images which should be restricted to certain age group. besides these images are not safe for work nsfw in which employees should not be seen accessing such contents during work. recently <phrase>convolutional neural networks</phrase> have been successfully <phrase>applied to</phrase> many <phrase>computer vision</phrase> problems. <phrase>inspired by</phrase> these successes we propose a mixture of <phrase>convolutional neural networks</phrase> for adult content recognition. unlike other works our method is formulated on a weighted sum of multiple <phrase>deep neural network</phrase> models. the weights of each cnn models are expressed as a <phrase>linear regression</phrase> problem learned using ordinary least squares ols . <phrase>experimental results</phrase> demonstrate that <phrase>the proposed model</phrase> outperforms both single cnn model and the average sum of cnn models in adult content recognition.
cortical spatio temporal <phrase>dimensionality reduction</phrase> for visual grouping
the visual systems of many mammals including humans is <phrase>able to</phrase> integrate the geometric information of visual stimuli and <phrase>to perform</phrase> cognitive tasks already at the first stages of the cortical processing. this is thought to be the result of a <phrase>combination of</phrase> mechanisms which include <phrase>feature extraction</phrase> at single cell level and geometric processing by means of cells connectivity. we present a geometric model of such connectivities in the space of detected features associated to spatio temporal visual stimuli and show how they can be used <phrase>to obtain</phrase> low level object segmentation. the main idea is that of defining a <phrase>spectral clustering</phrase> procedure with anisotropic affinities over datasets <phrase>consisting of</phrase> embeddings of the visual stimuli into higher dimensional spaces. neural plausibility of <phrase>the proposed</phrase> arguments will be discussed.
visual sentiment prediction with <phrase>deep convolutional neural networks</phrase>
images have become one of the most popular <phrase>types of</phrase> media through which users convey their emotions within online <phrase>social networks</phrase>. although vast <phrase>amount of</phrase> research is devoted to <phrase>sentiment analysis</phrase> of textual data there has been very limited work that <phrase>focuses on</phrase> analyzing sentiment of image data. in <phrase>this work</phrase> we propose <phrase>a novel</phrase> visual sentiment prediction framework that performs image understanding with <phrase>deep convolutional neural networks</phrase> cnn . specifically <phrase>the proposed</phrase> sentiment prediction framework performs <phrase>transfer learning</phrase> from a cnn with millions of parameters which is <phrase>pre trained</phrase> on <phrase>large scale</phrase> data for <phrase>object recognition</phrase>. experiments conducted on two <phrase>real world</phrase> datasets from twitter and tumblr demonstrate <phrase>the effectiveness of</phrase> <phrase>the proposed</phrase> visual <phrase>sentiment analysis</phrase> framework.
correntropy maximization via admm <phrase>application to</phrase> robust hyperspectral unmixing
in hyperspectral images some spectral bands <phrase>suffer from</phrase> low <phrase>signal to noise ratio</phrase> <phrase>due to</phrase> noisy acquisition and atmospheric effects thus requiring robust techniques for the unmixing problem. <phrase>this paper</phrase> presents a robust supervised spectral unmixing approach for hyperspectral images. the robustness is <phrase>achieved by</phrase> writing the unmixing problem as the maximization of the correntropy criterion subject to the most commonly used constraints. two unmixing problems are derived the first problem considers the fully constrained unmixing with both the non negativity and sum to one constraints while the second one deals with the non negativity and the sparsity promoting of the abundances. the corresponding optimization problems are solved efficiently using an alternating direction method of multipliers admm approach. <phrase>experiments on</phrase> synthetic and real hyperspectral images validate <phrase>the performance of</phrase> <phrase>the proposed</phrase> algorithms for different scenarios demonstrating that the correntropy based unmixing is robust to outlier bands.
identifying individual facial expressions by deconstructing <phrase>a neural network</phrase>
<phrase>this paper</phrase> <phrase>focuses on</phrase> <phrase>the problem of</phrase> explaining predictions of psychological attributes <phrase>such as</phrase> attractiveness happiness confidence and intelligence from face photographs using <phrase>deep neural networks</phrase>. since psychological attribute datasets typically <phrase>suffer from</phrase> small sample sizes we apply <phrase>transfer learning</phrase> with two base models to avoid overfitting. <phrase>these models</phrase> were <phrase>trained on</phrase> an age and gender prediction task respectively. using <phrase>a novel</phrase> explanation method we extract heatmaps that highlight the <phrase>parts of</phrase> the image most responsible for the prediction. we further observe that the explanation method provides important insights into the nature of features of the base model which allow one to assess the aptitude of the base model for a given <phrase>transfer learning</phrase> task. finally we observe that the multiclass model is more feature rich than its binary counterpart. the experimental evaluation is performed on the 2222 images from the 10k us faces dataset containing psychological attribute labels <phrase>as well as</phrase> on <phrase>a subset of</phrase> kdef images.
object boundary detection and classification with image level labels
semantic boundary and <phrase>edge detection</phrase> aims at simultaneously detecting object edge pixels in images and assigning class labels to them. systematic training of predictors for <phrase>this task</phrase> requires the labeling of edges in images which is a particularly tedious task. we propose <phrase>a novel</phrase> strategy for solving <phrase>this task</phrase> when pixel level annotations are not available performing it in an almost <phrase>zero shot</phrase> manner by relying on conventional whole image neural net classifiers that were trained using large bounding boxes. our method performs the following two steps at <phrase>test time</phrase>. firstly it predicts the class labels by applying the trained whole image network to the test images. secondly it computes pixel wise scores from the obtained predictions by applying backprop gradients <phrase>as well as</phrase> recent visualization algorithms <phrase>such as</phrase> deconvolution and <phrase>layer wise</phrase> relevance propagation. we show that high pixel wise scores are indicative for the location of semantic boundaries which suggests that the semantic boundary problem can be approached without using edge labels during the training phase.
evolving spatially aggregated features from <phrase>satellite imagery</phrase> for regional modeling
<phrase>satellite imagery</phrase> and <phrase>remote sensing</phrase> provide explanatory variables at relatively high resolutions for modeling geospatial phenomena yet regional summaries are often desirable for analysis and actionable insight. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> method of inducing spatial aggregations as a component of the <phrase>machine learning</phrase> process yielding regional model features whose construction is driven by model prediction performance <phrase>rather than</phrase> prior assumptions. our <phrase>results demonstrate</phrase> that <phrase>genetic programming</phrase> is particularly well suited to this <phrase>type of</phrase> feature construction because it can automatically synthesize appropriate aggregations <phrase>as well as</phrase> better incorporate them into predictive models <phrase>compared to</phrase> other regression methods we tested. in our experiments we consider a specific problem instance and <phrase>real world</phrase> dataset relevant to predicting snow properties in high mountain asia.
pillar networks distributed non parametric deep and wide networks
in <phrase>recent work</phrase> it was shown that combining multi kernel based <phrase>support vector machines</phrase> svms can <phrase>lead to</phrase> near <phrase>state of</phrase> <phrase>the art performance on</phrase> an action recognition dataset hmdb 51 dataset . this was 0.4 lower than frameworks that used <phrase>hand crafted</phrase> features <phrase>in addition</phrase> to the <phrase>deep convolutional</phrase> feature extractors. in the present work we show that combining distributed gaussian processes with multi stream <phrase>deep convolutional neural networks</phrase> cnn alleviate the <phrase>need to</phrase> augment <phrase>a neural network</phrase> with <phrase>hand crafted</phrase> features. <phrase>in contrast to</phrase> prior work we treat each <phrase>deep neural</phrase> convolutional network as an expert wherein the individual predictions and their respective uncertainties are combined into a product of experts poe framework.
market based <phrase>reinforcement learning</phrase> in <phrase>partially observable</phrase> worlds
unlike traditional <phrase>reinforcement learning</phrase> rl market based rl is in principle <phrase>applicable to</phrase> worlds described by <phrase>partially observable</phrase> markov decision processes pomdps where <phrase>an agent</phrase> <phrase>needs to</phrase> learn <phrase>short term</phrase> memories of relevant previous events <phrase>in order to</phrase> execute optimal actions. most <phrase>previous work</phrase> however has <phrase>focused on</phrase> reactive settings mdps <phrase>instead of</phrase> pomdps. here we reimplement a recent <phrase>approach to</phrase> market based rl and for the first time evaluate it in a toy pomdp setting.
controlled hierarchical filtering model of neocortical sensory processing
a model of sensory <phrase>information processing</phrase> is presented. <phrase>the model</phrase> assumes that learning of internal hidden <phrase>generative models</phrase> which can predict the future and evaluate the precision of that prediction is of central importance for <phrase>information extraction</phrase>. furthermore <phrase>the model</phrase> makes a bridge to <phrase>goal oriented</phrase> systems and builds upon the structural similarity between the architecture of a robust controller and that of the hippocampal entorhinal loop. this generative control architecture is mapped to the neocortex and to the hippocampal entorhinal loop. <phrase>implicit memory</phrase> phenomena priming and prototype learning are emerging features of <phrase>the model</phrase>. mathematical theorems ensure stability and attractive learning <phrase>properties of</phrase> the architecture. connections to <phrase>reinforcement learning</phrase> are also established both the control network and <phrase>the network</phrase> with a hidden model converge to near optimal policy under suitable conditions. falsifying predictions including <phrase>the role of</phrase> the feedback connections between neocortical areas are made.
when do differences matter <phrase>on line</phrase> <phrase>feature extraction</phrase> through cognitive economy
for an <phrase>intelligent agent</phrase> to be truly autonomous it must be <phrase>able to</phrase> adapt its representation to the requirements of its task as it interacts with the world. most current approaches to <phrase>on line</phrase> <phrase>feature extraction</phrase> are <phrase>ad hoc</phrase> <phrase>in contrast</phrase> <phrase>this paper</phrase> presents an algorithm that bases judgments of state compatibility and <phrase>state space</phrase> abstraction on principled criteria <phrase>derived from</phrase> the psychological principle of cognitive economy. the algorithm incorporates an active form of q learning and partitions continuous state spaces by merging and splitting voronoi regions. the experiments illustrate <phrase>a new</phrase> methodology for testing and comparing representations by means of learning curves. results from the puck on a hill task demonstrate the algorithm s <phrase>ability to</phrase> learn effective representations superior to those <phrase>produced by</phrase> some other <phrase>well known</phrase> methods.
applying policy iteration for training <phrase>recurrent neural networks</phrase>
<phrase>recurrent neural networks</phrase> are often used for learning <phrase>time series</phrase> data. <phrase>based on</phrase> a few assumptions we model this learning task as a minimization problem of a nonlinear least squares cost function. the special structure of the cost function allows us to build a connection to <phrase>reinforcement learning</phrase>. we exploit this connection and derive a convergent policy iteration based algorithm. furthermore we argue that rnn training can be fit naturally into the <phrase>reinforcement learning</phrase> framework.
<phrase>a neural network</phrase> technique <phrase>to learn</phrase> concepts from electroencephalograms
<phrase>a new</phrase> technique is presented developed <phrase>to learn</phrase> <phrase>multi class</phrase> concepts from clinical electroencephalograms. a desired concept is represented as a neuronal computational model <phrase>consisting of</phrase> <phrase>the input</phrase> hidden and output neurons. in this model the hidden neurons learn independently to classify the electroencephalogram segments presented by spectral and statistical features. this technique has been <phrase>applied to</phrase> the electroencephalogram data recorded from 65 sleeping healthy newborns <phrase>in order to</phrase> learn a brain maturation concept of newborns aged between 35 and 51 weeks. the 39399 and 19670 segments from these data have been used for learning and testing the concept respectively. as a result the concept has correctly classified 80.1 of the testing segments or 87.7 of the 65 records.
empirical learning aided by weak <phrase>domain knowledge</phrase> in the form of feature importance
standard hybrid learners that use <phrase>domain knowledge</phrase> require stronger knowledge that is hard and expensive to acquire. however weaker <phrase>domain knowledge</phrase> can benefit from <phrase>prior knowledge</phrase> while being cost effective. weak knowledge in the form of feature relative importance fri is presented and explained. feature relative importance is a <phrase>real valued</phrase> approximation of a feature s importance provided by experts. <phrase>advantage of</phrase> using this knowledge is demonstrated by iann a modified multilayer <phrase>neural network</phrase> algorithm. iann is a very simple modification of standard <phrase>neural network</phrase> algorithm but attains significant performance gains. <phrase>experimental results</phrase> in <phrase>the field of</phrase> <phrase>molecular biology</phrase> show higher performance over other empirical <phrase>learning algorithms</phrase> including standard backpropagation and <phrase>support vector machines</phrase>. iann performance is even <phrase>comparable to</phrase> a theory refinement system kbann that uses stronger <phrase>domain knowledge</phrase>. this shows feature relative importance can <phrase>improve performance</phrase> of existing empirical <phrase>learning algorithms</phrase> significantly <phrase>with minimal</phrase> effort.
<phrase>evolutionary algorithms</phrase> for <phrase>reinforcement learning</phrase>
there are two distinct approaches to solving <phrase>reinforcement learning</phrase> problems namely searching in <phrase>value function</phrase> space and searching in policy space. temporal difference methods and <phrase>evolutionary algorithms</phrase> are <phrase>well known</phrase> examples of <phrase>these approaches</phrase>. kaelbling littman and moore recently provided an informative survey of temporal difference methods. this article <phrase>focuses on</phrase> the <phrase>application of</phrase> <phrase>evolutionary algorithms</phrase> to the <phrase>reinforcement learning</phrase> problem emphasizing alternative policy representations credit assignment methods and problem specific genetic operators. strengths and weaknesses of the evolutionary <phrase>approach to</phrase> <phrase>reinforcement learning</phrase> are presented <phrase>along with</phrase> a survey of representative applications.
on training deep <phrase>boltzmann machines</phrase>
the deep boltzmann machine dbm has been <phrase>an important</phrase> development in the quest for powerful deep probabilistic models. <phrase>to date</phrase> simultaneous or joint training of all layers of the dbm has been largely unsuccessful with existing training methods. we introduce <phrase>a simple</phrase> regularization scheme that encourages the weight vectors <phrase>associated with</phrase> each hidden unit to have similar norms. we demonstrate that this regularization can be easily <phrase>combined with</phrase> standard stochastic <phrase>maximum likelihood</phrase> to yield <phrase>an effective</phrase> training strategy for the simultaneous training of all layers of the deep boltzmann machine.
memristive fuzzy edge detector
fuzzy inference systems always <phrase>suffer from</phrase> <phrase>the lack of</phrase> efficient structures or platforms for their hardware implementation. in <phrase>this paper</phrase> we tried <phrase>to overcome</phrase> <phrase>this problem</phrase> by proposing new <phrase>method for</phrase> the implementation of those fuzzy inference systems which use fuzzy rule base to make inference. to achieve this goal we have designed a <phrase>multi layer</phrase> neuro fuzzy computing system <phrase>based on</phrase> the memristor crossbar structure <phrase>by introducing</phrase> some new concepts like fuzzy minterms. although <phrase>many applications</phrase> can be realized through <phrase>the use of</phrase> our proposed system in <phrase>this study</phrase> we show how the fuzzy xor function can be constructed and how it can be used <phrase>to extract</phrase> edges from grayscale images. our memristive fuzzy edge detector implemented in analog form <phrase>compared with</phrase> other common edge detectors has this advantage that it can extract edges of any given image all at once in <phrase>real time</phrase>.
echo state queueing network <phrase>a new</phrase> reservoir computing learning tool
in the last decade <phrase>a new</phrase> computational paradigm was introduced in <phrase>the field of</phrase> <phrase>machine learning</phrase> under the name of reservoir computing rc . rc models are <phrase>neural networks</phrase> which a recurrent part the reservoir that <phrase>does not</phrase> participate in the learning process and the rest of the system where no recurrence no neural circuit occurs. <phrase>this approach</phrase> has grown rapidly <phrase>due to</phrase> its success in solving <phrase>learning tasks</phrase> and other computational applications. some success was also observed with another <phrase>recently proposed</phrase> <phrase>neural network</phrase> designed using <phrase>queueing theory</phrase> the random <phrase>neural network</phrase> randnn . both approaches have good properties and identified drawbacks. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> rc model called echo state queueing network esqn where we use ideas coming from randnns for the design of the reservoir. esqns consist in esns where the reservoir has <phrase>a new</phrase> dynamics <phrase>inspired by</phrase> recurrent randnns. the paper positions esqns in the global <phrase>machine learning</phrase> area and provides examples of their use and performances. we show on largely used benchmarks that esqns are very accurate tools and we illustrate how they compare with standard esns.
the predictron <phrase>end to end</phrase> learning and planning
one of the key challenges of <phrase>artificial intelligence</phrase> is <phrase>to learn</phrase> models that are effective in <phrase>the context of</phrase> planning. in this document we introduce the predictron architecture. the predictron <phrase>consists of</phrase> a fully abstract model represented by a markov reward process that can be rolled forward multiple imagined planning steps. each <phrase>forward pass</phrase> of the predictron accumulates internal rewards and values over multiple planning depths. the predictron is <phrase>trained end to end</phrase> so as to make these accumulated values accurately approximate the true <phrase>value function</phrase>. we applied the predictron to procedurally generated random mazes and a simulator for the game of pool. the predictron yielded significantly <phrase>more accurate</phrase> predictions than conventional <phrase>deep neural network</phrase> architectures.
quadratically constrained <phrase>quadratic programming</phrase> for classification using particle swarms and applications
<phrase>particle swarm optimization</phrase> is used in several <phrase>combinatorial optimization</phrase> problems. in <phrase>this work</phrase> particle swarms are used <phrase>to solve</phrase> <phrase>quadratic programming</phrase> problems with quadratic constraints. the approach of particle swarms is an example for interior point methods in optimization as an iterative technique. <phrase>this approach</phrase> is novel and deals with <phrase>classification problems</phrase> without <phrase>the use of</phrase> a traditional classifier. our method determines the optimal hyperplane or classification boundary for a <phrase>data set</phrase>. in a <phrase>binary classification</phrase> problem we constrain each class as a cluster which is enclosed by an ellipsoid. the estimation of the optimal hyperplane between the two clusters is posed as a quadratically constrained quadratic problem. the <phrase>optimization problem</phrase> is solved in distributed format using modified particle swarms. our method has the <phrase>advantage of</phrase> using the direction towards optimal solution <phrase>rather than</phrase> searching the entire feasible region. our <phrase>results on</phrase> the iris pima wine and thyroid datasets show that <phrase>the proposed</phrase> method works <phrase>better than</phrase> <phrase>a neural network</phrase> and the performance is <phrase>close to</phrase> that of svm.
learning to execute
<phrase>recurrent neural networks</phrase> rnns with <phrase>long short term memory</phrase> units lstm are <phrase>widely used</phrase> because they are expressive and are <phrase>easy to</phrase> train. our interest lies in empirically evaluating the expressiveness and the learnability of lstms in the <phrase>sequence to sequence</phrase> regime by training them to evaluate short computer programs a domain that has traditionally been seen as too complex for <phrase>neural networks</phrase>. we consider <phrase>a simple</phrase> class of programs that can be evaluated with <phrase>a single</phrase> left to right pass using constant memory. our main result is that lstms can learn to map the <phrase>character level</phrase> representations of such programs to their correct outputs. notably it was necessary to use <phrase>curriculum learning</phrase> and while conventional <phrase>curriculum learning</phrase> proved ineffective we developed <phrase>a new</phrase> variant of <phrase>curriculum learning</phrase> that improved our networks performance in all experimental conditions. the improved curriculum had a dramatic impact on an addition problem making it possible <phrase>to train</phrase> an lstm to add two 9 digit numbers with 99 accuracy.
bitwise <phrase>neural networks</phrase>
<phrase>based on</phrase> the assumption that there exists <phrase>a neural network</phrase> that efficiently represents <phrase>a set of</phrase> boolean functions between all binary inputs and outputs we propose a process for developing and deploying <phrase>neural networks</phrase> whose weight parameters bias terms input and intermediate <phrase>hidden layer</phrase> output signals are all binary valued and require only basic bit logic for the feedforward pass. <phrase>the proposed</phrase> bitwise <phrase>neural network</phrase> bnn is especially <phrase>suitable for</phrase> resource constrained environments since it replaces either floating or <phrase>fixed point arithmetic</phrase> with significantly <phrase>more efficient</phrase> bitwise operations. hence the bnn requires for less spatial complexity less memory bandwidth and less power consumption in hardware. <phrase>in order to</phrase> design such networks we propose to add a few training schemes <phrase>such as</phrase> weight compression and noisy backpropagation which result in a bitwise network that performs almost <phrase>as well as</phrase> its corresponding <phrase>real valued</phrase> network. we test <phrase>the proposed</phrase> network on the mnist dataset represented using binary features and show that bnns result in competitive performance while offering dramatic computational savings.
graying the <phrase>black box</phrase> understanding dqns
<phrase>in recent years</phrase> there is a growing interest in using deep representations for <phrase>reinforcement learning</phrase>. in <phrase>this paper</phrase> we present a methodology and tools to analyze <phrase>deep q</phrase> networks dqns in a non blind matter. moreover we propose <phrase>a new</phrase> model the semi aggregated <phrase>markov decision process</phrase> samdp and an algorithm that learns it automatically. the samdp model allows us to identify spatio temporal abstractions directly from features and may be <phrase>used as</phrase> a sub goal detector in future work. using our tools we reveal that the features learned by dqns aggregate the <phrase>state space</phrase> in a hierarchical fashion explaining its success. moreover we are <phrase>able to</phrase> understand and describe the policies learned by dqns for <phrase>three different</phrase> atari2600 games and suggest ways to interpret debug and optimize <phrase>deep neural networks</phrase> in <phrase>reinforcement learning</phrase>.
evaluation of a tree based pipeline optimization tool for automating <phrase>data science</phrase>
as <phrase>the field of</phrase> <phrase>data science</phrase> continues to grow there will be an ever increasing demand for tools that make <phrase>machine learning</phrase> accessible to non experts. in <phrase>this paper</phrase> we introduce the concept of tree based pipeline optimization for automating one of the most tedious <phrase>parts of</phrase> <phrase>machine learning</phrase> pipeline design. we implement an <phrase>open source</phrase> tree based pipeline optimization tool tpot in python and demonstrate its effectiveness on <phrase>a series of</phrase> simulated and <phrase>real world</phrase> benchmark <phrase>data sets</phrase>. <phrase>in particular</phrase> we show that tpot can design <phrase>machine learning</phrase> pipelines that provide a <phrase>significant improvement</phrase> over a basic <phrase>machine learning</phrase> analysis while requiring little to no input nor <phrase>prior knowledge</phrase> from the user. we also address the tendency for tpot to design overly complex pipelines by integrating pareto optimization which produces compact pipelines without sacrificing <phrase>classification accuracy</phrase>. as such <phrase>this work</phrase> represents <phrase>an important</phrase> step toward fully automating <phrase>machine learning</phrase> pipeline design.
probabilistic reasoning via <phrase>deep learning</phrase> neural association models
in <phrase>this paper</phrase> we propose <phrase>a new</phrase> <phrase>deep learning</phrase> approach called neural association model nam for probabilistic reasoning in <phrase>artificial intelligence</phrase>. we propose to use <phrase>neural networks</phrase> to model association between any two events in a domain. <phrase>neural networks</phrase> take one event as input and compute a <phrase>conditional probability</phrase> of the other event to model how likely these two events are to be associated. the actual meaning of the conditional probabilities varies between applications and <phrase>depends on</phrase> how the models are trained. in <phrase>this work</phrase> as two case studies we have investigated two nam structures namely <phrase>deep neural networks</phrase> dnn and relation modulated neural nets rmnn on several probabilistic reasoning tasks in ai including recognizing <phrase>textual entailment</phrase> triple classification in multi relational knowledge bases and commonsense reasoning. <phrase>experimental results</phrase> on several popular datasets <phrase>derived from</phrase> wordnet freebase and conceptnet have all demonstrated that both dnns and rmnns perform equally well and they can <phrase>significantly outperform</phrase> the conventional methods available for these reasoning tasks. moreover <phrase>compared with</phrase> dnns rmnns are superior in <phrase>knowledge transfer</phrase> where a <phrase>pre trained</phrase> model can be quickly extended to an unseen relation after observing only a few <phrase>training samples</phrase>. to further prove <phrase>the effectiveness of</phrase> <phrase>the proposed</phrase> models in <phrase>this work</phrase> we have applied nams to solving challenging winograd schema ws problems. experiments conducted on <phrase>a set of</phrase> ws problems prove that <phrase>the proposed</phrase> models have the potential for commonsense reasoning.
<phrase>deep reinforcement learning</phrase> with macro actions
<phrase>deep reinforcement learning</phrase> has been <phrase>shown to</phrase> be a powerful <phrase>framework for</phrase> learning policies from complex <phrase>high dimensional</phrase> sensory inputs to actions in complex <phrase>tasks such as</phrase> the atari domain. in <phrase>this paper</phrase> we explore output representation modeling in the form of temporal abstraction <phrase>to improve</phrase> convergence and reliability of <phrase>deep reinforcement learning</phrase> approaches. we concentrate on macro actions and evaluate these on different <phrase>atari 2600</phrase> games where we show that they yield <phrase>significant improvements</phrase> in learning speed. additionally we show that they can even achieve better scores than dqn. we offer analysis and explanation for both convergence and final results revealing a problem deep rl approaches have with sparse reward signals.
retain an interpretable predictive model for healthcare using reverse time <phrase>attention mechanism</phrase>
accuracy and interpretability are two dominant features of successful predictive models. typically a choice must be made in favor of complex <phrase>black box</phrase> models <phrase>such as</phrase> <phrase>recurrent neural networks</phrase> rnn for accuracy versus less accurate but more interpretable traditional models <phrase>such as</phrase> <phrase>logistic regression</phrase>. this tradeoff poses challenges in medicine where both accuracy and interpretability are important. we addressed this challenge by developing the reverse time <phrase>attention model</phrase> retain for <phrase>application to</phrase> <phrase>electronic health records</phrase> ehr data. retain achieves high accuracy while remaining clinically interpretable and is <phrase>based on</phrase> a two level neural <phrase>attention model</phrase> that detects influential past visits and significant clinical variables within those visits e.g. key diagnoses . retain mimics physician practice by attending the ehr data in a reverse time order so that recent clinical visits are likely to receive higher attention. retain was <phrase>tested on</phrase> <phrase>a large</phrase> health system ehr dataset with 14 million visits completed by 263k patients over an 8 year period and demonstrated predictive accuracy and computational scalability <phrase>comparable to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> methods <phrase>such as</phrase> rnn and ease of interpretability <phrase>comparable to</phrase> traditional models.
a high speed <phrase>multi label</phrase> classifier <phrase>based on</phrase> <phrase>extreme learning</phrase> machines
in <phrase>this paper</phrase> a high speed <phrase>neural network</phrase> classifier <phrase>based on</phrase> <phrase>extreme learning</phrase> machines <phrase>for multi label</phrase> classification problem is proposed and dis cussed. <phrase>multi label classification</phrase> is a superset of traditional binary and <phrase>multi class</phrase> <phrase>classification problems</phrase>. <phrase>the proposed</phrase> work extends the <phrase>extreme learning</phrase> machine technique to adapt to the <phrase>multi label</phrase> problems. as opposed to the single label problem both <phrase>the number of</phrase> labels the sample belongs to and each of those target labels are to be identified <phrase>for multi label</phrase> classification resulting in in creased complexity. <phrase>the proposed</phrase> high speed <phrase>multi label</phrase> classifier is <phrase>applied to</phrase> six <phrase>benchmark datasets</phrase> comprising of different application areas <phrase>such as</phrase> multi media text and biology. the training time and testing time of the classifier are <phrase>compared with</phrase> those of the <phrase>state of</phrase> the arts methods. experimental studies show that for all the six datasets our proposed technique have faster execution speed and <phrase>better performance</phrase> thereby outperforming all the existing <phrase>multi label</phrase> clas sification methods.
an online universal classifier for binary <phrase>multi class</phrase> and <phrase>multi label classification</phrase>
classification involves the learning of the mapping function that associates input samples to corresponding target label. there are two major categories of <phrase>classification problems</phrase> single <phrase>label classification</phrase> and <phrase>multi label classification</phrase>. traditional binary and <phrase>multi class</phrase> classifications are sub categories of single <phrase>label classification</phrase>. several classifiers are developed for binary <phrase>multi class</phrase> and <phrase>multi label classification</phrase> problems but there are no classifiers available in the literature <phrase>capable of</phrase> performing all three <phrase>types of</phrase> classification. in <phrase>this paper</phrase> <phrase>a novel</phrase> online universal classifier <phrase>capable of</phrase> performing all the three <phrase>types of</phrase> classification is proposed. being a high speed online classifier <phrase>the proposed</phrase> technique can be <phrase>applied to</phrase> streaming data applications. <phrase>the performance of</phrase> the developed classifier is evaluated using datasets from binary <phrase>multi class</phrase> and <phrase>multi label</phrase> problems. the results obtained are <phrase>compared with</phrase> <phrase>state of</phrase> <phrase>the art</phrase> techniques from each of the classification types.
adaptive online sequential elm for concept drift tackling
a <phrase>machine learning</phrase> method <phrase>needs to</phrase> adapt to over time changes in the environment. such changes are <phrase>known as</phrase> concept drift. in <phrase>this paper</phrase> we propose concept drift tackling method as an enhancement of online sequential <phrase>extreme learning</phrase> machine os elm and constructive enhancement os elm ceos elm by adding adaptive capability for classification and regression problem. the scheme is named as adaptive os elm aos elm . it is <phrase>a single</phrase> classifier scheme that works well to handle real drift virtual drift and hybrid drift. the aos elm also works well for sudden drift and recurrent context change type. the scheme is <phrase>a simple</phrase> unified method implemented in simple lines of code. we evaluated aos elm on regression and classification problem <phrase>by using</phrase> concept drift public <phrase>data set</phrase> sea and stagger and other public <phrase>data sets</phrase> <phrase>such as</phrase> mnist usps and ids. <phrase>experiments show</phrase> that our method gives higher kappa value <phrase>compared to</phrase> the multiclassifier elm ensemble. even though aos elm <phrase>in practice</phrase> <phrase>does not</phrase> need hidden nodes increase we address some issues <phrase>related to</phrase> the increasing of the hidden nodes <phrase>such as</phrase> error condition and rank values. we propose taking the rank of the pseudoinverse matrix as an indicator parameter to detect underfitting condition.
adaptive convolutional elm for concept drift handling in online stream data
in <phrase>big data</phrase> era the data continuously generated and its distribution may keep changes overtime. these challenges in online stream of data are <phrase>known as</phrase> concept drift. in <phrase>this paper</phrase> we proposed the adaptive convolutional elm method acnnelm as enhancement of <phrase>convolutional neural network</phrase> cnn with a hybrid <phrase>extreme learning</phrase> machine elm model plus adaptive capability. this method is aimed for concept drift handling. we enhanced the cnn as convolutional hiererchical features representation learner <phrase>combined with</phrase> elastic elm e 2 lm as a parallel supervised classifier. we propose an adaptive os elm aos elm for concept drift adaptability in classifier level named acnnelm 1 and matrices concatenation ensembles for concept drift adaptability in ensemble level named acnnelm 2 . our proposed adaptive cnnelm is flexible that works well in classifier level and ensemble level while most current methods only proposed to work on either one of the levels. we verified our method in extended mnist <phrase>data set</phrase> and not mnist <phrase>data set</phrase>. we set the experiment to simulate virtual drift real drift and hybrid drift event and we demonstrated how our cnnelm adaptability works. our <phrase>proposed method</phrase> works well and gives better accuracy computation scalability and concept drifts adaptability <phrase>compared to</phrase> the regular elm and cnn. further researches are still required to study the optimum parameters and to use more varied image <phrase>data set</phrase>.
<phrase>particle swarm optimization</phrase> for generating interpretable fuzzy <phrase>reinforcement learning</phrase> policies
fuzzy controllers are efficient and interpretable system controllers for continuous state and action spaces. <phrase>to date</phrase> such controllers have been constructed manually or trained automatically either using expert generated problem specific cost functions or incorporating detailed knowledge about the <phrase>optimal control</phrase> strategy. both requirements for automatic training processes are not found in most <phrase>real world</phrase> <phrase>reinforcement learning</phrase> rl problems. in such applications online learning is often prohibited for safety reasons because online learning requires exploration of the problem s dynamics during policy training. we introduce a fuzzy particle swarm <phrase>reinforcement learning</phrase> fpsrl approach that can construct fuzzy rl policies solely by training parameters on world models that simulate real system dynamics. these world models are created by employing an autonomous <phrase>machine learning</phrase> technique that uses previously generated transition samples of a real system. to <phrase>the best</phrase> of our knowledge <phrase>this approach</phrase> is the first to relate self organizing fuzzy controllers to <phrase>model based</phrase> batch rl. therefore fpsrl is intended <phrase>to solve</phrase> problems in domains where online learning is prohibited system dynamics are relatively <phrase>easy to</phrase> model from previously generated default policy transition samples and it is expected that a relatively easily interpretable control policy exists. the efficiency of <phrase>the proposed</phrase> approach with problems from such domains is demonstrated using three standard rl benchmarks i.e. mountain car cart pole balancing and cart pole swing up. our <phrase>experimental results</phrase> demonstrate high performing interpretable fuzzy policies.
a growing <phrase>long term</phrase> episodic <phrase>semantic memory</phrase>
the <phrase>long term memory</phrase> of most connectionist systems lies entirely in the weights of the system. since <phrase>the number of</phrase> weights is typically fixed this bounds the total <phrase>amount of</phrase> knowledge that can be learned and stored. though this is not normally a problem for <phrase>a neural network</phrase> designed for a specific task such a bound is undesirable for a system that continually learns over an <phrase>open range</phrase> of domains. <phrase>to address</phrase> this we describe a <phrase>lifelong learning</phrase> system that leverages a fast though non differentiable <phrase>content addressable memory</phrase> which can be exploited to encode both a long history of sequential episodic knowledge and semantic knowledge over many episodes for an unbounded <phrase>number of</phrase> domains. this opens the door for investigation into <phrase>transfer learning</phrase> and leveraging <phrase>prior knowledge</phrase> that has been learned over a lifetime of experiences to new domains.
cognitive discriminative mappings for rapid learning
humans can learn concepts or recognize items from just a handful of examples while machines require many more samples <phrase>to perform</phrase> <phrase>the same</phrase> task. in <phrase>this paper</phrase> we build a computational model to investigate the possibility of this <phrase>kind of</phrase> rapid learning. <phrase>the proposed</phrase> method aims <phrase>to improve</phrase> the learning task of input from sensory memory by leveraging the information retrieved from <phrase>long term memory</phrase>. we present <phrase>a simple</phrase> and intuitive technique called cognitive discriminative mappings cdm to explore the cognitive problem. first cdm separates and clusters the data instances retrieved from <phrase>long term memory</phrase> into distinct classes with a discrimination method in <phrase>working memory</phrase> when a sensory input triggers the algorithm. cdm then maps each sensory data instance to be as close as possible to the median point of the data group with <phrase>the same</phrase> class. the <phrase>experimental results</phrase> demonstrate that the cdm approach is effective for learning the discriminative features of supervised classifications with few training sensory input instances.
towards a mathematical understanding of the difficulty in learning with feedforward <phrase>neural networks</phrase>
<phrase>training deep neural networks</phrase> for solving <phrase>machine learning</phrase> problems is one great challenge in the field mainly <phrase>due to</phrase> its associated optimisation problem being highly <phrase>non convex</phrase>. recent developments have suggested that many training algorithms <phrase>do not</phrase> <phrase>suffer from</phrase> undesired <phrase>local minima</phrase> under certain scenario and consequently led to great efforts in pursuing mathematical explanations for such observations. <phrase>this work</phrase> provides <phrase>an alternative</phrase> mathematical understanding of the challenge from a smooth optimisation perspective. by assuming exact learning of finite samples sufficient conditions are identified via a critical point analysis to ensure any local minimum to be globally minimal as well. furthermore a <phrase>state of</phrase> <phrase>the art</phrase> algorithm <phrase>known as</phrase> the generalised gauss newton ggn algorithm is rigorously revisited as an approximate newton s algorithm which shares the property of being locally quadratically convergent to a global minimum under the condition of exact learning.
<phrase>an effective</phrase> algorithm for hyperparameter optimization of <phrase>neural networks</phrase>
a major challenge in designing <phrase>neural network</phrase> nn systems is to determine <phrase>the best</phrase> structure and parameters for <phrase>the network</phrase> given the data for the <phrase>machine learning</phrase> problem at hand. examples of parameters are <phrase>the number of</phrase> layers and nodes the learning rates and the dropout rates. typically these parameters are chosen <phrase>based on</phrase> heuristic rules and manually fine tuned which may be very time consuming because evaluating <phrase>the performance of</phrase> <phrase>a single</phrase> parametrization of the nn may require several hours. <phrase>this paper</phrase> addresses <phrase>the problem of</phrase> choosing appropriate parameters for the nn by formulating it as a box constrained <phrase>mathematical optimization</phrase> problem and applying a derivative free optimization tool that automatically and effectively searches the parameter space. the optimization tool employs a <phrase>radial basis function</phrase> model of the <phrase>objective function</phrase> the prediction accuracy of the nn to accelerate the discovery of configurations yielding high accuracy. candidate configurations explored by the algorithm are trained to <phrase>a small</phrase> <phrase>number of</phrase> epochs and only the most promising candidates receive full training. <phrase>the performance of</phrase> <phrase>the proposed</phrase> methodology is assessed on benchmark sets and in <phrase>the context of</phrase> predicting drug drug interactions showing <phrase>promising results</phrase>. the optimization tool used in <phrase>this paper</phrase> is <phrase>open source</phrase>.
evolutionary training of sparse <phrase>artificial neural networks</phrase> a <phrase>network science</phrase> perspective
through the success of <phrase>deep learning</phrase> <phrase>artificial neural networks</phrase> anns are among the most used <phrase>artificial intelligence</phrase> methods nowadays. anns have led to major breakthroughs in various <phrase>domains such as</phrase> <phrase>particle physics</phrase> <phrase>reinforcement learning</phrase> <phrase>speech recognition</phrase> <phrase>computer vision</phrase> and so on. taking inspiration from <phrase>the network</phrase> <phrase>properties of</phrase> biological <phrase>neural networks</phrase> e.g. sparsity scale freeness we argue that contrary to general practice <phrase>artificial neural networks</phrase> ann too should not have fully connected layers. we show how anns perform perfectly well with sparsely connected layers. following a darwinian evolutionary approach we propose <phrase>a novel</phrase> algorithm which evolves an initial random sparse topology i.e. an erd h o s r enyi <phrase>random graph</phrase> of two consecutive layers of neurons into a scale free topology during the ann training process. the resulting sparse layers can safely replace the corresponding fully connected layers. our method allows to quadratically reduce <phrase>the number of</phrase> parameters in the fully conencted layers of anns yielding quadratically faster computational times in both phases i.e. training and inference at no <phrase>decrease in</phrase> accuracy. we demonstrate our claims on two popular ann types restricted boltzmann machine and <phrase>multi layer</phrase> perceptron on two <phrase>types of</phrase> tasks supervised and <phrase>unsupervised learning</phrase> and on 14 <phrase>benchmark datasets</phrase>. we anticipate that our approach will enable anns having billions of neurons and evolved topologies to be <phrase>capable of</phrase> handling complex <phrase>real world</phrase> tasks that are intractable using <phrase>state of</phrase> <phrase>the art</phrase> methods.
attend and predict understanding <phrase>gene regulation</phrase> by selective attention on chromatin
<phrase>the past</phrase> decade has seen a revolution in genomic technologies that enable a flood of genome wide profiling of chromatin marks. recent literature tried <phrase>to understand</phrase> <phrase>gene regulation</phrase> by predicting <phrase>gene expression</phrase> from <phrase>large scale</phrase> chromatin measurements. two fundamental challenges exist for such <phrase>learning tasks</phrase> 1 genome wide chromatin signals are spatially structured <phrase>high dimensional</phrase> and highly modular and 2 the core aim is <phrase>to understand</phrase> what are the relevant factors and how they work together previous studies either failed to model complex dependencies among input signals or relied on separate feature analysis to explain the decisions. <phrase>this paper</phrase> presents an <phrase>attention based</phrase> <phrase>deep learning</phrase> approach we call attentivechrome that uses <phrase>a unified</phrase> architecture to model and to interpret dependencies among chromatin factors for controlling <phrase>gene regulation</phrase>. attentivechrome uses a hierarchy of multiple <phrase>long short term memory lstm</phrase> modules to encode <phrase>the input</phrase> signals and to model how various chromatin marks cooperate automatically. attentivechrome trains two levels of attention jointly with the target prediction enabling it to attend differentially to relevant marks and to locate important positions per mark. we evaluate <phrase>the model</phrase> across 56 different cell types tasks in human. <phrase>not only</phrase> is <phrase>the proposed</phrase> architecture <phrase>more accurate</phrase> but its attention scores also provide a better interpretation than <phrase>state of</phrase> <phrase>the art</phrase> feature visualization methods <phrase>such as</phrase> saliency map. code and data are shared at www.deepchrome.org
parallelizing linear <phrase>recurrent neural</phrase> nets over sequence length
<phrase>recurrent neural networks</phrase> rnns are <phrase>widely used</phrase> to model sequential data but their <phrase>non linear</phrase> dependencies between sequence elements prevent parallelizing training over sequence length. we show the training of rnns with only linear sequential dependencies can be parallelized over the sequence length using the parallel scan algorithm <phrase>leading to</phrase> rapid training on long sequences even with small minibatch size. we develop a parallel linear recurrence cuda kernel and show that it can be <phrase>applied to</phrase> immediately speed up training and inference of several <phrase>state of</phrase> <phrase>the art</phrase> rnn architectures by up to 9x. we abstract <phrase>recent work</phrase> on linear rnns into <phrase>a new</phrase> framework of linear surrogate rnns and develop a linear surrogate model for the <phrase>long short term memory</phrase> unit the gilr lstm that utilizes parallel linear recurrence. we extend <phrase>sequence learning</phrase> to new extremely long sequence regimes that were previously out of reach by successfully training a gilr lstm on a synthetic sequence <phrase>classification task</phrase> with a one million timestep dependency.
<phrase>feature learning</phrase> in feature sample networks using multi objective optimization
data and <phrase>knowledge representation</phrase> are fundamental concepts in <phrase>machine learning</phrase>. the quality of the representation impacts <phrase>the performance of</phrase> the learning model directly. <phrase>feature learning</phrase> transforms or enhances raw data to structures that are effectively exploited by those models. <phrase>in recent years</phrase> several works have been using complex networks for data representation and analysis. however no <phrase>feature learning</phrase> method has been proposed for such category of techniques. here we present an unsupervised <phrase>feature learning</phrase> mechanism that works on datasets with binary features. first the dataset is mapped into a feature sample network. then a multi objective optimization process selects <phrase>a set of</phrase> new vertices <phrase>to produce</phrase> an enhanced <phrase>version of</phrase> <phrase>the network</phrase>. the new features depend on a nonlinear function of a <phrase>combination of</phrase> preexisting features. effectively the process projects <phrase>the input</phrase> data into a higher dimensional space. <phrase>to solve</phrase> the <phrase>optimization problem</phrase> we design two metaheuristics <phrase>based on</phrase> the lexicographic <phrase>genetic algorithm</phrase> and the improved strength pareto <phrase>evolutionary algorithm</phrase> spea2 . we show that the enhanced network contains more information and can be exploited <phrase>to improve</phrase> <phrase>the performance of</phrase> <phrase>machine learning</phrase> methods. the advantages and disadvantages of each optimization strategy are discussed.
<phrase>meta learning</phrase> and universality deep representations and <phrase>gradient descent</phrase> can approximate any <phrase>learning algorithm</phrase>
learning <phrase>to learn</phrase> is a powerful paradigm for enabling models <phrase>to learn</phrase> from data more effectively and efficiently. a popular <phrase>approach to</phrase> <phrase>meta learning</phrase> is <phrase>to train</phrase> a recurrent model to read in a training dataset as input and output <phrase>the parameters of</phrase> a learned model or output predictions for new test inputs. alternatively a more recent <phrase>approach to</phrase> <phrase>meta learning</phrase> aims to acquire deep representations that can be effectively fine tuned via standard <phrase>gradient descent</phrase> to new tasks. in <phrase>this paper</phrase> we consider the <phrase>meta learning</phrase> problem from the perspective of universality formalizing the <phrase>notion of</phrase> <phrase>learning algorithm</phrase> approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed <phrase>gradient descent</phrase> into the meta learner. <phrase>in particular</phrase> we <phrase>seek to</phrase> answer the following question does deep representation <phrase>combined with</phrase> standard <phrase>gradient descent</phrase> have sufficient capacity to approximate any <phrase>learning algorithm</phrase> we find that this is indeed true and further find in our experiments that <phrase>gradient based</phrase> <phrase>meta learning</phrase> consistently <phrase>leads to</phrase> learning strategies that generalize more widely <phrase>compared to</phrase> those represented by recurrent models.
hindsight policy gradients
goal conditional policies allow <phrase>reinforcement learning</phrase> agents to pursue specific goals during different episodes. <phrase>in addition</phrase> to their potential to generalize desired behavior to unseen goals such policies may also help in defining options for arbitrary subgoals enabling <phrase>higher level</phrase> planning. while trying to achieve a specific goal <phrase>an agent</phrase> may also be <phrase>able to</phrase> exploit <phrase>information about</phrase> the degree to which it has achieved alternative goals. <phrase>reinforcement learning</phrase> agents have only recently been endowed with such capacity for hindsight which is highly valuable in environments with sparse rewards. in <phrase>this paper</phrase> we show how hindsight can be introduced to <phrase>likelihood ratio</phrase> policy gradient methods generalizing this capacity to an entire class of highly successful algorithms. our preliminary experiments suggest that hindsight may increase the sample efficiency of policy gradient methods.
squishednets squishing squeezenet further for edge device scenarios via deep evolutionary synthesis
while <phrase>deep neural networks</phrase> have been shown <phrase>in recent years</phrase> to outperform other <phrase>machine learning</phrase> methods in <phrase>a wide range of</phrase> applications one of the biggest challenges with enabling <phrase>deep neural networks</phrase> for widespread deployment on edge devices <phrase>such as</phrase> mobile and other consumer devices is high computational and memory requirements. recently there has been greater exploration into small <phrase>deep neural network</phrase> architectures that are more <phrase>suitable for</phrase> edge devices with one of the most popular architectures being squeezenet with an incredibly small model size of 4.8mb. taking further <phrase>advantage of</phrase> the notion that <phrase>many applications</phrase> of <phrase>machine learning</phrase> on edge devices are often characterized by a low <phrase>number of</phrase> target classes <phrase>this study</phrase> explores the utility of combining architectural modifications and an evolutionary synthesis strategy for synthesizing even smaller <phrase>deep neural</phrase> architectures <phrase>based on</phrase> the more recent squeezenet v1.1 macroarchitecture for applications with fewer target classes. <phrase>in particular</phrase> architectural modifications are first made to squeezenet v1.1 to accommodate for <phrase>a 10</phrase> class imagenet 10 dataset and then an evolutionary synthesis strategy is leveraged to synthesize <phrase>more efficient</phrase> <phrase>deep neural networks</phrase> <phrase>based on</phrase> this modified macroarchitecture. the resulting squishednets possess model sizes ranging from 2.4mb to 0.95mb 5.17x smaller than squeezenet v1.1 or 253x smaller than alexnet . furthermore the squishednets are still <phrase>able to</phrase> achieve accuracies ranging from 81.2 to 77 and <phrase>able to</phrase> process at speeds of 156 images sec to as much as 256 images sec on a nvidia jetson tx1 embedded chip. these preliminary <phrase>results show</phrase> that a <phrase>combination of</phrase> architectural modifications and an evolutionary synthesis strategy can be a useful tool for producing very small <phrase>deep neural network</phrase> architectures that are well suited for edge device scenarios.
autonomous development and learning in <phrase>artificial intelligence</phrase> and robotics scaling up <phrase>deep learning</phrase> to human like learning
autonomous lifelong development and learning is a fundamental capability of humans differentiating them from current <phrase>deep learning</phrase> systems. however other branches of <phrase>artificial intelligence</phrase> have designed crucial ingredients towards autonomous learning curiosity and intrinsic motivation <phrase>social learning</phrase> and natural interaction with peers and embodiment. these mechanisms guide exploration and autonomous <phrase>choice of</phrase> goals and integrating them with <phrase>deep learning</phrase> opens stimulating perspectives. <phrase>deep learning</phrase> dl approaches made great <phrase>advances in</phrase> <phrase>artificial intelligence</phrase> but are still far away from human learning. as argued convincingly by lake <phrase>et al</phrase>. differences include human capabilities <phrase>to learn</phrase> causal models of the world from very little data leveraging compositional representations and priors like intuitive physics and psychology. however there are other fundamental differences between current dl systems and human learning <phrase>as well as</phrase> technical ingredients to fill this gap that are either superficially or not adequately discussed by lake <phrase>et al</phrase>. these fundamental mechanisms relate to autonomous development and learning. they are bound <phrase>to play</phrase> a central <phrase>role in</phrase> <phrase>artificial intelligence</phrase> in the future. current dl systems require engineers to manually specify a <phrase>task specific</phrase> <phrase>objective function</phrase> for every new task and learn through off line processing of large training databases. on the contrary humans learn autonomously open ended repertoires of skills deciding for themselves which goals to pursue or value and which skills to explore driven by intrinsic motivation curiosity and <phrase>social learning</phrase> through natural interaction with peers. such learning processes are incremental online and progressive. human <phrase>child development</phrase> involves a progressive increase of complexity in a curriculum of learning where skills are explored acquired and built on each other through particular ordering and timing. finally human learning happens in the physical world and through bodily and physical experimentation under severe constraints on energy time and computational resources. in the two last decades <phrase>the field of</phrase> developmental and cognitive robotics cangelosi and schlesinger 2015 asada <phrase>et al</phrase>. 2009 in <phrase>strong interaction</phrase> with <phrase>developmental psychology</phrase> and neuroscience has achieved significant <phrase>advances in</phrase> computational
learning from scarce experience
searching the space of policies directly for the optimal policy has been one popular <phrase>method for</phrase> solving <phrase>partially observable</phrase> <phrase>reinforcement learning</phrase> problems. typically with each change of the target policy its value is estimated from the results of following that very policy. this requires <phrase>a large number of</phrase> interactions with the environment as different polices are considered. we present a <phrase>family of</phrase> algorithms <phrase>based on</phrase> <phrase>likelihood ratio</phrase> estimation that use data gathered when executing one policy or collection of policies to estimate the value of a different policy. the algorithms combine estimation and optimization stages. the former utilizes experience to build a non parametric representation of an optimized function. <phrase>the latter</phrase> performs optimization on this estimate. we show positive empirical results and provide the sample complexity bound.
fitness inheritance in the bayesian optimization algorithm
<phrase>this paper</phrase> describes how fitness inheritance can be used to estimate fitness for a proportion of newly sampled candidate solutions in the bayesian optimization algorithm boa . <phrase>the goal of</phrase> estimating fitness for some candidate solutions is <phrase>to reduce</phrase> <phrase>the number of</phrase> fitness evaluations for problems where fitness evaluation is expensive. bayesian networks used in boa to model promising solutions and generate the new ones are extended to allow <phrase>not only</phrase> for modeling and sampling candidate solutions <phrase>but also</phrase> for estimating their fitness. the results indicate that fitness inheritance is a promising concept in boa because population sizing requirements for building appropriate models of promising solutions <phrase>lead to</phrase> good fitness estimates even if only <phrase>a small</phrase> proportion of candidate solutions is evaluated using the actual <phrase>fitness function</phrase>. this can <phrase>lead to</phrase> a reduction of <phrase>the number of</phrase> actual fitness evaluations by a factor of 30 or more.
the combined technique for detection of artifacts in clinical electroencephalograms of sleeping newborns
in <phrase>this paper</phrase> we describe <phrase>a new</phrase> method combining the polynomial <phrase>neural network</phrase> and <phrase>decision tree</phrase> techniques <phrase>in order to</phrase> derive comprehensible classification rules from clinical electroencephalograms eegs recorded from sleeping newborns. these eegs are heavily corrupted by cardiac eye movement muscle and noise artifacts and as a consequence some eeg features are irrelevant to <phrase>classification problems</phrase>. combining the polynomial network and <phrase>decision tree</phrase> techniques we discover comprehensible classification rules whilst also attempting to keep their classification error down. this technique is <phrase>shown to</phrase> outperform <phrase>a number of</phrase> commonly used <phrase>machine learning</phrase> technique <phrase>applied to</phrase> automatically recognize artifacts in the sleep eegs.
evolving classifiers methods for incremental learning
the ability of a classifier to take on new information and classes by evolving the classifier without it having to be fully retrained is <phrase>known as</phrase> incremental learning. incremental learning has been successfully <phrase>applied to</phrase> many <phrase>classification problems</phrase> where the data is changing and is not all <phrase>available at</phrase> once. in <phrase>this paper</phrase> there is a comparison between learn which is one of the most recent incremental <phrase>learning algorithms</phrase> and the new <phrase>proposed method</phrase> of incremental learning using <phrase>genetic algorithm</phrase> iluga . learn has shown good incremental learning capabilities on <phrase>benchmark datasets</phrase> on which the new iluga method has been tested. iluga has also shown good incremental learning ability using only a few classifiers and <phrase>does not</phrase> <phrase>suffer from</phrase> catastrophic forgetting. the results obtained for iluga on the <phrase>optical character recognition</phrase> ocr and wine datasets are good with an overall accuracy of 93 and 94 respectively showing <phrase>a 4</phrase> improvement over learn .mt for the difficult <phrase>multi class</phrase> ocr dataset.
automatic pattern classification by <phrase>unsupervised learning</phrase> using <phrase>dimensionality reduction</phrase> of data with mirroring <phrase>neural networks</phrase>
<phrase>this paper</phrase> proposes an <phrase>unsupervised learning</phrase> technique <phrase>by using</phrase> <phrase>multi layer</phrase> mirroring <phrase>neural network</phrase> and forgy s clustering algorithm. <phrase>multi layer</phrase> mirroring <phrase>neural network</phrase> is <phrase>a neural network</phrase> that can be trained with generalized data inputs different categories of image patterns <phrase>to perform</phrase> <phrase>non linear</phrase> <phrase>dimensionality reduction</phrase> and the resultant <phrase>low dimensional</phrase> code is used for unsupervised pattern classification using forgy s algorithm. by adapting the <phrase>non linear</phrase> <phrase>activation function</phrase> modified sigmoidal function and initializing the weights and bias terms to small random values mirroring of <phrase>the input</phrase> pattern is initiated. in training the weights and bias terms are changed in such a way that <phrase>the input</phrase> presented is reproduced at the output by back propagating the error. the mirroring <phrase>neural network</phrase> is <phrase>capable of</phrase> reducing <phrase>the input</phrase> vector to a great degree approximately 1 30th <phrase>the original</phrase> size and also <phrase>able to</phrase> reconstruct <phrase>the input</phrase> pattern at <phrase>the output layer</phrase> from this reduced code units. the feature set output of central <phrase>hidden layer</phrase> <phrase>extracted from</phrase> this network is fed to forgy s algorithm which classify <phrase>input data</phrase> patterns into distinguishable classes. in the implementation of forgy s algorithm initial seed points are selected in such a way that they are distant enough to be perfectly grouped into different categories. thus <phrase>a new</phrase> method of <phrase>unsupervised learning</phrase> is formulated and demonstrated in <phrase>this paper</phrase>. this method gave impressive results when <phrase>applied to</phrase> classification of different image patterns.
improving <phrase>the performance of</phrase> piecewise linear separation incremental algorithms for practical hardware implementations
in <phrase>this paper</phrase> we shall review the common problems <phrase>associated with</phrase> piecewise linear separation incremental algorithms. this <phrase>kind of</phrase> <phrase>neural models</phrase> yield poor performances when dealing with some <phrase>classification problems</phrase> <phrase>due to</phrase> the evolving schemes used to construct the resulting networks. so as to avoid this undesirable behavior we shall propose a modification criterion. it is based upon the definition of a function which will provide <phrase>information about</phrase> the quality of <phrase>the network</phrase> growth process during the learning phase. this function is evaluated periodically as <phrase>the network</phrase> structure evolves and will permit as we shall show through exhaustive benchmarks to considerably improve the performance measured <phrase>in terms of</phrase> network complexity and generalization capabilities offered by the networks generated by these incremental models.
<phrase>a novel</phrase> rough set reduct algorithm for medical domain <phrase>based on</phrase> bee colony optimization
<phrase>feature selection</phrase> refers to <phrase>the problem of</phrase> selecting relevant features which produce the most predictive outcome. <phrase>in particular</phrase> <phrase>feature selection</phrase> task is involved in datasets containing huge <phrase>number of</phrase> features. rough <phrase>set theory</phrase> has been one of the most successful methods used for <phrase>feature selection</phrase>. however this method is still not <phrase>able to</phrase> find optimal subsets. <phrase>this paper</phrase> proposes <phrase>a new</phrase> <phrase>feature selection</phrase> method <phrase>based on</phrase> rough <phrase>set theory</phrase> hybrid with bee colony optimization bco in an <phrase>attempt to</phrase> combat this. this proposed work is applied in the medical domain to find the minimal reducts and experimentally <phrase>compared with</phrase> the quick reduct entropy based reduct and other hybrid rough set methods <phrase>such as</phrase> <phrase>genetic algorithm</phrase> ga <phrase>ant colony</phrase> optimization aco and <phrase>particle swarm optimization</phrase> pso .
automated query learning with wikipedia and <phrase>genetic programming</phrase>
most of the existing <phrase>information retrieval</phrase> systems are <phrase>based on</phrase> bag of words model and are not equipped with common world knowledge. work has been done towards improving the efficiency of such systems <phrase>by using</phrase> intelligent algorithms <phrase>to generate</phrase> search queries however not much research has been done in the direction of incorporating human and society level knowledge in the queries. <phrase>this paper</phrase> is one of the first attempts where such information is incorporated into the search queries using wikipedia semantics. the <phrase>paper presents</phrase> an essential shift from conventional token based queries to concept based queries <phrase>leading to</phrase> an enhanced efficiency of <phrase>information retrieval</phrase> systems. to efficiently handle the automated query learning problem we propose wikipedia based evolutionary semantics wiki es framework where concept based queries are learnt using a co evolving evolutionary procedure. learning concept based queries using an intelligent evolutionary procedure yields <phrase>significant improvement</phrase> in performance which is shown through an extensive study using reuters newswire documents. comparison of <phrase>the proposed</phrase> framework is performed with other <phrase>information retrieval</phrase> systems. concept <phrase>based approach</phrase> has also been implemented on other <phrase>information retrieval</phrase> systems to justify <phrase>the effectiveness of</phrase> a transition from token based queries to concept based queries.
scaling up estimation of distribution algorithms for continuous optimization
since estimation of distribution algorithms eda were proposed many attempts have been made <phrase>to improve</phrase> edas performance in <phrase>the context of</phrase> <phrase>global optimization</phrase>. <phrase>so far</phrase> the studies or applications of multivariate probabilistic <phrase>model based</phrase> continuous edas are still restricted to rather <phrase>low dimensional</phrase> problems smaller than 100d . traditional edas have difficulties in solving higher dimensional problems because of the curse of dimensionality and their rapidly increasing <phrase>computational cost</phrase>. however scaling up continuous edas for higher dimensional optimization is still necessary which is supported by the distinctive feature of edas because a probabilistic model is explicitly estimated from the learnt model one can discover useful properties or features of the problem. besides obtaining a good solution understanding of the problem structure can be of great benefit especially for <phrase>black box</phrase> optimization. we propose <phrase>a novel</phrase> eda framework with model complexity control eda mcc to scale up edas. <phrase>by using</phrase> weakly <phrase>dependent variable</phrase> identification wi and subspace modeling sm eda mcc shows significantly <phrase>better performance</phrase> than traditional edas on <phrase>high dimensional</phrase> problems. moreover the <phrase>computational cost</phrase> and the requirement of large population sizes can be reduced in eda mcc. <phrase>in addition</phrase> to being <phrase>able to</phrase> find a good solution eda mcc can also produce a useful problem structure characterization. eda mcc is the first successful instance of multivariate <phrase>model based</phrase> edas that can be effectively applied a general class of up to 500d problems. it also outperforms some newly developed algorithms designed specifically for <phrase>large scale</phrase> optimization. <phrase>in order to</phrase> understand the strength and weakness of eda mcc we have carried out extensive computational studies of eda mcc. our results have revealed when eda mcc is likely to outperform others on what <phrase>kind of</phrase> benchmark functions.
<phrase>transfer learning</phrase> soft distance based bias and the hierarchical boa
an automated technique has recently been proposed to <phrase>transfer learning</phrase> in the hierarchical bayesian optimization algorithm hboa <phrase>based on</phrase> distance based statistics. the technique enables practitioners <phrase>to improve</phrase> hboa efficiency by collecting statistics from probabilistic models obtained in previous hboa runs and using the obtained statistics to bias future hboa runs on similar problems. the purpose of <phrase>this paper</phrase> is threefold 1 test the technique on several classes of <phrase>np complete</phrase> problems including maxsat spin glasses and minimum <phrase>vertex cover</phrase> 2 demonstrate that the technique is effective even when previous runs were done on problems of different size 3 provide <phrase>empirical evidence</phrase> that combining <phrase>transfer learning</phrase> with other efficiency enhancement techniques can often yield nearly multiplicative speedups.
discrete dynamical <phrase>genetic programming</phrase> in xcs
<phrase>a number of</phrase> representation schemes have been presented for use within learning classifier systems ranging from binary encodings to <phrase>neural networks</phrase>. <phrase>this paper</phrase> presents results from an investigation into using a discrete dynamical system representation within the xcs learning classifier system. <phrase>in particular</phrase> asynchronous random boolean networks are used <phrase>to represent</phrase> the traditional condition action production system rules. it is shown possible to use self adaptive open ended evolution to design an ensemble of such discrete <phrase>dynamical systems</phrase> within xcs <phrase>to solve</phrase> <phrase>a number of</phrase> <phrase>well known</phrase> test problems.
fuzzy dynamical <phrase>genetic programming</phrase> in xcsf
<phrase>a number of</phrase> representation schemes have been presented for use within learning classifier systems ranging from binary encodings to <phrase>neural networks</phrase> and more recently dynamical <phrase>genetic programming</phrase> dgp . <phrase>this paper</phrase> presents results from an investigation into using a fuzzy dgp representation within the xcsf learning classifier system. <phrase>in particular</phrase> asynchronous <phrase>fuzzy logic</phrase> networks are used <phrase>to represent</phrase> the traditional condition action production system rules. it is shown possible to use self adaptive open ended evolution to design an ensemble of such fuzzy <phrase>dynamical systems</phrase> within xcsf <phrase>to solve</phrase> several <phrase>well known</phrase> continuous valued test problems.
learning based procedural content generation
procedural content generation pcg has recently become one of the hottest topics in <phrase>computational intelligence</phrase> and ai game researches. among <phrase>a variety of</phrase> pcg techniques search <phrase>based approaches</phrase> overwhelmingly dominate pcg development at present. while sbpcg <phrase>leads to</phrase> <phrase>promising results</phrase> and successful applications it poses <phrase>a number of</phrase> challenges ranging from representation to evaluation of the content being generated. in <phrase>this paper</phrase> we present <phrase>an alternative</phrase> yet generic pcg framework named learning based procedure content generation lbpcg to provide potential solutions to several challenging problems in existing pcg techniques. by exploring and exploiting information gained in <phrase>game development</phrase> and public beta test via <phrase>data driven</phrase> learning our framework can generate robust content adaptable to end user or target players <phrase>on line</phrase> <phrase>with minimal</phrase> interruption to their experience. furthermore we develop enabling techniques to implement the various models required in our framework. for a proof of concept we have developed a prototype <phrase>based on</phrase> the classic <phrase>open source</phrase> <phrase>first person shooter</phrase> game quake. simulation <phrase>results suggest</phrase> that our framework is promising in generating quality content.
systematic n tuple networks for position evaluation exceeding 90 in the othello league
n tuple networks have been successfully <phrase>used as</phrase> position evaluation functions for <phrase>board games</phrase> <phrase>such as</phrase> othello or connect four. <phrase>the effectiveness of</phrase> such networks <phrase>depends on</phrase> their architecture which is determined by the placement of constituent n tuples sequences of board locations providing input to <phrase>the network</phrase>. the most popular method of placing n tuples consists in randomly generating <phrase>a small</phrase> <phrase>number of</phrase> long snake shaped board location sequences. in comparison we show that learning n tuple networks is significantly <phrase>more effective</phrase> if they involve <phrase>a large number of</phrase> systematically placed short straight n tuples. moreover we demonstrate that <phrase>in order to</phrase> obtain <phrase>the best</phrase> performance and the steepest <phrase>learning curve</phrase> for othello it is enough to use n tuples of size just 2 yielding a network <phrase>consisting of</phrase> only 288 weights. <phrase>the best</phrase> such network evolved in <phrase>this study</phrase> has been evaluated in the online othello league obtaining <phrase>the performance of</phrase> nearly 96 <phrase>more than</phrase> any other player <phrase>to date</phrase>.
towards a self organized agent based simulation model for exploration of human synaptic connections
in <phrase>this paper</phrase> the early design of our self organized agent based simulation model for exploration of synaptic connections that faithfully generates what is observed in natural situation is given. while we take inspiration from neuroscience our intent is not to create a veridical model of processes in neurodevelopmental biology nor <phrase>to represent</phrase> a real biological system. instead our goal is to design a simulation model that learns acting in <phrase>the same</phrase> way of human nervous system <phrase>by using</phrase> findings on human subjects using reflex methodologies <phrase>in order to</phrase> estimate unknown connections.
<phrase>motion planning</phrase> of an autonomous <phrase>mobile robot</phrase> using <phrase>artificial neural network</phrase>
the <phrase>paper presents</phrase> the electronic design and <phrase>motion planning</phrase> of a robot <phrase>based on</phrase> <phrase>decision making</phrase> regarding its straight motion and precise turn using <phrase>artificial neural network</phrase> ann . the ann helps in learning of robot so that it performs motion autonomously. the weights calculated are implemented in microcontroller. the performance has been tested to be excellent.
learning <phrase>bayesian network</phrase> equivalence classes with <phrase>ant colony</phrase> optimization
bayesian networks are a useful tool in the representation of uncertain knowledge. <phrase>this paper</phrase> proposes <phrase>a new</phrase> algorithm called aco e <phrase>to learn</phrase> the structure of a <phrase>bayesian network</phrase>. it does this by conducting a search through the space of equivalence classes of bayesian networks using <phrase>ant colony</phrase> optimization aco . to this end two novel extensions of traditional aco techniques are proposed and implemented. firstly multiple <phrase>types of</phrase> moves are allowed. secondly moves can be given <phrase>in terms of</phrase> indices that are not <phrase>based on</phrase> construction graph nodes. the results of testing show that aco e performs <phrase>better than</phrase> a greedy search and other <phrase>state of</phrase> <phrase>the art</phrase> and metaheuristic algorithms whilst searching in the space of equivalence classes.
probabilistic neural programs
we present probabilistic neural programs a <phrase>framework for</phrase> program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling <phrase>the use of</phrase> <phrase>deep neural networks</phrase>. probabilistic neural programs combine a computation graph for specifying <phrase>a neural network</phrase> with an operator for weighted nondeterministic choice. thus a program describes both a collection of decisions <phrase>as well as</phrase> the <phrase>neural network</phrase> architecture used to make each one. we evaluate our approach on a challenging diagram <phrase>question answering</phrase> task where probabilistic neural programs correctly execute nearly twice as many programs as a baseline model.
cognitive deep machine can train itself
<phrase>machine learning</phrase> is making substantial progress in diverse applications. the success is mostly <phrase>due to</phrase> <phrase>advances in</phrase> <phrase>deep learning</phrase>. however <phrase>deep learning</phrase> can make mistakes and its generalization abilities to new tasks are questionable. we ask when and how one can combine network outputs when i details of the observations are evaluated by learned deep components and ii facts and confirmation rules are available in <phrase>knowledge based systems</phrase>. we show that in limited contexts the required <phrase>number of</phrase> <phrase>training samples</phrase> can be low and self improvement of <phrase>pre trained</phrase> networks in more general context is possible. we argue that the <phrase>combination of</phrase> sparse outlier detection with deep components that can support each other diminish the fragility of deep methods <phrase>an important</phrase> requirement for engineering applications. we argue that <phrase>supervised learning</phrase> of labels may be fully eliminated under certain conditions a component based architecture together with a knowledge based system can train itself and provide <phrase>high quality</phrase> answers. we demonstrate these concepts on the <phrase>state farm</phrase> distracted driver detection benchmark. we argue that the view of the study panel 2016 may overestimate the requirements on years of focused research and careful unique construction for ai systems .
summary terpret a probabilistic <phrase>programming language</phrase> for program induction
we study <phrase>machine learning</phrase> formulations of inductive program synthesis that is given <phrase>input output</phrase> examples synthesize <phrase>source code</phrase> that maps inputs to corresponding outputs. our key contribution is terpret a <phrase>domain specific</phrase> language for expressing program synthesis problems. a terpret model is <phrase>composed of</phrase> a specification of a program representation and an interpreter that describes how programs map inputs to outputs. the inference task is to observe <phrase>a set of</phrase> <phrase>input output</phrase> examples and infer the underlying program. from a terpret model we automatically perform inference using four different back ends <phrase>gradient descent</phrase> thus each terpret model can be seen as defining a differentiable interpreter <phrase>linear program</phrase> lp relaxations for <phrase>graphical models</phrase> discrete satisfiability solving and the sketch program synthesis system. terpret has two main benefits. first it enables rapid exploration of <phrase>a range of</phrase> domains program representations and interpreter models. second it separates <phrase>the model</phrase> specification from the inference algorithm allowing proper comparisons between different approaches to inference. we illustrate the value of terpret by developing several interpreter models and performing an extensive empirical comparison between alternative inference algorithms on <phrase>a variety of</phrase> program models. to our knowledge this is the first work to compare <phrase>gradient based</phrase> search over program space to traditional search based alternatives. our key empirical finding is that constraint solvers dominate the <phrase>gradient descent</phrase> and lp based formulations. this is a workshop summary of a longer report at arxiv 1608.04428
learning in the machine random backpropagation and the <phrase>deep learning</phrase> channel
random backpropagation rbp is a variant of the backpropagation algorithm for training <phrase>neural networks</phrase> where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. it is remarkable both because of its effectiveness in spite of using random matrices to communicate error information and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. to better understand random backpropagation we first connect it to the notions of local learning and learning channels. through this connection we derive several alternatives to rbp including skipped rbp srpb adaptive rbp arbp sparse rbp and their combinations e.g. asrbp and analyze their <phrase>computational complexity</phrase>. we then study their behavior through simulations using the mnist and <phrase>cifar 10</phrase> bechnmark datasets. these simulations show that most of these variants work robustly almost <phrase>as well as</phrase> backpropagation and that multiplication by the derivatives of the <phrase>activation functions</phrase> is important. as a follow up we study also the low end of <phrase>the number of</phrase> bits required to communicate error information over the learning channel. we then provide partial intuitive explanations for some of the remarkable <phrase>properties of</phrase> rbp and its variations. finally we prove several mathematical results including the convergence to fixed points of linear chains of arbitrary length the convergence to fixed points of linear autoencoders with decorrelated data the <phrase>long term</phrase> <phrase>existence of</phrase> solutions for linear systems with <phrase>a single</phrase> <phrase>hidden layer</phrase> and convergence in special cases and the convergence to fixed points of <phrase>non linear</phrase> chains when the derivative of the <phrase>activation functions</phrase> is included.
highway and <phrase>residual networks</phrase> learn unrolled iterative estimation
<phrase>the past</phrase> year saw the introduction of new architectures <phrase>such as</phrase> highway networks and <phrase>residual networks</phrase> which for the first time enabled the training of feedforward networks with dozens to hundreds of layers using simple <phrase>gradient descent</phrase>. while depth of representation has been posited as a primary reason for their success there are indications that these architectures defy a popular view of <phrase>deep learning</phrase> as a hierarchical computation of increasingly abstract features at <phrase>each layer</phrase>. in this report we argue that this view is incomplete and <phrase>does not</phrase> adequately explain several recent findings. we propose <phrase>an alternative</phrase> viewpoint <phrase>based on</phrase> unrolled iterative estimation a group of successive layers iteratively refine their estimates of <phrase>the same</phrase> features <phrase>instead of</phrase> computing an entirely new representation. we demonstrate that this viewpoint directly <phrase>leads to</phrase> the construction of highway and <phrase>residual networks</phrase>. finally we provide preliminary experiments to discuss the similarities and differences between the two architectures.
<phrase>deep neural</phrase> <phrase>heart rate</phrase> variability analysis
despite of the pain and limited accuracy of blood tests for early recognition of <phrase>cardiovascular disease</phrase> they dominate risk screening and triage. on the other hand <phrase>heart rate</phrase> variability is non invasive and cheap but not considered accurate enough for clinical practice. here we tackle heart beat interval based classification with <phrase>deep learning</phrase>. we introduce <phrase>an end to end</phrase> differentiable hybrid architecture <phrase>consisting of</phrase> a layer of biological neuron models of cardiac dynamics modified fitzhugh nagumo neurons and several layers of a standard <phrase>feed forward</phrase> <phrase>neural network</phrase>. <phrase>the proposed</phrase> model is evaluated on ecgs from 474 stable at risk <phrase>coronary artery disease</phrase> patients and 1172 <phrase>chest pain</phrase> patients of an <phrase>emergency department</phrase>. we show that it can <phrase>significantly outperform</phrase> models <phrase>based on</phrase> traditional <phrase>heart rate</phrase> variability predictors <phrase>as well as</phrase> approaching or in some cases outperforming clinical blood tests based only on 60 seconds of inter beat intervals.
<phrase>a neural network</phrase> <phrase>approach to</phrase> ordinal regression
ordinal regression is <phrase>an important</phrase> <phrase>type of</phrase> learning which has <phrase>properties of</phrase> both classification and regression. here we describe <phrase>a simple</phrase> and effective <phrase>approach to</phrase> adapt a traditional <phrase>neural network</phrase> <phrase>to learn</phrase> ordinal categories. our approach is a generalization of the perceptron <phrase>method for</phrase> ordinal regression. on several <phrase>benchmark datasets</phrase> our method nnrank outperforms <phrase>a neural network</phrase> classification method. <phrase>compared with</phrase> the ordinal regression methods using gaussian processes and <phrase>support vector machines</phrase> nnrank achieves comparable performance. moreover nnrank has the advantages of traditional <phrase>neural networks</phrase> learning in both online and batch modes handling very large training datasets and making rapid predictions. these features make nnrank a useful and complementary tool for <phrase>large scale</phrase> <phrase>data processing</phrase> <phrase>tasks such as</phrase> <phrase>information retrieval</phrase> web page ranking <phrase>collaborative filtering</phrase> and protein ranking in bioinformatics.
computational model of music <phrase>sight reading</phrase> a <phrase>reinforcement learning</phrase> approach
although the music <phrase>sight reading</phrase> process has been studied from the <phrase>cognitive psychology</phrase> view points but the computational <phrase>learning methods</phrase> like the <phrase>reinforcement learning</phrase> have not yet been used to modeling of such processes. in <phrase>this paper</phrase> with regards to essential <phrase>properties of</phrase> our specific problem we consider the <phrase>value function</phrase> concept and will indicate that the optimum policy can be <phrase>obtained by</phrase> the method we offer without to be getting involved with computing of the complex value functions. also we will offer a normative behavioral model for the interaction of the agent with the musical pitch environment and <phrase>by using</phrase> a slightly different <phrase>version of</phrase> <phrase>partially observable</phrase> markov decision processes we will show that our method helps for faster learning of state action pairs in our implemented agents.
using artificial bee colony algorithm for mlp training on earthquake <phrase>time series</phrase> data prediction
nowadays computer scientists have shown the interest in the study of social insect s behaviour in <phrase>neural networks</phrase> area for solving different combinatorial and statistical problems. chief among these is the artificial bee colony abc algorithm. <phrase>this paper</phrase> investigates <phrase>the use of</phrase> abc algorithm that simulates the intelligent foraging behaviour of a <phrase>honey bee</phrase> swarm. <phrase>multilayer perceptron</phrase> mlp trained with the standard <phrase>back propagation</phrase> algorithm normally utilises computationally intensive training algorithms. one of the crucial problems with the backpropagation bp algorithm is that it can sometimes yield the networks with suboptimal weights because of the presence of many local optima in the solution space. <phrase>to overcome</phrase> abc algorithm used in <phrase>this work</phrase> <phrase>to train</phrase> mlp learning the complex behaviour of earthquake <phrase>time series</phrase> data trained by bp <phrase>the performance of</phrase> mlp abc is benchmarked against mlp training with the standard bp. the experimental result shows that mlp abc performance is <phrase>better than</phrase> mlp bp for <phrase>time series</phrase> data.
multiple chaotic central pattern generators with learning for legged locomotion and malfunction compensation
an originally chaotic system can be controlled into various periodic dynamics. when it is implemented into a legged robot s locomotion control as a <phrase>central pattern generator</phrase> cpg sophisticated gait patterns arise so that the robot can perform various walking behaviors. however such <phrase>a single</phrase> chaotic cpg controller has difficulties dealing with leg malfunction. specifically in the scenarios presented here its movement permanently deviates from the desired trajectory. <phrase>to address</phrase> <phrase>this problem</phrase> we extend the single chaotic cpg to multiple cpgs with learning. the learning mechanism is <phrase>based on</phrase> a <phrase>simulated annealing</phrase> algorithm. in a normal situation the cpgs synchronize and their dynamics are identical. with leg malfunction or disability the cpgs lose synchronization <phrase>leading to</phrase> independent dynamics. in this case the learning mechanism is <phrase>applied to</phrase> automatically adjust the remaining legs oscillation frequencies so that the robot adapts its locomotion to deal with the malfunction. as a consequence the trajectory <phrase>produced by</phrase> the multiple chaotic cpgs resembles <phrase>the original</phrase> trajectory far <phrase>better than</phrase> the one <phrase>produced by</phrase> only <phrase>a single</phrase> cpg. <phrase>the performance of</phrase> the system is evaluated first in a physical simulation of a quadruped <phrase>as well as</phrase> a hexapod robot and finally in a real six legged walking machine called amosii. the <phrase>experimental results</phrase> presented here reveal that using multiple cpgs with learning is <phrase>an effective</phrase> approach for adaptive locomotion generation where for instance different body parts have <phrase>to perform</phrase> independent movements for malfunction compensation.
teaching <phrase>deep convolutional neural networks</phrase> <phrase>to play</phrase> go
mastering the game of go has remained a long standing challenge to <phrase>the field of</phrase> ai. modern computer go systems <phrase>rely on</phrase> processing millions of possible future positions <phrase>to play</phrase> well but intuitively a stronger and more humanlike way <phrase>to play</phrase> the game would be to <phrase>rely on</phrase> <phrase>pattern recognition</phrase> abilities rather then brute force computation. following this sentiment we train <phrase>deep convolutional neural networks</phrase> <phrase>to play</phrase> go by training them <phrase>to predict</phrase> the moves made by expert go players. <phrase>to solve</phrase> <phrase>this problem</phrase> we introduce <phrase>a number of</phrase> novel techniques including a method of tying weights in <phrase>the network</phrase> to hard code symmetries that are expect to exist in the target function and demonstrate in an ablation study they considerably <phrase>improve performance</phrase>. our final networks are <phrase>able to</phrase> achieve move prediction accuracies of 41.1 and 44.4 on two different go datasets surpassing <phrase>previous state of</phrase> <phrase>the art</phrase> on <phrase>this task</phrase> by significant margins. additionally while previous move prediction programs have not yielded strong go playing programs we show that the networks trained in <phrase>this work</phrase> acquired high levels of skill. our <phrase>convolutional neural networks</phrase> can consistently defeat the <phrase>well known</phrase> go program gnu go indicating it is <phrase>state of</phrase> <phrase>the art</phrase> among programs that <phrase>do not</phrase> use <phrase>monte carlo</phrase> tree search. it is also <phrase>able to</phrase> win some games against <phrase>state of</phrase> <phrase>the art</phrase> go playing program fuego while using a fraction of the play time. this success at playing go indicates <phrase>high level</phrase> principles of the game were learned.
<phrase>polyphonic music</phrase> generation by modeling temporal dependencies using a rnn dbn
in <phrase>this paper</phrase> we propose a generic technique to model temporal dependencies and sequences using a <phrase>combination of</phrase> <phrase>a recurrent neural network</phrase> and a deep belief network. our technique rnn dbn is an amalgamation of the memory <phrase>state of</phrase> the rnn that allows it to provide temporal information and a <phrase>multi layer</phrase> dbn that helps in <phrase>high level</phrase> representation of the data. this makes rnn dbns ideal for sequence generation. further <phrase>the use of</phrase> a dbn in conjunction with the rnn makes this model <phrase>capable of</phrase> significantly more complex data representation than an rbm. we apply this technique to <phrase>the task of</phrase> <phrase>polyphonic music</phrase> generation.
massively parallel methods for <phrase>deep reinforcement learning</phrase>
we present the first massively distributed architecture for <phrase>deep reinforcement learning</phrase>. this architecture uses four main components parallel actors that generate new behaviour parallel learners that are trained from stored experience a distributed <phrase>neural network</phrase> <phrase>to represent</phrase> the <phrase>value function</phrase> or behaviour policy and a distributed store of experience. we used our architecture to implement the <phrase>deep q</phrase> network algorithm dqn . our distributed algorithm was <phrase>applied to</phrase> 49 games from <phrase>atari 2600</phrase> games from the arcade learning environment using identical hyperparameters. our performance surpassed non distributed dqn in 41 of the 49 games and also reduced the wall time required to achieve these results by an order <phrase>of magnitude</phrase> on most games.
a <phrase>genetic algorithm</phrase> for autonomous navigation in <phrase>partially observable</phrase> domain
<phrase>the problem of</phrase> autonomous navigation is one of the basic problems for robotics. although in general it may be challenging when an autonomous vehicle is placed into <phrase>partially observable</phrase> domain. in <phrase>this paper</phrase> we consider simplistic environment model and introduce a navigation algorithm <phrase>based on</phrase> learning classifier system.
distributed <phrase>deep q</phrase> learning
we propose a distributed <phrase>deep learning</phrase> model to successfully learn control policies directly from <phrase>high dimensional</phrase> sensory input using <phrase>reinforcement learning</phrase>. <phrase>the model</phrase> is <phrase>based on</phrase> the <phrase>deep q</phrase> network <phrase>a convolutional neural network</phrase> trained with a variant of q learning. its input is raw pixels and its output is a <phrase>value function</phrase> estimating future rewards from taking an action given a system state. to distribute the <phrase>deep q</phrase> <phrase>network training</phrase> we adapt the distbelief <phrase>software framework</phrase> to <phrase>the context of</phrase> efficiently training <phrase>reinforcement learning</phrase> agents. as a result the method is completely asynchronous and scales well with <phrase>the number of</phrase> machines. we demonstrate that the <phrase>deep q</phrase> network agent receiving only the pixels and the game score as inputs was <phrase>able to</phrase> achieve reasonable success on <phrase>a simple</phrase> game <phrase>with minimal</phrase> parameter tuning.
lifted relational <phrase>neural networks</phrase>
we propose a method combining relational logic representations with <phrase>neural network</phrase> learning. a general lifted architecture possibly reflecting some background <phrase>domain knowledge</phrase> is described through relational rules which may be handcrafted or learned. the relational rule set serves as a template for unfolding possibly <phrase>deep neural networks</phrase> whose structures also reflect the structures of given training or testing relational examples. different networks corresponding to different examples share their weights which co evolve <phrase>during training</phrase> by <phrase>stochastic gradient descent</phrase> algorithm. the framework allows for hierarchical relational modeling constructs and learning of latent relational concepts through shared <phrase>hidden layers</phrase> weights corresponding to the rules. discovery of notable relational concepts and <phrase>experiments on</phrase> 78 relational learning benchmarks demonstrate favorable performance of the method.
giraffe using <phrase>deep reinforcement learning</phrase> <phrase>to play</phrase> chess
this report presents giraffe a <phrase>chess engine</phrase> that uses self play <phrase>to discover</phrase> all its <phrase>domain specific</phrase> knowledge <phrase>with minimal</phrase> <phrase>hand crafted</phrase> knowledge given by the programmer. unlike previous attempts using <phrase>machine learning</phrase> only <phrase>to perform</phrase> parameter tuning on <phrase>hand crafted</phrase> evaluation functions giraffe s learning system also performs automatic <phrase>feature extraction</phrase> and <phrase>pattern recognition</phrase>. the trained evaluation function performs comparably to the evaluation functions of <phrase>state of</phrase> <phrase>the art</phrase> chess engines all of which containing thousands of lines of carefully <phrase>hand crafted</phrase> pattern recognizers tuned over many years by both computer chess experts and human chess masters. giraffe is the most successful attempt thus far at using <phrase>end to end</phrase> <phrase>machine learning</phrase> <phrase>to play</phrase> chess.
attention with intention for <phrase>a neural network</phrase> conversation model
in a conversation or a dialogue process attention and intention play intrinsic roles. <phrase>this paper</phrase> proposes <phrase>a neural network</phrase> <phrase>based approach</phrase> that models the attention and intention processes. it essentially <phrase>consists of</phrase> three recurrent networks. the encoder network is a <phrase>word level</phrase> model representing source side sentences. the intention network is a <phrase>recurrent network</phrase> that models the dynamics of the intention process. the decoder network is a <phrase>recurrent network</phrase> produces responses to <phrase>the input</phrase> from the source side. it is a <phrase>language model</phrase> that is dependent on the intention and has an <phrase>attention mechanism</phrase> to attend to particular source side words when predicting a symbol in the response. <phrase>the model</phrase> is <phrase>trained end to end</phrase> without labeling data. <phrase>experiments show</phrase> that this model generates natural responses to user inputs.
<phrase>deep reinforcement learning</phrase> in parameterized action space
<phrase>recent work</phrase> has shown that <phrase>deep neural networks</phrase> are <phrase>capable of</phrase> approximating both value functions and policies in <phrase>reinforcement learning</phrase> domains featuring continuous state and action spaces. however to <phrase>the best</phrase> of our knowledge no <phrase>previous work</phrase> has succeeded at using <phrase>deep neural networks</phrase> in structured parameterized continuous action spaces. to fill this gap <phrase>this paper</phrase> <phrase>focuses on</phrase> learning within the domain of simulated robocup soccer which features <phrase>a small</phrase> <phrase>set of</phrase> discrete action types each of which is parameterized with continuous variables. <phrase>the best</phrase> learned agent can score goals more reliably than the 2012 robocup champion agent. as such <phrase>this paper</phrase> represents a successful extension of <phrase>deep reinforcement learning</phrase> to the class of parameterized action space mdps.
mazebase a sandbox for learning from games
<phrase>this paper</phrase> introduces mazebase an environment for simple 2d games designed as a sandbox for <phrase>machine learning</phrase> approaches to reasoning and planning. within it we create 10 simple games embodying <phrase>a range of</phrase> algorithmic tasks e.g. if then statements or set negation . <phrase>a variety of</phrase> <phrase>neural models</phrase> fully connected convolutional network <phrase>memory network</phrase> are deployed via <phrase>reinforcement learning</phrase> on these games with and without a procedurally generated curriculum. despite the tasks simplicity <phrase>the performance of</phrase> the models is far from optimal suggesting directions for future development. we also demonstrate the versatility of mazebase <phrase>by using</phrase> it to emulate small combat scenarios from starcraft. models <phrase>trained on</phrase> the mazebase version can be directly <phrase>applied to</phrase> starcraft where they consistently beat the in game ai.
on learning to think <phrase>algorithmic information theory</phrase> for novel combinations of <phrase>reinforcement learning</phrase> controllers and <phrase>recurrent neural</phrase> world models
<phrase>this paper</phrase> addresses the general problem of <phrase>reinforcement learning</phrase> rl in <phrase>partially observable</phrase> environments. in 2013 our large rl <phrase>recurrent neural networks</phrase> rnns learned <phrase>from scratch</phrase> to drive simulated cars from <phrase>high dimensional</phrase> video input. however real brains are <phrase>more powerful</phrase> in many ways. <phrase>in particular</phrase> they learn a predictive model of their initially unknown environment and somehow use it for abstract e.g. hierarchical planning and reasoning. guided by <phrase>algorithmic information theory</phrase> we describe <phrase>rnn based</phrase> ais rnnais designed to do <phrase>the same</phrase>. such an rnnai can be <phrase>trained on</phrase> never ending sequences of tasks some of them provided by the user others invented by the rnnai itself in a curious playful fashion <phrase>to improve</phrase> its <phrase>rnn based</phrase> world model. unlike our previous model building <phrase>rnn based</phrase> rl machines dating back to 1990 the rnnai learns to actively query its model for abstract reasoning and planning and <phrase>decision making</phrase> essentially learning to think. the basic ideas of this report can be <phrase>applied to</phrase> many other cases where one rnn like system exploits the algorithmic information content of another. they are taken from a grant proposal submitted in fall 2014 and also explain concepts <phrase>such as</phrase> mirror neurons. <phrase>experimental results</phrase> will be described in separate papers.
an empirical comparison of <phrase>neural architectures</phrase> for <phrase>reinforcement learning</phrase> in <phrase>partially observable</phrase> environments
<phrase>this paper</phrase> explores <phrase>the performance of</phrase> fitted neural q iteration for <phrase>reinforcement learning</phrase> in several <phrase>partially observable</phrase> environments using three <phrase>recurrent neural network</phrase> architectures <phrase>long short term memory</phrase> <phrase>gated recurrent</phrase> unit and mut1 <phrase>a recurrent neural</phrase> architecture evolved from a pool of several thousands candidate architectures. a variant of fitted q iteration <phrase>based on</phrase> advantage values <phrase>instead of</phrase> q values is also explored. the <phrase>results show</phrase> that gru performs significantly <phrase>better than</phrase> lstm and mut1 for most of the problems considered requiring less training episodes and less cpu time before learning a very good policy. advantage learning also tends <phrase>to produce</phrase> better results.
predicting clinical events by combining static and dynamic information using <phrase>recurrent neural networks</phrase>
in clinical <phrase>data sets</phrase> we often find static information e.g. patient gender <phrase>blood type</phrase> etc. <phrase>combined with</phrase> sequences of data that are recorded during multiple hospital visits e.g. medications prescribed tests performed etc. . <phrase>recurrent neural networks</phrase> rnns have proven to be very successful for modelling sequences of data in many areas of <phrase>machine learning</phrase>. in <phrase>this work</phrase> we present an <phrase>approach based on</phrase> rnns specifically designed for the clinical domain that combines static and dynamic information <phrase>in order to</phrase> predict future events. we work with a database collected in the charit e hospital in berlin that contains complete information concerning patients that underwent a <phrase>kidney transplantation</phrase>. after the transplantation three main endpoints can occur rejection of the kidney loss of the kidney and death of the patient. our goal is <phrase>to predict</phrase> <phrase>based on</phrase> information recorded in the <phrase>electronic health record</phrase> of each patient whether any of those endpoints will occur within the next six or twelve months after each visit to the clinic. we compared different <phrase>types of</phrase> rnns that we developed for <phrase>this work</phrase> with a <phrase>model based</phrase> on a feedforward <phrase>neural network</phrase> and a <phrase>logistic regression</phrase> model. we found that the rnn that we developed <phrase>based on</phrase> <phrase>gated recurrent</phrase> units provides <phrase>the best</phrase> performance for <phrase>this task</phrase>. we also used <phrase>the same</phrase> models for a second task i.e. next event prediction and found that here <phrase>the model</phrase> <phrase>based on</phrase> a feedforward <phrase>neural network</phrase> outperformed the other models. our hypothesis is that <phrase>long term</phrase> dependencies are not as relevant in <phrase>this task</phrase>.
weight normalization <phrase>a simple</phrase> reparameterization to accelerate training of <phrase>deep neural networks</phrase>
we present weight normalization a reparameterization of the weight vectors in <phrase>a neural network</phrase> that decouples the length of those weight vectors from their direction. by reparameterizing the weights in this way we improve the conditioning of the <phrase>optimization problem</phrase> and we speed up convergence of <phrase>stochastic gradient descent</phrase>. our reparameterization is <phrase>inspired by</phrase> <phrase>batch normalization</phrase> but <phrase>does not</phrase> introduce any dependencies between the examples in a minibatch. this means that our method can also be applied successfully to recurrent models <phrase>such as</phrase> lstms and to noise sensitive <phrase>applications such as</phrase> <phrase>deep reinforcement learning</phrase> or <phrase>generative models</phrase> for which <phrase>batch normalization</phrase> is less well suited. although our method is much simpler it still provides much of the speed up of full <phrase>batch normalization</phrase>. <phrase>in addition</phrase> the computational overhead of our method is lower permitting more optimization steps to be taken in <phrase>the same</phrase> <phrase>amount of</phrase> time. we demonstrate the usefulness of our method on applications in supervised image recognition generative modelling and <phrase>deep reinforcement learning</phrase>.
bounded rational <phrase>decision making</phrase> in feedforward <phrase>neural networks</phrase>
bounded rational decision makers transform sensory input into motor output under limited computational resources. mathematically such decision makers can be modeled as information theoretic channels with limited transmission rate. here we apply this formalism for the first time to multilayer feedforward <phrase>neural networks</phrase>. we derive synaptic weight update rules for two scenarios where either each neuron is considered as a bounded rational decision maker or <phrase>the network</phrase> as a whole. in the update rules <phrase>bounded rationality</phrase> translates into information theoretically motivated <phrase>types of</phrase> regularization in weight space. in <phrase>experiments on</phrase> the mnist benchmark <phrase>classification task</phrase> for handwritten digits we show that such information theoretic regularization successfully prevents overfitting across different architectures and attains results that are competitive with other recent techniques like dropout dropconnect and bayes by backprop for both ordinary and <phrase>convolutional neural networks</phrase>.
lie access neural <phrase>turing machine</phrase>
following the recent trend in explicit neural memory structures we present <phrase>a new</phrase> design of an external memory wherein memories are stored in an euclidean key space mathbb r n . an lstm controller performs read and write via specialized read and write heads. it can move a head by either providing <phrase>a new</phrase> address in the key space aka <phrase>random access</phrase> or moving from its previous position via a <phrase>lie group</phrase> action aka lie access . in this way the l and r instructions of a traditional <phrase>turing machine</phrase> are generalized to arbitrary elements of <phrase>a fixed</phrase> <phrase>lie group</phrase> action. for this reason we name this new model the lie access neural <phrase>turing machine</phrase> or lantm. we tested two different configurations of lantm against an lstm baseline in several basic experiments. we found the right configuration of lantm to outperform the baseline in all of our experiments. <phrase>in particular</phrase> we trained lantm on addition of k digit numbers for 2 le k le 16 but it was <phrase>able to</phrase> generalize almost perfectly to 17 le k le 32 all with <phrase>the number of</phrase> parameters 2 orders <phrase>of magnitude</phrase> below the lstm baseline.
towards machine intelligence
there exists a theory of <phrase>a single</phrase> <phrase>general purpose</phrase> <phrase>learning algorithm</phrase> which could explain the principles of its operation. this theory assumes that the brain has some initial rough architecture <phrase>a small</phrase> library of simple innate circuits which are prewired at birth and proposes that all significant mental algorithms can be learned. given current understanding and observations <phrase>this paper</phrase> reviews and lists the ingredients of such an algorithm from both architectural and functional perspectives.
dynamic frame skip <phrase>deep q</phrase> network
<phrase>deep reinforcement learning</phrase> methods have achieved <phrase>state of</phrase> <phrase>the art</phrase> performance in learning control policies for the games in the <phrase>atari 2600</phrase> domain. one of the important parameters in the arcade learning environment ale is the frame skip rate. it decides the granularity at which agents can control game play. a frame skip value of k allows the agent to repeat a selected action k <phrase>number of</phrase> times. <phrase>the current state of</phrase> <phrase>the art</phrase> architectures like <phrase>deep q</phrase> network dqn and dueling <phrase>network architectures</phrase> dudqn consist of a framework with a static frame skip rate where the action output from <phrase>the network</phrase> is repeated for <phrase>a fixed</phrase> <phrase>number of</phrase> frames regardless of <phrase>the current state</phrase>. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> architecture dynamic frame skip <phrase>deep q</phrase> network dfdqn which makes the frame skip rate a dynamic learnable parameter. this allows us to choose <phrase>the number of</phrase> times an action is to be repeated <phrase>based on</phrase> <phrase>the current state</phrase>. we show empirically that such a setting improves the <phrase>performance on</phrase> relatively harder games like seaquest.
programming with a differentiable forth interpreter
given that <phrase>in practice</phrase> <phrase>training data</phrase> is scarce for all but <phrase>a small</phrase> <phrase>set of</phrase> problems a core question is how to incorporate <phrase>prior knowledge</phrase> into a model. in <phrase>this paper</phrase> we consider the case of prior <phrase>procedural knowledge</phrase> for <phrase>neural networks</phrase> <phrase>such as</phrase> knowing how a program should traverse a sequence but not what local actions should be performed at each step. to this end we present <phrase>an end to end</phrase> differentiable interpreter for the <phrase>programming language</phrase> forth which enables programmers to write program sketches with slots that can be filled with behaviour trained from program <phrase>input output</phrase> data. we can optimise this behaviour directly through <phrase>gradient descent</phrase> techniques on user specified objectives and also integrate the program into any larger neural computation graph. we show empirically that our interpreter is <phrase>able to</phrase> effectively leverage different levels of prior program structure and learn complex behaviours <phrase>such as</phrase> sequence sorting and addition. when connected to outputs of an lstm and trained jointly our interpreter <phrase>achieves state of</phrase> <phrase>the art</phrase> accuracy for <phrase>end to end</phrase> reasoning about quantities expressed in <phrase>natural language</phrase> stories.
generative choreography using <phrase>deep learning</phrase>
<phrase>recent advances in</phrase> <phrase>deep learning</phrase> have enabled the extraction of <phrase>high level</phrase> features <phrase>from raw</phrase> sensor data which has opened up new possibilities in many different fields including computer generated choreography. in <phrase>this paper</phrase> we present a system chor rnn for generating novel choreographic material in the nuanced choreographic language and style of an individual choreographer. it also shows <phrase>promising results</phrase> in producing a <phrase>higher level</phrase> compositional cohesion <phrase>rather than</phrase> just generating sequences of movement. at the core of chor rnn is a deep <phrase>recurrent neural network</phrase> <phrase>trained on</phrase> raw <phrase>motion capture</phrase> data and that can generate new dance sequences for a solo dancer. chor rnn can be used for collaborative human machine choreography or as a creative catalyst serving as inspiration for a choreographer.
logic tensor networks <phrase>deep learning</phrase> and logical reasoning from data and knowledge
we propose logic tensor networks a uniform <phrase>framework for</phrase> integrating automatic learning and reasoning. a logic formalism called real logic is defined on a first order language whereby formulas have truth value in the interval 0 1 and semantics defined concretely on the domain of real numbers. logical constants are interpreted as feature vectors of real numbers. real logic promotes a well founded integration of <phrase>deductive reasoning</phrase> on a <phrase>knowledge base</phrase> and efficient <phrase>data driven</phrase> relational <phrase>machine learning</phrase>. we show how real logic can be implemented in deep tensor <phrase>neural networks</phrase> with <phrase>the use of</phrase> google s tensorflow primitives. the paper concludes with experiments applying logic tensor networks on <phrase>a simple</phrase> but representative example of knowledge completion.
identifying and harnessing the <phrase>building blocks</phrase> of <phrase>machine learning</phrase> pipelines for sensible initialization of a <phrase>data science</phrase> automation tool
as <phrase>data science</phrase> continues to grow in popularity there will be an increasing <phrase>need to</phrase> make <phrase>data science</phrase> tools more scalable flexible and accessible. <phrase>in particular</phrase> automated <phrase>machine learning</phrase> automl systems <phrase>seek to</phrase> automate the process of designing and optimizing <phrase>machine learning</phrase> pipelines. in this chapter we present a <phrase>genetic programming</phrase> based automl system called tpot that optimizes <phrase>a series of</phrase> feature preprocessors and <phrase>machine learning</phrase> models with <phrase>the goal of</phrase> maximizing <phrase>classification accuracy</phrase> on a supervised classification problem. further we analyze <phrase>a large</phrase> database of pipelines that were previously used <phrase>to solve</phrase> various supervised <phrase>classification problems</phrase> and identify 100 short <phrase>series of</phrase> <phrase>machine learning</phrase> operations that appear the most frequently which we call the <phrase>building blocks</phrase> of <phrase>machine learning</phrase> pipelines. we harness these <phrase>building blocks</phrase> to initialize tpot with promising solutions and find that this sensible initialization method significantly improves tpot s <phrase>performance on</phrase> one benchmark at no cost of significantly degrading <phrase>performance on</phrase> the others. thus sensible initialization with <phrase>machine learning</phrase> pipeline <phrase>building blocks</phrase> shows promise for gp based automl systems and should be further refined in future work.
neuroevolution based inverse <phrase>reinforcement learning</phrase>
<phrase>the problem of</phrase> learning from demonstration is targeted at learning <phrase>to perform</phrase> tasks <phrase>based on</phrase> observed examples. one <phrase>approach to</phrase> learning from demonstration is inverse <phrase>reinforcement learning</phrase> in which actions are observed to infer rewards. <phrase>this work</phrase> combines a feature based state evaluation <phrase>approach to</phrase> inverse <phrase>reinforcement learning</phrase> with neuroevolution a paradigm for modifying <phrase>neural networks</phrase> <phrase>based on</phrase> their <phrase>performance on</phrase> a given task. <phrase>neural networks</phrase> are used <phrase>to learn</phrase> from a demonstrated expert policy and are evolved <phrase>to generate</phrase> a policy <phrase>similar to</phrase> the demonstration. the algorithm is discussed and evaluated against competitive feature based inverse <phrase>reinforcement learning</phrase> approaches. at the cost of execution time <phrase>neural networks</phrase> allow for <phrase>non linear</phrase> combinations of features in state evaluations. these valuations may correspond to state value or state reward. this results in better correspondence to observed examples as opposed to using linear combinations. <phrase>this work</phrase> also extends existing work on bayesian non parametric feature construction for inverse <phrase>reinforcement learning</phrase> <phrase>by using</phrase> <phrase>non linear</phrase> combinations of intermediate data <phrase>to improve</phrase> performance. the algorithm is observed to be specifically <phrase>suitable for</phrase> a linearly solvable non deterministic markov decision processes in which multiple rewards are sparsely scattered in <phrase>state space</phrase>. a conclusive performance hierarchy between evaluated algorithms is presented.
terpret a probabilistic <phrase>programming language</phrase> for program induction
we study <phrase>machine learning</phrase> formulations of inductive program synthesis given <phrase>input output</phrase> examples we try to synthesize <phrase>source code</phrase> that maps inputs to corresponding outputs. our aims are to develop new <phrase>machine learning</phrase> approaches <phrase>based on</phrase> <phrase>neural networks</phrase> and <phrase>graphical models</phrase> and <phrase>to understand</phrase> the capabilities of <phrase>machine learning</phrase> techniques relative to traditional alternatives <phrase>such as</phrase> those <phrase>based on</phrase> constraint solving from the <phrase>programming languages</phrase> community. our key contribution is the proposal of terpret a <phrase>domain specific</phrase> language for expressing program synthesis problems. terpret is <phrase>similar to</phrase> a probabilistic <phrase>programming language</phrase> a model is <phrase>composed of</phrase> a specification of a program representation declarations of <phrase>random variables</phrase> and an interpreter describing how programs map inputs to outputs a model connecting unknowns to observations . the inference task is to observe <phrase>a set of</phrase> <phrase>input output</phrase> examples and infer the underlying program. terpret has two main benefits. first it enables rapid exploration of <phrase>a range of</phrase> domains program representations and interpreter models. second it separates <phrase>the model</phrase> specification from the inference algorithm allowing like to like comparisons between different approaches to inference. from <phrase>a single</phrase> terpret specification we automatically perform inference using four different back ends. these are <phrase>based on</phrase> <phrase>gradient descent</phrase> <phrase>linear program</phrase> lp relaxations for <phrase>graphical models</phrase> discrete satisfiability solving and the sketch program synthesis system. we illustrate the value of terpret by developing several interpreter models and performing an empirical comparison between alternative inference algorithms. our key empirical finding is that constraint solvers dominate the <phrase>gradient descent</phrase> and lp based formulations. we conclude with suggestions for the <phrase>machine learning</phrase> community to make progress on program synthesis.
<phrase>multi label classification</phrase> method <phrase>based on</phrase> <phrase>extreme learning</phrase> machines
in <phrase>this paper</phrase> an <phrase>extreme learning</phrase> machine elm based technique <phrase>for multi label</phrase> <phrase>classification problems</phrase> is proposed and discussed. in <phrase>multi label classification</phrase> each of <phrase>the input</phrase> data samples belongs to one or <phrase>more than</phrase> one class labels. the traditional binary and <phrase>multi class</phrase> <phrase>classification problems</phrase> are the <phrase>subset of</phrase> the <phrase>multi label</phrase> problem with <phrase>the number of</phrase> labels corresponding to each sample limited to one. <phrase>the proposed</phrase> elm based <phrase>multi label classification</phrase> technique is evaluated with six different benchmark <phrase>multi label</phrase> datasets from different <phrase>domains such as</phrase> multimedia text and biology. a detailed comparison of the results is made by comparing <phrase>the proposed</phrase> method with the results from nine <phrase>state of</phrase> the arts techniques for five different <phrase>evaluation metrics</phrase>. the nine methods are chosen from different categories of <phrase>multi label</phrase> methods. the comparative results shows that <phrase>the proposed</phrase> <phrase>extreme learning</phrase> machine based <phrase>multi label classification</phrase> technique is a better alternative than the existing <phrase>state of</phrase> <phrase>the art</phrase> methods <phrase>for multi label</phrase> problems.
<phrase>a novel</phrase> online <phrase>real time</phrase> classifier <phrase>for multi label</phrase> data streams
in <phrase>this paper</phrase> <phrase>a novel</phrase> <phrase>extreme learning</phrase> machine based online <phrase>multi label</phrase> classifier for <phrase>real time</phrase> data streams is proposed. <phrase>multi label classification</phrase> is one of the actively researched <phrase>machine learning</phrase> paradigm that has gained much attention in the <phrase>recent years</phrase> <phrase>due to</phrase> its rapidly increasing <phrase>real world</phrase> applications. <phrase>in contrast to</phrase> traditional binary and <phrase>multi class</phrase> classification <phrase>multi label classification</phrase> involves association of each of <phrase>the input</phrase> samples with <phrase>a set of</phrase> target labels simultaneously. there are no <phrase>real time</phrase> online <phrase>neural network</phrase> based <phrase>multi label</phrase> classifier available in the literature. in <phrase>this paper</phrase> we exploit the inherent nature of high speed exhibited by the <phrase>extreme learning</phrase> machines to develop <phrase>a novel</phrase> online <phrase>real time</phrase> classifier <phrase>for multi label</phrase> data streams. the developed classifier is experimented with datasets from different application domains for consistency performance and speed. the experimental studies show that <phrase>the proposed</phrase> method outperforms the existing <phrase>state of</phrase> <phrase>the art</phrase> techniques <phrase>in terms of</phrase> speed and accuracy and can classify <phrase>multi label</phrase> data streams in <phrase>real time</phrase>.
<phrase>a novel</phrase> progressive learning technique for <phrase>multi class</phrase> classification
in <phrase>this paper</phrase> a progressive learning technique for <phrase>multi class</phrase> classification is proposed. this newly developed learning technique is independent of <phrase>the number of</phrase> class constraints and it can learn new classes while still retaining the knowledge of previous classes. whenever <phrase>a new</phrase> class non native to the knowledge learnt thus far is encountered the <phrase>neural network</phrase> structure gets remodeled automatically by facilitating new neurons and interconnections and the parameters are calculated in such a way that it retains the knowledge learnt thus far. this technique is <phrase>suitable for</phrase> <phrase>real world</phrase> applications where <phrase>the number of</phrase> classes is often unknown and online learning from <phrase>real time</phrase> data is required. the consistency and <phrase>the complexity of</phrase> the progressive learning technique are analyzed. several standard datasets are used to evaluate <phrase>the performance of</phrase> the developed technique. a comparative study shows that the developed technique is superior.
<phrase>a novel</phrase> online <phrase>multi label</phrase> classifier for high speed streaming data applications
in <phrase>this paper</phrase> a high speed online <phrase>neural network</phrase> classifier <phrase>based on</phrase> <phrase>extreme learning</phrase> machines <phrase>for multi label</phrase> classification is proposed. in <phrase>multi label classification</phrase> each of <phrase>the input</phrase> data sample belongs to one or <phrase>more than</phrase> one of the target labels. the traditional binary and <phrase>multi class</phrase> classification where each sample belongs to only one target class forms the <phrase>subset of</phrase> <phrase>multi label classification</phrase>. <phrase>multi label classification</phrase> problems are far more complex than binary and <phrase>multi class</phrase> <phrase>classification problems</phrase> as both <phrase>the number of</phrase> target labels and each of the target labels corresponding to each of <phrase>the input</phrase> samples are to be identified. <phrase>the proposed</phrase> work exploits the high speed nature of the <phrase>extreme learning</phrase> machines to achieve <phrase>real time</phrase> <phrase>multi label classification</phrase> of streaming data. <phrase>a new</phrase> threshold based online sequential <phrase>learning algorithm</phrase> is proposed for high speed and streaming data classification of <phrase>multi label</phrase> problems. <phrase>the proposed</phrase> method is experimented with six different datasets from different application <phrase>domains such as</phrase> multimedia text and biology. the hamming loss accuracy training time and testing time of <phrase>the proposed</phrase> technique is <phrase>compared with</phrase> nine different <phrase>state of</phrase> <phrase>the art</phrase> methods. experimental studies shows that <phrase>the proposed</phrase> technique outperforms the existing <phrase>multi label</phrase> classifiers <phrase>in terms of</phrase> performance and speed.
ternary <phrase>neural networks</phrase> for resource efficient ai applications
the computation and storage requirements for <phrase>deep neural networks</phrase> dnns are usually high. <phrase>this issue</phrase> limits their deployability on <phrase>ubiquitous computing</phrase> devices <phrase>such as</phrase> <phrase>smart phones</phrase> wearables and autonomous drones. in <phrase>this paper</phrase> we propose ternary <phrase>neural networks</phrase> tnns <phrase>in order to</phrase> make <phrase>deep learning</phrase> more resource efficient. we train these tnns using a teacher student <phrase>approach based on</phrase> <phrase>a novel</phrase> <phrase>layer wise</phrase> greedy methodology. thanks to our two stage training procedure the teacher network is still <phrase>able to</phrase> use <phrase>state of</phrase> <phrase>the art</phrase> methods <phrase>such as</phrase> dropout and <phrase>batch normalization</phrase> to increase accuracy and reduce training time. using only ternary weights and activations the student ternary network learns to mimic the behavior of its teacher network without using any multiplication. unlike its 1 1 binary counterparts a ternary <phrase>neural network</phrase> inherently prunes the smaller weights by setting them to zero <phrase>during training</phrase>. this makes them sparser and thus more energy efficient. we design a purpose built hardware architecture for tnns and implement it on fpga and asic. we evaluate tnns on several <phrase>benchmark datasets</phrase> and demonstrate up to 3.1x better energy efficiency <phrase>with respect to</phrase> the <phrase>state of</phrase> <phrase>the art</phrase> while also improving accuracy.
fitted <phrase>learning models</phrase> with awareness of their limits
though <phrase>deep learning</phrase> has pushed the boundaries of classification forward <phrase>in recent years</phrase> hints of the limits of standard classification have begun to emerge. problems <phrase>such as</phrase> fooling adding new classes over time and the <phrase>need to</phrase> retrain <phrase>learning models</phrase> only for small changes to <phrase>the original</phrase> problem all point to a potential shortcoming in the classic classification regime where a comprehensive a priori knowledge of the possible classes or concepts is critical. without such knowledge classifiers misjudge the limits of their knowledge and overgeneralization therefore becomes a serious obstacle to consistent performance. in response to these challenges <phrase>this paper</phrase> extends the classic regime by reframing classification instead with the assumption that concepts present in the <phrase>training set</phrase> are only a sample of the hypothetical final <phrase>set of</phrase> concepts. to bring <phrase>learning models</phrase> into this new paradigm <phrase>a novel</phrase> elaboration of standard architectures called the competitive overcomplete <phrase>output layer</phrase> cool <phrase>neural network</phrase> is introduced. <phrase>experiments demonstrate</phrase> <phrase>the effectiveness of</phrase> cool by applying it to fooling separable concept learning one class <phrase>neural networks</phrase> and standard classification benchmarks. the <phrase>results suggest</phrase> that unlike conventional classifiers the <phrase>amount of</phrase> generalization in cool networks can be tuned to match the problem.
learning <phrase>to learn</phrase> with backpropagation of hebbian plasticity
hebbian plasticity is a powerful principle that allows biological brains <phrase>to learn</phrase> from their lifetime experience. by contrast <phrase>artificial neural networks</phrase> trained with backpropagation generally have fixed connection weights that <phrase>do not</phrase> change once training is complete. while recent methods can endow <phrase>neural networks</phrase> with <phrase>long term</phrase> memories hebbian plasticity is currently not amenable to <phrase>gradient descent</phrase>. here we derive analytical expressions for activity gradients in <phrase>neural networks</phrase> with hebbian plastic connections. using these expressions we can use backpropagation <phrase>to train</phrase> not just the baseline weights of the connections <phrase>but also</phrase> their plasticity. as a result the networks learn how <phrase>to learn</phrase> <phrase>in order to</phrase> solve the problem at hand the trained networks automatically perform fast learning of unpredictable environmental features during their lifetime expanding the range of solvable problems. we test the algorithm on various <phrase>on line</phrase> <phrase>learning tasks</phrase> including pattern completion one <phrase>shot learning</phrase> and reversal learning. the algorithm successfully learns how <phrase>to learn</phrase> the relevant associations from one shot instruction and fine tunes the temporal dynamics of plasticity to allow for continual learning in response to changing environmental parameters. we conclude that backpropagation of hebbian plasticity offers a powerful model for <phrase>lifelong learning</phrase>.
learning by stimulation avoidance a principle to control <phrase>spiking neural networks</phrase> dynamics
learning <phrase>based on</phrase> networks of real neurons and by extension biologically inspired models of <phrase>neural networks</phrase> has yet to find general learning rules <phrase>leading to</phrase> widespread applications. in <phrase>this paper</phrase> we argue for <phrase>the existence of</phrase> a principle allowing to steer the dynamics of a biologically inspired <phrase>neural network</phrase>. using carefully timed external stimulation <phrase>the network</phrase> can be driven towards a desired dynamical state. we term this principle learning by stimulation avoidance lsa . we demonstrate through simulation that the minimal sufficient conditions <phrase>leading to</phrase> lsa in artificial networks are also sufficient to reproduce learning results <phrase>similar to</phrase> those obtained in biological neurons by shahaf and marom 1 . we examine the mechanism s basic dynamics in a reduced network and demonstrate how it scales up to a network of 100 neurons. we show that lsa has a higher explanatory power than existing hypotheses about the response of biological <phrase>neural networks</phrase> to external simulation and can be <phrase>used as</phrase> a learning rule for an embodied application learning of wall avoidance by a simulated robot. the surge in popularity of <phrase>artificial neural networks</phrase> is mostly directed to disembodied models of neurons with biologically irrelevant dynamics to the authors knowledge this is the first work demonstrating sensory <phrase>motor learning</phrase> with random spiking networks through pure hebbian learning.
surprisal driven zoneout
we propose <phrase>a novel</phrase> method of regularization for <phrase>recurrent neural networks</phrase> called suprisal driven zoneout. in this method states zoneout maintain their previous value <phrase>rather than</phrase> updating when the suprisal discrepancy between the last state s prediction and target is small. thus regularization is adaptive and input driven on a per neuron basis. we demonstrate <phrase>the effectiveness of</phrase> this idea by achieving <phrase>state of</phrase> <phrase>the art</phrase> bits per character of 1.31 on the hutter prize wikipedia dataset significantly reducing the gap to <phrase>the best</phrase> known highly engineered compression methods.
neural architecture search with <phrase>reinforcement learning</phrase>
<phrase>neural networks</phrase> are powerful and flexible models that work well for many difficult <phrase>learning tasks</phrase> in image speech and <phrase>natural language</phrase> understanding. despite their success <phrase>neural networks</phrase> are still hard to design. in <phrase>this paper</phrase> we use a <phrase>recurrent network</phrase> <phrase>to generate</phrase> <phrase>the model</phrase> descriptions of <phrase>neural networks</phrase> and train this rnn with <phrase>reinforcement learning</phrase> to maximize the expected accuracy of the generated architectures on a validation set. on the <phrase>cifar 10</phrase> dataset our method starting <phrase>from scratch</phrase> can design <phrase>a novel</phrase> <phrase>network architecture</phrase> that rivals <phrase>the best</phrase> human invented architecture <phrase>in terms of</phrase> <phrase>test set</phrase> accuracy. our <phrase>cifar 10</phrase> <phrase>model achieves</phrase> a test <phrase>error rate</phrase> of 3.65 which is 0.09 percent better and 1.05x <phrase>faster than</phrase> the <phrase>previous state of</phrase> <phrase>the art</phrase> model that used a similar architectural scheme. on the <phrase>penn treebank</phrase> dataset our model can compose <phrase>a novel</phrase> recurrent cell that outperforms the <phrase>widely used</phrase> lstm cell and other <phrase>state of</phrase> <phrase>the art</phrase> baselines. our cell achieves a <phrase>test set</phrase> perplexity of 62.4 on the <phrase>penn treebank</phrase> which is 3.6 perplexity <phrase>better than</phrase> the <phrase>previous state of</phrase> <phrase>the art</phrase> model. the cell can also be transferred to the character <phrase>language modeling</phrase> task on ptb and achieves a <phrase>state of</phrase> <phrase>the art</phrase> perplexity of 1.214.
emergence of foveal image sampling from learning to attend in visual scenes
we describe a neural <phrase>attention model</phrase> with a learnable retinal sampling lattice. <phrase>the model</phrase> is <phrase>trained on</phrase> a <phrase>visual search</phrase> task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest <phrase>number of</phrase> fixations. we explore the tiling properties that emerge in <phrase>the model</phrase> s retinal sampling lattice after training. specifically we show that this lattice resembles the eccentricity dependent sampling lattice of the primate retina with a high resolution region in the fovea surrounded by a low resolution periphery. furthermore we find conditions where these emergent properties are amplified or eliminated providing clues to their function.
long timescale credit assignment in neuralnetworks with external memory
credit assignment in traditional <phrase>recurrent neural networks</phrase> usually involves back propagating through a long chain of tied weight matrices. the length of this chain scales linearly with <phrase>the number of</phrase> time steps as <phrase>the same</phrase> network is run at each time step. this creates many problems <phrase>such as</phrase> vanishing gradients that have been well studied. <phrase>in contrast</phrase> a nnem s architecture recurrent activity doesn t involve a long chain of activity though some architectures <phrase>such as</phrase> the ntm do utilize a traditional recurrent architecture as a controller . rather the externally stored embedding vectors are used at each time step but no messages are passed from previous time steps. this means that vanishing gradients aren t a problem as all of the necessary gradient paths are short. however these paths are extremely numerous one per embedding vector in memory and reused for a very long time until it leaves the memory . thus the <phrase>forward pass</phrase> information of each memory must be stored for the entire duration of the memory. this is problematic as this additional storage far surpasses that of the actual memories to the extent that large memories on infeasible to back propagate through in <phrase>high dimensional</phrase> settings. one way to get around the <phrase>need to</phrase> hold onto <phrase>forward pass</phrase> information is to recalculate the <phrase>forward pass</phrase> whenever gradient information is available. however if the observations are too large to store in the domain of interest direct reinstatement of a <phrase>forward pass</phrase> cannot occur. instead we <phrase>rely on</phrase> a learned autoencoder to reinstate the observation and then use the embedding network to recalculate the <phrase>forward pass</phrase>. since the recalculated embedding vector is unlikely to perfectly match the one stored in memory we try out 2 approximations to utilize error gradient w.r.t. the vector in memory.
energy saving additive <phrase>neural network</phrase>
<phrase>in recent years</phrase> <phrase>machine learning</phrase> techniques <phrase>based on</phrase> <phrase>neural networks</phrase> for <phrase>mobile computing</phrase> become increasingly popular. classical <phrase>multi layer</phrase> <phrase>neural networks</phrase> require matrix multiplications at each stage. multiplication operation is not an energy efficient operation and consequently it drains the battery of the <phrase>mobile device</phrase>. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> energy efficient <phrase>neural network</phrase> with the universal approximation property over space of lebesgue integrable functions. this network called additive <phrase>neural network</phrase> is very <phrase>suitable for</phrase> <phrase>mobile computing</phrase>. the neural structure is <phrase>based on</phrase> <phrase>a novel</phrase> vector product definition called ef operator that permits a multiplier free implementation. in ef operation the product of two real numbers is defined as the sum of their absolute values with the sign determined by the sign of the product of the numbers. this product is used to construct a vector product in r n . the vector product induces the l 1 norm. <phrase>the proposed</phrase> additive <phrase>neural network</phrase> successfully solves the xor problem. the <phrase>experiments on</phrase> mnist dataset show that the classification performances of <phrase>the proposed</phrase> additive <phrase>neural networks</phrase> are very <phrase>similar to</phrase> the corresponding <phrase>multi layer</phrase> perceptron and <phrase>convolutional neural networks</phrase> lenet .
learning to repeat <phrase>fine grained</phrase> action repetition for <phrase>deep reinforcement learning</phrase>
<phrase>reinforcement learning</phrase> algorithms can learn complex behavioral patterns for sequential <phrase>decision making</phrase> tasks wherein <phrase>an agent</phrase> interacts with an environment and acquires feedback in the form of rewards sampled from it. traditionally such algorithms make decisions i.e. select actions to execute at every single time step of the agent environment interactions. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> framework <phrase>fine grained</phrase> action repetition figar which enables the agent to decide the action <phrase>as well as</phrase> the time scale of repeating it. figar can be used for improving any <phrase>deep reinforcement learning</phrase> algorithm which maintains an explicit policy estimate by enabling temporal abstractions in the action space. we empirically demonstrate <phrase>the efficacy of</phrase> our framework by showing performance improvements on top of three policy search algorithms in different domains asynchronous advantage <phrase>actor critic</phrase> in the <phrase>atari 2600</phrase> domain trust region policy optimization in mujoco domain and deep deterministic policy gradients in the torcs car racing domain.
survey of reasoning using <phrase>neural networks</phrase>
reason and inference require process <phrase>as well as</phrase> memory skills by humans. <phrase>neural networks</phrase> are <phrase>able to</phrase> process tasks like image recognition <phrase>better than</phrase> humans but in memory aspects are still limited by <phrase>attention mechanism</phrase> size . <phrase>recurrent neural network</phrase> rnn and it s modified version lstm are <phrase>able to</phrase> solve small memory contexts but as context becomes larger than a threshold it is difficult to use them. the solution is to use large external memory. still it poses many challenges like how <phrase>to train</phrase> <phrase>neural networks</phrase> for discrete memory representation how to describe <phrase>long term</phrase> dependencies in sequential data etc. most prominent <phrase>neural architectures</phrase> for such tasks are <phrase>memory networks</phrase> inference components <phrase>combined with</phrase> <phrase>long term memory</phrase> and neural <phrase>turing machines</phrase> <phrase>neural networks</phrase> using external memory resources. also additional techniques like <phrase>attention mechanism</phrase> <phrase>end to end</phrase> <phrase>gradient descent</phrase> on discrete memory representation are needed to support these solutions. preliminary results of above <phrase>neural architectures</phrase> on simple algorithms sorting copying and <phrase>question answering</phrase> <phrase>based on</phrase> story dialogs application are comparable with the <phrase>state of</phrase> <phrase>the art</phrase>. in <phrase>this paper</phrase> i explain these architectures in general the additional techniques used and the results of their application.
one shot imitation learning
imitation learning has been commonly <phrase>applied to</phrase> solve different tasks in isolation. this usually requires either careful feature engineering or a significant <phrase>number of</phrase> samples. this is far from what we desire ideally robots should be <phrase>able to</phrase> learn from very few demonstrations of any given task and instantly generalize to new situations of <phrase>the same</phrase> task <phrase>without requiring</phrase> <phrase>task specific</phrase> engineering. in <phrase>this paper</phrase> we propose a <phrase>meta learning</phrase> <phrase>framework for</phrase> achieving such capability which we call one shot imitation learning. specifically we consider the setting where there is a very large <phrase>set of</phrase> tasks and each task has many instantiations. for example a task could be to stack all blocks on a table into <phrase>a single</phrase> tower another task could be to place all blocks on a table into two block towers etc. in each case different instances of the task would consist of different sets of blocks with different initial states. at training time our algorithm is presented with pairs of demonstrations for <phrase>a subset of</phrase> all tasks. a neural net is trained that takes as input one demonstration and <phrase>the current state</phrase> which initially is the initial <phrase>state of</phrase> the other demonstration of the pair and outputs an action with the goal that the resulting sequence of states and actions matches as closely as possible with the second demonstration. at <phrase>test time</phrase> a demonstration of <phrase>a single</phrase> instance of <phrase>a new</phrase> task is presented and the neural net is expected <phrase>to perform</phrase> well on new instances of this new task. <phrase>the use of</phrase> soft attention allows <phrase>the model</phrase> to generalize to conditions and tasks unseen in <phrase>the training data</phrase>. we anticipate that by training this model on a much greater <phrase>variety of</phrase> tasks and settings we will obtain a general system that can turn any demonstrations into robust policies that can accomplish an overwhelming <phrase>variety of</phrase> tasks. videos <phrase>available at</phrase> https bit.ly nips2017 oneshot .
<phrase>deep learning</phrase> for explicitly modeling optimization landscapes
in all but the most trivial optimization problems the structure of the solutions exhibit complex interdependencies between <phrase>the input</phrase> parameters. decades of research with stochastic search techniques has shown the benefit of explicitly modeling the interactions between sets of parameters and the overall quality of the solutions discovered. we demonstrate <phrase>a novel</phrase> method <phrase>based on</phrase> learning <phrase>deep networks</phrase> to model the global landscapes of optimization problems. <phrase>to represent</phrase> the search space concisely and accurately the <phrase>deep networks</phrase> must encode <phrase>information about</phrase> the underlying parameter interactions and their contributions to the quality of the solution. once the networks are trained the networks are probed to reveal parameter combinations with high expected performance <phrase>with respect to</phrase> the optimization task. these estimates are used to initialize fast randomized local search algorithms which in turn expose more <phrase>information about</phrase> the search space that is subsequently used to refine the models. we demonstrate the technique on multiple optimization problems that have arisen in <phrase>a variety of</phrase> <phrase>real world</phrase> domains including packing graphics job scheduling layout and compression. the problems include combinatoric search spaces discontinuous and highly <phrase>non linear</phrase> spaces and span binary higher cardinality discrete <phrase>as well as</phrase> continuous parameters. strengths limitations and extensions of the approach are extensively discussed and demonstrated.
stochastic <phrase>neural networks</phrase> for hierarchical <phrase>reinforcement learning</phrase>
<phrase>deep reinforcement learning</phrase> has achieved many impressive results <phrase>in recent years</phrase>. however tasks with sparse rewards or long horizons continue to pose significant challenges. <phrase>to tackle</phrase> these important problems we propose a general framework that first learns useful skills in a <phrase>pre training</phrase> environment and then leverages the acquired skills for learning faster in downstream tasks. our approach brings together some of the strengths of intrinsic motivation and hierarchical methods the learning of useful skill is guided by <phrase>a single</phrase> proxy reward the design of which requires very minimal <phrase>domain knowledge</phrase> about the downstream tasks. then a <phrase>high level</phrase> policy is <phrase>trained on</phrase> top of these skills providing a <phrase>significant improvement</phrase> of the exploration and allowing <phrase>to tackle</phrase> sparse rewards in the downstream tasks. to efficiently pre train <phrase>a large</phrase> span of skills we use stochastic <phrase>neural networks</phrase> <phrase>combined with</phrase> an information theoretic regularizer. our <phrase>experiments show</phrase> that this combination is effective in learning a wide span of interpretable skills in a sample efficient way and can significantly boost the learning performance uniformly across <phrase>a wide range of</phrase> downstream tasks.
batch <phrase>reinforcement learning</phrase> on the industrial benchmark first experiences
the <phrase>particle swarm optimization</phrase> policy pso p has been recently introduced and proven <phrase>to produce</phrase> remarkable <phrase>results on</phrase> interacting with academic <phrase>reinforcement learning</phrase> benchmarks in an off policy batch based setting. to further investigate the properties and feasibility on <phrase>real world</phrase> applications <phrase>this paper</phrase> investigates pso p on the so called industrial benchmark ib <phrase>a novel</phrase> <phrase>reinforcement learning</phrase> rl benchmark that aims at being realistic by including <phrase>a variety of</phrase> aspects found in industrial applications like continuous state and action spaces a <phrase>high dimensional</phrase> <phrase>partially observable</phrase> <phrase>state space</phrase> delayed effects and complex stochasticity. the <phrase>experimental results</phrase> of pso p on ib are <phrase>compared to</phrase> results of <phrase>closed form</phrase> control policies <phrase>derived from</phrase> <phrase>the model</phrase> based recurrent control <phrase>neural network</phrase> rcnn and <phrase>the model</phrase> free neural fitted q iteration nfq . <phrase>experiments show</phrase> that pso p is <phrase>not only</phrase> of interest for academic benchmarks <phrase>but also</phrase> for <phrase>real world</phrase> industrial applications since it also yielded <phrase>the best</phrase> performing policy in our ib setting. <phrase>compared to</phrase> other well established rl techniques pso p produced outstanding results in performance and robustness requiring only a relatively low <phrase>amount of</phrase> effort in finding adequate parameters or making complex design decisions.
<phrase>end to end</phrase> differentiable proving
we introduce <phrase>neural networks</phrase> for <phrase>end to end</phrase> differentiable proving of queries to knowledge bases by operating on dense <phrase>vector representations</phrase> of symbols. these <phrase>neural networks</phrase> are constructed recursively by taking inspiration from the backward chaining algorithm as used in prolog. specifically we replace symbolic unification with a differentiable computation on <phrase>vector representations</phrase> of symbols using a <phrase>radial basis function</phrase> kernel thereby combining symbolic reasoning with learning subsymbolic <phrase>vector representations</phrase>. <phrase>by using</phrase> <phrase>gradient descent</phrase> the resulting <phrase>neural network</phrase> can be trained to infer facts from a given incomplete <phrase>knowledge base</phrase>. it learns to i place representations of similar symbols in close proximity in a <phrase>vector space</phrase> ii make use of such similarities to prove queries iii induce logical rules and iv use provided and induced logical rules for multi hop reasoning. we demonstrate that this architecture outperforms complex a <phrase>state of</phrase> <phrase>the art</phrase> neural link prediction model on three out of four benchmark knowledge bases while at <phrase>the same</phrase> time inducing interpretable function free <phrase>first order logic</phrase> rules.
<phrase>multi agent</phrase> <phrase>actor critic</phrase> for mixed cooperative competitive environments
we explore <phrase>deep reinforcement learning</phrase> methods for <phrase>multi agent</phrase> domains. we begin by analyzing the difficulty of traditional algorithms in the <phrase>multi agent</phrase> case q learning is challenged by an inherent non stationarity of the environment while policy gradient suffers from a variance that increases as <phrase>the number of</phrase> agents grows. we then present an adaptation of <phrase>actor critic</phrase> methods that considers action policies of other agents and is <phrase>able to</phrase> successfully learn policies that require complex <phrase>multi agent</phrase> coordination. additionally we introduce a training regimen utilizing an ensemble of policies for each agent that <phrase>leads to</phrase> <phrase>more robust</phrase> <phrase>multi agent</phrase> policies. we show the strength of our approach <phrase>compared to</phrase> <phrase>existing methods</phrase> in cooperative <phrase>as well as</phrase> competitive scenarios where agent populations are <phrase>able to</phrase> discover various physical and informational coordination strategies.
getting deep recommenders fit bloom embeddings for sparse binary <phrase>input output</phrase> networks
recommendation algorithms that incorporate techniques from <phrase>deep learning</phrase> are becoming increasingly popular. <phrase>due to</phrase> the structure of the data coming from recommendation domains i.e. one hot encoded vectors of item preferences these algorithms <phrase>tend to</phrase> have large input and output dimensionalities that dominate their overall size. this makes them difficult <phrase>to train</phrase> <phrase>due to</phrase> the limited memory of graphical processing units and difficult to deploy on mobile devices with limited hardware. <phrase>to address</phrase> these difficulties we propose bloom embeddings a compression technique that can be <phrase>applied to</phrase> <phrase>the input</phrase> and output of <phrase>neural network</phrase> models dealing with sparse <phrase>high dimensional</phrase> binary coded instances. bloom embeddings are computationally efficient and <phrase>do not</phrase> seriously compromise the accuracy of <phrase>the model</phrase> up to 1 5 compression ratios. in some cases they even improve over <phrase>the original</phrase> accuracy with relative increases up to 12 . we evaluate bloom embeddings on 7 <phrase>data sets</phrase> and compare it against 4 alternative methods obtaining favorable results. we also discuss <phrase>a number of</phrase> further advantages of bloom embeddings <phrase>such as</phrase> on the fly constant time operation zero or marginal space requirements training time speedups or the fact that they <phrase>do not</phrase> require any change to the core model architecture or training configuration.
beyond <phrase>monte carlo</phrase> tree search playing go with deep alternative <phrase>neural network</phrase> and <phrase>long term</phrase> evaluation
<phrase>monte carlo</phrase> tree search mcts is extremely popular in computer go which determines each action by enormous simulations in a broad and deep search tree. however human experts select most actions by pattern analysis and careful evaluation <phrase>rather than</phrase> brute search of millions of future nteractions. in <phrase>this paper</phrase> we propose a computer go system that follows experts way of thinking and playing. our system <phrase>consists of</phrase> two parts. the first part is <phrase>a novel</phrase> deep alternative <phrase>neural network</phrase> dann used <phrase>to generate</phrase> candidates of next move. <phrase>compared with</phrase> existing <phrase>deep convolutional</phrase> <phrase>neural network</phrase> dcnn dann inserts recurrent layer after each convolutional layer and stacks them in <phrase>an alternative</phrase> manner. we show such setting can preserve more contexts of local features and its evolutions which are beneficial for move prediction. the second part is a <phrase>long term</phrase> evaluation lte module used to provide a reliable evaluation of candidates <phrase>rather than</phrase> <phrase>a single</phrase> probability from move predictor. this is consistent with human experts nature of playing since they can foresee tens of steps to give an accurate estimation of candidates. in our system for each candidate lte calculates a cumulative reward after several future interactions when local variations are settled. combining criteria from the two parts our system determines the optimal <phrase>choice of</phrase> next move. for more comprehensive experiments we introduce <phrase>a new</phrase> professional go dataset pgd <phrase>consisting of</phrase> 253233 professional records. <phrase>experiments on</phrase> gogod and pgd datasets show the dann can substantially <phrase>improve performance</phrase> of move prediction over pure dcnn. when combining lte our system outperforms most relevant approaches and open engines <phrase>based on</phrase> mcts.
hindsight experience replay
dealing with sparse rewards is one of the biggest challenges in <phrase>reinforcement learning</phrase> rl . we present <phrase>a novel</phrase> technique called hindsight experience replay which allows sample efficient learning from rewards which are sparse and binary and therefore avoid <phrase>the need for</phrase> complicated reward engineering. it can be <phrase>combined with</phrase> an arbitrary off policy rl algorithm and may be seen as a form of implicit curriculum. we demonstrate our approach on <phrase>the task of</phrase> manipulating objects with a <phrase>robotic arm</phrase>. <phrase>in particular</phrase> we run <phrase>experiments on</phrase> <phrase>three different</phrase> tasks pushing sliding and pick and place in each case using only binary rewards indicating whether or not the task is completed. our ablation studies show that hindsight experience replay is a crucial ingredient which makes training possible in these challenging environments. we show that our policies <phrase>trained on</phrase> a physics simulation can be deployed on a physical robot and successfully complete the task.
trial without error towards safe <phrase>reinforcement learning</phrase> via human intervention
ai systems are increasingly <phrase>applied to</phrase> complex tasks that involve interaction with humans. <phrase>during training</phrase> such systems are potentially dangerous as they haven t yet learned to avoid actions that could cause serious harm. how can an ai system explore and learn without making <phrase>a single</phrase> mistake that harms humans or otherwise causes serious damage for model free <phrase>reinforcement learning</phrase> having a human in the loop and ready to intervene is currently the only way to prevent all catastrophes. we formalize human intervention for rl and show how <phrase>to reduce</phrase> the human labor required by training a supervised learner to imitate the human s intervention decisions. we evaluate this scheme on <phrase>atari games</phrase> with a deep rl agent being overseen by a human for four hours. when the class of catastrophes is simple we are <phrase>able to</phrase> prevent all catastrophes without affecting the agent s learning whereas an rl baseline fails <phrase>due to</phrase> catastrophic forgetting . however this scheme is less successful when catastrophes are more complex it reduces but <phrase>does not</phrase> eliminate catastrophes and the supervised learner fails on <phrase>adversarial examples</phrase> found by the agent. extrapolating to more challenging environments we show that our implementation would not scale <phrase>due to</phrase> the infeasible <phrase>amount of</phrase> human labor required . we outline extensions of the scheme that are necessary if we are <phrase>to train</phrase> model free agents without <phrase>a single</phrase> catastrophe.
reverse curriculum generation for <phrase>reinforcement learning</phrase>
many relevant tasks require <phrase>an agent</phrase> to reach a certain state or to manipulate objects into a desired configuration. for example we might want a robot to align and assemble a gear onto an axle or insert and turn a key in a lock. these <phrase>goal oriented</phrase> tasks present a considerable challenge for <phrase>reinforcement learning</phrase> since their natural reward function is sparse and prohibitive <phrase>amounts of</phrase> exploration are required to reach the goal and receive some learning signal. past approaches tackle these problems by exploiting expert demonstrations or by manually designing a <phrase>task specific</phrase> reward shaping function to guide the learning agent. instead we propose a method <phrase>to learn</phrase> these tasks <phrase>without requiring</phrase> any <phrase>prior knowledge</phrase> other than obtaining <phrase>a single</phrase> state in which the task is achieved. the robot is trained in reverse gradually learning to reach the goal from <phrase>a set of</phrase> start states increasingly far from the goal. our method automatically generates a curriculum of start states that adapts to the agent s performance <phrase>leading to</phrase> efficient training on <phrase>goal oriented</phrase> tasks. we demonstrate our approach on difficult simulated navigation and <phrase>fine grained</phrase> manipulation problems not solvable by <phrase>state of</phrase> <phrase>the art</phrase> <phrase>reinforcement learning</phrase> methods.
ideological sublations resolution of dialectic in population based optimization
a population based optimization algorithm was designed <phrase>inspired by</phrase> two main thinking modes in philosophy both <phrase>based on</phrase> dialectic concept and thesis antithesis paradigm. they impose two different kinds of dialectics. idealistic and materialistic antitheses are formulated as optimization models. <phrase>based on</phrase> the models the population is coordinated for dialectical interactions. at the population based context the formulated optimization models are reduced to <phrase>a simple</phrase> detection problem for each thinker particle . <phrase>according to</phrase> the assigned thinking mode to each thinker and her his measurements of corresponding dialectic with other candidate particles they deterministically decide to interact with a thinker in maximum dialectic with their theses. the position of a thinker at maximum dialectic is <phrase>known as</phrase> an available antithesis among the existing solutions. the dialectical interactions at each ideological community are distinguished by meaningful distributions of step sizes for each thinking mode. in fact the thinking modes are regarded as exploration and exploitation elements of <phrase>the proposed</phrase> algorithm. the result is a delicate balance without any requirement for adjustment of step size coefficients. main parameter of <phrase>the proposed</phrase> algorithm is <phrase>the number of</phrase> particles appointed to each thinking modes or equivalently for each <phrase>kind of</phrase> motions. an additional integer parameter is defined to boost the stability of <phrase>the final</phrase> algorithm in some particular problems. <phrase>the proposed</phrase> algorithm is evaluated by a testbed of 12 single objective continuous benchmark functions. moreover its performance and speed were highlighted in sparse reconstruction and antenna selection problems at <phrase>the context of</phrase> <phrase>compressed sensing</phrase> and massive mimo respectively. the results indicate fast and efficient performance in comparison with <phrase>well known</phrase> <phrase>evolutionary algorithms</phrase> and dedicated <phrase>state of</phrase> <phrase>the art</phrase> algorithms.
projectionnet learning efficient on device <phrase>deep networks</phrase> using neural projections
<phrase>deep neural networks</phrase> have become ubiquitous for applications <phrase>related to</phrase> visual recognition and <phrase>language understanding</phrase> tasks. however it is often prohibitive to use typical <phrase>neural networks</phrase> on devices like <phrase>mobile phones</phrase> or smart watches since <phrase>the model</phrase> sizes are huge and cannot fit in the limited memory available on such devices. while these devices could make use of <phrase>machine learning</phrase> models running on high performance <phrase>data centers</phrase> with cpus or gpus this is not feasible for <phrase>many applications</phrase> because data can be privacy sensitive and inference <phrase>needs to</phrase> be performed directly on device. we introduce <phrase>a new</phrase> architecture for training compact <phrase>neural networks</phrase> using a joint optimization framework. at its core lies <phrase>a novel</phrase> objective that jointly trains using two different <phrase>types of</phrase> networks a full trainer <phrase>neural network</phrase> using existing architectures like <phrase>feed forward</phrase> nns or lstm rnns <phrase>combined with</phrase> a simpler projection network that leverages random projections to transform inputs or intermediate representations into bits. the simpler network encodes lightweight and efficient to compute operations in bit space with a low <phrase>memory footprint</phrase>. the two networks are trained jointly using backpropagation where the projection network learns from the full network <phrase>similar to</phrase> apprenticeship learning. once trained the smaller network can be used directly for inference at low memory and computation cost. we demonstrate <phrase>the effectiveness of</phrase> the new approach at significantly shrinking the memory requirements of different <phrase>types of</phrase> <phrase>neural networks</phrase> while preserving good accuracy on visual recognition and <phrase>text classification</phrase> tasks. we also study the question how many neural bits are required <phrase>to solve</phrase> a given task using the new framework and show empirical results contrasting model predictive capacity in bits versus accuracy on several datasets.
a flow model of <phrase>neural networks</phrase>
<phrase>based on</phrase> a natural connection between resnet and transport equation or its characteristic equation we propose a continuous flow model for both resnet and plain net. through this continuous model a resnet can be explicitly constructed as a refinement of a plain net. the flow model provides <phrase>an alternative</phrase> perspective <phrase>to understand</phrase> phenomena in <phrase>deep neural networks</phrase> <phrase>such as</phrase> why it is necessary and sufficient to use 2 layer blocks in resnets why deeper is better and why resnets are even deeper and so on. it also opens a gate to bring in more tools from the huge area of <phrase>differential equations</phrase>.
multimodal <phrase>content analysis</phrase> for effective advertisements on youtube
the rapid <phrase>advances in</phrase> <phrase>e commerce</phrase> and <phrase>web 2.0</phrase> technologies have greatly increased the impact of commercial advertisements on the general public. as a key enabling technology a multitude of recommender systems exists which analyzes user features and browsing patterns to recommend appealing advertisements to users. in <phrase>this work</phrase> we <phrase>seek to</phrase> study the characteristics or attributes that characterize <phrase>an effective</phrase> advertisement and recommend a useful <phrase>set of</phrase> features to aid the designing and production processes of commercial advertisements. we analyze the temporal patterns from multimedia content of advertisement videos including auditory visual and textual components and study their individual roles and synergies in the success of an advertisement. the objective of <phrase>this work</phrase> is then to measure <phrase>the effectiveness of</phrase> an advertisement and to recommend a useful <phrase>set of</phrase> features to advertisement designers to make it more successful and approachable to users. our <phrase>proposed framework</phrase> employs the <phrase>signal processing</phrase> technique of cross modality <phrase>feature learning</phrase> where data streams from different components are employed <phrase>to train</phrase> separate <phrase>neural network</phrase> models and are then fused together <phrase>to learn</phrase> a shared representation. subsequently <phrase>a neural network</phrase> model <phrase>trained on</phrase> this joint feature embedding representation is utilized as a classifier <phrase>to predict</phrase> advertisement effectiveness. we validate our approach using subjective ratings from a dedicated user study the sentiment strength of online viewer comments and a viewer opinion metric of the ratio of the likes and views received by each advertisement from an online platform.
overcoming exploration in <phrase>reinforcement learning</phrase> with demonstrations
exploration in environments with sparse rewards has been a persistent problem in <phrase>reinforcement learning</phrase> rl . many tasks are natural to specify with a sparse reward and manually shaping a reward function can result in suboptimal performance. however finding a non zero reward is exponentially more difficult with increasing task horizon or action dimensionality. this puts many <phrase>real world</phrase> tasks out of practical reach of rl methods. in <phrase>this work</phrase> we use demonstrations <phrase>to overcome</phrase> the exploration problem and successfully learn <phrase>to perform</phrase> long horizon multi step robotics tasks with continuous control <phrase>such as</phrase> stacking blocks with a robot arm. our method which builds on top of deep deterministic policy gradients and hindsight experience replay provides an order <phrase>of magnitude</phrase> of speedup over rl on simulated robotics tasks. it is simple to implement and makes only the additional assumption that we can collect <phrase>a small</phrase> <phrase>set of</phrase> demonstrations. furthermore our method is <phrase>able to</phrase> solve tasks not solvable by either rl or behavior cloning alone and often ends up outperforming the demonstrator policy.
lattice recurrent unit improving convergence and statistical efficiency for <phrase>sequence modeling</phrase>
<phrase>recurrent neural networks</phrase> have shown remarkable success in modeling sequences. however low resource situations still adversely affect the generalizability of <phrase>these models</phrase>. we introduce <phrase>a new</phrase> <phrase>family of</phrase> models called lattice recurrent units lru <phrase>to address</phrase> the challenge of learning deep <phrase>multi layer</phrase> recurrent models with limited resources. lru models achieve this goal by creating distinct but coupled flow of information inside the units a first flow along time dimension and a second flow along depth dimension. it also offers a symmetry in how information can flow horizontally and vertically. we analyze the effects of decoupling <phrase>three different</phrase> components of our lru model reset gate update gate and projected state. we evaluate this family on new lru models on computational convergence rates and statistical efficiency. our experiments are performed on four <phrase>publicly available</phrase> datasets comparing with grid lstm and recurrent highway networks. our <phrase>results show</phrase> that lru has better empirical computational convergence rates and statistical efficiency values <phrase>along with</phrase> learning <phrase>more accurate</phrase> <phrase>language models</phrase>.
scalable recollections for continual <phrase>lifelong learning</phrase>
given the recent success of <phrase>deep learning</phrase> <phrase>applied to</phrase> <phrase>a variety of</phrase> single tasks it is natural to consider more human realistic settings. perhaps the most difficult of these settings is that of continual <phrase>lifelong learning</phrase> where <phrase>the model</phrase> must learn online over a continuous stream of non stationary data. a continual <phrase>lifelong learning</phrase> system must have three primary capabilities to succeed it must learn and adapt over time it must not forget what it has learned and it must be efficient in both training time and memory. recent techniques have focused their efforts largely on the first two capabilities while the third capability remains largely unexplored. in <phrase>this paper</phrase> we consider <phrase>the problem of</phrase> efficient and effective storage of experiences over very large time frames. <phrase>in particular</phrase> we consider the case where typical experiences are n bits and memories are limited to k bits for k n. we present <phrase>a novel</phrase> scalable architecture and training algorithm in this challenging domain and provide an extensive evaluation of its performance. our <phrase>results show</phrase> that we can achieve considerable gains on top of <phrase>state of</phrase> <phrase>the art</phrase> methods <phrase>such as</phrase> gem.
hidden tree markov networks deep and wide learning for structured data
the <phrase>paper introduces</phrase> the hidden tree markov network htn a neuro probabilistic hybrid fusing the representation power of <phrase>generative models</phrase> for trees with the incremental and discriminative learning capabilities of <phrase>neural networks</phrase>. we put forward a modular architecture in which multiple <phrase>generative models</phrase> of limited complexity are trained <phrase>to learn</phrase> structural feature detectors whose outputs are then combined and integrated by neural layers at a later stage. in this respect <phrase>the model</phrase> is both deep thanks to the unfolding of the <phrase>generative models</phrase> on <phrase>the input</phrase> structures <phrase>as well as</phrase> wide given the potentially <phrase>large number of</phrase> generative modules that can be trained in parallel. <phrase>experimental results</phrase> show that <phrase>the proposed</phrase> approach can outperform <phrase>state of</phrase> <phrase>the art</phrase> syntactic kernels <phrase>as well as</phrase> generative kernels built on <phrase>the same</phrase> probabilistic model as the htn.
hierarchical <phrase>actor critic</phrase>
the <phrase>ability to</phrase> learn at different resolutions in time may help overcome one of the main challenges in <phrase>deep reinforcement learning</phrase> sample efficiency. hierarchical agents that operate at different levels of temporal abstraction can learn tasks more quickly because they can divide the work of learning behaviors among multiple policies and can also explore the environment at a <phrase>higher level</phrase>. in <phrase>this paper</phrase> we present <phrase>a novel</phrase> <phrase>approach to</phrase> hierarchical <phrase>reinforcement learning</phrase> called hierarchical <phrase>actor critic</phrase> hac that enables agents <phrase>to learn</phrase> to break down problems involving continuous action spaces into simpler subproblems belonging to different time scales. hac has two key advantages over most existing hierarchical <phrase>learning methods</phrase> i the potential for faster learning as agents learn short policies at each level of the hierarchy and ii <phrase>an end to end</phrase> approach. we demonstrate that hac significantly accelerates learning in <phrase>a series of</phrase> tasks that require behavior over a relatively long time horizon and involve sparse rewards.
proximodistal exploration in <phrase>motor learning</phrase> as an emergent property of optimization
to harness <phrase>the complexity of</phrase> their <phrase>high dimensional</phrase> bodies during sensorimotor development infants are guided by patterns of freezing and freeing of degrees of freedom. for instance when learning to reach infants free the degrees of freedom in their arm proximodistally i.e. from joints that are closer to the body to those that are more distant. here we formulate and study computationally the hypothesis that such patterns can emerge spontaneously as the result of a <phrase>family of</phrase> <phrase>stochastic optimization</phrase> processes evolution strategies with <phrase>covariance matrix</phrase> adaptation without an innate encoding of a maturational schedule. <phrase>in particular</phrase> we present simulated experiments with an arm where a computational learner progressively acquires reaching skills through adaptive exploration and we show that a proximodistal organization appears spontaneously which we denote pdff proximodistal freezing and freeing of degrees of freedom . we also compare this emergent organization between different arm morphologies from human like to quite unnatural ones to study <phrase>the effect of</phrase> different kinematic structures on the emergence of pdff. keywords human <phrase>motor learning</phrase> proximo distal exploration <phrase>stochastic optimization</phrase> modelling evolution strategies <phrase>cross entropy</phrase> methods policy search morphology. 
null dynamical state models of human cognitive dysfunction
the hard problem in <phrase>artificial intelligence</phrase> asks how the shuffling of syntactical symbols in a program can <phrase>lead to</phrase> systems which experience semantics and qualia. we address this question in three stages. first we introduce <phrase>a new</phrase> class of human semantic symbols which appears when unexpected and drastic <phrase>environmental change</phrase> causes humans to become surprised confused uncertain and in extreme cases unresponsive passive and dysfunctional. for this class of symbols pre learned programs become inoperative so these syntactical programs cannot be the source of experienced qualia. second we model the dysfunctional human response to a radically changed environment as being the natural response of any learning machine facing novel inputs from well outside its previous <phrase>training set</phrase>. in this situation <phrase>learning machines</phrase> are unable <phrase>to extract</phrase> information from their input and will typically enter a dynamical state characterized by null outputs and a lack of response. this state immediately predicts and explains the characteristics of the semantic experiences of humans in similar circumstances. in the third stage we consider <phrase>learning machines</phrase> trained to implement multiple functions in simple sequential programs using environmental data to specify subroutine names <phrase>control flow</phrase> instructions memory calls and so on. drastic change in any of these environmental inputs can again <phrase>lead to</phrase> inoperative programs. by examining changes specific to people or locations we can model human cognitive symbols featuring these dependencies <phrase>such as</phrase> attachment and grief. our approach links known dynamical machines states with human qualia and thus offers new insight into the hard problem of <phrase>artificial intelligence</phrase>.
accelerating <phrase>deep learning</phrase> with memcomputing
restricted <phrase>boltzmann machines</phrase> rbms and their extensions called deep belief networks are powerful <phrase>neural networks</phrase> that have found applications in the fields of <phrase>machine learning</phrase> and <phrase>big data</phrase>. the standard way to training <phrase>these models</phrase> resorts to an iterative unsupervised procedure <phrase>based on</phrase> <phrase>gibbs sampling</phrase> called contrastive divergence cd and additional supervised tuning via <phrase>back propagation</phrase>. however this procedure has been shown not to follow any gradient and can <phrase>lead to</phrase> suboptimal solutions. in <phrase>this paper</phrase> we show an efficient alternative to cd by means of simulations of digital memcomputing machines dmms . we test our approach on <phrase>pattern recognition</phrase> using a modified <phrase>version of</phrase> the mnist <phrase>data set</phrase>. dmms sample effectively the vast <phrase>phase space</phrase> given by <phrase>the model</phrase> distribution of the rbm and provide a very good approximation <phrase>close to</phrase> the optimum. this efficient search significantly reduces <phrase>the number of</phrase> pretraining iterations necessary to achieve a given level of accuracy <phrase>as well as</phrase> a total performance gain over cd. in fact the acceleration of pretraining <phrase>achieved by</phrase> simulating dmms is <phrase>comparable to</phrase> in <phrase>number of</phrase> iterations the recently reported hardware <phrase>application of</phrase> the quantum annealing method on <phrase>the same</phrase> network and <phrase>data set</phrase>. notably however dmms perform far <phrase>better than</phrase> the reported quantum annealing results <phrase>in terms of</phrase> quality of the training. we also compare our method to <phrase>advances in</phrase> supervised training like <phrase>batch normalization</phrase> and rectifiers that work <phrase>to reduce</phrase> the <phrase>advantage of</phrase> pretraining. we find that the memcomputing method still maintains a quality advantage 1 in accuracy and <phrase>a 20</phrase> <phrase>reduction in</phrase> <phrase>error rate</phrase> over <phrase>these approaches</phrase>. furthermore our method is agnostic about the connectivity of <phrase>the network</phrase>. therefore it can be extended <phrase>to train</phrase> full <phrase>boltzmann machines</phrase> and even <phrase>deep networks</phrase> at once.
mvn2vec preservation and collaboration in <phrase>multi view</phrase> network embedding
<phrase>multi view</phrase> networks are ubiquitous in <phrase>real world</phrase> applications. <phrase>in order to</phrase> extract knowledge or business value it is of interest to transform such networks into representations that are easily machine actionable. meanwhile network embedding has emerged as <phrase>an effective</phrase> <phrase>approach to</phrase> generate distributed network representations. therefore we are motivated to study <phrase>the problem of</phrase> <phrase>multi view</phrase> network embedding with a <phrase>focus on</phrase> the characteristics that are specific and important in embedding this <phrase>type of</phrase> networks. in our practice of embedding <phrase>real world</phrase> <phrase>multi view</phrase> networks we identify two such characteristics which we refer to as preservation and collaboration. we then explore the feasibility of achieving better embedding quality by simultaneously modeling preservation and collaboration and propose the mvn2vec algorithms. with <phrase>experiments on</phrase> <phrase>a series of</phrase> synthetic datasets an internal snapchat dataset and two public datasets we further confirm the presence and importance of preservation and collaboration. these experiments also demonstrate that better embedding can be <phrase>obtained by</phrase> simultaneously modeling the two characteristics while not over complicating <phrase>the model</phrase> or requiring additional supervision.
granger causal attentive mixtures of experts
several methods have recently been proposed to detect salient <phrase>input features</phrase> for outputs of <phrase>neural networks</phrase>. those methods offer a qualitative glimpse at feature importance but they fall short of providing quantifiable attributions that can be compared across decisions and measures of the expected quality of their explanations. <phrase>to address</phrase> these shortcomings we present an attentive mixture of experts ame that couples attentive gating with a granger causal objective to jointly produce accurate predictions <phrase>as well as</phrase> measures of feature importance. we demonstrate the utility of ames by determining factors driving demand for medical prescriptions comparing predictive features for parkinson s disease and pinpointing discriminatory genes across cancer types.
memorize or generalize searching for a compositional rnn in a haystack
<phrase>neural networks</phrase> are very powerful learning systems but they <phrase>do not</phrase> readily generalize from one task to the other. this is partly <phrase>due to</phrase> the fact that they <phrase>do not</phrase> learn in a compositional way that is by discovering skills that are shared by different tasks and recombining them <phrase>to solve</phrase> new problems. in <phrase>this paper</phrase> we explore the compositional generalization capabilities of <phrase>recurrent neural networks</phrase> rnns . we first propose the <phrase>lookup table</phrase> composition domain as <phrase>a simple</phrase> setup to test compositional behaviour and show that it is theoretically possible for a standard rnn <phrase>to learn</phrase> to behave compositionally in this domain when trained with standard <phrase>gradient descent</phrase> and provided with additional supervision. we then remove this additional supervision and perform a search over <phrase>a large number of</phrase> model initializations to investigate the proportion of rnns that can still converge to a compositional solution. we discover that <phrase>a small</phrase> but non negligible proportion of rnns do reach partial compositional solutions even without special architectural constraints. this suggests that a <phrase>combination of</phrase> <phrase>gradient descent</phrase> and evolutionary strategies directly favouring the minority models that developed more compositional approaches might suffice to lead standard rnns towards compositional solutions.
continual <phrase>reinforcement learning</phrase> with complex synapses
unlike humans who are <phrase>capable of</phrase> continual learning over their lifetimes <phrase>artificial neural networks</phrase> have long been known to <phrase>suffer from</phrase> a phenomenon <phrase>known as</phrase> catastrophic forgetting whereby new learning can <phrase>lead to</phrase> abrupt erasure of previously acquired knowledge. whereas in <phrase>a neural network</phrase> the parameters are typically modelled as scalar values an individual synapse in the brain comprises a <phrase>complex network</phrase> of interacting biochemical components that evolve at different timescales. in <phrase>this paper</phrase> we show that by equipping tabular and <phrase>deep reinforcement learning</phrase> agents with a synaptic model that incorporates this biological complexity benna fusi 2016 catastrophic forgetting can be mitigated at multiple timescales. <phrase>in particular</phrase> we find that <phrase>as well as</phrase> enabling continual learning across sequential training of two simple tasks it can also be used <phrase>to overcome</phrase> within task forgetting by reducing <phrase>the need for</phrase> an experience replay database.
meta <phrase>reinforcement learning</phrase> of structured exploration strategies
exploration is a fundamental challenge in <phrase>reinforcement learning</phrase> rl . many of the current exploration methods for deep rl use task agnostic objectives <phrase>such as</phrase> information gain or bonuses <phrase>based on</phrase> state visitation. however many practical applications of rl involve learning <phrase>more than</phrase> <phrase>a single</phrase> task and prior tasks can be used to inform how exploration should be performed in new tasks. in <phrase>this work</phrase> we explore how prior tasks can inform <phrase>an agent</phrase> about how to explore effectively in new situations. we introduce <phrase>a novel</phrase> <phrase>gradient based</phrase> fast adaptation algorithm model agnostic exploration with structured noise maesn <phrase>to learn</phrase> exploration strategies from prior experience. the prior experience is used both to initialize a policy and to acquire a latent exploration space that can inject structured stochasticity into a policy producing exploration strategies that are informed by <phrase>prior knowledge</phrase> and are <phrase>more effective</phrase> than random action space noise. we show that maesn is <phrase>more effective</phrase> at learning exploration strategies when <phrase>compared to</phrase> prior meta rl methods rl without learned exploration strategies and task agnostic exploration methods. we evaluate our method on <phrase>a variety of</phrase> simulated tasks locomotion with a wheeled robot locomotion with a quadrupedal walker and object manipulation.
approximation algorithms for cascading prediction models
we present an <phrase>approximation algorithm</phrase> that takes a pool of <phrase>pre trained</phrase> models as input and produces from it a cascaded model with similar accuracy but lower average case cost. <phrase>applied to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> imagenet classification models this yields up to a 2x <phrase>reduction in</phrase> <phrase>floating point</phrase> multiplications and up to a 6x <phrase>reduction in</phrase> average case memory i o. the auto generated cascades exhibit intuitive properties <phrase>such as</phrase> using lower resolution input for easier images and requiring higher prediction confidence when using a computationally cheaper model.
coloring black boxes visualization of <phrase>neural network</phrase> decisions
<phrase>neural networks</phrase> are commonly regarded as black boxes performing incomprehensible functions. for <phrase>classification problems</phrase> networks provide maps from <phrase>high dimensional</phrase> <phrase>feature space</phrase> to k dimensional image space. images of training vector are projected on polygon vertices providing visualization of network function. such visualization may show the dynamics of learning allow for comparison of different networks display training vectors around which potential problems may arise show differences <phrase>due to</phrase> regularization and optimization procedures investigate stability of network classification under perturbation of original vectors and place new data sample in relation to <phrase>training data</phrase> allowing for estimation of confidence in classification of a given sample. an illustrative example for the three class wine data and five class satimage data is described. the visualization method proposed here is <phrase>applicable to</phrase> any <phrase>black box</phrase> system that provides continuous outputs.
relational neural expectation maximization unsupervised discovery of objects and their interactions
common sense physical reasoning is an essential ingredient for any <phrase>intelligent agent</phrase> operating in the <phrase>real world</phrase>. for example it can be used to simulate the environment or to infer the <phrase>state of</phrase> <phrase>parts of</phrase> the world that are currently unobserved. <phrase>in order to</phrase> match <phrase>real world</phrase> conditions this causal knowledge must be learned without access to supervised data. <phrase>to address</phrase> <phrase>this problem</phrase> we present <phrase>a novel</phrase> method that learns <phrase>to discover</phrase> objects and model their physical interactions <phrase>from raw</phrase> visual images in a purely emph unsupervised fashion. it incorporates <phrase>prior knowledge</phrase> about the compositional nature of <phrase>human perception</phrase> to factor interactions between object pairs and learn efficiently. on videos of bouncing balls we show the superior modelling capabilities of our method <phrase>compared to</phrase> other unsupervised neural approaches that <phrase>do not</phrase> incorporate such <phrase>prior knowledge</phrase>. we demonstrate its <phrase>ability to</phrase> handle occlusion and show that it can extrapolate learned knowledge to scenes with different numbers of objects.
a bayesian model for activities recommendation and event structure optimization using visitors tracking
in events that are composed by many activities there is a problem that involves retrieve and management the information of visitors that are visiting the activities. this management is crucial to find some activities that are drawing attention of visitors identify an ideal positioning for activities which path is more frequented by visitors. in <phrase>this work</phrase> these features are studied using <phrase>complex network</phrase> theory. for the beginning an artificial database was generated to study the mentioned features. secondly <phrase>this work</phrase> shows a method to optimize the event structure that is <phrase>better than</phrase> a random method and a recommendation system that achieves 95 of accuracy.
the lottery ticket hypothesis training pruned <phrase>neural networks</phrase>
<phrase>recent work</phrase> on <phrase>neural network</phrase> pruning indicates that at training time <phrase>neural networks</phrase> <phrase>need to</phrase> be significantly larger in size than is necessary <phrase>to represent</phrase> the eventual functions that they learn. <phrase>this paper</phrase> articulates <phrase>a new</phrase> hypothesis to explain this phenomenon. this conjecture which we term the lottery ticket hypothesis proposes that successful training <phrase>depends on</phrase> lucky random initialization of a smaller subcomponent of <phrase>the network</phrase>. larger networks have more of these lottery tickets meaning they are more likely to luck out with a subcomponent initialized in a configuration amenable to successful optimization. <phrase>this paper</phrase> conducts <phrase>a series of</phrase> experiments with xor and mnist that support the lottery ticket hypothesis. <phrase>in particular</phrase> we identify these fortuitously initialized subcomponents by pruning low magnitude weights from trained networks. we then demonstrate that these subcomponents can be successfully retrained in isolation so long as the subnetworks are given <phrase>the same</phrase> initializations as they had at the beginning of the training process. initialized as such these small networks reliably converge successfully often <phrase>faster than</phrase> <phrase>the original</phrase> network at <phrase>the same</phrase> level of accuracy. however when these subcomponents are randomly reinitialized or rearranged they perform worse than <phrase>the original</phrase> network. in other words large networks that train successfully contain small subnetworks with initializations conducive to optimization. the lottery ticket hypothesis and its connection to pruning are a step toward developing architectures initializations and training strategies that make it possible <phrase>to solve</phrase> <phrase>the same</phrase> problems with much smaller networks.
learning recurrent dynamics in spiking networks
spiking activity of neurons engaged in learning and performing a task show complex spatiotemporal dynamics. while the output of <phrase>recurrent network</phrase> models can learn <phrase>to perform</phrase> various tasks the possible range of recurrent dynamics that emerge after learning remains unknown. here we show that modifying the recurrent connectivity with a recursive least squares algorithm provides sufficient flexibility for synaptic and spiking rate dynamics of spiking networks <phrase>to produce</phrase> <phrase>a wide range of</phrase> spatiotemporal activity. we apply the training method <phrase>to learn</phrase> arbitrary firing patterns stabilize irregular spiking activity of a balanced network and reproduce the heterogeneous spiking rate patterns of cortical neurons engaged in motor planning and movement. we identify sufficient conditions for successful learning characterize two <phrase>types of</phrase> learning errors and assess <phrase>the network</phrase> capacity. our findings show that synaptically coupled recurrent spiking networks possess a vast computational capability that can support the diverse activity patterns in the brain.
principal graphs and manifolds
in many physical statistical biological and other investigations it is desirable to approximate a system of points by objects of lower dimension and or complexity. for this purpose <phrase>karl pearson</phrase> invented <phrase>principal component analysis</phrase> in 1901 and found lines and planes of closest fit to system of points . the famous k means algorithm solves the approximation problem too but by finite sets <phrase>instead of</phrase> lines and planes. this chapter gives a brief practical introduction into the methods of construction of general principal objects i.e. objects embedded in the middle of the multidimensional <phrase>data set</phrase>. as a basis the unifying framework of mean squared distance approximation of finite datasets is selected. principal graphs and manifolds are constructed as generalisations of principal components and k means principal points. for this purpose the <phrase>family of</phrase> expectation maximisation algorithms with nearest generalisations is presented. construction of principal graphs with controlled complexity is <phrase>based on</phrase> the graph grammar approach.
sparse penalty in deep belief networks using the mixed norm constraint
deep belief networks dbn have been successfully applied on popular <phrase>machine learning</phrase> tasks. specifically when applied on hand written digit recognition dbns have achieved approximate accuracy rates of 98.8 . in an effort to optimize the data representation <phrase>achieved by</phrase> the dbn and maximize their descriptive power <phrase>recent advances</phrase> have <phrase>focused on</phrase> inducing sparse constraints at <phrase>each layer</phrase> of the dbn. in <phrase>this paper</phrase> we present a theoretical approach for sparse constraints in the dbn using the mixed norm for both non overlapping and overlapping groups. we explore how these constraints affect the <phrase>classification accuracy</phrase> for digit recognition in <phrase>three different</phrase> datasets mnist usps rimes and provide initial estimations of their usefulness by altering different parameters <phrase>such as</phrase> the group size and overlap percentage.
understanding dropout training <phrase>multi layer</phrase> perceptrons with auxiliary independent stochastic neurons
in <phrase>this paper</phrase> <phrase>a simple</phrase> general method of adding auxiliary stochastic neurons to a <phrase>multi layer</phrase> perceptron is proposed. it is shown that <phrase>the proposed</phrase> method is a generalization of recently successful methods of dropout hinton <phrase>et al</phrase>. 2012 explicit noise injection vincent <phrase>et al</phrase>. 2010 bishop 1995 and semantic hashing salakhutdinov hinton 2009 . under <phrase>the proposed</phrase> framework an extension of dropout which allows using separate dropping probabilities for different hidden neurons or layers is found to be available. <phrase>the use of</phrase> different dropping probabilities for <phrase>hidden layers</phrase> separately is empirically investigated.
locally imposing function for generalized constraint <phrase>neural networks</phrase> a study on equality constraints
<phrase>this work</phrase> is a further study on the generalized constraint <phrase>neural network</phrase> gcnn model 1 2 . two challenges are encountered in the study that is to embed any <phrase>type of</phrase> prior information and <phrase>to select</phrase> its imposing schemes. the work <phrase>focuses on</phrase> the second challenge and studies <phrase>a new</phrase> constraint imposing scheme for equality constraints. <phrase>a new</phrase> method called locally imposing function lif is proposed to provide a local correction to the gcnn prediction function which therefore falls within locally imposing scheme lis . in comparison the conventional <phrase>lagrange multiplier</phrase> method is considered as globally imposing scheme gis because its added constraint term exhibits a global impact to its <phrase>objective function</phrase>. two advantages are gained from lis over gis. first lis enables constraints to fire locally and explicitly in the domain only where they need on the prediction function. second constraints can be implemented within a network setting directly. we <phrase>attempt to</phrase> interpret several constraint methods graphically from a viewpoint of the locality principle. numerical examples confirm the advantages of <phrase>the proposed</phrase> method. in solving boundary value problems with dirichlet and neumann constraints the gcnn model with lif is possible to achieve an exact satisfaction of the constraints.
evolution of covariance functions for <phrase>gaussian process</phrase> regression using <phrase>genetic programming</phrase>
in this contribution we describe an <phrase>approach to</phrase> evolve composite covariance functions for gaussian processes using <phrase>genetic programming</phrase>. a critical aspect of gaussian processes and similar kernel based models <phrase>such as</phrase> svm is that the covariance function should be adapted to the modeled data. frequently the squared exponential covariance function is <phrase>used as</phrase> a default. however this can <phrase>lead to</phrase> a misspecified model which <phrase>does not</phrase> fit the data well. in <phrase>the proposed</phrase> approach we use a grammar for the composition of covariance functions and <phrase>genetic programming</phrase> to search over the space of sentences that can be <phrase>derived from</phrase> the grammar. we tested <phrase>the proposed</phrase> approach on synthetic data from two dimensional test functions and on the <phrase>mauna loa</phrase> co2 <phrase>time series</phrase>. the <phrase>results show</phrase> that our approach is feasible finding covariance functions that perform much <phrase>better than</phrase> a default covariance function. for the co2 <phrase>data set</phrase> a composite covariance function is found that matches <phrase>the performance of</phrase> a hand tuned covariance function.
gaussian binary restricted <phrase>boltzmann machines</phrase> on modeling natural image statistics
we present a theoretical analysis of gaussian binary restricted <phrase>boltzmann machines</phrase> grbms from the perspective of density models. the key aspect of this analysis is to show that grbms can be formulated as a constrained mixture of gaussians which gives a much better insight into <phrase>the model</phrase> s capabilities and limitations. we show that grbms are <phrase>capable of</phrase> learning meaningful features both in a two dimensional blind source separation task and in modeling natural images. further we show that reported difficulties in training grbms are <phrase>due to</phrase> the failure of the training algorithm <phrase>rather than</phrase> <phrase>the model</phrase> itself. <phrase>based on</phrase> our analysis we are <phrase>able to</phrase> propose several training recipes which allowed successful and fast training in our experiments. finally we discuss the relationship of grbms to several modifications that have been proposed <phrase>to improve</phrase> <phrase>the model</phrase>.
training restricted boltzmann machine by perturbation
<phrase>a new approach</phrase> to <phrase>maximum likelihood</phrase> learning of discrete <phrase>graphical models</phrase> and rbm <phrase>in particular</phrase> is introduced. our method perturb and descend pd is <phrase>inspired by</phrase> two ideas i perturb and map <phrase>method for</phrase> sampling ii learning by contrastive divergence minimization. <phrase>in contrast to</phrase> perturb and map pd leverages <phrase>training data</phrase> <phrase>to learn</phrase> the models that <phrase>do not</phrase> allow efficient map estimation. during the learning <phrase>to produce</phrase> a sample from the current model we start from a <phrase>training data</phrase> and descend in the energy landscape of the perturbed model for <phrase>a fixed</phrase> <phrase>number of</phrase> steps or until a local optima is reached. for rbm this involves linear calculations and thresholding which can be very fast. furthermore we show that the <phrase>amount of</phrase> perturbation is closely <phrase>related to</phrase> the temperature parameter and it can regularize <phrase>the model</phrase> by producing robust features resulting in sparse <phrase>hidden layer</phrase> activation.
multilayer bootstrap networks
multilayer bootstrap network builds a gradually narrowed multilayer nonlinear network from bottom up for unsupervised nonlinear <phrase>dimensionality reduction</phrase>. <phrase>each layer</phrase> of <phrase>the network</phrase> is a nonparametric density estimator. it <phrase>consists of</phrase> a group of k centroids clusterings. each clustering randomly selects data points with randomly selected features as its centroids and learns a one hot encoder by one nearest neighbor optimization. geometrically the nonparametric density estimator at <phrase>each layer</phrase> projects <phrase>the input</phrase> data space to a uniformly distributed discrete <phrase>feature space</phrase> where the similarity of two data points in the discrete <phrase>feature space</phrase> is measured by <phrase>the number of</phrase> the nearest centroids they share in common. the multilayer network gradually reduces the nonlinear variations of data from bottom up by building a vast <phrase>number of</phrase> hierarchical trees implicitly on <phrase>the original</phrase> data space. theoretically the estimation error caused by the nonparametric density estimator is proportional to the correlation between the clusterings both of which are reduced by the randomization steps.
invariant backpropagation how <phrase>to train</phrase> a transformation invariant <phrase>neural network</phrase>
in many <phrase>classification problems</phrase> a classifier should be robust to small variations in <phrase>the input</phrase> vector. this is a desired property <phrase>not only</phrase> for particular transformations <phrase>such as</phrase> translation and rotation in <phrase>image classification</phrase> problems <phrase>but also</phrase> for all others for which the change is small enough to retain the object perceptually indistinguishable. we propose two extensions of the backpropagation algorithm that train <phrase>a neural network</phrase> to be robust to variations in the feature vector. while the first of them enforces robustness of the <phrase>loss function</phrase> to all variations the second method trains the predictions to be robust to a particular variation which changes the <phrase>loss function</phrase> the most. the second methods demonstrates better results but is slightly slower. we analytically compare <phrase>the proposed</phrase> algorithm with two the most similar approaches tangent bp and adversarial training and propose their fast versions. in the experimental part we perform comparison of all algorithms <phrase>in terms of</phrase> <phrase>classification accuracy</phrase> and robustness to noise on mnist and <phrase>cifar 10</phrase> datasets. additionally we analyze how <phrase>the performance of</phrase> <phrase>the proposed</phrase> algorithm <phrase>depends on</phrase> the dataset size and <phrase>data augmentation</phrase>.
shared latent subspace modelling within gaussian binary restricted <phrase>boltzmann machines</phrase> for nist i vector challenge 2014
<phrase>this paper</phrase> presents <phrase>a novel</phrase> <phrase>approach to</phrase> speaker subspace modelling <phrase>based on</phrase> gaussian binary restricted <phrase>boltzmann machines</phrase> grbm . <phrase>the proposed</phrase> model is <phrase>based on</phrase> the idea of shared factors as in the probabilistic <phrase>linear discriminant analysis</phrase> plda . grbm <phrase>hidden layer</phrase> is divided into speaker and channel factors herein the speaker factor is shared over all vectors of the speaker. then <phrase>maximum likelihood</phrase> parameter estimation mle for <phrase>proposed model</phrase> is introduced. various new scoring techniques for speaker verification using grbm are proposed. the results for nist i vector challenge 2014 dataset are presented.
a neural <phrase>transfer function</phrase> for a smooth and differentiable transition between additive and multiplicative interactions
<phrase>existing approaches</phrase> to combine both additive and multiplicative neural units either use <phrase>a fixed</phrase> assignment of operations or require discrete optimization to determine what function a neuron should perform. this leads either to an inefficient distribution of computational resources or an extensive increase in the <phrase>computational complexity</phrase> of the training procedure. we present <phrase>a novel</phrase> parameterizable <phrase>transfer function</phrase> <phrase>based on</phrase> the mathematical concept of non integer functional iteration that allows the operation each neuron performs to be smoothly and most importantly differentiablely adjusted between addition and multiplication. this allows the decision between addition and multiplication to be integrated into the standard backpropagation training procedure.
a probabilistic <phrase>framework for</phrase> <phrase>deep learning</phrase>
we develop a probabilistic <phrase>framework for</phrase> <phrase>deep learning</phrase> <phrase>based on</phrase> the deep rendering <phrase>mixture model</phrase> drmm <phrase>a new</phrase> generative probabilistic model that explicitly capture variations in data <phrase>due to</phrase> latent task nuisance variables. we demonstrate that max sum inference in the drmm yields an algorithm that exactly reproduces the operations in <phrase>deep convolutional neural networks</phrase> dcns providing a first principles derivation. our framework provides new insights into the successes and shortcomings of dcns <phrase>as well as</phrase> a principled route to their improvement. drmm training via the expectation maximization em algorithm is a powerful alternative to dcn <phrase>back propagation</phrase> and initial training results are promising. classification <phrase>based on</phrase> the drmm and other variants outperforms dcns in supervised digit classification training 2 3x faster while achieving similar accuracy. moreover the drmm is <phrase>applicable to</phrase> <phrase>semi supervised</phrase> and <phrase>unsupervised learning</phrase> tasks achieving results that are <phrase>state of</phrase> <phrase>the art</phrase> in several categories on the mnist benchmark and <phrase>comparable to</phrase> <phrase>state of</phrase> <phrase>the art</phrase> on the cifar10 benchmark.
neurogenesis <phrase>deep learning</phrase>
neural <phrase>machine learning</phrase> methods <phrase>such as</phrase> <phrase>deep neural networks</phrase> dnn have achieved remarkable success in <phrase>a number of</phrase> complex <phrase>data processing</phrase> tasks. these methods have arguably had their strongest impact on <phrase>tasks such as</phrase> image and audio processing <phrase>data processing</phrase> domains in which humans have long held clear advantages over conventional algorithms. <phrase>in contrast to</phrase> biological neural systems which are <phrase>capable of</phrase> learning continuously deep artificial networks have a limited ability for incorporating new information in an already trained network. as a result methods for continuous learning are potentially highly impactful in enabling the <phrase>application of</phrase> <phrase>deep networks</phrase> to dynamic <phrase>data sets</phrase>. here <phrase>inspired by</phrase> the process of adult neurogenesis in the hippocampus we explore the potential for adding new neurons to deep layers of <phrase>artificial neural networks</phrase> <phrase>in order to</phrase> facilitate their acquisition of novel information while preserving previously trained data representations. our <phrase>results on</phrase> the mnist handwritten digit dataset and the nist sd 19 dataset which includes lower and upper case letters and digits demonstrate that neurogenesis is well suited for addressing the stability plasticity dilemma that has long challenged adaptive <phrase>machine learning</phrase> algorithms.
<phrase>deep learning</phrase> for neuroimaging a validation study
<phrase>deep learning</phrase> methods have recently made notable <phrase>advances in</phrase> the tasks of classification and <phrase>representation learning</phrase>. these tasks are important for <phrase>brain imaging</phrase> and neuroscience discovery making the methods attractive for porting to a neuroimager s toolbox. success of these methods is in part explained by the flexibility of <phrase>deep learning</phrase> models. however this flexibility makes the process of porting to new areas a difficult parameter <phrase>optimization problem</phrase>. in <phrase>this work</phrase> we demonstrate our results and feasible parameter ranges in <phrase>application of</phrase> <phrase>deep learning</phrase> methods to structural and functional <phrase>brain imaging</phrase> data. we also describe <phrase>a novel</phrase> constraint <phrase>based approach</phrase> to visualizing <phrase>high dimensional</phrase> data. we use it to analyze <phrase>the effect of</phrase> parameter choices on data transformations. our <phrase>results show</phrase> that <phrase>deep learning</phrase> methods are <phrase>able to</phrase> learn physiologically important representations and detect latent relations in neuroimaging data.
improving <phrase>deep neural networks</phrase> with probabilistic maxout units
we present a probabilistic variant of the recently introduced maxout unit. the success of <phrase>deep neural networks</phrase> utilizing maxout can partly be attributed to favorable performance under dropout when <phrase>compared to</phrase> <phrase>rectified linear</phrase> units. it however also <phrase>depends on</phrase> the fact that each maxout unit performs a pooling operation over a group of linear transformations and is thus partially invariant to changes in its input. starting from this observation we ask the question can the desirable <phrase>properties of</phrase> maxout units be preserved while improving their invariance properties we argue that our probabilistic maxout probout units successfully achieve this balance. we quantitatively verify this claim and report <phrase>classification performance</phrase> matching or exceeding <phrase>the current state of</phrase> <phrase>the art</phrase> on three challenging <phrase>image classification</phrase> benchmarks <phrase>cifar 10</phrase> cifar 100 and svhn .
how many dissimilarity kernel <phrase>self organizing map</phrase> variants do we need 
in numerous applicative contexts data are too rich and too complex to be represented by numerical vectors. a general <phrase>approach to</phrase> extend <phrase>machine learning</phrase> and <phrase>data mining</phrase> techniques to such data is to really on a dissimilarity or on a kernel that measures how different or similar two objects are. <phrase>this approach</phrase> has been used to define several variants of the <phrase>self organizing map</phrase> som . <phrase>this paper</phrase> reviews those variants in using a common <phrase>set of</phrase> notations <phrase>in order to</phrase> outline differences and similarities between them. it discusses the advantages and drawbacks of the variants <phrase>as well as</phrase> the actual relevance of the dissimilarity kernel som for practical applications.
deep unfolding <phrase>model based</phrase> inspiration of novel deep architectures
<phrase>model based</phrase> methods and <phrase>deep neural networks</phrase> have both been tremendously successful paradigms in <phrase>machine learning</phrase>. in <phrase>model based</phrase> methods problem <phrase>domain knowledge</phrase> can be built into the constraints of <phrase>the model</phrase> typically at the expense of difficulties during inference. <phrase>in contrast</phrase> deterministic <phrase>deep neural networks</phrase> are constructed in such a way that inference is straightforward but their architectures are generic and it is unclear how to incorporate knowledge. <phrase>this work</phrase> aims <phrase>to obtain</phrase> the advantages of both approaches. to do so we start with a <phrase>model based</phrase> approach and an associated inference algorithm and emph unfold the inference iterations as layers in a <phrase>deep network</phrase>. <phrase>rather than</phrase> optimizing <phrase>the original</phrase> model we emph untie <phrase>the model</phrase> parameters across layers <phrase>in order to</phrase> create a <phrase>more powerful</phrase> network. the resulting architecture can be trained discriminatively <phrase>to perform</phrase> accurate inference within <phrase>a fixed</phrase> network size. we show how this framework allows us to interpret conventional networks as mean field inference in markov random fields and <phrase>to obtain</phrase> new architectures by instead using <phrase>belief propagation</phrase> as the inference algorithm. we then show its <phrase>application to</phrase> a non negative matrix factorization model that incorporates the problem <phrase>domain knowledge</phrase> that sound sources are additive. deep unfolding of this model yields <phrase>a new</phrase> <phrase>kind of</phrase> non negative <phrase>deep neural network</phrase> that can be trained using a multiplicative backpropagation style update algorithm. we present speech enhancement experiments showing that our approach is competitive with conventional <phrase>neural networks</phrase> despite using far <phrase>fewer parameters</phrase>.
learning deep dynamical models from image pixels
modeling <phrase>dynamical systems</phrase> is important in many disciplines e.g. control robotics or neurotechnology. commonly the <phrase>state of</phrase> these systems is not directly observed but only available through noisy and potentially <phrase>high dimensional</phrase> observations. in these cases system identification i.e. finding the measurement mapping and the transition mapping system dynamics in <phrase>latent space</phrase> can be challenging. for linear system dynamics and measurement mappings efficient solutions for system identification are available. however in practical applications the linearity assumptions <phrase>does not</phrase> hold requiring <phrase>non linear</phrase> system identification techniques. if additionally the observations are <phrase>high dimensional</phrase> e.g. images <phrase>non linear</phrase> system identification is inherently hard. <phrase>to address</phrase> <phrase>the problem of</phrase> <phrase>non linear</phrase> system identification from <phrase>high dimensional</phrase> observations we combine <phrase>recent advances in</phrase> <phrase>deep learning</phrase> and system identification. <phrase>in particular</phrase> we jointly learn a <phrase>low dimensional</phrase> embedding of the observation by means of deep auto encoders and a predictive transition model in this <phrase>low dimensional</phrase> space. we demonstrate that our model enables learning good predictive models of <phrase>dynamical systems</phrase> from pixel information only.
from neural pca to deep <phrase>unsupervised learning</phrase>
a network supporting deep <phrase>unsupervised learning</phrase> is presented. <phrase>the network</phrase> is an autoencoder with lateral shortcut connections from the encoder to decoder at each level of the hierarchy. the lateral shortcut connections allow the higher levels of the hierarchy to <phrase>focus on</phrase> abstract invariant features. while standard autoencoders are analogous to <phrase>latent variable</phrase> models with <phrase>a single</phrase> layer of stochastic variables <phrase>the proposed</phrase> network is analogous to hierarchical <phrase>latent variables</phrase> models. learning combines denoising autoencoder and denoising sources separation frameworks. <phrase>each layer</phrase> of <phrase>the network</phrase> contributes to the cost function a term which measures the distance of the representations <phrase>produced by</phrase> the encoder and the decoder. since training signals originate from all levels of <phrase>the network</phrase> all layers can learn efficiently even in <phrase>deep networks</phrase>. the speedup offered by cost terms from higher levels of the hierarchy and the <phrase>ability to</phrase> learn invariant features are demonstrated in experiments.
qualitatively characterizing <phrase>neural network</phrase> optimization problems
training <phrase>neural networks</phrase> involves solving <phrase>large scale</phrase> <phrase>non convex</phrase> optimization problems. <phrase>this task</phrase> has long been believed to be extremely difficult with fear of <phrase>local minima</phrase> and other obstacles motivating <phrase>a variety of</phrase> schemes <phrase>to improve</phrase> optimization <phrase>such as</phrase> unsupervised pretraining. however modern <phrase>neural networks</phrase> are <phrase>able to</phrase> achieve negligible training error on complex tasks using only direct training with <phrase>stochastic gradient descent</phrase>. we introduce <phrase>a simple</phrase> analysis technique to look for evidence that such networks are overcoming local optima. we find that in fact on a straight path from initialization to solution <phrase>a variety of</phrase> <phrase>state of</phrase> <phrase>the art</phrase> <phrase>neural networks</phrase> never encounter any significant obstacles.
why does <phrase>deep learning</phrase> work a perspective from <phrase>group theory</phrase>
why does <phrase>deep learning</phrase> work what representations does it capture how do higher order representations emerge we study these questions from the perspective of <phrase>group theory</phrase> thereby opening <phrase>a new</phrase> approach towards a theory of <phrase>deep learning</phrase>. one factor behind the recent resurgence of the subject is a key algorithmic step called <phrase>pre training</phrase> first search for a good <phrase>generative model</phrase> for <phrase>the input</phrase> samples and repeat the process one layer at a time. we show deeper implications of this simple principle by establishing a connection with the interplay of orbits and stabilizers of group actions. although the <phrase>neural networks</phrase> themselves may not form groups we show <phrase>the existence of</phrase> em shadow groups whose elements serve as close approximations. over the shadow groups the <phrase>pre training</phrase> step originally introduced as a mechanism to better initialize a network becomes equivalent to a search for features <phrase>with minimal</phrase> orbits. intuitively these features are in a way the em simplest . which explains why a <phrase>deep learning</phrase> network learns simple features first. next we show how <phrase>the same</phrase> principle when repeated in the deeper layers can capture higher order representations and why representation complexity increases as the layers get deeper.
adasecant robust adaptive secant <phrase>method for</phrase> <phrase>stochastic gradient</phrase>
<phrase>stochastic gradient</phrase> algorithms have been the main focus of <phrase>large scale</phrase> learning problems and they led to important successes in <phrase>machine learning</phrase>. the convergence of sgd <phrase>depends on</phrase> the careful <phrase>choice of</phrase> <phrase>learning rate</phrase> and the <phrase>amount of</phrase> the noise in stochastic estimates of the gradients. in <phrase>this paper</phrase> we propose <phrase>a new</phrase> adaptive <phrase>learning rate</phrase> algorithm which utilizes curvature information for automatically tuning the learning rates. the <phrase>information about</phrase> the element wise curvature of the <phrase>loss function</phrase> is estimated from the local statistics of the stochastic first order gradients. we further propose <phrase>a new</phrase> variance reduction technique to speed up the convergence. in our preliminary experiments with <phrase>deep neural networks</phrase> we obtained <phrase>better performance</phrase> <phrase>compared to</phrase> the popular <phrase>stochastic gradient</phrase> algorithms.
<phrase>a unified</phrase> perspective on multi domain and <phrase>multi task learning</phrase>
in <phrase>this paper</phrase> we provide <phrase>a new</phrase> <phrase>neural network</phrase> based perspective on <phrase>multi task learning</phrase> mtl and multi domain learning mdl . <phrase>by introducing</phrase> the concept of a semantic descriptor this framework unifies mdl and mtl <phrase>as well as</phrase> encompassing various classic and recent mtl mdl algorithms by interpreting them as different ways of constructing semantic descriptors. our interpretation provides <phrase>an alternative</phrase> pipeline for <phrase>zero shot</phrase> learning zsl where a model for <phrase>a novel</phrase> class can be constructed without <phrase>training data</phrase>. moreover it <phrase>leads to</phrase> <phrase>a new</phrase> and practically relevant problem setting of <phrase>zero shot</phrase> <phrase>domain adaptation</phrase> zsda which is the analogous to zsl but for novel domains a model for an unseen domain can be generated by its semantic descriptor. experiments across this range of problems demonstrate that our framework outperforms <phrase>a variety of</phrase> alternatives.
<phrase>a neural network</phrase> anomaly detector using the random cluster model
the random cluster model is used to define an upper bound on a distance measure as a function of <phrase>the number of</phrase> data points to be classified and the expected value of <phrase>the number of</phrase> classes to form in a hybrid k means and regression classification methodology with the intent of detecting anomalies. conditions are given for the identification of classes which contain anomalies and individual anomalies within identified classes. <phrase>a neural network</phrase> model describes the decision region separating surface for offline storage and recall in any new <phrase>anomaly detection</phrase>.
a group theoretic perspective on unsupervised <phrase>deep learning</phrase>
why does <phrase>deep learning</phrase> work what representations does it capture how do higher order representations emerge we study these questions from the perspective of <phrase>group theory</phrase> thereby opening <phrase>a new</phrase> approach towards a theory of <phrase>deep learning</phrase>. one factor behind the recent resurgence of the subject is a key algorithmic step called em pretraining first search for a good <phrase>generative model</phrase> for <phrase>the input</phrase> samples and repeat the process one layer at a time. we show deeper implications of this simple principle by establishing a connection with the interplay of orbits and stabilizers of group actions. although the <phrase>neural networks</phrase> themselves may not form groups we show <phrase>the existence of</phrase> em shadow groups whose elements serve as close approximations. over the shadow groups the <phrase>pre training</phrase> step originally introduced as a mechanism to better initialize a network becomes equivalent to a search for features <phrase>with minimal</phrase> orbits. intuitively these features are in a way the em simplest . which explains why a <phrase>deep learning</phrase> network learns simple features first. next we show how <phrase>the same</phrase> principle when repeated in the deeper layers can capture higher order representations and why representation complexity increases as the layers get deeper.
a <phrase>generative model</phrase> for <phrase>deep convolutional</phrase> learning
a <phrase>generative model</phrase> is developed for deep multi layered convolutional dictionary learning. <phrase>a novel</phrase> probabilistic pooling operation is integrated into the deep model yielding efficient bottom up pretraining and top down refinement probabilistic learning. <phrase>experimental results</phrase> demonstrate powerful capabilities of <phrase>the model</phrase> <phrase>to learn</phrase> <phrase>multi layer</phrase> features from images and excellent classification results are obtained on the mnist and caltech 101 datasets.
<phrase>knowledge transfer</phrase> <phrase>pre training</phrase>
<phrase>pre training</phrase> is crucial for learning <phrase>deep neural networks</phrase>. most of existing <phrase>pre training</phrase> methods train simple models e.g. restricted <phrase>boltzmann machines</phrase> and then stack them layer by layer to form the deep structure. this <phrase>layer wise</phrase> <phrase>pre training</phrase> has found strong theoretical foundation and broad empirical support. however it is not <phrase>easy to</phrase> employ such method to pre train models without a clear <phrase>multi layer</phrase> structure e.g. <phrase>recurrent neural networks</phrase> rnns . <phrase>this paper</phrase> presents <phrase>a new</phrase> <phrase>pre training</phrase> <phrase>approach based on</phrase> <phrase>knowledge transfer</phrase> learning. <phrase>in contrast to</phrase> the <phrase>layer wise</phrase> approach which trains model components incrementally the new approach trains the entire model as a whole but with an easier <phrase>objective function</phrase>. this is <phrase>achieved by</phrase> utilizing soft targets <phrase>produced by</phrase> a prior trained model teacher model . <phrase>compared to</phrase> the conventional <phrase>layer wise</phrase> methods this new method <phrase>does not</phrase> care about <phrase>the model</phrase> structure so can be used to pre train very complex models. <phrase>experiments on</phrase> a <phrase>speech recognition</phrase> task demonstrated that with <phrase>this approach</phrase> complex rnns can be well trained with a weaker <phrase>deep neural network</phrase> dnn model. furthermore the new method can be <phrase>combined with</phrase> conventional <phrase>layer wise</phrase> <phrase>pre training</phrase> to deliver additional gains.
stacked what where auto encoders
we present <phrase>a novel</phrase> architecture the stacked what where auto encoders swwae which integrates discriminative and generative pathways and provides <phrase>a unified</phrase> <phrase>approach to</phrase> supervised <phrase>semi supervised</phrase> and <phrase>unsupervised learning</phrase> without relying on sampling <phrase>during training</phrase>. an instantiation of swwae uses a convolutional net convnet lecun <phrase>et al</phrase>. 1998 to encode <phrase>the input</phrase> and employs a deconvolutional net deconvnet zeiler <phrase>et al</phrase>. 2010 <phrase>to produce</phrase> the reconstruction. the <phrase>objective function</phrase> includes reconstruction terms that induce the hidden states in the deconvnet to be <phrase>similar to</phrase> those of the convnet. each pooling layer produces two sets of variables the what which are fed to the next layer and its complementary variable where that are fed to the corresponding layer in the generative decoder.
training recurrent networks online without backtracking
we introduce the nobacktrack algorithm <phrase>to train</phrase> <phrase>the parameters of</phrase> <phrase>dynamical systems</phrase> <phrase>such as</phrase> <phrase>recurrent neural networks</phrase>. this algorithm works in an online memoryless setting thus requiring no backpropagation through time and is scalable avoiding the large computational and memory cost of maintaining the full gradient of <phrase>the current state</phrase> <phrase>with respect to</phrase> the parameters. the algorithm essentially maintains at each time <phrase>a single</phrase> search direction in parameter space. the evolution of this search direction is partly stochastic and is constructed in such a way to provide at every time an unbiased random estimate of the gradient of the <phrase>loss function</phrase> <phrase>with respect to</phrase> the parameters. because the gradient estimate is unbiased on average over time the parameter is updated as it should. the resulting gradient estimate can then be fed to a lightweight kalman like filter to yield an improved algorithm. for <phrase>recurrent neural networks</phrase> the resulting algorithms scale linearly with <phrase>the number of</phrase> parameters. small scale experiments confirm the suitability of the approach showing that the stochastic approximation of the gradient introduced in the algorithm is not detrimental to learning. <phrase>in particular</phrase> the kalman like <phrase>version of</phrase> nobacktrack is superior to backpropagation through time bptt when the time span of dependencies in the data is longer than the truncation span for bptt.
deep clustering discriminative embeddings for segmentation and separation
we address <phrase>the problem of</phrase> acoustic source separation in a <phrase>deep learning</phrase> framework we call deep clustering. <phrase>rather than</phrase> directly estimating signals or masking functions we train a <phrase>deep network</phrase> <phrase>to produce</phrase> spectrogram embeddings that are discriminative for partition labels given in <phrase>training data</phrase>. previous <phrase>deep network</phrase> approaches provide great advantages <phrase>in terms of</phrase> learning power and speed but previously it has been unclear how to use them to separate signals in a class independent way. <phrase>in contrast</phrase> <phrase>spectral clustering</phrase> approaches are flexible <phrase>with respect to</phrase> the classes and <phrase>number of</phrase> items to be segmented but it has been unclear how to leverage the learning power and speed of <phrase>deep networks</phrase>. <phrase>to obtain</phrase> <phrase>the best</phrase> of both worlds we use an <phrase>objective function</phrase> that <phrase>to train</phrase> embeddings that yield a low rank approximation to an ideal pairwise affinity matrix in a class independent way. this avoids the high cost of spectral factorization and instead produces compact clusters that are amenable to simple clustering methods. the segmentations are therefore implicitly encoded in the embeddings and can be decoded by clustering. preliminary <phrase>experiments show</phrase> that <phrase>the proposed</phrase> method can separate speech when <phrase>trained on</phrase> spectrogram features containing mixtures of two speakers and <phrase>tested on</phrase> mixtures of a held out <phrase>set of</phrase> speakers it can infer masking functions that improve signal quality by around 6db. we show that <phrase>the model</phrase> can generalize to three speaker mixtures despite training only on two speaker mixtures. the framework can be used without class labels and therefore has the potential to be <phrase>trained on</phrase> a diverse <phrase>set of</phrase> sound types and to generalize to novel sources. we hope that future work will <phrase>lead to</phrase> segmentation of arbitrary sounds with extensions to microphone array methods <phrase>as well as</phrase> <phrase>image segmentation</phrase> and other domains.
scalable out of sample extension of graph embeddings using <phrase>deep neural networks</phrase>
several popular graph embedding techniques for <phrase>representation learning</phrase> and <phrase>dimensionality reduction</phrase> <phrase>rely on</phrase> performing computationally expensive eigendecompositions to derive a nonlinear transformation of <phrase>the input</phrase> data space. the resulting eigenvectors encode the embedding coordinates for the <phrase>training samples</phrase> only and so the embedding of novel data samples requires further costly computation. in <phrase>this paper</phrase> we present a <phrase>method for</phrase> the out of sample extension of graph embeddings using <phrase>deep neural networks</phrase> dnn to parametrically approximate these nonlinear maps. <phrase>compared with</phrase> traditional nonparametric out of sample extension methods we demonstrate that the dnns can generalize with equal or better fidelity and require orders <phrase>of magnitude</phrase> less computation at <phrase>test time</phrase>. moreover we find that unsupervised pretraining of the dnns improves optimization for larger network sizes thus removing sensitivity to <phrase>model selection</phrase>.
model accuracy and runtime tradeoff in distributed <phrase>deep learning</phrase> a systematic study
<phrase>this paper</phrase> presents rudra a parameter server based <phrase>distributed computing</phrase> framework tuned for training <phrase>large scale</phrase> <phrase>deep neural networks</phrase>. using variants of the asynchronous <phrase>stochastic gradient descent</phrase> algorithm we study the impact of synchronization protocol stale gradient updates minibatch size learning rates and <phrase>number of</phrase> learners on runtime performance and model accuracy. we introduce <phrase>a new</phrase> <phrase>learning rate</phrase> modulation strategy to counter <phrase>the effect of</phrase> stale gradients and propose <phrase>a new</phrase> synchronization protocol that can effectively bound the staleness in gradients improve runtime performance and achieve good model accuracy. our empirical investigation reveals a principled approach for distributed training of <phrase>neural networks</phrase> the mini <phrase>batch size</phrase> per learner should be reduced as more learners are added to the system to preserve <phrase>the model</phrase> accuracy. we validate <phrase>this approach</phrase> using commonly used <phrase>image classification</phrase> benchmarks cifar10 and imagenet.
convolutional networks on graphs for learning molecular fingerprints
we introduce <phrase>a convolutional neural network</phrase> that operates directly on graphs. these networks allow <phrase>end to end</phrase> learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. the architecture we present generalizes standard molecular <phrase>feature extraction</phrase> methods <phrase>based on</phrase> circular fingerprints. we show that these <phrase>data driven</phrase> features are more interpretable and have better predictive <phrase>performance on</phrase> <phrase>a variety of</phrase> tasks.
population contrastive divergence does consistency help with rbm training 
estimating the log likelihood gradient <phrase>with respect to</phrase> <phrase>the parameters of</phrase> a restricted boltzmann machine rbm typically requires sampling using <phrase>markov chain</phrase> <phrase>monte carlo</phrase> mcmc techniques. to save computation time the markov chains are only run for <phrase>a small</phrase> <phrase>number of</phrase> steps which <phrase>leads to</phrase> a biased estimate. this bias can cause rbm training algorithms <phrase>such as</phrase> contrastive divergence cd learning to deteriorate. we adopt the idea behind population <phrase>monte carlo</phrase> pmc methods to devise <phrase>a new</phrase> rbm training algorithm termed population contrastive divergence pop cd . <phrase>compared to</phrase> cd it <phrase>leads to</phrase> a consistent estimate and may have a significantly lower bias. its computational overhead is negligible <phrase>compared to</phrase> cd. however the variance of the gradient estimate increases. we experimentally show that pop cd can <phrase>significantly outperform</phrase> cd. in many cases we observed a smaller bias and achieved higher log likelihood values. however when the rbm distribution has many hidden neurons the consistent estimate of pop cd may still have a considerable bias and the variance of the gradient estimate requires a smaller <phrase>learning rate</phrase>. thus despite its superior theoretical properties it is not advisable to use pop cd in its current form on large problems.
atomnet a <phrase>deep convolutional</phrase> <phrase>neural network</phrase> for bioactivity prediction in structure based <phrase>drug discovery</phrase>
<phrase>deep convolutional neural networks</phrase> comprise a subclass of <phrase>deep neural networks</phrase> dnn with a constrained architecture that leverages the spatial and temporal structure of the domain they model. convolutional networks achieve <phrase>the best</phrase> predictive performance in areas <phrase>such as</phrase> speech and image recognition by hierarchically composing simple local features into complex models. although dnns have been used in <phrase>drug discovery</phrase> for qsar and ligand based bioactivity predictions none of <phrase>these models</phrase> have benefited from this powerful convolutional architecture. <phrase>this paper</phrase> introduces atomnet the first structure based <phrase>deep convolutional</phrase> <phrase>neural network</phrase> designed <phrase>to predict</phrase> the bioactivity of small molecules for <phrase>drug discovery</phrase> applications. we demonstrate how to apply the convolutional concepts of feature locality and hierarchical composition to the modeling of bioactivity and chemical interactions. in further contrast to existing dnn techniques we show that atomnet s <phrase>application of</phrase> local convolutional filters to structural target information successfully predicts new active molecules for targets with no previously known modulators. finally we show that atomnet outperforms previous docking approaches on a diverse <phrase>set of</phrase> benchmarks by <phrase>a large</phrase> margin achieving an auc greater than 0.9 on 57.8 of the targets in the dude benchmark.
distillation as a defense to <phrase>adversarial perturbations</phrase> against <phrase>deep neural networks</phrase>
<phrase>deep learning</phrase> algorithms have been <phrase>shown to</phrase> perform extremely well on many classical <phrase>machine learning</phrase> problems. however recent studies have shown that <phrase>deep learning</phrase> like other <phrase>machine learning</phrase> techniques is vulnerable to adversarial samples inputs crafted to force <phrase>a deep neural network</phrase> dnn to provide adversary selected outputs. such attacks can seriously undermine the security of the system supported by the dnn sometimes with devastating consequences. for example autonomous vehicles can be crashed illicit or illegal content can bypass content filters or biometric authentication systems can be manipulated to allow improper access. in <phrase>this work</phrase> we introduce a defensive mechanism called defensive distillation <phrase>to reduce</phrase> <phrase>the effectiveness of</phrase> adversarial samples on dnns. we analytically investigate the generalizability and robustness properties granted by <phrase>the use of</phrase> defensive distillation when training dnns. we also empirically study <phrase>the effectiveness of</phrase> our defense mechanisms on two dnns placed in adversarial settings. the study shows that defensive distillation can reduce effectiveness of sample creation from 95 to less than 0.5 on a studied dnn. such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 10 30. we also find that distillation increases the average minimum <phrase>number of</phrase> features that <phrase>need to</phrase> be modified to create adversarial samples by about 800 on one of the dnns we tested.
the variational <phrase>gaussian process</phrase>
<phrase>variational inference</phrase> is a powerful tool for approximate inference and it has been recently applied for <phrase>representation learning</phrase> with deep <phrase>generative models</phrase>. we develop the variational <phrase>gaussian process</phrase> vgp a bayesian nonparametric variational family which adapts its shape to match complex posterior distributions. the vgp generates approximate posterior samples by generating latent inputs and warping them through random <phrase>non linear</phrase> mappings the distribution over random mappings is learned during inference enabling the transformed outputs to adapt to varying complexity. we prove a universal approximation theorem for the vgp demonstrating its representative power for learning any model. for inference we present a variational objective <phrase>inspired by</phrase> auto encoders and perform <phrase>black box</phrase> inference over a wide class of models. the vgp achieves new <phrase>state of</phrase> <phrase>the art</phrase> results for <phrase>unsupervised learning</phrase> inferring models <phrase>such as</phrase> the deep latent gaussian model and the <phrase>recently proposed</phrase> draw.
partial reinitialisation for optimisers
heuristic optimisers which search for an optimal configuration of variables relative to an <phrase>objective function</phrase> often get stuck in local optima where the algorithm is unable to find further improvement. the standard <phrase>approach to</phrase> circumvent <phrase>this problem</phrase> involves periodically restarting the algorithm from random initial configurations when no further improvement can be found. we propose a method of partial reinitialization whereby in an <phrase>attempt to</phrase> find a better solution only sub sets of variables are re initialised <phrase>rather than</phrase> the whole configuration. much of the information gained from previous runs is hence retained. this <phrase>leads to</phrase> <phrase>significant improvements</phrase> in the quality of the solution found in a given time for <phrase>a variety of</phrase> optimisation problems in <phrase>machine learning</phrase>.
efficient representation of <phrase>low dimensional</phrase> manifolds using <phrase>deep networks</phrase>
we consider the ability of <phrase>deep neural networks</phrase> <phrase>to represent</phrase> data that lies near a <phrase>low dimensional</phrase> manifold in a <phrase>high dimensional</phrase> space. we show that <phrase>deep networks</phrase> can efficiently extract the intrinsic <phrase>low dimensional</phrase> coordinates of such data. we first show that the first two layers of a <phrase>deep network</phrase> can exactly embed points lying on a monotonic chain <phrase>a special</phrase> <phrase>type of</phrase> piecewise linear manifold mapping them to a <phrase>low dimensional</phrase> <phrase>euclidean space</phrase>. remarkably <phrase>the network</phrase> can do this using an almost optimal <phrase>number of</phrase> parameters. we <phrase>also show</phrase> that this network projects nearby points onto the manifold and then embeds them with little error. we then extend these results to more general manifolds.
enhanced perceptrons using contrastive biclusters
perceptrons are neuronal devices <phrase>capable of</phrase> fully discriminating linearly separable classes. although straightforward to implement and train their applicability is usually hindered by non trivial requirements imposed by <phrase>real world</phrase> <phrase>classification problems</phrase>. therefore several approaches <phrase>such as</phrase> kernel perceptrons have been conceived to counteract such difficulties. in <phrase>this paper</phrase> we investigate an enhanced perceptron <phrase>model based</phrase> on the <phrase>notion of</phrase> contrastive biclusters. from this perspective a good discriminative bicluster comprises <phrase>a subset of</phrase> data instances belonging to one class that show high coherence across <phrase>a subset of</phrase> features and high differentiation from nearest instances of the other class under <phrase>the same</phrase> features referred to as its contrastive bicluster . upon each local subspace <phrase>associated with</phrase> a pair of contrastive biclusters a perceptron is trained and <phrase>the model</phrase> with highest area under the <phrase>receiver operating characteristic</phrase> curve auc value is selected as <phrase>the final</phrase> classifier. experiments conducted on <phrase>a range of</phrase> <phrase>data sets</phrase> including those <phrase>related to</phrase> a difficult biosignal classification problem show that <phrase>the proposed</phrase> variant can be indeed very useful prevailing in most of the cases upon standard and kernel perceptrons <phrase>in terms of</phrase> accuracy and auc measures.
alternating optimization method <phrase>based on</phrase> nonnegative matrix factorizations for <phrase>deep neural networks</phrase>
the backpropagation algorithm for calculating gradients has been <phrase>widely used</phrase> in computation of weights for <phrase>deep neural networks</phrase> dnns . this method requires derivatives of objective functions and has some difficulties finding appropriate parameters <phrase>such as</phrase> <phrase>learning rate</phrase>. in <phrase>this paper</phrase> we propose <phrase>a novel</phrase> approach for computing weight matrices of fully connected dnns <phrase>by using</phrase> two <phrase>types of</phrase> semi nonnegative matrix factorizations semi nmfs . in this method optimization processes are performed by calculating weight matrices alternately and backpropagation bp is not used. we <phrase>also present</phrase> a method to calculate stacked autoencoder using a nmf. the output results of the autoencoder are <phrase>used as</phrase> <phrase>pre training</phrase> data for dnns. the <phrase>experimental results</phrase> show that our method using three <phrase>types of</phrase> nmfs attains similar <phrase>error rates</phrase> to the conventional dnns with bp.
robust large margin <phrase>deep neural networks</phrase>
the generalization error of <phrase>deep neural networks</phrase> via their classification margin is studied in <phrase>this work</phrase>. our approach is <phrase>based on</phrase> the <phrase>jacobian matrix</phrase> of <phrase>a deep neural network</phrase> and can be <phrase>applied to</phrase> networks with arbitrary non linearities and pooling layers and to networks with different architectures <phrase>such as</phrase> <phrase>feed forward</phrase> networks and <phrase>residual networks</phrase>. our analysis <phrase>leads to</phrase> the conclusion that a bounded spectral norm of <phrase>the network</phrase> s <phrase>jacobian matrix</phrase> in the neighbourhood of the <phrase>training samples</phrase> is crucial for <phrase>a deep neural network</phrase> of arbitrary depth and width to generalize well. this is a <phrase>significant improvement</phrase> over the current bounds in the literature which imply that the generalization error grows with either the width or the depth of <phrase>the network</phrase>. moreover it shows that the <phrase>recently proposed</phrase> <phrase>batch normalization</phrase> and weight normalization re parametrizations enjoy good generalization properties and <phrase>leads to</phrase> <phrase>a novel</phrase> network regularizer <phrase>based on</phrase> <phrase>the network</phrase> s <phrase>jacobian matrix</phrase>. the analysis is supported with <phrase>experimental results</phrase> on the mnist <phrase>cifar 10</phrase> lared and imagenet datasets.
no bad <phrase>local minima</phrase> data independent training error guarantees for multilayer <phrase>neural networks</phrase>
we use smoothed analysis techniques to provide guarantees on the training loss of multilayer <phrase>neural networks</phrase> mnns at differentiable <phrase>local minima</phrase>. specifically we examine mnns with piecewise linear <phrase>activation functions</phrase> quadratic loss and <phrase>a single</phrase> output under mild over parametrization. we prove that for a mnn with one <phrase>hidden layer</phrase> the training error is zero at every differentiable local minimum for almost every dataset and dropout like noise realization. we then extend these results to the case of <phrase>more than</phrase> one <phrase>hidden layer</phrase>. our theoretical guarantees assume essentially nothing on <phrase>the training data</phrase> and are verified numerically. these <phrase>results suggest</phrase> why the highly <phrase>non convex</phrase> loss of such mnns can be easily optimized using local updates e.g. <phrase>stochastic gradient descent</phrase> as observed empirically.
learning structured sparsity in <phrase>deep neural networks</phrase>
high demand for computation resources severely hinders deployment of <phrase>large scale</phrase> <phrase>deep neural networks</phrase> dnn in resource constrained devices. in <phrase>this work</phrase> we propose a structured sparsity learning ssl method to regularize the structures i.e. filters channels filter shapes and layer depth of dnns. ssl can 1 learn a compact structure from a bigger dnn <phrase>to reduce</phrase> computation cost 2 obtain a hardware friendly structured sparsity of dnn to efficiently accelerate the dnns evaluation. <phrase>experimental results</phrase> show that ssl achieves on average 5.1x and 3.1x speedups of convolutional layer computation of alexnet against cpu and gpu respectively with off the shelf libraries. these speedups are about twice speedups of non structured sparsity 3 regularize the dnn structure <phrase>to improve</phrase> <phrase>classification accuracy</phrase>. the <phrase>results show</phrase> that for <phrase>cifar 10</phrase> regularization on layer depth can reduce 20 layers of a deep residual network resnet to 18 layers while improve the accuracy from 91.25 to 92.60 which is still slightly higher than that of original resnet with 32 layers. for alexnet structure regularization by ssl also reduces the error by around 1 . <phrase>open source</phrase> code is in https github.com wenwei202 caffe tree scnn
depth width tradeoffs in approximating natural functions with <phrase>neural networks</phrase>
we provide several new depth based separation results for <phrase>feed forward</phrase> <phrase>neural networks</phrase> proving that various <phrase>types of</phrase> simple and natural functions can be better approximated using deeper networks than shallower ones even if the shallower networks are much larger. this includes indicators of balls and ellipses <phrase>non linear</phrase> functions which are radial <phrase>with respect to</phrase> the l 1 norm and smooth <phrase>non linear</phrase> functions. we <phrase>also show</phrase> that these gaps can be observed experimentally increasing the depth indeed allows better learning than increasing width when training <phrase>neural networks</phrase> <phrase>to learn</phrase> an indicator of a unit ball.
tensor switching networks
we present <phrase>a novel</phrase> <phrase>neural network</phrase> algorithm the tensor switching ts network which generalizes the <phrase>rectified linear</phrase> unit relu nonlinearity to tensor valued hidden units. the ts network copies its entire input vector to different locations in an expanded representation with the location determined by its hidden unit activity. in this way even <phrase>a simple</phrase> linear readout from the ts representation can implement a highly expressive <phrase>deep network</phrase> like function. the ts network hence avoids the vanishing gradient problem by construction at the cost of larger representation size. we develop several methods <phrase>to train</phrase> the ts network including equivalent kernels for infinitely wide and deep ts networks a one pass linear <phrase>learning algorithm</phrase> and two backpropagation inspired <phrase>representation learning</phrase> algorithms. our <phrase>experimental results</phrase> demonstrate that the ts network is indeed more expressive and consistently learns <phrase>faster than</phrase> standard relu networks.
survey of expressivity in <phrase>deep neural networks</phrase>
we survey <phrase>results on</phrase> <phrase>neural network</phrase> expressivity described in on the expressive power of <phrase>deep neural networks</phrase> . the paper motivates and develops three natural measures of expressiveness which all display an exponential dependence on the depth of <phrase>the network</phrase>. in fact all of these measures are <phrase>related to</phrase> a fourth quantity trajectory length. this quantity grows exponentially in the depth of <phrase>the network</phrase> and is responsible for the depth sensitivity observed. these results translate to consequences for networks during and after training. they suggest that parameters earlier in a network have greater influence on its expressive power <phrase>in particular</phrase> given a layer its influence on expressivity is determined by the remaining depth of <phrase>the network</phrase> after that layer. this is verified with <phrase>experiments on</phrase> mnist and <phrase>cifar 10</phrase>. we also explore <phrase>the effect of</phrase> training on <phrase>the input</phrase> output map and find that it trades off between the stability and expressivity.
precise recovery of latent vectors from <phrase>generative adversarial networks</phrase>
<phrase>generative adversarial networks</phrase> gans transform latent vectors into visually plausible images. it is generally thought that <phrase>the original</phrase> gan formulation gives no out of the box method to reverse the mapping projecting images back into <phrase>latent space</phrase>. we introduce <phrase>a simple</phrase> <phrase>gradient based</phrase> technique called stochastic clipping. in experiments for images generated by the gan we precisely recover their latent vector pre images 100 of the time. additional <phrase>experiments demonstrate</phrase> that this method is robust to noise. finally we show that even for unseen images our method appears to recover unique encodings.
predicting surgery duration with neural heteroscedastic regression
scheduling surgeries is a <phrase>challenging task</phrase> <phrase>due to</phrase> the fundamental uncertainty of the clinical environment <phrase>as well as</phrase> the risks and costs <phrase>associated with</phrase> under and over booking. we investigate neural regression algorithms to estimate <phrase>the parameters of</phrase> surgery case durations focusing on the issue of heteroscedasticity. we <phrase>seek to</phrase> simultaneously estimate the duration of each surgery <phrase>as well as</phrase> a surgery specific <phrase>notion of</phrase> our uncertainty about its duration. estimating this uncertainty can <phrase>lead to</phrase> more nuanced and effective scheduling strategies as we are <phrase>able to</phrase> schedule surgeries more efficiently while allowing an informed and case specific margin of error. using surgery records from the <phrase>uc san diego</phrase> health system from <phrase>a large</phrase> <phrase>united states</phrase> health system we demonstrate potential improvements on the order of 20 <phrase>in terms of</phrase> minutes overbooked <phrase>compared to</phrase> current scheduling techniques. moreover we demonstrate that surgery durations are indeed heteroscedastic. we show that models that estimate case specific uncertainty better fit the data log likelihood . additionally we show that the heteroscedastic predictions can more optimally trade off between over and under booking minutes especially when idle minutes and scheduling collisions confer disparate costs.
depth creates no bad <phrase>local minima</phrase>
in <phrase>deep learning</phrase> textit depth <phrase>as well as</phrase> textit nonlinearity create <phrase>non convex</phrase> loss surfaces. then does depth alone create bad <phrase>local minima</phrase> in <phrase>this paper</phrase> we prove that without nonlinearity depth alone <phrase>does not</phrase> create bad <phrase>local minima</phrase> although it induces <phrase>non convex</phrase> loss surface. using this insight we greatly simplify a <phrase>recently proposed</phrase> proof to show that all of the <phrase>local minima</phrase> of feedforward deep linear <phrase>neural networks</phrase> are global minima. our theoretical results generalize previous results with fewer assumptions and this analysis provides a method to show similar results beyond square loss in deep linear models.
deep semi random features for nonlinear function approximation
we propose semi random features for nonlinear function approximation. the flexibility of semi random feature lies between the fully adjustable units in <phrase>deep learning</phrase> and the random features used in kernel methods. for one <phrase>hidden layer</phrase> models with semi random features we prove with no unrealistic assumptions that <phrase>the model</phrase> classes contain an arbitrarily good function as the width increases universality and despite non convexity we can find such a good function optimization theory that generalizes to unseen new data generalization bound . for deep models with no unrealistic assumptions we prove universal approximation ability a lower bound on approximation error a partial optimization guarantee and a generalization bound. depending on the problems the generalization bound of deep semi random features can be exponentially <phrase>better than</phrase> the known bounds of deep relu nets our generalization error bound can be independent of the depth <phrase>the number of</phrase> trainable weights <phrase>as well as</phrase> <phrase>the input</phrase> dimensionality. in experiments we show that semi random features can match <phrase>the performance of</phrase> <phrase>neural networks</phrase> <phrase>by using</phrase> slightly more units and it outperforms random features <phrase>by using</phrase> significantly fewer units. moreover we introduce <phrase>a new</phrase> implicit ensemble method <phrase>by using</phrase> semi random features.
curriculum dropout
dropout is a very effective way of regularizing <phrase>neural networks</phrase>. stochastically dropping out units with a certain probability discourages over specific co adaptations of feature detectors preventing overfitting and improving network generalization. besides dropout can be interpreted as an approximate model aggregation technique where an exponential <phrase>number of</phrase> smaller networks are averaged <phrase>in order to</phrase> get a <phrase>more powerful</phrase> ensemble. in <phrase>this paper</phrase> we show that using <phrase>a fixed</phrase> dropout probability <phrase>during training</phrase> is a suboptimal choice. we thus propose a time scheduling for the probability of retaining neurons in <phrase>the network</phrase>. this induces an adaptive regularization scheme that smoothly increases the difficulty of the <phrase>optimization problem</phrase>. this idea of starting easy and adaptively increasing the difficulty of the learning problem has its roots in <phrase>curriculum learning</phrase> and allows one <phrase>to train</phrase> better models. indeed we prove that our optimization strategy implements a very general curriculum scheme by gradually adding noise to both <phrase>the input</phrase> and intermediate <phrase>feature representations</phrase> within <phrase>the network</phrase> architecture. <phrase>experiments on</phrase> seven <phrase>image classification</phrase> datasets and different <phrase>network architectures</phrase> show that our method named curriculum dropout frequently yields to better generalization and at worst performs just <phrase>as well as</phrase> the standard dropout method.
the power of deeper networks for expressing natural functions
it is <phrase>well known</phrase> that <phrase>neural networks</phrase> are universal approximators but that deeper networks <phrase>tend to</phrase> be much <phrase>more efficient</phrase> than shallow ones. we shed light on this by proving that the total <phrase>number of</phrase> neurons m required to approximate natural classes of multivariate polynomials of n variables grows only linearly with n for <phrase>deep neural networks</phrase> but grows exponentially when merely <phrase>a single</phrase> <phrase>hidden layer</phrase> is allowed. we also provide evidence that when <phrase>the number of</phrase> <phrase>hidden layers</phrase> is increased from 1 to k the neuron requirement grows exponentially not with n but with n 1 k suggesting that the minimum <phrase>number of</phrase> layers required for computational tractability grows only logarithmically with n .
<phrase>gradient descent</phrase> for <phrase>spiking neural networks</phrase>
much of studies on neural computation are <phrase>based on</phrase> network models of static neurons that produce analog output despite the fact that <phrase>information processing</phrase> in the brain is predominantly carried out by dynamic neurons that produce discrete pulses called spikes. research in spike based computation has been impeded by <phrase>the lack of</phrase> efficient <phrase>supervised learning</phrase> algorithm for spiking networks. here we present a <phrase>gradient descent</phrase> <phrase>method for</phrase> optimizing spiking network models <phrase>by introducing</phrase> a differentiable formulation of spiking networks and deriving the exact gradient calculation. for demonstration we trained recurrent spiking networks on two dynamic tasks one that requires optimizing fast millisecond spike based interactions for efficient encoding of information and a delayed memory xor task over extended duration second . the <phrase>results show</phrase> that our method indeed optimizes the spiking network dynamics on the time scale of individual spikes <phrase>as well as</phrase> behavioral time scales. in conclusion our result offers a <phrase>general purpose</phrase> <phrase>supervised learning</phrase> algorithm for <phrase>spiking neural networks</phrase> thus advancing further investigations on spike based computation.
unsure when to stop ask your semantic neighbors
in iterative <phrase>supervised learning</phrase> algorithms it is common to reach a point in the search where no further induction seems to be possible with the available data. if the search is continued beyond this point the risk of overfitting increases significantly. following the recent developments in inductive semantic stochastic methods <phrase>this paper</phrase> studies the feasibility of using information gathered from the semantic neighborhood to decide when to stop the search. two semantic stopping criteria are proposed and experimentally assessed in geometric semantic <phrase>genetic programming</phrase> gsgp and in the semantic learning machine slm algorithm the equivalent algorithm for <phrase>neural networks</phrase> . the experiments are performed on <phrase>real world</phrase> <phrase>high dimensional</phrase> regression datasets. the <phrase>results show</phrase> that <phrase>the proposed</phrase> semantic stopping criteria are <phrase>able to</phrase> detect stopping points that result in a competitive generalization for both gsgp and slm. <phrase>this approach</phrase> also yields computationally efficient algorithms as it allows the evolution of <phrase>neural networks</phrase> in less than 3 seconds on average and of gp trees in at most 10 seconds. the usage of <phrase>the proposed</phrase> semantic stopping criteria in conjunction with the computation of optimal mutation learning steps also results in small trees and <phrase>neural networks</phrase>.
<phrase>anomaly detection</phrase> on graph <phrase>time series</phrase>
in <phrase>this paper</phrase> we use variational <phrase>recurrent neural network</phrase> to investigate the <phrase>anomaly detection</phrase> problem on graph <phrase>time series</phrase>. the temporal correlation is modeled by the <phrase>combination of</phrase> <phrase>recurrent neural network</phrase> rnn and <phrase>variational inference</phrase> vi while the spatial information is captured by the graph convolutional network. <phrase>in order to</phrase> incorporate external factors we use feature extractor to augment the transition of <phrase>latent variables</phrase> which can learn the influence of external factors. with the target function as accumulative elbo it is <phrase>easy to</phrase> extend this model to <phrase>on line</phrase> method. the experimental study on traffic flow data shows the detection capability of <phrase>the proposed</phrase> method.
<phrase>a neural network</phrase> architecture combining <phrase>gated recurrent</phrase> unit gru and <phrase>support vector machine</phrase> svm for <phrase>intrusion detection</phrase> in network traffic data
<phrase>gated recurrent</phrase> unit gru is a recently developed variation of the <phrase>long short term memory lstm</phrase> unit both of which are <phrase>types of</phrase> <phrase>recurrent neural network</phrase> rnn . through <phrase>empirical evidence</phrase> both models have been proven to be effective in a wide <phrase>variety of</phrase> <phrase>machine learning</phrase> <phrase>tasks such as</phrase> <phrase>natural language</phrase> processing wen <phrase>et al</phrase>. 2015 <phrase>speech recognition</phrase> chorowski <phrase>et al</phrase>. 2015 and <phrase>text classification</phrase> yang <phrase>et al</phrase>. 2016 . conventionally like most <phrase>neural networks</phrase> both of the aforementioned rnn variants employ the softmax function as its final <phrase>output layer</phrase> for its prediction and the <phrase>cross entropy</phrase> function for computing its loss. in <phrase>this paper</phrase> we present an amendment to this norm <phrase>by introducing</phrase> linear <phrase>support vector machine</phrase> svm as the replacement for softmax in <phrase>the final</phrase> <phrase>output layer</phrase> of a gru model. furthermore the <phrase>cross entropy</phrase> function shall be replaced with a margin based function. while there have been similar studies alalshekmubarak smith 2013 tang 2013 this proposal is primarily intended for <phrase>binary classification</phrase> on <phrase>intrusion detection</phrase> using the 2013 network traffic data from the honeypot systems of <phrase>kyoto university</phrase>. <phrase>results show</phrase> that the gru svm model performs relatively higher than the conventional gru softmax model. <phrase>the proposed</phrase> model reached a training accuracy of 81.54 and a testing accuracy of 84.15 while <phrase>the latter</phrase> was <phrase>able to</phrase> reach a training accuracy of 63.07 and a testing accuracy of 70.75 . <phrase>in addition</phrase> the juxtaposition of these two final output layers indicate that the svm would outperform softmax in prediction time a theoretical implication which was supported by the actual training and testing time in the study.
deepsafe a <phrase>data driven</phrase> approach for checking adversarial robustness in <phrase>neural networks</phrase>
<phrase>deep neural networks</phrase> have become <phrase>widely used</phrase> obtaining remarkable results in <phrase>domains such as</phrase> <phrase>computer vision</phrase> <phrase>speech recognition</phrase> <phrase>natural language</phrase> processing audio recognition <phrase>social network</phrase> filtering <phrase>machine translation</phrase> and bio informatics where they have produced results <phrase>comparable to</phrase> human experts. however these networks can be easily fooled by <phrase>adversarial perturbations</phrase> minimal changes to correctly classified inputs that cause <phrase>the network</phrase> to mis classify them. this phenomenon represents a concern for both safety and security but it is currently unclear how to measure a network s robustness against such perturbations. existing techniques are limited to checking robustness around a few individual input points providing only very limited guarantees. we propose <phrase>a novel</phrase> approach for automatically identifying safe regions of <phrase>the input</phrase> space within which <phrase>the network</phrase> is robust against <phrase>adversarial perturbations</phrase>. the approach is data guided relying on clustering to identify well defined geometric regions as candidate safe regions. we then utilize verification techniques to confirm that these regions are safe or to provide counter examples showing that they are not safe. we also introduce the <phrase>notion of</phrase> targeted robustness which for a given target label and reg