{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import urllib\n",
    "from urllib.error import HTTPError\n",
    "import difflib\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'dual recurrent attention units for visual question answering\\nwe propose an architecture for vqa which utilizes recurrent layers to generate visual and textual attention. the memory characteristic of the proposed recurrent attention units offers a rich joint embedding of visual and textual features and enables the model to reason relations between several parts of the image and question. our single model outperforms the first place winner on the vqa 1.0 dataset performs within margin to the current state of the art ensemble model. we also experiment with replacing attention mechanisms in other state of the art models with our implementation and show increased accuracy. in both cases our recurrent attention mechanism improves performance in tasks requiring sequential or relational reasoning on the vqa dataset. sequential short text classification with recurrent and convolutional neural networks\\n recent approaches based on artificial neural networks anns have shown promising results for short text classification. however many short texts occur in sequences e.g. sentences in a document or utterances in a dialog and most existing ann based systems do not leverage the preceding short texts when classifying a subsequent one. in this work we present a model based on recurrent neural networks and convolutional neural networks that incorporates the preceding short texts. our model achieves state of the art results on three different datasets for dialog act prediction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(file, size = 1000000):\n",
    "    '''\n",
    "    partition the input file into block with maximum size of 1000000, since SpaCy v2.x parser may have issues allocating memory with size larger than 1000000\n",
    "    '''\n",
    "    while True:\n",
    "        data = file.read(size)\n",
    "        if not data:\n",
    "            break\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-34f535270901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mnp_phrases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seqs_in)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mXh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X__BI)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mX__BOP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__BI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mX__BOP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mX__BOP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX__BOP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__BOP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np_phrases = set()\n",
    "np_phrase_frequency = defaultdict(int)\n",
    "with open('../final_stuff/data/arxiv_titles_and_abstracts.txt', 'r') as file:\n",
    "    file_chunks = partition(file)\n",
    "    for chunk in file_chunks:\n",
    "        doc = nlp(chunk)\n",
    "        for np in doc.noun_chunks:\n",
    "            np_phrases.add(np.text)\n",
    "            np_phrase_frequency[np.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_phrases = set()\n",
    "np_phrase_frequency = defaultdict(int)\n",
    "for np in doc.noun_chunks:\n",
    "    np_phrases.add(np.text)\n",
    "    np_phrase_frequency[np.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_phrases = sorted(np_phrase_frequency, key=np_phrase_frequency.__getitem__, reverse=True)\n",
    "sorted_phrases_w_freq = [(p, np_phrase_frequency[p]) for p in sorted_phrases if len(p.split(\" \")) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this paper', 14866),\n",
       " ('the problem', 3598),\n",
       " ('this work', 3197),\n",
       " ('our method', 3013),\n",
       " ('our approach', 2959),\n",
       " ('the performance', 2531),\n",
       " ('the number', 2515),\n",
       " ('the state', 2307),\n",
       " ('a set', 1969),\n",
       " ('the model', 1940),\n",
       " ('the proposed method', 1785),\n",
       " ('the results', 1784),\n",
       " ('the art', 1742),\n",
       " ('the data', 1606),\n",
       " ('this problem', 1582),\n",
       " ('experimental results', 1565),\n",
       " ('our model', 1549),\n",
       " ('the effectiveness', 1519),\n",
       " ('the use', 1471),\n",
       " ('the algorithm', 1374),\n",
       " ('the task', 1284),\n",
       " ('the method', 1218),\n",
       " ('a method', 1203),\n",
       " ('the network', 1193),\n",
       " ('deep neural networks', 1164),\n",
       " ('deep learning', 1105),\n",
       " ('our algorithm', 1078),\n",
       " ('a number', 1074),\n",
       " ('our results', 1056),\n",
       " ('this approach', 1012),\n",
       " ('neural networks', 1011),\n",
       " ('a variety', 999),\n",
       " ('the system', 996),\n",
       " ('the art methods', 991),\n",
       " ('the proposed approach', 929),\n",
       " ('the context', 867),\n",
       " ('convolutional neural networks', 853),\n",
       " ('our experiments', 845),\n",
       " ('the case', 807),\n",
       " ('the accuracy', 748),\n",
       " ('an algorithm', 730),\n",
       " ('machine learning', 723),\n",
       " ('the quality', 712),\n",
       " ('computer vision', 711),\n",
       " ('an image', 711),\n",
       " ('the art performance', 703),\n",
       " ('a model', 696),\n",
       " ('the image', 688),\n",
       " ('the ability', 681),\n",
       " ('extensive experiments', 680),\n",
       " ('the need', 667),\n",
       " ('the literature', 654),\n",
       " ('the approach', 653),\n",
       " ('the presence', 642),\n",
       " ('this method', 633),\n",
       " ('the paper', 631),\n",
       " ('this study', 623),\n",
       " ('the art results', 622),\n",
       " ('the goal', 622),\n",
       " ('the proposed algorithm', 622),\n",
       " ('an approach', 616),\n",
       " ('our framework', 607),\n",
       " ('these methods', 574),\n",
       " ('this article', 566),\n",
       " ('the field', 559),\n",
       " ('recent years', 559),\n",
       " ('a framework', 553),\n",
       " ('this task', 546),\n",
       " ('the structure', 540),\n",
       " ('the framework', 535),\n",
       " ('the parameters', 533),\n",
       " ('a wide range', 513),\n",
       " ('our system', 496),\n",
       " ('the form', 495),\n",
       " ('the proposed model', 492),\n",
       " ('existing methods', 487),\n",
       " ('the experimental results', 487),\n",
       " ('the development', 486),\n",
       " ('this model', 486),\n",
       " ('a large number', 486),\n",
       " ('an end', 479),\n",
       " ('the process', 478),\n",
       " ('our knowledge', 473),\n",
       " ('a novel approach', 473),\n",
       " ('this end', 467),\n",
       " ('the size', 458),\n",
       " ('the analysis', 457),\n",
       " ('a sequence', 455),\n",
       " ('the application', 451),\n",
       " ('the features', 441),\n",
       " ('training data', 437),\n",
       " ('recurrent neural networks', 435),\n",
       " ('the complexity', 417),\n",
       " ('the experiments', 416),\n",
       " ('these models', 413),\n",
       " ('a dataset', 412),\n",
       " ('the set', 410),\n",
       " ('our work', 408),\n",
       " ('real time', 406),\n",
       " ('previous work', 399),\n",
       " ('the output', 396),\n",
       " ('a result', 393),\n",
       " ('the efficiency', 392),\n",
       " ('the fact', 390),\n",
       " ('the input', 388),\n",
       " ('a system', 385),\n",
       " ('the potential', 383),\n",
       " ('the information', 376),\n",
       " ('many applications', 374),\n",
       " ('this framework', 373),\n",
       " ('a series', 369),\n",
       " ('the idea', 364),\n",
       " ('the effect', 363),\n",
       " ('the proposed framework', 362),\n",
       " ('the concept', 360),\n",
       " ('the dataset', 359),\n",
       " ('this issue', 354),\n",
       " ('a class', 352),\n",
       " ('deep networks', 350),\n",
       " ('a new approach', 348),\n",
       " ('a novel method', 348),\n",
       " ('the robustness', 348),\n",
       " ('the user', 347),\n",
       " ('object detection', 345),\n",
       " ('these results', 345),\n",
       " ('our analysis', 344),\n",
       " ('a range', 341),\n",
       " ('the training', 339),\n",
       " ('a way', 339),\n",
       " ('a state', 338),\n",
       " ('the notion', 334),\n",
       " ('deep convolutional neural networks', 334),\n",
       " ('this algorithm', 333),\n",
       " ('the distribution', 331),\n",
       " ('a network', 329),\n",
       " ('the amount', 327),\n",
       " ('a combination', 317),\n",
       " ('the agent', 317),\n",
       " ('an extension', 316),\n",
       " ('the models', 314),\n",
       " ('natural language', 313),\n",
       " ('the images', 313),\n",
       " ('the result', 313),\n",
       " ('the solution', 313),\n",
       " ('the basis', 312),\n",
       " ('the advantages', 312),\n",
       " ('artificial intelligence', 310),\n",
       " ('the design', 308),\n",
       " ('the other hand', 306),\n",
       " ('a function', 306),\n",
       " ('the space', 305),\n",
       " ('the theory', 305),\n",
       " ('the same time', 303),\n",
       " ('a new method', 302),\n",
       " ('the training data', 302),\n",
       " ('the relationship', 301),\n",
       " ('adversarial examples', 301),\n",
       " ('the environment', 299),\n",
       " ('the importance', 295),\n",
       " ('the question', 295),\n",
       " ('these problems', 294),\n",
       " ('semantic segmentation', 294),\n",
       " ('a subset', 293),\n",
       " ('the world', 292),\n",
       " ('image classification', 290),\n",
       " ('reinforcement learning', 289),\n",
       " ('the efficacy', 288),\n",
       " ('bayesian networks', 288),\n",
       " ('recent advances', 287),\n",
       " ('generative adversarial networks', 277),\n",
       " ('the art approaches', 274),\n",
       " ('the benefits', 274),\n",
       " ('a classifier', 273),\n",
       " ('the current state', 272),\n",
       " ('the impact', 272),\n",
       " ('the object', 272),\n",
       " ('a collection', 267),\n",
       " ('the graph', 267),\n",
       " ('the representation', 265),\n",
       " ('our proposed method', 264),\n",
       " ('the assumption', 264),\n",
       " ('a neural network', 263),\n",
       " ('the objective', 263),\n",
       " ('the domain', 263),\n",
       " ('our methods', 263),\n",
       " ('the probability', 262),\n",
       " ('the study', 261),\n",
       " ('these algorithms', 261),\n",
       " ('the choice', 261),\n",
       " ('recent work', 260),\n",
       " ('the existence', 260),\n",
       " ('the success', 260),\n",
       " ('different types', 260),\n",
       " ('the purpose', 260),\n",
       " ('the aim', 259),\n",
       " ('the superiority', 258),\n",
       " ('the cost', 258),\n",
       " ('the time', 258),\n",
       " ('better performance', 257),\n",
       " ('the lack', 256),\n",
       " ('the behavior', 256),\n",
       " ('the scene', 254),\n",
       " ('the weights', 253),\n",
       " ('its performance', 252),\n",
       " ('the class', 252),\n",
       " ('a wide variety', 251),\n",
       " ('a lot', 250),\n",
       " ('an application', 248),\n",
       " ('a solution', 243),\n",
       " ('the power', 240),\n",
       " ('the first time', 240),\n",
       " ('natural images', 239),\n",
       " ('existing approaches', 235),\n",
       " ('synthetic data', 233),\n",
       " ('a convolutional neural network', 232),\n",
       " ('the learning', 232),\n",
       " ('the value', 232),\n",
       " ('a problem', 230),\n",
       " ('the effects', 229),\n",
       " ('other state', 228),\n",
       " ('a family', 228),\n",
       " ('the evaluation', 228),\n",
       " ('a generalization', 225),\n",
       " ('our network', 224),\n",
       " ('the possibility', 223),\n",
       " ('natural language processing', 221),\n",
       " ('the advantage', 220),\n",
       " ('the sense', 220),\n",
       " ('numerical experiments', 219),\n",
       " ('a challenging task', 218),\n",
       " ('word embeddings', 217),\n",
       " ('a graph', 217),\n",
       " ('a technique', 216),\n",
       " ('the classifier', 216),\n",
       " ('the role', 216),\n",
       " ('the properties', 216),\n",
       " ('the combination', 215),\n",
       " ('prior knowledge', 215),\n",
       " ('action recognition', 215),\n",
       " ('an agent', 214),\n",
       " ('significant improvements', 214),\n",
       " ('the way', 212),\n",
       " ('generative models', 211),\n",
       " ('superior performance', 211),\n",
       " ('the methods', 209),\n",
       " ('our models', 209),\n",
       " ('data points', 209),\n",
       " ('the utility', 209),\n",
       " ('the construction', 208),\n",
       " ('our experimental results', 208),\n",
       " ('a variant', 208),\n",
       " ('an ensemble', 207),\n",
       " ('the challenge', 206),\n",
       " ('empirical results', 206),\n",
       " ('the classification', 205),\n",
       " ('the architecture', 205),\n",
       " ('an example', 204),\n",
       " ('the objective function', 204),\n",
       " ('the problems', 204),\n",
       " ('a small number', 202),\n",
       " ('feature selection', 202),\n",
       " ('their performance', 198),\n",
       " ('the algorithms', 198),\n",
       " ('a new algorithm', 197),\n",
       " ('the gap', 197),\n",
       " ('face recognition', 197),\n",
       " ('our algorithms', 196),\n",
       " ('sentiment analysis', 195),\n",
       " ('this result', 195),\n",
       " ('other methods', 195),\n",
       " ('the difference', 194),\n",
       " ('the influence', 193),\n",
       " ('the sequence', 192),\n",
       " ('an important role', 192),\n",
       " ('an object', 192),\n",
       " ('the area', 191),\n",
       " ('a measure', 189),\n",
       " ('time series', 189),\n",
       " ('this technique', 188),\n",
       " ('the proposed methods', 188),\n",
       " ('these approaches', 187),\n",
       " ('the degree', 187),\n",
       " ('the similarity', 187),\n",
       " ('the dynamics', 187),\n",
       " ('the computation', 186),\n",
       " ('the estimation', 186),\n",
       " ('the work', 184),\n",
       " ('the convergence', 184),\n",
       " ('the difficulty', 182),\n",
       " ('the art algorithms', 182),\n",
       " ('machine translation', 181),\n",
       " ('a mixture', 180),\n",
       " ('these issues', 178),\n",
       " ('gaussian processes', 178),\n",
       " ('the dimension', 178),\n",
       " ('a challenging problem', 178),\n",
       " ('a challenge', 177),\n",
       " ('such models', 176),\n",
       " ('this way', 176),\n",
       " ('each iteration', 174),\n",
       " ('gradient descent', 172),\n",
       " ('this research', 171),\n",
       " ('these features', 170),\n",
       " ('these techniques', 170),\n",
       " ('our goal', 170),\n",
       " ('a novel framework', 169),\n",
       " ('the learning process', 168),\n",
       " ('the distance', 168),\n",
       " ('the future', 168),\n",
       " ('real data', 167),\n",
       " ('previous methods', 167),\n",
       " ('a pair', 167),\n",
       " ('the target', 167),\n",
       " ('this setting', 167),\n",
       " ('an accuracy', 166),\n",
       " ('large amounts', 166),\n",
       " ('high accuracy', 166),\n",
       " ('the knowledge', 165),\n",
       " ('an analysis', 165),\n",
       " ('the usefulness', 165),\n",
       " ('test time', 164),\n",
       " ('the error', 164),\n",
       " ('large datasets', 164),\n",
       " ('an improvement', 164),\n",
       " ('a survey', 163),\n",
       " ('promising results', 163),\n",
       " ('graphical models', 163),\n",
       " ('the uncertainty', 163),\n",
       " ('the language', 162),\n",
       " ('latent variables', 162),\n",
       " ('high dimensional data', 162),\n",
       " ('object recognition', 161),\n",
       " ('the gradient', 161),\n",
       " ('a representation', 160),\n",
       " ('a corpus', 160),\n",
       " ('the objects', 159),\n",
       " ('feature extraction', 159),\n",
       " ('classification accuracy', 159),\n",
       " ('the text', 158),\n",
       " ('a cnn', 158),\n",
       " ('the applicability', 158),\n",
       " ('neural network', 157),\n",
       " ('the optimization', 157),\n",
       " ('a special case', 157),\n",
       " ('a deep neural network', 157),\n",
       " ('the web', 157),\n",
       " ('this purpose', 157),\n",
       " ('high probability', 157),\n",
       " ('many cases', 156),\n",
       " ('the variance', 156),\n",
       " ('several state', 155),\n",
       " ('artificial neural networks', 154),\n",
       " ('a general framework', 154),\n",
       " ('stochastic gradient descent', 154),\n",
       " ('some cases', 154),\n",
       " ('a word', 154),\n",
       " ('the cnn', 154),\n",
       " ('the issue', 153),\n",
       " ('the generation', 153),\n",
       " ('this dataset', 153),\n",
       " ('previous approaches', 153),\n",
       " ('a video', 153),\n",
       " ('the prediction', 153),\n",
       " ('current state', 153),\n",
       " ('this challenge', 152),\n",
       " ('the nature', 152),\n",
       " ('the search', 152),\n",
       " ('the detection', 151),\n",
       " ('the relation', 151),\n",
       " ('the computational complexity', 151),\n",
       " ('an overview', 150),\n",
       " ('this context', 150),\n",
       " ('the proposed system', 150),\n",
       " ('the implementation', 150),\n",
       " ('a single image', 150),\n",
       " ('unsupervised learning', 149),\n",
       " ('the end', 149),\n",
       " ('image segmentation', 149),\n",
       " ('the sum', 149),\n",
       " ('the technique', 149),\n",
       " ('prior work', 148),\n",
       " ('the search space', 148),\n",
       " ('previous works', 148),\n",
       " ('big data', 148),\n",
       " ('a group', 148),\n",
       " ('a user', 147),\n",
       " ('the identification', 147),\n",
       " ('the level', 146),\n",
       " ('our technique', 146),\n",
       " ('dimensionality reduction', 146),\n",
       " ('the challenges', 146),\n",
       " ('a sentence', 146),\n",
       " ('the observation', 145),\n",
       " ('the generator', 144),\n",
       " ('a unified framework', 144),\n",
       " ('neural machine translation', 143),\n",
       " ('a comparison', 143),\n",
       " ('et al', 142),\n",
       " ('convolutional networks', 142),\n",
       " ('the training set', 142),\n",
       " ('labeled data', 142),\n",
       " ('its effectiveness', 142),\n",
       " ('real world applications', 141),\n",
       " ('an order', 141),\n",
       " ('this report', 141),\n",
       " ('the input image', 141),\n",
       " ('each layer', 140),\n",
       " ('its ability', 140),\n",
       " ('this process', 139),\n",
       " ('social media', 139),\n",
       " ('the feasibility', 138),\n",
       " ('two types', 137),\n",
       " ('the help', 137),\n",
       " ('the availability', 137),\n",
       " ('a new dataset', 136),\n",
       " ('benchmark datasets', 136),\n",
       " ('a novel algorithm', 136),\n",
       " ('the art models', 135),\n",
       " ('speech recognition', 135),\n",
       " ('significant improvement', 135),\n",
       " ('this case', 135),\n",
       " ('a generative model', 135),\n",
       " ('its application', 135),\n",
       " ('an alternative', 134),\n",
       " ('these networks', 134),\n",
       " ('bayesian optimization', 133),\n",
       " ('the signal', 133),\n",
       " ('special cases', 133),\n",
       " ('the segmentation', 132),\n",
       " ('the order', 132),\n",
       " ('competitive results', 132),\n",
       " ('our study', 131),\n",
       " ('unlabeled data', 131),\n",
       " ('the tasks', 131),\n",
       " ('the function', 131),\n",
       " ('a task', 131),\n",
       " ('the robot', 131),\n",
       " ('the semantics', 131),\n",
       " ('the recognition', 130),\n",
       " ('a large margin', 130),\n",
       " ('domain adaptation', 130),\n",
       " ('the networks', 130),\n",
       " ('a scene', 130),\n",
       " ('optical flow', 129),\n",
       " ('the sample complexity', 129),\n",
       " ('the wild', 129),\n",
       " ('a policy', 128),\n",
       " ('deep learning models', 127),\n",
       " ('the learner', 127),\n",
       " ('variational inference', 127),\n",
       " ('a database', 127),\n",
       " ('image denoising', 127),\n",
       " ('a large amount', 126),\n",
       " ('the setting', 126),\n",
       " ('better results', 125),\n",
       " ('the brain', 125),\n",
       " ('their ability', 125),\n",
       " ('a case study', 125),\n",
       " ('the evolution', 125),\n",
       " ('competitive performance', 124),\n",
       " ('good performance', 124),\n",
       " ('the core', 124),\n",
       " ('our findings', 123),\n",
       " ('the loss function', 123),\n",
       " ('this kind', 122),\n",
       " ('the proposed algorithms', 122),\n",
       " ('supervised learning', 121),\n",
       " ('evolutionary algorithms', 121),\n",
       " ('a consequence', 121),\n",
       " ('these tasks', 121),\n",
       " ('the variables', 121),\n",
       " ('an efficient algorithm', 121),\n",
       " ('the relationships', 120),\n",
       " ('this gap', 119),\n",
       " ('the word', 119),\n",
       " ('real world data', 119),\n",
       " ('different levels', 119),\n",
       " ('these challenges', 119),\n",
       " ('our proposed approach', 119),\n",
       " ('data augmentation', 119),\n",
       " ('each pixel', 119),\n",
       " ('the characteristics', 118),\n",
       " ('the likelihood', 118),\n",
       " ('the noise', 118),\n",
       " ('the introduction', 118),\n",
       " ('the video', 118),\n",
       " ('practical applications', 118),\n",
       " ('data sets', 118),\n",
       " ('each node', 117),\n",
       " ('machine learning algorithms', 116),\n",
       " ('the capability', 116),\n",
       " ('each image', 116),\n",
       " ('the diversity', 116),\n",
       " ('the geometry', 116),\n",
       " ('pattern recognition', 116),\n",
       " ('the training process', 116),\n",
       " ('hidden markov models', 115),\n",
       " ('the input data', 115),\n",
       " ('the labels', 115),\n",
       " ('the sparsity', 114),\n",
       " ('deep learning methods', 114),\n",
       " ('the dictionary', 114),\n",
       " ('the benefit', 114),\n",
       " ('a form', 114),\n",
       " ('a distribution', 114),\n",
       " ('a new framework', 114),\n",
       " ('polynomial time', 114),\n",
       " ('this type', 114),\n",
       " ('the corpus', 114),\n",
       " ('the shape', 114),\n",
       " ('genetic algorithms', 114),\n",
       " ('the majority', 113),\n",
       " ('training time', 113),\n",
       " ('the location', 113),\n",
       " ('the research', 113),\n",
       " ('a person', 113),\n",
       " ('these systems', 112),\n",
       " ('the manifold', 112),\n",
       " ('convolutional neural network', 112),\n",
       " ('probability distributions', 112),\n",
       " ('the risk', 112),\n",
       " ('a methodology', 112),\n",
       " ('the existing methods', 112),\n",
       " ('the proposed technique', 112),\n",
       " ('random forests', 112),\n",
       " ('the selection', 112),\n",
       " ('a new model', 111),\n",
       " ('a small set', 111),\n",
       " ('the outputs', 111),\n",
       " ('this area', 111),\n",
       " ('the definition', 111),\n",
       " ('the art techniques', 111),\n",
       " ('the background', 111),\n",
       " ('the loss', 111),\n",
       " ('face images', 111),\n",
       " ('support vector machines', 111),\n",
       " ('the content', 110),\n",
       " ('the contribution', 110),\n",
       " ('this idea', 110),\n",
       " ('classification tasks', 110),\n",
       " ('based method', 110),\n",
       " ('cross validation', 110),\n",
       " ('a study', 110),\n",
       " ('each class', 110),\n",
       " ('image processing', 110),\n",
       " ('based methods', 110),\n",
       " ('large scale', 110),\n",
       " ('the strength', 109),\n",
       " ('future research', 109),\n",
       " ('the words', 109),\n",
       " ('probabilistic models', 108),\n",
       " ('the meaning', 108),\n",
       " ('such problems', 108),\n",
       " ('the type', 107),\n",
       " ('each step', 107),\n",
       " ('this information', 107),\n",
       " ('the comparison', 107),\n",
       " ('existing algorithms', 107),\n",
       " ('fine tuning', 106),\n",
       " ('this representation', 106),\n",
       " ('this goal', 106),\n",
       " ('the predictions', 106),\n",
       " ('a tool', 106),\n",
       " ('good results', 106),\n",
       " ('the model parameters', 106),\n",
       " ('the computational cost', 106),\n",
       " ('this system', 106),\n",
       " ('the arts', 106),\n",
       " ('the game', 106),\n",
       " ('the matrix', 105),\n",
       " ('the neural network', 105),\n",
       " ('the extent', 105),\n",
       " ('the emergence', 105),\n",
       " ('the principle', 105),\n",
       " ('a robot', 105),\n",
       " ('random variables', 105),\n",
       " ('anomaly detection', 105),\n",
       " ('the face', 105),\n",
       " ('the past', 104),\n",
       " ('this assumption', 104),\n",
       " ('this field', 104),\n",
       " ('this thesis', 104),\n",
       " ('the methodology', 104),\n",
       " ('the database', 104),\n",
       " ('the feature space', 104),\n",
       " ('training samples', 103),\n",
       " ('much attention', 103),\n",
       " ('a factor', 103),\n",
       " ('simulation results', 103),\n",
       " ('the consistency', 103),\n",
       " ('the constraints', 103),\n",
       " ('the nodes', 103),\n",
       " ('the source', 102),\n",
       " ('a novel', 102),\n",
       " ('the representations', 102),\n",
       " ('the flexibility', 102),\n",
       " ('online learning', 102),\n",
       " ('the focus', 102),\n",
       " ('the creation', 102),\n",
       " ('mutual information', 102),\n",
       " ('the first step', 102),\n",
       " ('model parameters', 101),\n",
       " ('computational complexity', 101),\n",
       " ('a matrix', 101),\n",
       " ('topic models', 101),\n",
       " ('an important problem', 100),\n",
       " ('a time', 100),\n",
       " ('the dimensionality', 100),\n",
       " ('the real world', 100),\n",
       " ('active learning', 100),\n",
       " ('existing state', 100),\n",
       " ('high dimensions', 100),\n",
       " ('a review', 99),\n",
       " ('real world datasets', 99),\n",
       " ('this limitation', 99),\n",
       " ('real images', 99),\n",
       " ('the procedure', 99),\n",
       " ('a means', 98),\n",
       " ('this analysis', 98),\n",
       " ('a large set', 98),\n",
       " ('the target domain', 98),\n",
       " ('this question', 98),\n",
       " ('deep features', 98),\n",
       " ('kernel methods', 98),\n",
       " ('improved performance', 98),\n",
       " ('the validity', 98),\n",
       " ('decision trees', 98),\n",
       " ('the absence', 98),\n",
       " ('the techniques', 98),\n",
       " ('a step', 97),\n",
       " ('contextual information', 97),\n",
       " ('the key', 97),\n",
       " ('a significant improvement', 97),\n",
       " ('lower bounds', 97),\n",
       " ('a probabilistic model', 97),\n",
       " ('the interaction', 97),\n",
       " ('ground truth', 97),\n",
       " ('visual question', 96),\n",
       " ('the observations', 96),\n",
       " ('the k', 96),\n",
       " ('the population', 96),\n",
       " ('our proposed model', 95),\n",
       " ('the classification accuracy', 95),\n",
       " ('the discriminator', 95),\n",
       " ('other words', 95),\n",
       " ('two methods', 95),\n",
       " ('the previous state', 95),\n",
       " ('extensive experimental results', 95),\n",
       " ('the range', 95),\n",
       " ('time series data', 95),\n",
       " ('the article', 95),\n",
       " ('transfer learning', 94),\n",
       " ('the agents', 94),\n",
       " ('the samples', 94),\n",
       " ('different domains', 94),\n",
       " ('model selection', 94),\n",
       " ('our theory', 94),\n",
       " ('such data', 94),\n",
       " ('the speed', 94),\n",
       " ('the ground truth', 94),\n",
       " ('the correlation', 93),\n",
       " ('convex optimization', 93),\n",
       " ('this class', 93),\n",
       " ('hand crafted features', 93),\n",
       " ('recent studies', 92),\n",
       " ('the optimization problem', 92),\n",
       " ('a question', 92),\n",
       " ('the community', 92),\n",
       " ('the authors', 92),\n",
       " ('a deep network', 92),\n",
       " ('spectral clustering', 92),\n",
       " ('our solution', 92),\n",
       " ('the solutions', 92),\n",
       " ('a theory', 92),\n",
       " ('the rate', 92),\n",
       " ('the limitations', 91),\n",
       " ('the query', 91),\n",
       " ('computational efficiency', 91),\n",
       " ('a recurrent neural network', 91),\n",
       " ('the users', 91),\n",
       " ('various types', 91),\n",
       " ('the code', 91),\n",
       " ('simulated data', 91),\n",
       " ('mobile devices', 91),\n",
       " ('approximate inference', 91),\n",
       " ('the heart', 91),\n",
       " ('medical images', 91),\n",
       " ('the inference', 90),\n",
       " ('our dataset', 90),\n",
       " ('adversarial training', 90),\n",
       " ('its use', 90),\n",
       " ('the stability', 90),\n",
       " ('a sample', 90),\n",
       " ('the posterior distribution', 90),\n",
       " ('the decoder', 89),\n",
       " ('text classification', 89),\n",
       " ('the differences', 89),\n",
       " ('different scales', 89),\n",
       " ('the mapping', 89),\n",
       " ('the one', 89),\n",
       " ('an implementation', 89),\n",
       " ('a broad range', 89),\n",
       " ('the outcome', 89),\n",
       " ('a notion', 89),\n",
       " ('data mining', 89),\n",
       " ('the distributions', 88),\n",
       " ('the baseline', 88),\n",
       " ('a mechanism', 88),\n",
       " ('the proposed network', 88),\n",
       " ('the last decade', 88),\n",
       " ('machine learning techniques', 88),\n",
       " ('the extraction', 88),\n",
       " ('dictionary learning', 88),\n",
       " ('the internet', 88),\n",
       " ('deep learning techniques', 87),\n",
       " ('the answer', 87),\n",
       " ('back propagation', 87),\n",
       " ('deep convolutional networks', 87),\n",
       " ('the key idea', 87),\n",
       " ('a mapping', 87),\n",
       " ('the integration', 87),\n",
       " ('such systems', 87),\n",
       " ('the superior performance', 87),\n",
       " ('the fly', 87),\n",
       " ('the optimal solution', 87),\n",
       " ('many tasks', 86),\n",
       " ('the values', 86),\n",
       " ('the tree', 86),\n",
       " ('the best performance', 86),\n",
       " ('these limitations', 86),\n",
       " ('machine learning models', 86),\n",
       " ('training examples', 86),\n",
       " ('future work', 86),\n",
       " ('a basis', 86),\n",
       " ('the sample size', 86),\n",
       " ('image retrieval', 86),\n",
       " ('side information', 86),\n",
       " ('the regret', 86),\n",
       " ('multi task', 85),\n",
       " ('the clusters', 85),\n",
       " ('a dictionary', 85),\n",
       " ('deep models', 85),\n",
       " ('the approximation', 85),\n",
       " ('such methods', 85),\n",
       " ('the first stage', 85),\n",
       " ('the usage', 84),\n",
       " ('an instance', 84),\n",
       " ('the evidence', 84),\n",
       " ('the capacity', 84),\n",
       " ('an attempt', 84),\n",
       " ('our proposal', 84),\n",
       " ('the proposed architecture', 84),\n",
       " ('a probability distribution', 84),\n",
       " ('the region', 84),\n",
       " ('pascal voc', 84),\n",
       " ('logistic regression', 84),\n",
       " ('the experiment', 84),\n",
       " ('binary classification', 84),\n",
       " ('the kernel', 84),\n",
       " ('both cases', 83),\n",
       " ('each word', 83),\n",
       " ('the art accuracy', 83),\n",
       " ('a powerful tool', 83),\n",
       " ('convolutional layers', 83),\n",
       " ('a hierarchy', 83),\n",
       " ('the reliability', 83),\n",
       " ('deep generative models', 83),\n",
       " ('the subject', 83),\n",
       " ('the appearance', 83),\n",
       " ('the conditions', 83),\n",
       " ('the rest', 83),\n",
       " ('the scope', 83),\n",
       " ('a document', 82),\n",
       " ('this architecture', 82),\n",
       " ('a vector', 82),\n",
       " ('the curse', 82),\n",
       " ('previous studies', 82),\n",
       " ('several datasets', 82),\n",
       " ('the convergence rate', 82),\n",
       " ('the parameter', 82),\n",
       " ('our proposed algorithm', 82),\n",
       " ('theoretical guarantees', 82),\n",
       " ('two datasets', 81),\n",
       " ('deep learning algorithms', 81),\n",
       " ('sequential data', 81),\n",
       " ('the encoder', 81),\n",
       " ('a benchmark', 81),\n",
       " ('the hypothesis', 81),\n",
       " ('comparable performance', 81),\n",
       " ('the classes', 81),\n",
       " ('the perspective', 81),\n",
       " ('each frame', 81),\n",
       " ('domain knowledge', 81),\n",
       " ('the improvement', 81),\n",
       " ('visual tracking', 81),\n",
       " ('most cases', 81),\n",
       " ('the present paper', 81),\n",
       " ('a large dataset', 80),\n",
       " ('our architecture', 80),\n",
       " ('optimization problems', 80),\n",
       " ('these properties', 80),\n",
       " ('the generalization error', 80),\n",
       " ('the depth', 80),\n",
       " ('this data', 80),\n",
       " ('a linear combination', 80),\n",
       " ('the connection', 80),\n",
       " ('a fundamental problem', 79),\n",
       " ('the performances', 79),\n",
       " ('the rules', 79),\n",
       " ('sparse coding', 79),\n",
       " ('traditional methods', 79),\n",
       " ('super resolution', 79),\n",
       " ('a deep convolutional neural network', 78),\n",
       " ('the data distribution', 78),\n",
       " ('both tasks', 78),\n",
       " ('various applications', 78),\n",
       " ('efficient algorithms', 78),\n",
       " ('recent works', 78),\n",
       " ('the capabilities', 78),\n",
       " ('a part', 78),\n",
       " ('a proof', 78),\n",
       " ('a new class', 78),\n",
       " ('an important task', 78),\n",
       " ('the length', 78),\n",
       " ('a comparative study', 78),\n",
       " ('the limit', 78),\n",
       " ('the camera', 78),\n",
       " ('the relevance', 77),\n",
       " ('this observation', 77),\n",
       " ('the interactions', 77),\n",
       " ('previous state', 77),\n",
       " ('deep reinforcement learning', 77),\n",
       " ('convolutional neural networks cnns', 77),\n",
       " ('the concepts', 77),\n",
       " ('this strategy', 77),\n",
       " ('human action recognition', 77),\n",
       " ('a large class', 77),\n",
       " ('our implementation', 76),\n",
       " ('this survey', 76),\n",
       " ('temporal information', 76),\n",
       " ('the ones', 76),\n",
       " ('other approaches', 76),\n",
       " ('nearest neighbors', 76),\n",
       " ('a lack', 76),\n",
       " ('higher accuracy', 76),\n",
       " ('linear models', 75),\n",
       " ('several methods', 75),\n",
       " ('the best results', 75),\n",
       " ('different tasks', 75),\n",
       " ('a need', 75),\n",
       " ('this network', 75),\n",
       " ('deep neural network', 75),\n",
       " ('different modalities', 75),\n",
       " ('the edges', 75),\n",
       " ('class labels', 75),\n",
       " ('an optimization problem', 75),\n",
       " ('the hierarchy', 75),\n",
       " ('belief propagation', 75),\n",
       " ('the classifiers', 75),\n",
       " ('outlier detection', 75),\n",
       " ('a broad class', 75),\n",
       " ('the data points', 75),\n",
       " ('feature vectors', 74),\n",
       " ('a new state', 74),\n",
       " ('deep architectures', 74),\n",
       " ('conditional random fields', 74),\n",
       " ('the feature', 74),\n",
       " ('an open problem', 74),\n",
       " ('video sequences', 74),\n",
       " ('semantic information', 74),\n",
       " ('the input space', 74),\n",
       " ('a bayesian network', 74),\n",
       " ('missing data', 74),\n",
       " ('adversarial attacks', 74),\n",
       " ('social networks', 74),\n",
       " ('the interpretation', 74),\n",
       " ('the proposed scheme', 74),\n",
       " ('face detection', 74),\n",
       " ('a query', 73),\n",
       " ('traditional approaches', 73),\n",
       " ('an action', 73),\n",
       " ('theoretical analysis', 73),\n",
       " ('existing work', 73),\n",
       " ('the trade', 73),\n",
       " ('different classes', 73),\n",
       " ('empirical evidence', 73),\n",
       " ('the product', 73),\n",
       " ('genetic algorithm', 73),\n",
       " ('independent interest', 73),\n",
       " ('fully convolutional networks', 73),\n",
       " ('differential privacy', 73),\n",
       " ('matrix completion', 73),\n",
       " ('the latent space', 72),\n",
       " ('structured prediction', 72),\n",
       " ('an approximation', 72),\n",
       " ('the memory', 72),\n",
       " ('current methods', 72),\n",
       " ('pre training', 72),\n",
       " ('visual features', 72),\n",
       " ('the point', 72),\n",
       " ('the reconstruction', 72),\n",
       " ('this note', 72),\n",
       " ('great success', 72),\n",
       " ('the obtained results', 72),\n",
       " ('the posterior', 72),\n",
       " ('multiple views', 72),\n",
       " ('the strengths', 71),\n",
       " ('a process', 71),\n",
       " ('the state space', 71),\n",
       " ('the inputs', 71),\n",
       " ('the datasets', 71),\n",
       " ('human performance', 71),\n",
       " ('sufficient conditions', 71),\n",
       " ('video frames', 71),\n",
       " ('semi supervised learning', 71),\n",
       " ('mr images', 71),\n",
       " ('the action', 71),\n",
       " ('stochastic optimization', 71),\n",
       " ('our result', 71),\n",
       " ('parameter estimation', 71),\n",
       " ('logic programs', 71),\n",
       " ('large scale problems', 70),\n",
       " ('the components', 70),\n",
       " ('a feature', 70),\n",
       " ('the pixels', 70),\n",
       " ('observational data', 70),\n",
       " ('this property', 70),\n",
       " ('a text', 70),\n",
       " ('the proposed methodology', 70),\n",
       " ('principal component analysis', 70),\n",
       " ('synthetic and real data', 70),\n",
       " ('the coefficients', 70),\n",
       " ('salient object detection', 70),\n",
       " ('adversarial perturbations', 69),\n",
       " ('the present work', 69),\n",
       " ('real world', 69),\n",
       " ('an input', 69),\n",
       " ('a modification', 69),\n",
       " ('sparse representation', 69),\n",
       " ('the relations', 69),\n",
       " ('the scalability', 69),\n",
       " ('the probabilities', 69),\n",
       " ('human pose estimation', 69),\n",
       " ('linear regression', 69),\n",
       " ('the person', 69),\n",
       " ('the points', 69),\n",
       " ('facial expressions', 69),\n",
       " ('the lasso', 69),\n",
       " ('an architecture', 68),\n",
       " ('a major challenge', 68),\n",
       " ('visual recognition', 68),\n",
       " ('the interpretability', 68),\n",
       " ('increasing attention', 68),\n",
       " ('the attention', 68),\n",
       " ('the latent variables', 68),\n",
       " ('an empirical study', 68),\n",
       " ('an experiment', 68),\n",
       " ('multiple tasks', 68),\n",
       " ('the response', 68),\n",
       " ('distributed representations', 68),\n",
       " ('a region', 68),\n",
       " ('the rank', 68),\n",
       " ('the change', 68),\n",
       " ('new algorithms', 68),\n",
       " ('the resulting algorithm', 68),\n",
       " ('probabilistic inference', 68),\n",
       " ('the document', 67),\n",
       " ('the new method', 67),\n",
       " ('large numbers', 67),\n",
       " ('knowledge bases', 67),\n",
       " ('classification problems', 67),\n",
       " ('new state', 67),\n",
       " ('an unsupervised manner', 67),\n",
       " ('useful information', 67),\n",
       " ('the cost function', 67),\n",
       " ('the same class', 67),\n",
       " ('our formulation', 67),\n",
       " ('numerical results', 67),\n",
       " ('the second one', 67),\n",
       " ('each cluster', 67),\n",
       " ('least squares', 67),\n",
       " ('community detection', 67),\n",
       " ('fuzzy logic', 67),\n",
       " ('the past few years', 66),\n",
       " ('the policy', 66),\n",
       " ('the classification performance', 66),\n",
       " ('each task', 66),\n",
       " ('feature maps', 66),\n",
       " ('this procedure', 66),\n",
       " ('matrix factorization', 66),\n",
       " ('many problems', 66),\n",
       " ('their use', 66),\n",
       " ('two steps', 66),\n",
       " ('both methods', 66),\n",
       " ('two approaches', 66),\n",
       " ('the discovery', 66),\n",
       " ('existing techniques', 66),\n",
       " ('the worst case', 66),\n",
       " ('the source code', 66),\n",
       " ('belief networks', 66),\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_phrases_w_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_np_phrases = []\n",
    "for npp in np_phrases:\n",
    "    if len(npp.split(\" \")) in [2, 3]:\n",
    "        good_np_phrases.append(npp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13806"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_np_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(words_set, mode):\n",
    "    good = set()\n",
    "    bad = set()\n",
    "    very_bad = set()\n",
    "    \n",
    "    prefix = \"prdr_\"\n",
    "    if mode == 0:\n",
    "        prefix = \"prdr_\"\n",
    "    elif mode == 1:\n",
    "        prefix = \"ap_\"      \n",
    "    \n",
    "    f = open(prefix + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + \".txt\", 'w+')\n",
    "    if mode == 0:\n",
    "        f.write(\"PR Dual Rank Logs:\\n\")\n",
    "    elif mode == 1:\n",
    "        f.write(\"Auto Phrase Logs:\\n\")\n",
    "    \n",
    "    for i, word in enumerate(words_set):\n",
    "        try:\n",
    "            url_suffix = (word.replace(\" \", \"_\").replace(\"-\", \"_\")).capitalize()\n",
    "            url = \"https://en.wikipedia.org/wiki/\" + url_suffix\n",
    "            status = 0\n",
    "            try:\n",
    "                code = urllib.request.urlopen(url).getcode()\n",
    "                if code == 200:\n",
    "                    good.add(word)\n",
    "                    status = 1\n",
    "            except HTTPError:\n",
    "#                 bad.add(word)\n",
    "#             print(\"Ran \" + str(i + 1) + \"... Keyword: \" + word + \" URL: \" + url + \" Status: \" + str(status))\n",
    "                if status == 0 and word[-1] == 's' and len(word.split(\" \")) > 1:\n",
    "                    url = url[:-1]\n",
    "                    try:\n",
    "                        code = urllib.request.urlopen(url).getcode()\n",
    "                        if code == 200:\n",
    "                            good.add(word)\n",
    "                            status = 1\n",
    "                    except HTTPError:\n",
    "                        bad.add(word)\n",
    "            print(\"Ran \" + str(i + 1) + \"... Keyword: \" + word + \" URL: \" + url + \" Status: \" + str(status))\n",
    "            f.write(\"Ran \" + str(i + 1) + \"... Keyword: \" + word + \" URL: \" + url + \" Status: \" + str(status) + \"\\n\")\n",
    "        except:\n",
    "            very_bad.add(word)\n",
    "    \n",
    "    probably_good = set()\n",
    "    for word in words_set.difference(good):\n",
    "        query = word.replace(\"-\", \" \").lower()\n",
    "        query_tok = nlp(query)\n",
    "        values = []\n",
    "        for result in wikipedia.search(query):\n",
    "            result_tok = nlp(result.lower().replace(\"-\", \" \"))\n",
    "            d = result_tok.similarity(query_tok) * 100 \n",
    "            values.append(d)\n",
    "        if len(values) != 0:\n",
    "            print(\"Rechecking... \" + \"Keyword: \" + word + \" Max Similarity: \" + str(max(values)))\n",
    "            f.write(\"Rechecking... \" + \"Keyword: \" + word + \" Max Similarity: \" + str(max(values)) + \"\\n\")\n",
    "            if max(values) > 80.0:\n",
    "                probably_good.add(word)\n",
    "    \n",
    "    f.write(\"Good Set:\\n\" + str(good) + \"\\n\")\n",
    "    f.write(\"Probably Good Set:\\n\" + str(probably_good) + \"\\n\")\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return good, probably_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 1... Keyword: short text classification URL: https://en.wikipedia.org/wiki/Short_text_classification Status: 0\n",
      "Ran 2... Keyword: dialog act prediction URL: https://en.wikipedia.org/wiki/Dialog_act_prediction Status: 0\n",
      "Ran 3... Keyword: utterances URL: https://en.wikipedia.org/wiki/Utterances Status: 1\n",
      "Ran 4... Keyword: a subsequent one URL: https://en.wikipedia.org/wiki/A_subsequent_one Status: 0\n",
      "Ran 5... Keyword: the memory characteristic URL: https://en.wikipedia.org/wiki/The_memory_characteristic Status: 0\n",
      "Ran 6... Keyword: both cases URL: https://en.wikipedia.org/wiki/Both_case Status: 0\n",
      "Ran 7... Keyword: sequential or relational reasoning URL: https://en.wikipedia.org/wiki/Sequential_or_relational_reasoning Status: 0\n",
      "Ran 8... Keyword: recurrent layers URL: https://en.wikipedia.org/wiki/Recurrent_layer Status: 0\n",
      "Ran 9... Keyword: the preceding short texts URL: https://en.wikipedia.org/wiki/The_preceding_short_text Status: 0\n",
      "Ran 10... Keyword: several parts URL: https://en.wikipedia.org/wiki/Several_part Status: 0\n",
      "Ran 11... Keyword: state URL: https://en.wikipedia.org/wiki/State Status: 1\n",
      "Ran 12... Keyword: visual question URL: https://en.wikipedia.org/wiki/Visual_question Status: 0\n",
      "Ran 13... Keyword: visual and textual features URL: https://en.wikipedia.org/wiki/Visual_and_textual_feature Status: 0\n",
      "Ran 14... Keyword: the art ensemble model URL: https://en.wikipedia.org/wiki/The_art_ensemble_model Status: 0\n",
      "Ran 15... Keyword: recurrent and convolutional neural networks URL: https://en.wikipedia.org/wiki/Recurrent_and_convolutional_neural_network Status: 0\n",
      "Ran 16... Keyword: three different datasets URL: https://en.wikipedia.org/wiki/Three_different_dataset Status: 0\n",
      "Ran 17... Keyword: anns URL: https://en.wikipedia.org/wiki/Anns Status: 0\n",
      "Ran 18... Keyword: this work URL: https://en.wikipedia.org/wiki/This_work Status: 0\n",
      "Ran 19... Keyword: our model URL: https://en.wikipedia.org/wiki/Our_model Status: 0\n",
      "Ran 20... Keyword: vqa URL: https://en.wikipedia.org/wiki/Vqa Status: 0\n",
      "Ran 21... Keyword: the art results URL: https://en.wikipedia.org/wiki/The_art_result Status: 0\n",
      "Ran 22... Keyword: question URL: https://en.wikipedia.org/wiki/Question Status: 1\n",
      "Ran 23... Keyword: attention mechanisms URL: https://en.wikipedia.org/wiki/Attention_mechanism Status: 0\n",
      "Ran 24... Keyword: other state URL: https://en.wikipedia.org/wiki/Other_state Status: 0\n",
      "Ran 25... Keyword: many short texts URL: https://en.wikipedia.org/wiki/Many_short_text Status: 0\n",
      "Ran 26... Keyword: the model URL: https://en.wikipedia.org/wiki/The_model Status: 0\n",
      "Ran 27... Keyword: artificial neural networks URL: https://en.wikipedia.org/wiki/Artificial_neural_networks Status: 1\n",
      "Ran 28... Keyword: recurrent neural networks URL: https://en.wikipedia.org/wiki/Recurrent_neural_networks Status: 1\n",
      "Ran 29... Keyword: the vqa 1.0 dataset URL: https://en.wikipedia.org/wiki/The_vqa_1.0_dataset Status: 0\n",
      "Ran 30... Keyword: margin URL: https://en.wikipedia.org/wiki/Margin Status: 1\n",
      "Ran 31... Keyword: convolutional neural networks URL: https://en.wikipedia.org/wiki/Convolutional_neural_networks Status: 1\n",
      "Ran 32... Keyword: a dialog URL: https://en.wikipedia.org/wiki/A_dialog Status: 0\n",
      "Ran 33... Keyword: the current state URL: https://en.wikipedia.org/wiki/The_current_state Status: 0\n",
      "Ran 34... Keyword: the image URL: https://en.wikipedia.org/wiki/The_image Status: 0\n",
      "Ran 35... Keyword: our recurrent attention mechanism URL: https://en.wikipedia.org/wiki/Our_recurrent_attention_mechanism Status: 0\n",
      "Ran 36... Keyword: the art models URL: https://en.wikipedia.org/wiki/The_art_model Status: 0\n",
      "Ran 37... Keyword: results URL: https://en.wikipedia.org/wiki/Results Status: 1\n",
      "Ran 38... Keyword: a document URL: https://en.wikipedia.org/wiki/A_document Status: 0\n",
      "Ran 39... Keyword: our single model outperforms URL: https://en.wikipedia.org/wiki/Our_single_model_outperform Status: 0\n",
      "Ran 40... Keyword: increased accuracy URL: https://en.wikipedia.org/wiki/Increased_accuracy Status: 0\n",
      "Ran 41... Keyword: an architecture URL: https://en.wikipedia.org/wiki/An_architecture Status: 0\n",
      "Ran 42... Keyword: performance URL: https://en.wikipedia.org/wiki/Performance Status: 1\n",
      "Ran 43... Keyword: tasks URL: https://en.wikipedia.org/wiki/Tasks Status: 1\n",
      "Ran 44... Keyword: recent approaches URL: https://en.wikipedia.org/wiki/Recent_approache Status: 0\n",
      "Ran 45... Keyword: relations URL: https://en.wikipedia.org/wiki/Relations Status: 1\n",
      "Ran 46... Keyword: the first place winner URL: https://en.wikipedia.org/wiki/The_first_place_winner Status: 0\n",
      "Ran 47... Keyword: our implementation URL: https://en.wikipedia.org/wiki/Our_implementation Status: 0\n",
      "Ran 48... Keyword: a rich joint embedding URL: https://en.wikipedia.org/wiki/A_rich_joint_embedding Status: 0\n",
      "Ran 49... Keyword: visual and textual attention URL: https://en.wikipedia.org/wiki/Visual_and_textual_attention Status: 0\n",
      "Ran 50... Keyword: most existing ann based systems URL: https://en.wikipedia.org/wiki/Most_existing_ann_based_system Status: 0\n",
      "Ran 51... Keyword: a model URL: https://en.wikipedia.org/wiki/A_model Status: 0\n",
      "Ran 52... Keyword: sequences URL: https://en.wikipedia.org/wiki/Sequences Status: 1\n",
      "Ran 53... Keyword: the proposed recurrent attention units URL: https://en.wikipedia.org/wiki/The_proposed_recurrent_attention_unit Status: 0\n",
      "Ran 54... Keyword: dual recurrent attention units URL: https://en.wikipedia.org/wiki/Dual_recurrent_attention_unit Status: 0\n",
      "Ran 55... Keyword: e.g. sentences URL: https://en.wikipedia.org/wiki/E.g._sentence Status: 0\n",
      "Ran 56... Keyword: we URL: https://en.wikipedia.org/wiki/We Status: 1\n",
      "Ran 57... Keyword: show URL: https://en.wikipedia.org/wiki/Show Status: 1\n",
      "Ran 58... Keyword: sequential short text classification URL: https://en.wikipedia.org/wiki/Sequential_short_text_classification Status: 0\n",
      "Ran 59... Keyword: the vqa dataset URL: https://en.wikipedia.org/wiki/The_vqa_dataset Status: 0\n",
      "Rechecking... Keyword: short text classification Max Similarity: 67.63988329850508\n",
      "Rechecking... Keyword: dialog act prediction Max Similarity: 53.649728504849826\n",
      "Rechecking... Keyword: a subsequent one Max Similarity: 85.05114058235664\n",
      "Rechecking... Keyword: the memory characteristic Max Similarity: 78.14820155489384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: both cases Max Similarity: 70.77190214261844\n",
      "Rechecking... Keyword: sequential or relational reasoning Max Similarity: 66.99154796573562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: recurrent layers Max Similarity: 75.25120583258973\n",
      "Rechecking... Keyword: the vqa dataset Max Similarity: 58.17074930042823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: the preceding short texts Max Similarity: 76.15267374284905\n",
      "Rechecking... Keyword: several parts Max Similarity: 72.70842216901737\n",
      "Rechecking... Keyword: visual question Max Similarity: 81.1343819583379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: visual and textual features Max Similarity: 68.79217819744602\n",
      "Rechecking... Keyword: the art ensemble model Max Similarity: 69.96634540922038\n",
      "Rechecking... Keyword: recurrent and convolutional neural networks Max Similarity: 91.04069916342951\n",
      "Rechecking... Keyword: three different datasets Max Similarity: 79.95617826005859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: anns Max Similarity: 99.9999946345186\n",
      "Rechecking... Keyword: this work Max Similarity: 92.05076584483292\n",
      "Rechecking... Keyword: our model Max Similarity: 72.11339483724379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: vqa Max Similarity: 100.0\n",
      "Rechecking... Keyword: attention mechanisms Max Similarity: 74.7096191847275\n",
      "Rechecking... Keyword: other state Max Similarity: 76.90893358393089\n",
      "Rechecking... Keyword: many short texts Max Similarity: 71.80237450895696\n",
      "Rechecking... Keyword: the model Max Similarity: 88.8227505614238\n",
      "Rechecking... Keyword: the vqa 1.0 dataset Max Similarity: 61.490323902651866\n",
      "Rechecking... Keyword: a dialog Max Similarity: 88.04968929188814\n",
      "Rechecking... Keyword: the current state Max Similarity: 89.0773541667505\n",
      "Rechecking... Keyword: the image Max Similarity: 100.0\n",
      "Rechecking... Keyword: our recurrent attention mechanism Max Similarity: 71.07254040864713\n",
      "Rechecking... Keyword: the art models Max Similarity: 88.66569808894764\n",
      "Rechecking... Keyword: a document Max Similarity: 85.6001907158494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: our single model outperforms Max Similarity: 65.6082051108381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diproray/miniconda3/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking... Keyword: increased accuracy Max Similarity: 80.71003428749522\n",
      "Rechecking... Keyword: an architecture Max Similarity: 90.92635369238926\n",
      "Rechecking... Keyword: recent approaches Max Similarity: 57.87216147240627\n",
      "Rechecking... Keyword: the first place winner Max Similarity: 91.66368955390558\n",
      "Rechecking... Keyword: our implementation Max Similarity: 79.88313192181164\n",
      "Rechecking... Keyword: a rich joint embedding Max Similarity: 47.16808753618129\n",
      "Rechecking... Keyword: visual and textual attention Max Similarity: 76.28319777189215\n",
      "Rechecking... Keyword: most existing ann based systems Max Similarity: 76.84651770326725\n",
      "Rechecking... Keyword: a model Max Similarity: 99.99999990995853\n",
      "Rechecking... Keyword: the proposed recurrent attention units Max Similarity: 67.49328037110158\n",
      "Rechecking... Keyword: dual recurrent attention units Max Similarity: 57.83173867614494\n",
      "Rechecking... Keyword: e.g. sentences Max Similarity: 86.4238133020316\n",
      "Rechecking... Keyword: sequential short text classification Max Similarity: 70.33879563420919\n",
      "Rechecking... Keyword: the art results Max Similarity: 84.7494198649971\n"
     ]
    }
   ],
   "source": [
    "good, prob_good = get_sets(np_phrases, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a dialog',\n",
       " 'a document',\n",
       " 'a model',\n",
       " 'a subsequent one',\n",
       " 'an architecture',\n",
       " 'anns',\n",
       " 'e.g. sentences',\n",
       " 'increased accuracy',\n",
       " 'recurrent and convolutional neural networks',\n",
       " 'the art models',\n",
       " 'the art results',\n",
       " 'the current state',\n",
       " 'the first place winner',\n",
       " 'the image',\n",
       " 'the model',\n",
       " 'this work',\n",
       " 'visual question',\n",
       " 'vqa'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
